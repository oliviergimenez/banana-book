# Dealing with covariates {#covariateschapter}

## Introduction

Capture–recapture models often aim not just to estimate demographic parameters, but also to understand what drives their variation as we have seen in Chapter \@ref(survival). In this chapter, we explore how to incorporate covariates -- whether measured at the individual or temporal scale. We cover selecting covariates from a potentially large set, using an extension of standard MCMC algorithms known as reversible jump MCMC (RJMCMC), and handling uncertainty in key covariates, namely age or sex, when these are not perfectly known for all individuals.

## Covariate selection with Reversible Jump MCMC

### Motivation

In Section \@ref(waic), we used WAIC to figure our which model, among several candidates, was best supported by the data. Each model there represented a different ecological hypothesis. Now when you are in a situation where you have several individual or temporal covariates that might explain variation in some demographic parameters, say survival as in Section \@ref(covariates), things can quickly become a bit more tedious. 

Let's look at a real-world example: The white stork (*Ciconia ciconia*) population in Baden-Württemberg, Germany. From the 1960s to the 1990s, all Western European stork populations were in decline. One leading hypothesis was that these declines were driven by reduced food availability, itself caused by severe droughts in the storks' wintering grounds in the Sahel region (e.g. @kanya90, @grosbois_assessing_2008).

To explore this idea, we'll use rainfall measurements from 10 meteorological stations chosen to represent the storks' wintering area: Diourbel, Gao, Kayes, Kita, Maradi, Mopti, Ouahigouya, Ségou, Tahoua, and Tombouctou. The data we have are the cumulative rainfall amounts (in mm) over June, July, August, and September -- roughly the rainy season in the Sahel.

```{r echo = FALSE}
# dakar	diourbel (2)	gao (3)	kandi	kayes (5)	kita (6)	koutiala	maradi (8)	mopti (9)	natitingou	ouahigouya (11)	sikasso	ségou (13)	tahoua (14)	tombouctou (15) 
rainfall_raw <- as.matrix(read.table(here::here("dat", "pluies.txt")))
# select Diourbel, Gao, Kayes, Kita, Maradi, Mopti, Ouahigouya, Ségou, Tahoua, and Tombouctou
filter <- c(2,3,5,6,8,9,11,13,14,15)
rainfall_raw <- rainfall_raw[,filter]
mean_rainfall <- apply(rainfall_raw, 2, mean)
sd_rainfall <- apply(rainfall_raw, 2, sd)
rainfall <- (rainfall_raw - matrix(rep(mean_rainfall, 16), ncol = 10, byrow = T)) / matrix(rep(sd_rainfall, 16), ncol = 10, byrow = T)
colnames(rainfall_raw) <- c("Diourbel", "Gao", "Kayes", "Kita", "Maradi", "Mopti", "Ouahigouya", "Ségou", "Tahoua", "Tombouctou")
head(rainfall_raw)
```

Our question is: Which combination of these stations best explains variation in survival? If we tried to answer this by testing every possible model, we would have to consider every subset of the 10 stations and compare 1024 models (2^10 combinations). That's far too many for a WAIC-based approach to be practical.

Instead of comparing all possible models one by one, we can use Reversible Jump MCMC (RJMCMC). RJMCMC is an extension of standard Bayesian inference that treats the model itself as an extra (discrete) parameter. In this framework, the posterior distribution spans both the parameter space (e.g. regression coefficients) and the model space (e.g. which covariates are included).

To work out the (marginal) posterior probability of each model, we integrate over the parameters using MCMC. Standard MCMC algorithms cannot handle this model-switching scenario, but RJMCMC is designed precisely for it and can explore parameters and models together within a single Markov chain. In other words, RJMCMC can 'jump' between models, turning covariates on or off. RJMCMC is like a hiker exploring different trails (models), stopping along each one to take measurements (parameters) before deciding whether to switch to another. From this, we can estimate the posterior probability that each covariate influences survival, as well as model-averaged regression coefficients and survival estimates that account for both parameter and model uncertainty. 

We won't dive into the mathematical details here but don't worry, you can still follow the analysis without them. Check out Chapter 7 of @king_bayesian_2009 (see also @gimenez2009winbugs) if you're interested in. 

### Model and NIMBLE implementation

For our example, we'll work with data from 321 encounter histories of white storks ringed as chicks between 1956 and 1970. We'll fit a Cormack–Jolly–Seber (CJS) model with time-dependent survival and constant detection probability, as described in Section \@ref(cjsderivatives). We model the survival probability `phi` as a linear function of our covariates stored in `x`. To handle model selection inside the RJMCMC, we use a clever trick: for each covariate, we introduce an indicator variable `ksi` that can take the value 1 (covariate is included in the model) or 0 (covariate is excluded). We then combine the regression coefficients `beta` with these indicators into a single vector `betaksi`. This means that if `ksi[j] = 0`, the effect of covariate `j` is zero, effectively removing it from the model. Here's how it works in the NIMBLE code:
```{r eval = FALSE}
for (t in 1:(T-1)){
  logit(phi[t]) <- intercept + inprod(betaksi[1:10], x[t, 1:10])
  gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)
  gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)
  gamma[2,1,t] <- 0           # Pr(dead t -> alive t+1)
  gamma[2,2,t] <- 1           # Pr(dead t -> dead t+1)
}
```

For the indicators and regression coefficients:
```{r eval = FALSE}
for (j in 1:10){
  betaksi[j] <- beta[j] * ksi[j]
  ksi[j] ~ dbern(psi) ## indicator variable associated with betaj
}
psi ~ dbeta(1, 1) ## hyperprior on inclusion probability
for (j in 1:10){
  beta[j] ~ dnorm(0, sd = 1.5) # prior slopes
}
intercept ~ dnorm(0, sd = 1.5) # prior intercept
```

The prior on `psi` controls the overall tendency to include covariates in the model. Setting it to `dbeta(1, 1)` makes all inclusion probabilities equally likely, so the data drive the selection. The priors on `beta` and the `intercept` (not consider in the selection) are weakly informative.

As we saw in Section \@ref(change-sampler), NIMBLE allows you to change the default sampler. Here, we're going to do something slightly different and use NIMBLE's `configureRJ()` function to set up RJMCMC for variable selection. The function `configureRJ()` modifies an existing MCMC configuration so that RJMCMC is used to sample certain parameters, allowing covariates to be turned on or off during the run. It uses a univariate normal proposal distribution, and you can adjust the proposal mean and scale. The main arguments are:  
- `targetNodes`: The parameters you want to apply variable selection to (e.g. `beta`);  
- `indicatorNodes`: The indicator variables paired with the target nodes (e.g. `ksi`);  
- `control`: A list for fine-tuning the proposal with `mean` the mean of the proposal distribution (default is 0), `scale` the standard deviation of the proposal (default is 1) and `fixedValue` the value a variable takes when excluded (default is 0). 

Here's how we apply it to our white stork example:
```{r eval = FALSE}
## Build the model and configure default MCMC
RJsurvival <- nimbleModel(code = hmm.phirjmcmcp, 
                          constants = my.constants,
                          data = my.data,
                          inits = initial.values())

Csurvival <- compileNimble(RJsurvival)

RJsurvivalConf <- configureMCMC(RJsurvival)
RJsurvivalConf$addMonitors('ksi')

# Switch to reversible jump sampling for the betas
configureRJ(conf = RJsurvivalConf,
            targetNodes = 'beta',
            indicatorNodes = 'ksi',
            control = list(mean = 0, scale = 2))
```

We then build, compile, and run the RJMCMC:
```{r eval = FALSE}
survivalMCMC <- buildMCMC(RJsurvivalConf)
CsurvivalMCMC <- compileNimble(survivalMCMC, project = RJsurvival)
samples <- runMCMC(mcmc = CsurvivalMCMC, 
                   niter = n.iter,
                   nburnin = n.burnin,
                   nchains = n.chains)
```

When we run this MCMC, `configureRJ()` takes care of proposing moves that either keep a covariate in the model or drop it out by setting its `ksi` value to 0. If a covariate is included (`ksi = 1`), the sampler updates its regression coefficient `beta` using the specified normal proposal distribution. If it's excluded (`ksi = 0`), the coefficient is fixed at zero (our `fixedValue`). Over many iterations, the chain 'jumps' between different combinations of covariates, building up posterior probabilities for each one's inclusion. This means we can later summarise which covariates are most likely to affect survival (via their inclusion probabilities), and model-averaged estimates of survival that incorporate the uncertainty about which covariates belong in the model. This is what we do in `R` in the next section. 

### Results and interpretation

```{r echo = FALSE}
load(here::here("dat","rjmcmc.RData"))
#MCMCsummary(out, round = 2)
```

The RJMCMC run gives us the posterior probabilities of different models where each model corresponds to a specific combination of covariates. In our white stork example, the results clearly show that the model including only the rainfall at the Kita station (covariate #4) is best supported by the data. 

To get these results, we first combine the MCMC samples from our two chains:
```{r eval = FALSE}
# Gather two chains
out <- rbind(samples[[1]], samples[[2]])
```

Next, we look at the inclusion indicators `ksi`, which take value 1 if a covariate is in the model and 0 if not. The posterior mean of each `ksi[j]` is simply the estimated probability that covariate j is included:
```{r}
# Number of covariates
K <- 10

# Extract only ksi columns, in order ksi[1], ..., ksi[10]
ksi <- out[, paste0("ksi[", 1:K, "]")]

# Posterior inclusion probabilities for each covariate
inclusion_prob <- colMeans(ksi)
inclusion_prob
```

The posterior inclusion probabilities tell us how likely each covariate is to appear in the 'true' model given the data and priors. Here, `ksi[4]` -- the Kita station -- stands out, with an inclusion probability around 0.96.

We can also identify the most probable models visited by the RJMCMC. Each MCMC draw corresponds to a model, which we encode as a binary string (e.g., "0101001001"):
```{r}
# Encode each model draw as a string of 0s and 1s
model_id <- apply(ksi, 1, paste0, collapse = "")

# Empirical posterior model probabilities
post_model_prob <- sort(prop.table(table(model_id)), decreasing = TRUE)

# Show the top models
head(data.frame(model = names(post_model_prob), 
                prob = as.numeric(post_model_prob)), 10)
```

The posterior model probabilities rank the different combinations of covariates, and in our case, the model containing only the rainfall at Kita is clearly dominant.

In conclusion, a very high inclusion probability for Kita (covariate #4) and a dominant model containing only Kita indicate that this station's rainfall is strongly linked to survival, while others are not.

Now turning to inference, we'd like to get model-averaged parameters. Each covariate's effect is 'on' only when its indicator (`ksi`) is 1. Multiplying `beta` by `ksi` zeros out the effect when that covariate is excluded. Summarising `betaksi` across draws gives the model-averaged effect on the logit scale:
```{r}
# Pull posterior draws
beta  <- out[, paste0("beta[", 1:K, "]")]

# Model-averaged coefficients on the logit scale
betaksi <- beta * ksi

# Summaries: mean, 95% credible intervals, and Pr(effect > 0)
df_betaksi <- data.frame(
  mean  = apply(betaksi, 2, mean),
  low  = apply(betaksi, 2, quantile, probs = 2.5/100),
  high  = apply(betaksi, 2, quantile, probs = 97.5/100),
  P_gt0 = apply(betaksi > 0, 2, mean))

round(df_betaksi, 3)
```

A large `P_gt0` (e.g., > 0.95) suggests strong evidence that the covariate increases survival (on the logit scale), while values near 0.5 mean the direction is uncertain.

Now let's get model-averaged survival estimates over time. For each MCMC draw, we build the linear predictor with all covariates using `beta * ksi`, add the intercept, then inverse-logit to get survival `phi`: 
```{r}
invlogit <- function(x) 1 / (1 + exp(-x))

# Table of covariate values
X <- rainfall[1:(16 - 1), 1:K]

# Intercept MCMC draws
intercept <- out[, "intercept"]

# Linear predictor for every time t (rows) and every MCMC draw (columns)
eta <- X %*% t(betaksi) 
eta <- sweep(eta, 2, intercept, "+")  # add intercept per draw

# Back-transform to survival probabilities
phi_draws <- invlogit(eta)

# Summaries by time
df_phi <- data.frame(
  mean  = apply(phi_draws, 1, mean),
  low  = apply(phi_draws, 1, quantile, probs = 2.5/100),
  high  = apply(phi_draws, 1, quantile, probs = 97.5/100))

ggplot(df_phi, aes(x = 1956:1970, y = mean)) +
  geom_ribbon(aes(ymin = low, ymax = high), alpha = 0.2) +
  geom_line(size = 0.9) +
  geom_point() +
  labs(
    x = "Years (interval start)",
    y = "Survival probability",
    title = "Model-averaged survival with 95% credible intervals"
  )
```

Shaded ribbons show 95% credible intervals; the solid line is the posterior mean of survival, model-averaged over covariate inclusion.

## Uncertainty in age {#ageuncertainty}

### Motivation 

Survival and other demographic parameters often differ between young and older animals, so if we blur age classes we can end up telling the wrong story about population dynamics. In Section \@ref(agecov), we incorporated age as a covariate in capture-recapture models, assuming it was perfectly known. With non-invasive genetics (Figure \@ref(fig:marking)), though, age is not observed: a DNA profile can identify who was there, but not how old they were. If we ignore that uncertainty, survival estimates can be biased. As we saw in Section \@ref(multievent), HMM capture–recapture models can handle this kind of problem by treating age as a hidden state and separating it from what we actually observe in the field. 

A neat example comes from Apennine brown bears in @Gervasi2017 (see also @gowan2021uncertainty). Because you cannot age a bear from its DNA, the authors paired genetics with field information to classify detections into two broad age classes, cubs (<1 year) and adults (≥1 year). To do so, they used two criteria. First, classify a newly detected bear as a cub in that year if it was sampled at least once on the same date and site as a known adult female and they shared ≥1 allele at every locus (mother–offspring consistent). That's the lenient criterion (P1). Second, apply a stricter criterion (P2): make the same mother–offspring call, but require two or more such co-sampling occasions with the same female, again on the same date and site each time. 

Why two criteria? Because there's a trade-off. P1 is better at catching real cubs (more sensitive) but risks misclassifying some adults as cubs; P2 is more conservative about calling 'cub', so it reduces false cubs but misses some true ones. 

Instead of pretending these criteria are perfect, the authors model the misclassification explicitly: age is hidden, 'cub/adult by P1/P2' is what we observe, and their model estimates both classification accuracy and age-specific survival at the same time. That way, uncertainty is propagated into the demographic estimates rather than swept under the rug.

Here, I show how to encode that logic in an HMM with NIMBLE: define the hidden age states, write the transition (survival) and detection components, and add a classification step that links hidden age to the observed P1/P2 outcomes. We'll also see how a small subset of known-age individuals (e.g., live-trapped or aged beforehand) anchors the classification step. The payoff is a set of age-specific survival estimates that are robust to imperfect age assignment, which is exactly what we need for sound ecological inference and management.

### Model and NIMBLE implementation

To estimate bear survival, we have at our disposal a 12-year time series of non-invasive genetic sampling data, collected between 2003 and 2014. To build up our model, we first define the states and observations:

- states 
    - alive as cub (C)
    - alive as adult (A)
    - dead (D)

- observations  
    - not detected (1)
    - detected and classified as cub by both criteria (2)
    - detected and classified as cub by P1 only (3)
    - detected and classified as adult by both criteria (4)

Now we turn to writing our model. 

We start with the vector of initial states. Unknown-age individuals enter as a mixture of cub/adult with probabilities $\pi$ and $1-\pi$: 

$$\begin{matrix}
& \\
\mathbf{\delta} =
  \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
          \end{matrix}
          \hspace{-1.2em}
          \begin{matrix}
          z_t=C & z_t=A & z_t=D \\ \hdashline
          \pi & 1 - \pi & 0\\
          \end{matrix}
          \hspace{-0.2em}
          \begin{matrix}
          & \\
          \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
\begin{matrix}
\end{matrix}
\end{matrix}$$

where $\pi$ is the probability of being alive as a cub, and $1 - \pi$ is the probability of being alive as an adult. For bears known-age at first detection, we fix the initial state accordingly. In NIMBLE we implement this with an individual-specific $\delta_i$ using `equals()` to pin known ages:
```{r eval = FALSE}
# Initial state
# age[i] == 0 → unknown → use probabilistic delta: pi, 1 - pi
# age[i] == 1 → known cub → force delta to [1, 0, 0]
# age[i] == 2 → known adult → force delta to [0, 1, 0]
for (i in 1:N){
  delta[1, i] <- equals(age[i], 0) * pi + equals(age[i], 1)  # Pr(C)
  delta[2, i] <- equals(age[i], 0) * (1 - pi) + equals(age[i], 2)  # Pr(A)
  delta[3, i] <- 0
}
```

We proceed with the transition matrix that contains the survival probabilities. A cub either survives and becomes adult next year ($\phi_C$), or dies; adults either survive in the same class ($\phi_A$) or die: 
$$\begin{matrix}
& \\
\mathbf{\Gamma} =
  \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
          \end{matrix}
          \hspace{-1.2em}
          \begin{matrix}
          z_t=C & z_t=A & z_t=D \\ \hdashline
          0  & \phi_C & 1 - \phi_C\\
          0 & \phi_A & 1 - \phi_A\\
          0 & 0 & 1
          \end{matrix}
          \hspace{-0.2em}
          \begin{matrix}
          & \\
          \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
\begin{matrix}
z_{t-1}=C \\ z_{t-1}=A \\ z_{t-1}=D
\end{matrix}
\end{matrix}$$
  
Following the paper, adult survival is sex-specific; cub survival is common to both sexes:
```{r eval = FALSE}
# Transition matrix
for (i in 1:N){
  gamma[1,1,i] <- 0
  gamma[1,2,i] <- phiC
  gamma[1,3,i] <- 1 - phiC
  gamma[2,1,i] <- 0
  gamma[2,2,i] <- phiA[sex[i]]   # sex-specific adult survival (1=f, 2=m)
  gamma[2,3,i] <- 1 - phiA[sex[i]]
  gamma[3,1,i] <- 0
  gamma[3,2,i] <- 0
  gamma[3,3,i] <- 1
}
```

Last step is about the observations, which arise in two steps: detection then classification. For the detection matrix, we need to introduce intermediate observations, say $y'$ for not detected (1), detected as cub (2) and detected as adult (2): 
$$\begin{matrix}
& \\
\mathbf{\Gamma_1} =
  \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
          \end{matrix}
          \hspace{-1.2em}
          \begin{matrix}
          y'_t=1 & y'_t=2 & y'_t=3 \\ \hdashline
          1-p_C  & p_C & 0\\
          1-p_A & 0 & 1 - p_A\\
          1 & 0 & 0
          \end{matrix}
          \hspace{-0.2em}
          \begin{matrix}
          & \\
          \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
\begin{matrix}
z_{t}=C \\ z_{t}=A \\ z_{t}=D
\end{matrix}
\end{matrix}$$

where $p_C$ is detection for cubs, and $p_A$ that for adults. Then the classification matrix is: 
$$\begin{matrix}
& \\
\mathbf{\Omega_2} =
    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
\end{matrix}
\hspace{-1.2em}
\begin{matrix}
    y_t=1 & y_t=2 & y_t=3 & y_t=4\\ \hdashline
1 & 0 & 0 & 0\\
0 & \beta_{C,CC} & \beta_{C,CA} & 1 - \beta_{C,CC} - \beta_{C,CA}\\
0 & \beta_{A,CC} & \beta_{A,CA} & 1 - \beta_{A,CC} - \beta_{A,CA}\\
\end{matrix}
\hspace{-0.2em}
\begin{matrix}
& \\
\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right )
    \begin{matrix}
    y'_{t}=1 \\ y'_{t}=2 \\ y'_{t}=3
    \end{matrix}
\end{matrix}$$

where $\beta_{C,CC}$ is the probability that, being a cub, and individual is classified with both criteria, $\beta_{C,CA}$ is the probability that, being a cub, an individual is classified as cub with P1 and as adult with P2, $\beta_{A,CC}$ is the probability that, being an adult, an individual is classified as cub with both criteria, $\beta_{A,CA}$ is the probability that, being an adult, an individual is classified as cub with P1 and as adult with P2.

The observation matrix is the product of the two detection and classification matrices $\mathbf{\Omega_1} \mathbf{\Omega_2}$: 
$$\begin{matrix}
& \\
\mathbf{\Omega} =
    \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right .
\end{matrix}
\hspace{-1.2em}
\begin{matrix}
    y_t=1 & y_t=2 & y_t=3 & y_t=4\\ \hdashline
1-p_C & p_C \beta_{C,CC} & p_C \beta_{C,CA} & p_C (1 - \beta_{C,CC} - \beta_{C,CA})\\
1-p_A & p_A \beta_{A,CC} & p_A \beta_{A,CA} & p_A (1 - \beta_{A,CC} - \beta_{A,CA})\\
1 & 0 & 0 & 0\\
\end{matrix}
\hspace{-0.2em}
\begin{matrix}
& \\
\left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12\end{matrix} } \right )
    \begin{matrix}
    z_{t}=1 \\ z_{t}=2 \\ z_{t}=3
    \end{matrix}
\end{matrix}$$

In code, we write $\mathbf{\Omega_1} \mathbf{\Omega_2}$ directly (faster than doing the matrix multiplication at each iteration). For simplicity we use a single detection probability $p$ for both ages, but you can let $p$ vary by age/sex/year or sampling method, as in the paper:
```{r eval = FALSE}
# Observation matrix
omega[1,1] <- 1 - p
omega[1,2] <- p * betaCCC
omega[1,3] <- p * betaCCA
omega[1,4] <- p * (1 - betaCCC - betaCCA)

omega[2,1] <- 1 - p
omega[2,2] <- p * betaACC
omega[2,3] <- p * betaACA
omega[2,4] <- p * (1 - betaACC - betaACA)

omega[3,1] <- 1
omega[3,2] <- 0
omega[3,3] <- 0
omega[3,4] <- 0
```

At first detection, the event 'not detected' is impossible by construction (we condition on the first detection). We therefore use an initial observation matrix $\mathbf{\Omega}_{\text{init}}$ with $p$ set to 1 (not shown). 

The likelihood and priors are handled as usual. 

### Results and interpretation

Here are the raw results: 
```{r echo = FALSE}
library(MCMCvis)
load(here::here("dat","age.RData"))
MCMCsummary(out, round = 2)
```

which we can arrange in a table to compare them with the results obtained by @Gervasi2017:
```{r results='asis', message=FALSE, echo=FALSE}
library(MCMCvis)
library(knitr)

# Request 'phiA' unindexed; MCMCsummary will return phiA[1], phiA[2]
params_request <- c("phiC","phiA","p","pi",
                    "betaCCC","betaCCA","betaACC","betaACA")

ours <- MCMCsummary(out, params = params_request)
rn <- rownames(ours)

# Find and order phiA elements safely
phiA_rows <- rn[startsWith(rn, "phiA[")]
phiA_idx  <- as.integer(sub("phiA\\[|\\]", "", phiA_rows))
phiA_rows <- phiA_rows[order(phiA_idx)]

# Final row order used everywhere below
rows <- c("phiC", phiA_rows, "p", "pi", "betaCCC", "betaCCA", "betaACC", "betaACA")

# Formatter: mean (L–U)
fmt <- function(m, l, u) sprintf("%.2f (%.2f–%.2f)", m, l, u)
ours_fmt <- setNames(
  mapply(fmt, ours[rows, "mean"], ours[rows, "2.5%"], ours[rows, "97.5%"]),
  rows
)

# Paper values (Gervasi et al. 2017, Table 3; detection is overall average from text)
paper_fmt <- c(
  "phiC"       = "0.51 (0.22–0.79)",
  "phiA[1]"    = "0.92 (0.87–0.95)",   # adult female
  "phiA[2]"    = "0.85 (0.76–0.91)",   # adult male
  "p"          = "≈0.71 (0.62–0.79)",  # overall average across designs/years
  "pi"         = "0.062 (0.007–0.396)",
  "betaCCC"    = "0.40 (0.15–0.72)",   # C_{c,cc}
  "betaCCA"    = "0.60 (0.28–0.85)",   # C_{c,ca}
  "betaACC"    = "0.067 (0.024–0.174)",# C_{a,cc}
  "betaACA"    = "0.191 (0.110–0.309)" # C_{a,ca}
)

# Pretty labels with math; no special symbols to keep MathJax happy
labels <- c(
  "phiC"       = "$\\phi_C$ (cub survival)",
  "phiA[1]"    = "$\\phi_{A,f}$ (adult female)",
  "phiA[2]"    = "$\\phi_{A,m}$ (adult male)",
  "p"          = "$p$ (detection)",
  "pi"         = "$\\pi$ (cub at first detection)",
  "betaCCC"    = "$C_{c,cc}$ (cub by both)",
  "betaCCA"    = "$C_{c,ca}$ (cub by P1 only)",
  "betaACC"    = "$C_{a,cc}$ (adult→cub by both)",
  "betaACA"    = "$C_{a,ca}$ (adult→cub by P1 only)"
)

tab <- data.frame(
  Quantity = unname(labels[rows]),
  `Our (NIMBLE)` = unname(ours_fmt[rows]),
  `Gervasi et al. (2017)` = unname(paper_fmt[rows]),
  check.names = FALSE
)

kable(
  tab,
  align = c("l","c","c"),
  escape = FALSE,
  caption = "Comparison of parameter estimates for the same HMM to account for age uncertainty: our NIMBLE fit vs. Gervasi et al. (2017, Table 3). Intervals are 95% credible intervals for NIMBLE and confidence intervals for Gervasi et al.. Detection in Gervasi et al. varies by design/year; we report their overall average."
)
```

Our NIMBLE fit reproduces the main biological signals reported for the Apennine brown bear. Survival shows the expected ordering, that cubs << adults, and adult females > adult males -- with estimates that closely match the published analysis. The credible/confidence intervals overlap broadly, indicating good agreement.

Our detection estimate aligns with the study's average detection, even though their analysis lets detection vary by design and year rather than assuming a single constant value.

For age classification (linking the hidden age to P1/P2 outcomes), mapping our parameters to theirs, we found lower adult-as-cub misclassification than the paper (and thus a higher probability that detected adults are correctly called 'adult by both'), which still matches their qualitative take: the stricter criterion (P2) performs very well for adults.

The main divergence is in the initial state mix. Intervals overlap, but the means differ. A likely explanation is model structure: we used a single, constant detection probability, while the published analysis allows detection to vary by sampling design and year -- and detectability does vary meaningfully across methods and years. Collapsing this heterogeneity into one $p$ can nudge the mixture at first detection toward a higher cub fraction to explain patterns that the richer detection model attributes to design/year effects.

In conclusion, we managed to recover the core findings of the published study (age- and sex-specific survival and average detection). Small discrepancies appear mainly in adult misclassification rates and $\pi$. To mirror @Gervasi2017 even more closely, the natural next step is to let $p$ vary by sampling design/year (an information I did not have), as in their best supported model.

## Uncertainty in sex

### Motivation

Many species show sex differences in demographic parameters, so mislabeling sex or discarding uncertain cases can bias the very patterns we want to estimate. In monomorphic birds for example, field sexing relies on behaviour (e.g., copulation posture, courtship displays, relative body size), and those clues vary in reliability; in the Audouin's gull (*Larus audouinii*) study that motivates this section, ~80% of individuals were never sexed in the field, making “known-sex only” analyses both wasteful and biased toward higher survival. 

@pradel2008sex (see also @genovart_exploiting_2012) turned this problem into a HMM inference task: treat sex as a hidden state (male/female/dead) and model the sex-assignment process itself. The model developed by Pradel, Genovart and colleagues separates (i) the probability of attempting a sex judgment (with a time trend, because sexing effort increased) from (ii) criterion-specific accuracy for four behavioural clues (copulation, courtship feeding, begging for food, body size). 

<!-- Two practical findings drive their design: (1) even the least reliable clue (body size) adds information and improves precision when its error rate is estimated, and (2) a small anchor set of genetically sexed birds (24 individuals) is enough to break the model’s inherent dual-solution/label-switching symmetry and stabilize sex ratio and sex-specific survival estimates (Table 5). -->

In brief, the message is: when field classifications are uncertain, exploit them rather than filter them out—use HMM to couple biological states to imperfect observations and propagate classification uncertainty into survival. 

That philosophy mirrors the age-uncertainty Section \@ref(ageuncertainty) we just completed: there, age was hidden and P1/P2 provided noisy age labels; here, sex is hidden and multiple behavioural criteria provide noisy sex labels. 

### Model and NIMBLE implementation

To estimate Audouin's gull survival, we have at our disposal a dataset with 4093 marked birds from a colony at the Ebro Delta (Spain), collected over 10 years. To build up our model, we first define the states and observations:
  
- states  
    - alive as male (M)
    - alive as female (F)
    - dead (D)

- observations  
    - not seen (1)
    - judged from copulation to be male (2)
    - judged from begging food to be male (3)
    - judged from coutship feeding to be male (4)
    - judged from body size to be male (5)
    - judged from copulation to be female (6)
    - judged from begging food to be female (7)
    - judged from coutship feeding to be female (8)
    - judged from body size to be female (9)
    - not judged (10). 

Now we turn to writing our model. 

We start with the vector of initial states. Unknown-sex individuals enter as a mixture of male/female with probabilities $\pi$ and $1-\pi$: 
$$\begin{matrix}
& \\
\mathbf{\delta} =
  \left ( \vphantom{ \begin{matrix} 12 \end{matrix} } \right .
          \end{matrix}
          \hspace{-1.2em}
          \begin{matrix}
          z_t=M & z_t=F & z_t=D \\ \hdashline
          \pi & 1 - \pi & 0\\
          \end{matrix}
          \hspace{-0.2em}
          \begin{matrix}
          & \\
          \left . \vphantom{ \begin{matrix} 12 \end{matrix} } \right )
\begin{matrix}
\end{matrix}
\end{matrix}$$

We proceed with the transition matrix that contains the survival probabilities. A male either survives next year as a male ($\phi_M$), or dies; the same happens for females (with probability $\phi_F$): 
$$\begin{matrix}
& \\
\mathbf{\Gamma} =
  \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right .
          \end{matrix}
          \hspace{-1.2em}
          \begin{matrix}
          z_t=M & z_t=F & z_t=D \\ \hdashline
          \phi_M  & 0 & 1 - \phi_M\\
          0 & \phi_F & 1 - \phi_F\\
          0 & 0 & 1
          \end{matrix}
          \hspace{-0.2em}
          \begin{matrix}
          & \\
          \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \end{matrix} } \right )
\begin{matrix}
z_{t-1}=M \\ z_{t-1}=F \\ z_{t-1}=D
\end{matrix}
\end{matrix}$$
  
The vector of initial states and the matrix of transition probabilities are written as usual in NIMBLE:
```{r eval = FALSE}
  delta[1] <- pi
  delta[2] <- 1 - pi
  delta[3] <- 0
  
  gamma[1,1] <- phiM            
  gamma[1,2] <- 0               
  gamma[1,3] <- 1 - phiM        
  gamma[2,1] <- 0               
  gamma[2,2] <- phiF            
  gamma[2,3] <- 1 - phiF        
  gamma[3,1] <- 0               
  gamma[3,2] <- 0               
  gamma[3,3] <- 1               
```

Last step is the observation matrix, which we write as follows (its transposed for convenience):
$$\begin{matrix}
& \\
\mathbf{\Gamma'} =
  \left ( \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12 \\ 12 \\ 12 \\ 12 \\ 12 \\ 12 \end{matrix} } \right .
          \end{matrix}
          \hspace{-1.2em}
          \begin{matrix}
          z_t=M & z_t=F & z_t=D \\ \hdashline
          1 - p  & 1 - p & 1\\
          p e (1-m_4) m_1 x_1 & p e (1-m_4) m_1 (1-x_1) & 0\\
          p e (1-m_4) m_2 x_2 & p e (1-m_4) m_2 (1-x_2) & 0\\
          p e (1-m_4) m_3 x_3 & p e (1-m_4) m_3 (1-x_3) & 0\\
          p e m_4 x_4 & p e m_4 (1-x_4) & 0\\
          p e (1-m_4) m_1 (1-x_1) & p e (1-m_4) m_1 x_1 & 0\\
          p e (1-m_4) m_2 (1-x_2) & p e (1-m_4) m_2 x_2 & 0\\
          p e (1-m_4) m_3 (1-x_3) & p e (1-m_4) m_3 x_3 & 0\\
          p e m_4 (1-x_4) & p e m_4 x_4 & 0\\
          p (1-e) & p (1-e) & 0\\
          \end{matrix}
          \hspace{-0.2em}
          \begin{matrix}
          & \\
          \left . \vphantom{ \begin{matrix} 12 \\ 12 \\ 12 \\ 12 \\ 12 \\ 12 \\ 12 \\ 12 \\ 12 \\ 12\end{matrix} } \right )
\begin{matrix}
y_{t}=1 \\ y_{t}=2 \\ y_{t}=3 \\ y_{t}=4 \\ y_{t}=5 \\ y_{t}=6 \\ y_{t}=7 \\ y_{t}=8 \\ y_{t}=9 \\ y_{t}=10
\end{matrix}
\end{matrix}$$

This matrix is a bit more complex than what we have encountered before, and needs some explanations. When an individual is encountered (with probability $p$), there is some chance that it will be sexed ($e$) based on its general appearance (body size: probability $m_4$) or its behaviour (probability $1 - m_4$). When behaviour is used, there are three different criteria (copulation, begging for food and courtship feeding), which occur with probabilities $m_1$, $m_2$, and $m_3$, respectively. Finally, each criterion has its own reliability (probabilities $x_1$, $x_2$, $x_3$, $x_4$, where $x_4$ is the reliability of the body-size criterion). 

I admit that this matrix representation can be difficult to grasp at once. It can be easier to split the observation matrix in several steps, like encountering, sexing, body size sexing, sex determination and correctness, then to sketch a decision treeMaybe a binary tree like in  Figure 2 in @genovart_exploiting_2012 (see also appendix S1 in @genovart_exploiting_2012).

In code, this gives: 
```{r eval = FALSE}
omega[1,1] <- 1 - p                                  
omega[1,2] <- p * e * (1 - m[4]) * m[1] * x[1]      
omega[1,3] <- p * e * (1 - m[4]) * m[2] * x[2]      
omega[1,4] <- p * e * (1 - m[4]) * m[3] * x[3]      
omega[1,5] <- p * e * m[4] * x[4]      
omega[1,6] <- p * e * (1 - m[4]) * m[1] * (1 - x[1])      
omega[1,7] <- p * e * (1 - m[4]) * m[2] * (1 - x[2])      
omega[1,8] <- p * e * (1 - m[4]) * m[3] * (1 - x[3])      
omega[1,9] <- p * e * m[4] * (1 - x[4])      
omega[1,10] <- p * (1 - e)      

omega[2,1] <- 1 - p                                  
omega[2,2] <- p * e * (1 - m[4]) * m[1] * (1 - x[1])      
omega[2,3] <- p * e * (1 - m[4]) * m[2] * (1 - x[2])      
omega[2,4] <- p * e * (1 - m[4]) * m[3] * (1 - x[3])      
omega[2,5] <- p * e * m[4] * (1 - x[4])      
omega[2,6] <- p * e * (1 - m[4]) * m[1] * x[1]      
omega[2,7] <- p * e * (1 - m[4]) * m[2] * x[2]     
omega[2,8] <- p * e * (1 - m[4]) * m[3] * x[3]   
omega[2,9] <- p * e * m[4] * x[4]   
omega[2,10] <- p * (1 - e)      

omega[3,1] <- 1                                  
omega[3,2] <- 0     
omega[3,3] <- 0     
omega[3,4] <- 0     
omega[3,5] <- 0     
omega[3,6] <- 0     
omega[3,7] <- 0     
omega[3,8] <- 0     
omega[3,9] <- 0     
omega[3,10] <- 0     
```

At first detection, the observation 'not detected' is impossible by construction (we condition on the first detection). We therefore use an initial observation matrix $\mathbf{\Omega}_{\text{init}}$ with $p$ set to 1 (not shown). 

The likelihood and priors are handled as usual. 

<!-- sm=b(1); % b(1) survie male -->
<!-- sf=b(2); % b(2) survie femelle -->
<!-- p=zeros(10,1); -->
<!-- p(1)=b(23); % b(23) capture occasion 1 %% oublie initialement -->
<!-- p(2)=b(3); % b(3) capture occasion 2 -->
<!-- p(3)=b(4); % b(4) capture occasion 3 -->
<!-- p(4)=b(5); % b(5) capture occasion 4 -->
<!-- p(5)=b(6); % b(6) capture occasion 5 -->
<!-- p(6)=b(7); % b(7) capture occasion 6 -->
<!-- p(7)=b(8); % b(8) capture occasion 7 -->
<!-- p(8)=b(9); % b(9) capture occasion 8 -->
<!-- p(9)=b(10); % b(10) capture occasion 9 -->
<!-- p(10)=b(11); % b(11) capture occasion 10 -->
<!-- sr=b(12); % b(12) sex-ratio = pourcentage de males -->
<!-- % sr=0.4+0.2*b(12); % b(12) sex-ratio = pourcentage de males -->
<!-- % sr=0.5; -->
<!-- ja=b(13); % b(13) intercept de la proba qu'un individu soit juge (tendance lineaire en fonction du temps) -->
<!-- jb=b(14); % b(14) pente de la proba qu'un individu soit juge (tendance lineaire en fonction du temps) -->
<!-- m4a=b(15); % b(15) intercept de la proba cdle (au jugement) d'un jugement par body size -->
<!-- m4b=b(16); % b(16) pente de la proba cdle (au jugement) d'un jugement par body size -->
<!-- m1=b(17); % b(17) proba cdle (au jugement autre que par body size) d'un jugement par copulation -->
<!-- % m1 proba cdle (au jugement autre que par body size) d'un jugement par copulation -->
<!-- m2=(1-m1)*b(18); % b(18) proba cdle (au jugement autre que par body size ou copulation) d'un jugement par begging food -->
<!-- % m2 proba cdle (au jugement autre que par body size) d'un jugement par begging food -->
<!-- m3=1-m1-m2; -->
<!-- % m3 proba cdle (au jugement autre que par body size) d'un jugement par courtship feeding -->
<!-- e1=b(19); % b(19) proba (cdtnt au jugement par copulation) d'une erreur -->
<!-- e2=b(20); % b(20) proba (cdtnt au jugement par begging food) d'une erreur -->
<!-- e3=b(21); % b(21) proba (cdtnt au jugement par courtship feeding) d'une erreur -->
<!-- e4=b(22); % b(122) proba (cdtnt au jugement par body size) d'une erreur -->
<!-- % e4=0; %TEMPO 11-10-04 -->

<!-- % probabilites des evenements (lignes) conditionnellement aux etats (colonnes) -->
<!-- % male femelle mort(male) mort(femelle) -->
<!-- % ------------------------------------------------------------------------------------ -->
<!-- % 0-pas vu -->
<!-- % 1-comportement copulatoire male -->
<!-- % 2-role male dans "beging food" -->
<!-- % 3-role male dans "courtship feeding" -->
<!-- % 4-grande taille relative -->
<!-- % 5-comportement copulatoire femelle -->
<!-- % 6-role femelle dans "beging food" -->
<!-- % 7-role femelle dans "courtship feeding" -->
<!-- % 8-petite taille relative -->
<!-- % 9-pas de jugement -->

### Results and interpretation

Here are the raw results: 

```{r echo = FALSE}
library(MCMCvis)
load(here::here("dat","sex.RData"))
MCMCsummary(out, round = 2)
```

which we can arrange in a table to compare them with the results obtained by @pradel2008sex:
```{r results='asis', echo=FALSE, message=FALSE, warning=FALSE}
library(MCMCvis)
library(knitr)

# --- Pull our summaries
params_req <- c("pi","phiF","phiM","m","x")   # m = criterion use; x = correctness p_i
ours <- MCMCsummary(out, params = params_req)
rn   <- rownames(ours)

# Locate and order m[i] and x[i]
m_rows <- rn[startsWith(rn, "m[")]
m_rows <- m_rows[order(as.integer(sub("m\\[|\\]", "", m_rows)))]
x_rows <- rn[startsWith(rn, "x[")]
x_rows <- x_rows[order(as.integer(sub("x\\[|\\]", "", x_rows)))]

# Helper: "mean (L–U)"
fmt <- function(m, l, u) sprintf("%.2f (%.2f–%.2f)", m, l, u)

# Our core
ours_fmt <- c(
  "pi"   = fmt(ours["pi","mean"],    ours["pi","2.5%"],    ours["pi","97.5%"]),
  "phiF" = fmt(ours["phiF","mean"],  ours["phiF","2.5%"],  ours["phiF","97.5%"]),
  "phiM" = fmt(ours["phiM","mean"],  ours["phiM","2.5%"],  ours["phiM","97.5%"])
)

# Our m[i] (criterion use)
ours_m_fmt <- setNames(
  mapply(fmt, ours[m_rows,"mean"], ours[m_rows,"2.5%"], ours[m_rows,"97.5%"]),
  m_rows
)

# Our error rates = 1 - x[i]
err_mean <- 1 - ours[x_rows,"mean"]
err_lcl  <- 1 - ours[x_rows,"97.5%"]
err_ucl  <- 1 - ours[x_rows,"2.5%"]
ours_err_fmt <- setNames(mapply(fmt, err_mean, err_lcl, err_ucl), x_rows)

# ---- Pradel et al. (2007), Table 5, Model B (RUN 6) ----
# Core (means with SEs)
pr_core <- c(
  "pi"   = "0.5325 (SE 0.0286)",
  "phiF" = "0.9122 (SE 0.0142)",
  "phiM" = "0.8597 (SE 0.0141)"
)

# m1..m3 constants; m4 time-varying (we'll print exact m4(t) in the caption)
pr_m <- c(
  "m[1]" = "0.2904 (const.)",
  "m[2]" = "0.5973 (const.)",
  "m[3]" = "0.1123 (const.)",
  "m[4]" = "time-varying (see caption)"
)

# Error rates (mean with SE)
pr_err <- c(
  "x[1]" = "0.0577 (SE 0.0407)",
  "x[2]" = "0.0561 (SE 0.0308)",
  "x[3]" = "0.0000 (SE 0.1553)",
  "x[4]" = "0.0928 (SE 0.0741)"
)

# Nice labels
crit_labs <- c("Copulation","Begging","Courtship feeding","Body size")
m_labs <- setNames(paste0("$m_", 1:4, "$ (", crit_labs, ")"), paste0("m[",1:4,"]"))
e_labs <- setNames(paste0("Error (", crit_labs, ")"), paste0("x[",1:4,"]"))
top_labs <- c(
  "pi"   = "$\\mu$ (proportion male)",
  "phiF" = "$\\phi_F$ (female survival)",
  "phiM" = "$\\phi_M$ (male survival)"
)

# Assemble comparison table
tab <- data.frame(
  Quantity = c(unname(top_labs[c("pi","phiF","phiM")]), unname(m_labs), unname(e_labs)),
  `Our (NIMBLE)` = c(
    ours_fmt[c("pi","phiF","phiM")],
    unname(ours_m_fmt[paste0("m[",1:4,"]")]),
    unname(ours_err_fmt[paste0("x[",1:4,"]")])
  ),
  `Pradel et al. (2007) Table 5, Model B` = c(
    pr_core[c("pi","phiF","phiM")],
    pr_m[paste0("m[",1:4,"]")],
    pr_err[paste0("x[",1:4,"]")]
  ),
  check.names = FALSE
)

# ---- Build caption with explicit m4(t) values ----
# RUN 6: logit(m4_t) = a + b*t
a <- -7.3979
b <-  0.6258
T <- 10                       # years reported for p(t) in RUN 6
t <- 1:T
m4_pred <- plogis(a + b * t)  # predicted m4(t)
m4_str  <- paste(sprintf("%.3f", m4_pred), collapse = ", ")
cap <- paste0(
  "Comparison with Pradel et al. (2007) Table 5, Model B (no genetically sexed anchors). ",
  "Our error rates are 1 − x[i]. ",
  "Pradel's m4 is time-varying; the estimates provided by the main author for m4(t) were for t=1..", T, ": ",
  m4_str, "."
)

kable(
  tab,
  align = c("l","c","c"),
  escape = FALSE,
  caption = cap
)
``` 

Our NIMBLE fit recovers the main biological signals reported for the Audouin's gulls analysis. Survival shows the expected ordering -- adult females ≥ adult males -- with broadly overlapping intervals and means that are close to the published model. In our run, the female--male gap is a bit smaller (≈0.90 vs 0.89), but the direction matches the paper's message (higher female survival).

We used a single, constant detection probability and obtained $p≈0.65$, which sits near the middle of the year‐specific values reported in the paper. 

The estimated probabilities of which clue is used align closely with the published analysis for the three 'behavioural' criteria: $m_1 \approx 0.29$ (copulation), $m_2 \approx 0.60$ (begging), $m_3 \approx 0.11$ (courtship feeding). The paper lets body size use vary over time; our constant estimate ($m_4 \approx 0.17$) should be read as a pooled average across years—consistent with their finding of a low but increasing use of this criterion.

The main tension with lies in the error rates by criterion. The published analysis finds low misclassification (roughly 5–10% for most criteria, with a very imprecise estimate for courtship feeding). Our fit suggests substantially higher error across criteria. That discrepancy is where we expect sensitivity when there are no known‐sex anchors (and some components are simplified). Without anchors, the model can admit dual solutions (swapping sex labels and flipping error probabilities) that fit nearly equally well; small modelling choices or initial values can tip the chain toward one mode, see @pradel2008sex. 

Our estimate of the proportion of males at first encounter ($\mu \approx 0.52$) agrees closely with the published result, reinforcing that the state mix is well constrained by the data even when sex is uncertain.

To conclude, the sex‐uncertainty HMM retrieves the core demographic pattern (female ≥ male survival) and matches the paper on overall detectability and the use of criteria. To mirror the published results more closely, one could add a small anchor set of genetically sexed individuals (an information used in @pradel2008sex but that I did not have).

<!-- ## Covariate selection with reversible jump MCMC -->

<!-- RJMCMC in @gimenez2009fitness on Common blackbirds or @gimenez2009winbugs on White stork. -->

<!-- As an illustration, we use data on the white stork *Ciconia ciconia* population in Baden Wurttemberg (Germany), consisting of 321 capture histories of individuals ringed as chicks between 1956 and 1971. From the 60's to the 90's, all Western European stork populations were declining @bair91. This trend was likely the result of reduced food availability @schau05 caused by severe droughts observed in the wintering ground of storks in the Sahel region. This hypothesis has been examined in several studies (@kanya90 and @barb99).  -->

<!-- Check out <https://r-nimble.org/nimbleExamples/RJMCMC_example.html> and <https://r-nimble.org/variable-selection-in-nimble-using-reversible-jump-mcmc>. -->

<!-- Somewhere explain how to use if-else in model code to consider alternative models, w/ some covariate in/out. Avoids rewriting all models, we see what's changed, and it avoids errors. Example: -->

<!-- ```{r eval = FALSE} -->
<!-- if(covariate){ -->
<!-- logit(survival[t]) <- beta[1] + beta[2] *x[t] -->
<!-- }else{ -->
<!-- logit(survival[t]) <- beta[1] -->
<!-- }#ifelse -->
<!-- ``` -->

<!-- then specify "covariate=TRUE/FALSE". -->

<!-- ## Missing values {#naincov} -->

<!-- Work on missing values by @bonner2006 (see @gimenez2009winbugs) and @langrock2013maximum and @worthington2015. See also @rose2018. -->

<!-- ## Nonlinearities -->

<!-- Splines à la @gimenez_semiparametric_2006, possibly w/ jagam <https://rdrr.io/cran/mgcv/src/R/jagam.r>.  -->

<!-- ## Spatial -->

<!-- 3D Splines as in @Peron2011. (I)CAR as in @saracco2010icar (see  (<https://github.com/Andrew9Lawson/Bayesian-DM-code-examples>, <https://github.com/Andrew9Lawson/Bayesian_DM_Nimble_code/tree/ICAR-and-other-code> and <https://r-nimble.org/html_manual/cha-spatial.html> for NIMBLE implementation). Add RSR @khan2022rsr (see Jags code at <https://gist.github.com/oliviergimenez/0d5519654adef09060581eb49e2128ce>).  -->

[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"Welcome online version book Bayesian analysis capture-recapture data hidden Markov models: Theory case studies R NIMBLE. , write three favorite research topics ‚Äì capture-recapture, hidden Markov models Bayesian statistics ‚Äì let‚Äôs enjoy great m/cocktail together üçπwelcome feedback. may raise issue , amend directly R Markdown file generated page ‚Äôre reading clicking ‚ÄòEdit page‚Äô icon right panel, email . Many thanks!Olivier Gimenez. Written Montpellier, France Athens, Greece.\nLast updated: September 14, 2025","code":""},{"path":"index.html","id":"how-to-cite","chapter":"Welcome","heading":"How to cite","text":"Gimenez, O. 2026. Bayesian analysis capture-recapture data hidden Markov models: Theory case studies R NIMBLE. Chapman & Hall/CRC Interdisciplinary Statistics series.","code":"@book{gimenez2026,\n  title = {Bayesian Analysis of Capture-Recapture Data with Hidden {{Markov}} Models: {{Theory}} and Case Studies in {{R}} and {{NIMBLE}}},\n  author = {Gimenez, Olivier},\n  year = {2026},\n  publisher = {Chapman & Hall/CRC Interdisciplinary Statistics series}\n}"},{"path":"index.html","id":"license","chapter":"Welcome","heading":"License","text":"online version book licensed Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.code public domain, licensed Creative Commons CC0 1.0 Universal (CC0 1.0).","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"preface.html","id":"why-this-book","chapter":"Preface","heading":"Why this book?","text":"hidden Markov modelling (HMM) framework gained much attention ecological literature last decade, suggested general modelling framework demography plant animal populations. HMMs increasingly used analyse capture-recapture data estimate key population parameters (e.g., survival, dispersal, recruitment) applications fields ecology (check https://oliviergimenez.github.io/curated-list--HMM-CR-papers/). first objective book illustrate flexibility HMM decompose complex problems smaller pieces easier understand, model analyse.parallel, Bayesian statistics well established fast expanding ecology related disciplines, resonates scientific reasoning offers natural framework handling uncertainty. popularity Bayesian statistics also comes availability free pieces software (WinBUGS, OpenBUGS, JAGS, Stan) allow practitioners code analyses. second objective book illustrate use R package NIMBLE (de Valpine et al. 2017) analyse capture-recapture data HMM Bayesian framework. NIMBLE seen many future Bayesian statistical ecology deal complex models.important part book consists case studies published papers presented tutorial style abide ‚Äúlearning ‚Äù philosophy. third objective book provide reproducible analyses code data teach example.","code":""},{"path":"preface.html","id":"who-should-read-this-book","chapter":"Preface","heading":"Who should read this book?","text":"book aimed beginners ‚Äôre comfortable using R write basic code, well connoisseurs capture-recapture ‚Äôd like tap power Bayesian side statistics. audiences, thinking HMM framework help confidently building models make capture-recapture data.won‚Äôt lie, math book. equations use either simple enough follow without strong mathematical background, can skipped without losing thread. solid math background, ‚Äôll find isn‚Äôt much, derivations (e.g.¬†posterior distributions) tucked away code. recognize certain level abstraction can useful, target audience ecologists. worried leaning heavily formal math feel like speaking foreign language, honest, ‚Äôm even sure still ‚Äòspeak math‚Äô fluently .","code":""},{"path":"preface.html","id":"what-will-you-learn","chapter":"Preface","heading":"What will you learn?","text":"book divided three parts. first part Foundations aimed getting --speed Bayesian statistics, NIMBLE, hidden Markov models. second part Transitions teach capture-recapture models open populations, reproducible R code ease learning process. third part Case studies provides real-world case studies scientific literature can reproduce using material covered previous chapters. problems can either ) used cement deepen understanding methods models, ii) adapted purpose, iii) serve teaching projects. data code available https://github.com/oliviergimenez/banana-book/tree/master/appendix. last chapter closes book take-home messages recommendations.","code":""},{"path":"preface.html","id":"what-wont-you-learn","chapter":"Preface","heading":"What won‚Äôt you learn?","text":"cover Bayesian statistics even hidden Markov models exhaustively, provide just need work capture-recapture data. interested knowing topics, hopefully section Suggested reading end chapter put right direction. also number important topics specific capture-recapture cover, including closed-population capture-recapture models (Williams, Nichols, Conroy 2002), spatial capture-recapture models (Royle et al. 2013), integrated population models (Besbeas Morgan 2019), semi-Markov models (e.g. Choquet et al. 2011) continuous-time models (Rushing 2023). models can treated HMMs, now usual formulation just fine. developments subject new chapters second edition, hopefully.","code":""},{"path":"preface.html","id":"prerequisites","chapter":"Preface","heading":"Prerequisites","text":"book uses primarily R package NIMBLE, need install least R NIMBLE. bunch R packages used. can install running:Besides NIMBLE, also make frequent use tidyverse packages R RStudio. piping, stick %>% magrittr package. Since R 4.1.0, R native pipe |>. code work , although admit, haven‚Äôt really checked.","code":"\ninstall.packages(c(\n  \"bookdown\", \"coda\", \"forecast\", \"ggtern\", \"gtools\", \n  \"here\", \"janitor\", \"magick\", \"MCMCvis\", \"nimble\", \n  \"nimbleEcology\", \"patchwork\", \"pdftools\", \n  \"RColorBrewer\", \"sessioninfo\", \"tidyverse\", \n  \"wesanderson\" \n))"},{"path":"preface.html","id":"how-this-book-was-written","chapter":"Preface","heading":"How this book was written","text":"wrote book RStudio http://www.rstudio.com/ide/ using bookdown http://bookdown.org/. book website https://oliviergimenez.github.io/banana-book hosted GitHub Pages https://pages.github.com/, automatically updated every push Github Actions https://github.com/features/actions. source available GitHub https://github.com/oliviergimenez/banana-book.version book ‚Äôre reading built R version 4.5.0 (2025-04-11) following packages:","code":""},{"path":"preface.html","id":"about-the-author","chapter":"Preface","heading":"About the author","text":"name Olivier Gimenez (https://oliviergimenez.github.io/). senior (euphemism young anymore) scientist National Centre Scientific Research (CNRS; https://www.cnrs.fr/en) beautiful city Montpellier, France.struggled studying maths, obtained PhD applied statistics long time ago galaxy wine cheese. awarded habilitation (https://en.wikipedia.org/wiki/Habilitation) ecology evolution stop pretending understand colleagues talking . recently embarked sociology studies hey, .Lost somewhere interface animal ecology, statistical modeling social sciences, -called expertise lies population dynamics species distribution modeling address questions ecology conservation biology impact human activities wildlife management. nothing without students colleagues kind enough bear .may find BlueSky (https://bsky.app/profile/oaggimenez.bsky.social), LinkedIn (https://www.linkedin.com//olivier-gimenez-545451115/), GitHub (https://github.com/oliviergimenez), get touch email olivier|dot|gimenez||cefe|dot|cnrs|dot|fr.","code":""},{"path":"preface.html","id":"acknowledgements","chapter":"Preface","heading":"Acknowledgements","text":"Writing book quite adventure, lot people contributed make book reality. wish thank:Rob Calver, Sherry Thomas, Vaishali Singh Kumar Shashi Chapman Hall/CRC.Marc K√©ry, Rachel McCrea, Byron Morgan Etienne Pr√©vost positive reviews book proposal sent Chapman Hall/CRC, constructive comments suggestions.Marc K√©ry precious pieces advice process writing.Perry de Valpine, Daniel Turek, Chris Paciorek Ben Goldstein NIMBLE nimbleEcology R packages.Colleagues shared data; See list https://github.com/oliviergimenez/banana-book#readmePeople commented, corrected, offered pieces advice; See list https://github.com/oliviergimenez/banana-book#readme.Yihui Xie bookdown R package.Attendees workshops run relation content book (latest edition 2023, see https://oliviergimenez.github.io/bayesian-hmm-cr-workshop-valencia/)Perry de Valpine, Sarah Cubaynes, Chlo√© Nater, Maud Qu√©rou√© Daniel Turek help running workshops relation content book (2021 edition: https://oliviergimenez.github.io/bayesian-cr-workshop/; 2022 edition: https://oliviergimenez.github.io/hmm-cr-nimble-isec2022-workshop/).Ruth King, Steve Brooks Byron Morgan workshop Bayesian statistics ecologists taught Cambridge, book wrote together (King et al. 2009), contribution statistical ecology.Jean-Dominique Lebreton, Roger Pradel R√©mi Choquet workshops modelling individual histories state uncertainty taught years, sharing science capture-recapture .employer Centre National de la Recherche Scientifique (CNRS) folks Centre d‚Äô√âcologie Fonctionnelle et √âvolutive (CEFE): researcher wonderful meaningful profession, even though academia faces growing challenges competition, greater precarity, fewer permanent positions. fortunate work supportive environment CNRS CEFE, people cultivate collaboration strong sense community.family, including mother, parents--law kindness hospitality, amazing kids wonderful wife putting writing book.","code":""},{"path":"introduction.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"first part Foundations aimed getting --speed Bayesian statistics, NIMBLE, hidden Markov models. code available https://github.com/oliviergimenez/banana-book/tree/master/appendix.","code":""},{"path":"crashcourse.html","id":"crashcourse","chapter":"1 Bayesian statistics & MCMC","heading":"1 Bayesian statistics & MCMC","text":"","code":""},{"path":"crashcourse.html","id":"introduction-1","chapter":"1 Bayesian statistics & MCMC","heading":"1.1 Introduction","text":"first chapter, learn Bayesian theory , may use simple example. also see implement simulation algorithms implement Bayesian method complex analyses. exhaustive treatment Bayesian statistics, get need navigate rest book.","code":""},{"path":"crashcourse.html","id":"bayes-theorem","chapter":"1 Bayesian statistics & MCMC","heading":"1.2 Bayes‚Äô theorem","text":"Let‚Äôs wait longer jump . Bayesian statistics relies Bayes‚Äô theorem (law, rule, whatever prefer) named Reverend Thomas Bayes (Figure 1.1). theorem published 1763 two years Bayes‚Äô death thanks friend‚Äôs efforts Richard Price, independently discovered Pierre-Simon Laplace (McGrayne 2011).\nFigure 1.1: Cartoon Thomas Bayes Bayes‚Äô theorem background. Source: James Kulich https://www.elmhurst.edu/blog/thomas-bayes/\nsee minute, Bayes‚Äô theorem conditional probabilities, somehow tricky understand. Conditional probability outcome event given event B, denote \\(\\Pr(\\mid B)\\), probability occurs, revised considering additional information event B occurred. example, friend rolls fair dice asks probability outcome six (event ). answer 1/6 side dice equally likely come . Now imagine ‚Äôre told number rolled even (event B) answer friend‚Äôs question. three even numbers, one six, may revise answer probability six rolled 1/6 \\(\\Pr(\\mid B) = 1/3\\). order B appear important, make sure confuse \\(\\Pr(\\mid B)\\) \\(\\Pr(B \\mid )\\).Bayes‚Äô theorem gives \\(\\Pr(\\mid B)\\) using marginal probabilities \\(\\Pr()\\) \\(\\Pr(B)\\) \\(\\Pr(B \\mid )\\):\\[\\Pr(\\mid B) = \\displaystyle{\\frac{ \\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}}.\\]talk marginal probability interested probability event ‚Äú‚Äù, without particular condition. example, \\(\\Pr()\\) \\(\\Pr(B)\\) overall chances \\(\\) \\(B\\), without taking anything else account. called marginal , built table possible combinations (instance, dice outcomes classified even/odd ‚Äúsix/six‚Äù), \\(\\Pr()\\) \\(\\Pr(B)\\) obtained adding entries row column, , read margins table.Originally, Bayes‚Äô theorem seen way infer unkown cause particular effect B, knowing probability effect B given cause . Think example situation medical diagnosis needed, unknown disease B symptoms, doctor knows Pr(symptoms|disease) wants derive Pr(disease|symptoms). way reversing \\(\\Pr(B \\mid )\\) \\(\\Pr(\\mid B)\\) explains Bayesian thinking used referred ‚Äòinverse probability‚Äô.don‚Äôt know , need think twice messing letters around.find easier remember Bayes‚Äô theorem written like :\\[\\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\text{hypothesis}) \\; \\Pr(\\text{hypothesis})}{\\Pr(\\text{data})}\\]\nhypothesis working assumption want learn using data. capture‚Äìrecapture analyses, hypothesis might parameter like detection probability, regression parameters relationship survival probability covariate (see Chapter 4). Bayes‚Äô theorem tells us obtain probability hypothesis given data .great think , exactly scientific method ! ‚Äôd like know plausible hypothesis based data collected, possibly compare several hypotheses among . respect, Bayesian reasoning matches scientific reasoning, probably explains Bayesian framework natural understanding statistics.might ask , Bayesian statistics default statistics? recently, practical problems implement Bayes‚Äô theorem. Recent advances computational power coupled development new algorithms led great increase application Bayesian methods within last three decades.","code":""},{"path":"crashcourse.html","id":"what-is-the-bayesian-approach","chapter":"1 Bayesian statistics & MCMC","heading":"1.3 What is the Bayesian approach?","text":"Typical statistical problems involve estimating parameter (several parameters) \\(\\theta\\) available data. , might used frequentist rather Bayesian method. frequentist approach, particular maximum likelihood estimation (MLE), assumes parameters fixed, unknown values estimated. Therefore classical estimates generally point estimates parameters interest. contrast, Bayesian approach assumes parameters fixed, unknown distribution. probability distribution mathematical expression gives probability random variable take particular values. may either discrete (e.g., Bernoulli, Binomial Poisson distribution) continuous (e.g., Gaussian distribution also known normal distribution).Bayesian approach based upon idea , experimenter, begin prior beliefs system. collect data update prior beliefs basis observations. observations might arise field work, lab work expertise esteemed colleagues. updating process based upon Bayes‚Äô theorem. Loosely, let‚Äôs say \\(= \\theta\\) \\(B = \\text{data}\\), Bayes‚Äô theorem gives way estimate parameter \\(\\theta\\) given data :\\[{\\color{red}{\\Pr(\\theta \\mid \\text{data})}} = \\frac{\\color{blue}{\\Pr(\\text{data} \\mid \\theta)} \\times \\color{green}{\\Pr(\\theta)}}{\\color{orange}{\\Pr(\\text{data})}}.\\]\nLet‚Äôs spend time going quantity formula.left-hand side \\(\\color{red}{\\Pr(\\theta \\mid \\text{data})}\\) \\(\\color{red}{\\text{posterior distribution}}\\). represents know seen data. basis inference clearly ‚Äôre , distribution, possibly multivariate one parameter.right-hand side, \\(\\color{blue}{\\Pr(\\text{data} \\mid \\theta)}\\) \\(\\color{blue}{\\text{likelihood}}\\). quantity MLE approach. Yes, Bayesian frequentist approaches likelihood core, mostly explains results often differ much. likelihood captures information data, given model parameterized \\(\\theta\\).\\(\\color{green}{\\Pr(\\theta)}\\) \\(\\color{green}{\\text{prior distribution}}\\). quantity represents know seeing data. source much discussion Bayesian approach. may vague don‚Äôt know anything \\(\\theta\\). Usually however, never start scratch, ‚Äôd like prior reflect information (see Section 4.9 accomplish ).Last, \\(\\color{orange}{\\Pr(\\text{data})}\\) sometimes called average likelihood obtained integrating likelihood respect prior \\(\\color{orange}{\\Pr(\\text{data}) = \\int{\\Pr(\\text{data} \\mid \\theta)\\Pr(\\theta) d\\theta}}\\) posterior standardized, integrates one posterior distribution. average likelihood integral dimension number parameters \\(\\theta\\) need estimate. quantity difficult, impossible, calculate general. one reasons Bayesian method wasn‚Äôt used recently, need algorithms estimate posterior distributions illustrate next section.","code":""},{"path":"crashcourse.html","id":"numerical-approx","chapter":"1 Bayesian statistics & MCMC","heading":"1.4 Approximating posteriors via numerical integration","text":"Let‚Äôs take example illustrate Bayes‚Äô theorem. Say capture, mark release \\(n = 57\\) animals beginning winter, recapture \\(y = 19\\) animals alive (used similar example King et al. 2009). ‚Äôd like estimate winter survival \\(\\theta\\). data :build model first. Assuming animals independent survival probability, \\(y\\) number alive animals end winter binomial distribution \\(n\\) trials \\(\\theta\\) probability success:\\[\\begin{align*}\ny &\\sim \\text{Binomial}(n, \\theta) &\\text{[likelihood]}\n\\end{align*}\\]Note follow McElreath (2020) use labels right help remember line . likelihood can visualised R:binomial likelihood \\(n = 57\\) released animals \\(y = 19\\) survivors winter. value survival (x-axis) corresponds maximum likelihood function (y-axis) MLE, proportion success example, close 0.33.Besides likelihood, priors another component model Bayesian approach. parameter probability, one thing know prior continuous random variable lies 0 1. reflect , often go uniform distribution \\(U(0,1)\\) imply vague priors. vague means survival , see data, probability falling 0.1 0.2 0.8 0.9, example.\\[\\begin{align*}\n\\theta &\\sim \\text{Uniform}(0, 1) &\\text{[prior }\\theta \\text{]}\n\\end{align*}\\]Now apply Bayes‚Äô theorem. write R function computes product likelihood times prior, numerator Bayes‚Äô theorem: \\(\\Pr(\\text{data} \\mid \\theta) \\times \\Pr(\\theta)\\)write another function calculates denominator, average likelihood: \\(\\Pr(\\text{data}) = \\int{\\Pr(\\text{data} \\mid \\theta) \\Pr(\\theta) d\\theta}\\)use R function integrate calculate integral denominator, implements quadrature techniques divide little squares area underneath curve delimited function integrate (numerator), count .get numerical approximation posterior winter survival applying Bayes‚Äô theorem:good numerical approximation survival posterior distribution? Ideally, want compare approximation true posterior distribution. Although closed-form expression posterior distribution general intractable, combine binomial likelihood together beta distribution prior, posterior distribution also beta distribution, makes amenable sorts exact calculations. say beta distribution conjugate prior distribution binomial distribution. beta distribution continuous 0 1, extends uniform distribution situations outcomes equally likely. two parameters \\(\\) \\(b\\) control shape (Figure 1.2).\nFigure 1.2: distribution beta(\\(\\),\\(b\\)) different values \\(\\) \\(b\\). Note \\(= b = 1\\), get uniform distribution 0 1 top left panel. \\(\\) \\(b\\) equal, distribution symmetric, bigger \\(\\) \\(b\\), peaked distribution around mean (smaller variance). expectation (mean) beta(\\(\\),\\(b\\)) \\(\\displaystyle{\\frac{}{+ b}}\\).\nlikelihood data \\(y\\) binomial \\(n\\) trials probability success \\(\\theta\\), prior beta distribution parameters \\(\\) \\(b\\), posterior beta distribution parameters \\(+ y\\) \\(b + n - y\\). example, \\(n = 57\\) trials \\(y = 19\\) animals survived uniform prior 0 1 beta distribution parameters \\(= b = 1\\), therefore survival beta posterior distribution parameters 20 39. Let‚Äôs superimpose exact posterior numerical approximation:\nClearly, exact (brick-red) vs.¬†numerical approximation (cream) winter survival posterior distribution indistinguishable, suggesting numerical approximation fine.example, single parameter estimate, winter survival. means dealing one-dimensional integral denominator pretty easy quadrature techniques R function integrate(). Now multiple parameters? example, imagine ‚Äôd like fit capture-recapture model detection probability \\(p\\) regression parameters \\(\\alpha\\) \\(\\beta\\) intercept slope relationship survival probability covariate, Bayes‚Äô theorem gives posterior distribution three parameters together:\\[ \\Pr(\\alpha, \\beta, p \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\alpha, \\beta, p) \\times \\Pr(\\alpha, \\beta, p)}{\\iiint \\, \\Pr(\\text{data} \\mid \\alpha, \\beta, p) \\Pr(\\alpha, \\beta, p) d\\alpha d\\beta dp} \\]\ntwo computational challenges formula. First, really wish calculate three-dimensional integral? answer , one-dimensional two-dimensional integrals much can go standard methods. Second, ‚Äôre interested posterior distribution parameter separately joint posterior distribution. -called marginal distribution \\(p\\) example obtained integrating parameters ‚Äì two-dimensional integral example. Now imagine tens hundreds parameters estimate, integrals become highly multi-dimensional simply intractable. next section, introduce powerful simulation methods circumvent issue.","code":"\ny <- 19 # nb of success\nn <- 57 # nb of attempts\ngrid <- seq(0, 1, 0.01) # grid of values for survival\nlikelihood <- dbinom(y, n, grid) # compute binomial likelihood\ndf <- data.frame(survival = grid, likelihood = likelihood) \ndf %>%\n  ggplot() + \n  aes(x = survival, y = likelihood) + \n  geom_line(linewidth = 1.5)\nnumerator <- function(theta) dbinom(y, n, theta) * dunif(theta, 0, 1)\ndenominator <- integrate(numerator,0,1)$value\ngrid <- seq(0, 1, 0.01) # grid of values for theta\nnumerical_posterior <- data.frame(survival = grid, \n  posterior = numerator(grid)/denominator) # Bayes' theorem\nnumerical_posterior %>%\n  ggplot() +\n  aes(x = survival, y = posterior) + \n  geom_line(linewidth = 1.5)"},{"path":"crashcourse.html","id":"markov-chain-monte-carlo-mcmc","chapter":"1 Bayesian statistics & MCMC","heading":"1.5 Markov chain Monte Carlo (MCMC)","text":"early 1990s, statisticians rediscovered work 1950‚Äôs physics. famous paper lay fundations modern Bayesian statistics (Figure 1.3), authors use simulations approximate posterior distributions precision drawing large samples. neat trick avoid explicit calculation multi-dimensional integrals struggle using Bayes‚Äô theorem.\nFigure 1.3: MCMC article cover. Source: Journal Chemical Physics ‚Äì https://aip.scitation.org/doi/10.1063/1.1699114\nsimulation algorithms called Markov chain Monte Carlo (MCMC), definitely gave boost Bayesian statistics. two parts MCMC, Markov chain Monte Carlo, let‚Äôs try make sense terms.","code":""},{"path":"crashcourse.html","id":"monte-carlo-integration","chapter":"1 Bayesian statistics & MCMC","heading":"1.5.1 Monte Carlo integration","text":"Monte Carlo stand ? Monte Carlo integration simulation technique calculate integrals function \\(f\\) random variable \\(X\\) distribution \\(\\Pr(X)\\) say \\(\\int f(X) \\Pr(X)dX\\). draw values \\(X_1,\\ldots,X_k\\) \\(\\Pr(X)\\) distribution \\(X\\), apply function \\(f\\) values, calculate mean new values \\(\\displaystyle{\\frac{1}{k}}\\sum_{=1}^k{f(X_i)}\\) approximate integral. Monte Carlo integration used Bayesian context? posterior distribution contains information need parameter estimated. dealing many parameters however, may want summarise posterior results calculating numerical summaries. simplest numerical summary mean posterior distribution, \\(E(\\theta) = \\int \\theta \\Pr(\\theta|\\text{data})\\), \\(X\\) \\(\\theta\\) now \\(f\\) identity function. Posterior mean can calculated Monte Carlo integration:may check mean just calculated matches closely expectation beta distribution:Another useful numerical summary credible interval within parameter falls probability, usually 0.95 hence 95\\(\\%\\) credible interval. Finding bounds credible interval requires calculating quantiles, turn involves integrals use Monte Carlo integration. 95\\(\\%\\) credible interval winter survival can obtained R :","code":"\n# draw 1000 values from posterior survival beta(20,39)\nsample_from_posterior <- rbeta(1000, 20, 39) \n# compute mean with Monte Carlo integration\nmean(sample_from_posterior) \n## [1] 0.3421\n20/(20+39) # expectation of beta(20,39)\n## [1] 0.339\nquantile(sample_from_posterior, probs = c(2.5/100, 97.5/100))\n##   2.5%  97.5% \n## 0.2258 0.4671"},{"path":"crashcourse.html","id":"markovmodelmcmc","chapter":"1 Bayesian statistics & MCMC","heading":"1.5.2 Markov chains","text":"Markov chain? Markov chain random sequence numbers, number depends previous number. example weather home town Southern France, Montpellier, sunny day likely followed another sunny day, say probability 0.8, rainy day rarely followed another rainy day, say probability 0.1. dynamic Markov chain captured transition matrix \\(\\Gamma\\):\n\\[\n\\begin{matrix}\n& \\\\\n\\Gamma =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    \\text{sunny tomorrow} & \\text{rainy tomorrow} \\\\[0.3em]\n0.8 & 0.2 \\\\\n0.9 & 0.1 \\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\text{sunny today} \\\\ \\text{rainy today}\n    \\end{matrix}\n\\end{matrix}\n\\]rows weather today, columns weather tomorrow. cells give probability sunny rainy day tomorrow, given day sunny rainy today. certain conditions, Markov chain converge unique stationary distribution. weather example, let‚Äôs run Markov chain 20 steps:row transition matrix converges distribution \\((0.82, 0.18)\\) number steps increases. Convergence happens matter state start , always probability 0.82 day sunny 0.18 day rainy.Back MCMC, core idea can build Markov chain given stationary distribution set desired posterior distribution.Putting Monte Carlo Markov chains together, MCMC allows us generate sample values (Markov chain) whose distribution converges posterior distribution, can use sample values calculate posterior summaries (Monte Carlo), posterior means credible intervals.","code":"\n# transition matrix\nweather <- matrix(c(0.8, 0.2, 0.9, 0.1), nrow = 2, byrow = T) \nsteps <- 20\nfor (i in 1:steps){\n  weather <- weather %*% weather # matrix multiplication\n}\nround(weather, 2) # matrix product after 20 steps\n##      [,1] [,2]\n## [1,] 0.82 0.18\n## [2,] 0.82 0.18"},{"path":"crashcourse.html","id":"metropolis-algorithm","chapter":"1 Bayesian statistics & MCMC","heading":"1.5.3 Metropolis algorithm","text":"several ways constructing Markov chains Bayesian inference. might heard Metropolis-Hastings Gibbs sampler. look https://chi-feng.github.io/mcmc-demo/ interactive gallery MCMC algorithms. illustrate Metropolis algorithm implement practice.Let‚Äôs go back example animal survival estimation. illustrate sampling survival posterior distribution. write functions likelihood, prior posterior:Metropolis algorithm works follows:pick value parameter estimated. start Markov chain ‚Äì starting value, starting location.pick value parameter estimated. start Markov chain ‚Äì starting value, starting location.decide go next, propose move away current value parameter ‚Äì candidate value. , add current value random value e.g.¬†normal distribution variance ‚Äì proposal distribution. Metropolis algorithm particular case Metropolis-Hastings algorithm symmetric proposals.decide go next, propose move away current value parameter ‚Äì candidate value. , add current value random value e.g.¬†normal distribution variance ‚Äì proposal distribution. Metropolis algorithm particular case Metropolis-Hastings algorithm symmetric proposals.compute ratio probabilities candidate current locations \\(R=\\displaystyle{\\frac{{\\Pr(\\text{candidate}|\\text{data})}}{{\\Pr(\\text{current}|\\text{data})}}}\\). magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes‚Äô theorem, appears numerator denominator \\(R\\) therefore cancels need calculated.compute ratio probabilities candidate current locations \\(R=\\displaystyle{\\frac{{\\Pr(\\text{candidate}|\\text{data})}}{{\\Pr(\\text{current}|\\text{data})}}}\\). magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes‚Äô theorem, appears numerator denominator \\(R\\) therefore cancels need calculated.posterior candidate location \\(\\Pr(\\text{candidate}|\\text{data})\\) higher current location \\(\\Pr(\\text{current}|\\text{data})\\), words candidate value plausible current value, definitely accept candidate value. , accept candidate value probability \\(R\\) reject probability \\(1-R\\). example, candidate value ten times less plausible current value, accept probability 0.1 reject probability 0.9. work practice? use continuous spinner lands somewhere 0 1 ‚Äì call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location. want accept reject often. practice, Metropolis algorithm acceptance probability 0.2 0.4, can achieved tuning variance normal proposal distribution.posterior candidate location \\(\\Pr(\\text{candidate}|\\text{data})\\) higher current location \\(\\Pr(\\text{current}|\\text{data})\\), words candidate value plausible current value, definitely accept candidate value. , accept candidate value probability \\(R\\) reject probability \\(1-R\\). example, candidate value ten times less plausible current value, accept probability 0.1 reject probability 0.9. work practice? use continuous spinner lands somewhere 0 1 ‚Äì call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location. want accept reject often. practice, Metropolis algorithm acceptance probability 0.2 0.4, can achieved tuning variance normal proposal distribution.repeat 2-4 number times ‚Äì steps.repeat 2-4 number times ‚Äì steps.Enough theory, let‚Äôs implement Metropolis algorithm R. Let‚Äôs start setting scene:Now follow 5 steps ‚Äôve just described. First, pick starting value, store (step 1):, need function propose candidate value:add value taken normal distribution mean zero standard deviation call away. work logit scale make sure candidate value survival lies 0 1.Now ‚Äôre ready steps 2, 3 4. write loop take care step 5. start initial value 0.5 run algorithm 100 steps iterations:get following values:Visually, may look chain:visualisation, remember Markov chain starts value 0.5. steps iterations x-axis, samples y-axis. graphical representation called trace plot.acceptance probability average number times accepted candidate value, 0.44 almost satisfying.make life easier avoid repeating lines code , let‚Äôs make function code written far:Can run another chain start initial value 0.2 time? Yes, just go algorithm , visualise results trace plot survival two chains starting 0.2 (yellow) 0.5 (blue) run 100 steps:Notice get exact results algorithm stochastic. question know whether reached stationary distribution. Let‚Äôs increase number steps, start 0.5 run chain 5000 iterations:‚Äôre , trace plot looks like beautiful lawn, see Section 1.6.stationary distribution reached, may regard realisations Markov chain sample posterior distribution, obtain numerical summaries. next section, consider several important implementation issues.","code":"\n# 19 recaptured alive out of 57 captured, marked and released\nsurvived <- 19\nreleased <- 57\n\n# binomial log-likelihood function\nloglikelihood <- function(x, p){\n  dbinom(x = x, size = released, prob = p, log = TRUE)\n}\n\n# uniform prior density\nlogprior <- function(p){\n  dunif(x = p, min = 0, max = 1, log = TRUE)\n}\n\n# posterior density function (log scale)\nposterior <- function(x, p){\n  loglikelihood(x, p) + logprior(p) # - log(Pr(data))\n}\nsteps <- 100 # number of steps\ntheta.post <- rep(NA, steps) # vector to store samples\naccept <- rep(NA, steps) # keep track of accept/reject\nset.seed(1234) # for reproducibility\ninits <- 0.5\ntheta.post[1] <- inits\naccept[1] <- 1\n# by default, standard deviation of the proposal distribution is 1\nmove <- function(x, away = 1){\n  # apply logit transform (-infinity,+infinity)\n  logitx <- log(x / (1 - x)) \n  # add a value taken from N(0,sd=away) to current value\n  logit_candidate <- logitx + rnorm(1, 0, away)\n  # back-transform (0,1)\n  candidate <- plogis(logit_candidate) \n  return(candidate)\n}\nfor (t in 2:steps){ # repeat steps 2-4 (step 5)\n  \n  # propose candidate value for survival (step 2)\n  theta_star <- move(theta.post[t-1])\n  \n  # calculate ratio R (step 3)\n  pstar <- posterior(survived, p = theta_star)  \n  pprev <- posterior(survived, p = theta.post[t-1])\n  logR <- pstar - pprev # likelihood and prior are on the log scale\n  R <- exp(logR)\n  \n  # accept candidate value or keep current value (step 4)\n  X <- runif(1, 0, 1) # spin continuous spinner\n  if (X < R){\n    theta.post[t] <- theta_star # accept candidate value\n    accept[t] <- 1 # accept\n  }\n  else{\n    theta.post[t] <- theta.post[t-1] # keep current value\n    accept[t] <- 0 # reject\n  }\n}\nhead(theta.post) # first values\n## [1] 0.5000 0.2302 0.2906 0.2906 0.2980 0.2980\ntail(theta.post) # last values\n## [1] 0.2622 0.2622 0.2622 0.3727 0.3232 0.3862\ndf <- data.frame(x = 1:steps, y = theta.post)\ndf %>%\n  ggplot() +\n  geom_line(aes(x = x, y = y), \n            size = 1.5, \n            color = wesanderson::wes_palettes$Zissou1[1]) + \n  labs(x = \"iterations\", y = \"samples\") + \n  ylim(0.1, 0.6)\nmetropolis <- function(steps = 100, inits = 0.5, away = 1){\n  \n  # pre-alloc memory\n  theta.post <- rep(NA, steps)\n  \n  # start\n  theta.post[1] <- inits\n  \n  for (t in 2:steps){\n    \n    # propose candidate value for prob of success\n    theta_star <- move(theta.post[t-1], away = away)\n    \n    # calculate ratio R\n    pstar <- posterior(survived, p = theta_star)  \n    pprev <- posterior(survived, p = theta.post[t-1])\n    logR <- pstar - pprev\n    R <- exp(logR)\n    \n    # accept candidate value or keep current value (step 4)\n    X <- runif(1, 0, 1) # spin continuous spinner\n    if (X < R){\n      theta.post[t] <- theta_star\n    }\n    else{\n      theta.post[t] <- theta.post[t-1]\n    }\n  }\n  theta.post\n}\ntheta.post2 <- metropolis(steps = 100, inits = 0.2)\ndf2 <- data.frame(x = 1:steps, y = theta.post2)\nggplot() +\n  geom_line(data = df,\n            aes(x = x, y = y), \n            size = 1.5, \n            color = wesanderson::wes_palettes$Zissou1[1]) + \n  geom_line(data = df2, \n            aes(x = x, y = y), \n            size = 1.5, \n            color = wesanderson::wes_palettes$Zissou1[3]) + \n  labs(x = \"iterations\", y = \"values from posterior distribution\") + \n  ylim(0.1, 0.6)\nsteps <- 5000\nset.seed(1234)\ntheta.post <- metropolis(steps = steps, inits = 0.5)\ndf <- data.frame(x = 1:steps, y = theta.post)\ndf %>%\n  ggplot() +\n  geom_line(aes(x = x, y = y), \n            size = 1, \n            color = wesanderson::wes_palettes$Zissou1[1]) + \n  labs(x = \"iterations\", y = \"values from posterior distribution\") + \n  ylim(0.1, 0.6) + \n  geom_hline(aes(yintercept = mean(theta.post), \n                 linetype = \"posterior mean\")) + \n  scale_linetype_manual(name = \"\", values = c(2,2)) "},{"path":"crashcourse.html","id":"convergence-diag","chapter":"1 Bayesian statistics & MCMC","heading":"1.6 Assessing convergence","text":"implementing MCMC, need determine long takes Markov chain converge target distribution, number iterations need achieving convergence get reasonable Monte Carlo estimates numerical summaries (posterior means credible intervals).","code":""},{"path":"crashcourse.html","id":"burn-in","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.1 Burn-in","text":"practice, discard observations start Markov chain just use observations chain converged. initial observations discard usually referred burn-.simplest method determine length burn-period look trace plots. Going back example, let‚Äôs look trace plot chain starts value 0.99.chain starts value 0.99 rapidly stabilises, values bouncing back forth around 0.3 100th iteration onwards. may choose shaded area burn-, discard first 100th values.see trace plot need least 100 iterations achieve convergence toward average survival around 0.3. always better conservative specifying length burn-period, example, use 250 even 500 iterations burn-. length burn-period can determined performing preliminary MCMC short runs.Inspecting trace plot single run Markov chain useful. However, usually run Markov chain several times, starting different -dispersed points, check runs achieve stationary distribution. approach formalised using Brooks-Gelman-Rubin (BGR) statistic \\(\\hat{R}\\) measures ratio total variability combining multiple chains (-chain plus within-chain) within-chain variability. BGR statistic asks whether chain effect, much alike \\(F\\) test analysis variance. Values 1.1 indicate likely convergence.Back example, run two Markov chains starting values 0.2 0.8 using 100 5000 iterations, calculate BGR statistic using half number iterations length burn-(code shown):get value BGR statistic near 1 2000 iterations, suggests 2000 iterations burn-, evidence lack convergence.important bear mind value near 1 BGR statistic necessary sufficient condition convergence. words, diagnostic tell sure Markov chain achieved convergence, .","code":"\n# set up the scene\nsteps <- 1000\ntheta.post <- metropolis(steps = steps, inits = 0.99)\ndf <- data.frame(x = 1:steps, y = theta.post)\ndf %>%\n  ggplot() +\n  geom_line(aes(x = x, y = y), \n            size = 1.2, \n            color = wesanderson::wes_palettes$Zissou1[1]) + \n  labs(x = \"iterations\", y = \"survival\") + \n  theme_light(base_size = 14) + \n  annotate(\"rect\", \n           xmin = 0, \n           xmax = 100, \n           ymin = 0.1, \n           ymax = 1, \n           alpha = .3) +\n  scale_y_continuous(expand = c(0,0))"},{"path":"crashcourse.html","id":"chain-length","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.2 Chain length","text":"long chain needed produce reliable parameter estimates? answer question, need keep mind successive steps Markov chain independent ‚Äì usually referred autocorrelation. Ideally, like keep autocorrelation low possible. , trace plots useful diagnose issues autocorrelation. Let‚Äôs get back survival example. figure shows trace plots different values standard deviation (parameter away) normal proposal distribution use propose candidate value (Section 1.5.3):Small big moves left right panels provide high correlations successive observations Markov chain, whereas standard deviation 1 center panel allows efficient exploration parameter space. movement around parameter space referred mixing. Mixing bad chain makes small big moves, good otherwise.addition trace plots, autocorrelation function (ACF) plots convenient way displaying strength autocorrelation given sample values. ACF plots provide autocorrelation successively sampled values separated increasing number iterations, lag. obtain autocorrelation function plots different values standard deviation proposal distribution R forecast::ggAcf() function:left right panels, autocorrelation strong, decreases slowly increasing lag mixing bad. center panel, autocorrelation weak, decreases rapidly increasing lag mixing good.Autocorrelation necessarily big issue. Strongly correlated observations just require large sample sizes therefore longer simulations. many iterations exactly? effective sample size (n.eff) measures chain length taking account chain autocorrelation. check n.eff every parameter interest, interesting parameter combinations. general, need \\(\\text{n.eff} \\geq 400\\) independent steps get reasonable Monte Carlo estimates model parameters. animal survival example, n.eff can calculated R coda::effectiveSize() function:expected, n.eff less number MCMC iterations autocorrelation. standard deviation proposal distribution 1 mixing good get satisfying effective sample size.","code":"\n# inspired from \n# https://bookdown.org/content/3686/markov-chain-monte-carlo.html\n\nn_steps <- 10000\n\nd <-\n  tibble(away = c(0.1, 1, 10)) %>% \n  mutate(accepted_traj = map(away, \n                             metropolis, \n                             steps = n_steps, \n                             inits = 0.1)) %>% \n  unnest(accepted_traj)\n\nd <-\n  d %>% \n  mutate(proposal_sd = str_c(\"Proposal SD = \", away),\n         iter        = rep(1:n_steps, times = 3))\n\ntrace <- d %>% \n  ggplot(aes(y = accepted_traj, x = iter)) +\n  geom_path(size = 1/4, color = \"steelblue\") +\n  geom_point(size = 1/2, alpha = 1/2, color = \"steelblue\") +\n  scale_y_continuous(\"survival\", \n                     breaks = 0:5 * 0.1, \n                     limits = c(0.15, 0.5)) +\n  scale_x_continuous(\"iterations\", \n                     breaks = seq(n_steps-n_steps*10/100,\n                                  n_steps,\n                                  by = 600), \n                     limits = c(n_steps-n_steps*10/100,n_steps)) +\n  facet_wrap(~proposal_sd, ncol = 3) +\n  theme_light(base_size = 14)\n\ntrace\nlibrary(forecast)\nmask <- d$proposal_sd==\"Proposal SD = 0.1\"\nplot1 <- ggAcf(x = d$accepted_traj[mask]) + ggtitle(\"SD = 0.1\")\nmask <- d$proposal_sd==\"Proposal SD = 1\"\nplot2 <- ggAcf(x = d$accepted_traj[mask]) + ggtitle(\"SD = 1\")\nmask <- d$proposal_sd==\"Proposal SD = 10\"\nplot3 <- ggAcf(x = d$accepted_traj[mask]) + ggtitle(\"SD = 10\")\n\nlibrary(patchwork)\n(plot1 + plot2 + plot3)\nmask <- d$proposal_sd==\"Proposal SD = 0.1\"\nneff1 <- coda::effectiveSize(d$accepted_traj[mask])\nmask <- d$proposal_sd==\"Proposal SD = 1\"\nneff2 <- coda::effectiveSize(d$accepted_traj[mask])\nmask <- d$proposal_sd==\"Proposal SD = 10\"\nneff3 <- coda::effectiveSize(d$accepted_traj[mask])\ndf <- tibble(\"Proposal SD\" = c(0.1, 1, 10),\n             \"n.eff\" = round(c(neff1, neff2, neff3)))\ndf\n## # A tibble: 3 √ó 2\n##   `Proposal SD` n.eff\n##           <dbl> <dbl>\n## 1           0.1   224\n## 2           1    1934\n## 3          10     230"},{"path":"crashcourse.html","id":"what-if-you-have-issues-of-convergence","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.3 What if you have issues of convergence?","text":"diagnosing MCMC convergence, () often run troubles. section find helpful tips hope.mixing bad effective sample size small, may just need increase burn-/sample . Using informative priors might also make Markov chains converge faster helping MCMC sampler (e.g.¬†Metropolis algorithm) navigating efficiently parameter space. spirit, picking better initial values starting chain harm. , strategy consists using estimates simpler model MCMC chains converge.convergence issues persist, often problem model (also known folk theorem statistical computing stated Andrew Gelman, see https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/). bug code? typo somewhere? mistake maths? often coding involved, issue can identified removing complexities, start simpler model find problem .general advice see model data generating tool first place, simulate data using realistic values parameters, try recover parameter values fitting model simulated data. Simulating model help understanding works, , data need get reasonable parameter estimates (e.g.¬†Chapter 3 Section 7.4).","code":""},{"path":"crashcourse.html","id":"summary","chapter":"1 Bayesian statistics & MCMC","heading":"1.7 Summary","text":"Bayes‚Äô theorem, update beliefs (prior) new data (likelihood) get posterior beliefs (posterior): posterior \\(\\propto\\) likelihood \\(\\times\\) prior.Bayes‚Äô theorem, update beliefs (prior) new data (likelihood) get posterior beliefs (posterior): posterior \\(\\propto\\) likelihood \\(\\times\\) prior.idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ‚Äôre .idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ‚Äôre .practice, run Markov chain multiple times starting -dispersed initial values.practice, run Markov chain multiple times starting -dispersed initial values.discard iterations initial burn-phase achieve convergence chains reach regime.discard iterations initial burn-phase achieve convergence chains reach regime., run chains long enough proceed calculating Monte Carlo estimates numerical summaries (e.g.¬†posterior means credible intervals) parameters., run chains long enough proceed calculating Monte Carlo estimates numerical summaries (e.g.¬†posterior means credible intervals) parameters.","code":""},{"path":"crashcourse.html","id":"suggested-reading","chapter":"1 Bayesian statistics & MCMC","heading":"1.8 Suggested reading","text":"McCarthy (2007) K√©ry Schaub (2011) excellent introductions Bayesian statistics ecologists. forthcoming second edition latter also include NIMBLE code. See also K√©ry Kellner (2024).McCarthy (2007) K√©ry Schaub (2011) excellent introductions Bayesian statistics ecologists. forthcoming second edition latter also include NIMBLE code. See also K√©ry Kellner (2024).deeper insights, recommend Gelman Hill (2006) analyse data using frequentist Bayesian approaches side--side. book McElreath (2020) also excellent read. presentation Metropolis algorithm Section 1.5.3 inspired Albert Hu (2019). ‚Äôd like know Monte Carlo methods, book Robert Casella (2004) must (see also R counterpart Robert Casella 2010). See also Vehtari et al. (2021) discussion \\(\\hat{R}\\) effective sample size.deeper insights, recommend Gelman Hill (2006) analyse data using frequentist Bayesian approaches side--side. book McElreath (2020) also excellent read. presentation Metropolis algorithm Section 1.5.3 inspired Albert Hu (2019). ‚Äôd like know Monte Carlo methods, book Robert Casella (2004) must (see also R counterpart Robert Casella 2010). See also Vehtari et al. (2021) discussion \\(\\hat{R}\\) effective sample size.also recommend Gelman et al. (2020) authors offer workflow Bayesian analyses. discuss model building, model comparison, model checking, model validation, model understanding troubleshooting computational problems.also recommend Gelman et al. (2020) authors offer workflow Bayesian analyses. discuss model building, model comparison, model checking, model validation, model understanding troubleshooting computational problems.","code":""},{"path":"intronimble.html","id":"intronimble","chapter":"2 NIMBLE tutorial","heading":"2 NIMBLE tutorial","text":"","code":""},{"path":"intronimble.html","id":"introduction-2","chapter":"2 NIMBLE tutorial","heading":"2.1 Introduction","text":"second chapter, get familiar NIMBLE, R package implements --date MCMC algorithms fitting complex models. NIMBLE spares coding MCMC algorithms hand, requires specification likelihood priors model parameters. wish dive deeper mechanics, NIMBLE also got covered allows write samples, use custom functions, etc. illustrate NIMBLE‚Äôs main features simple example, ideas hold complex problems.","code":""},{"path":"intronimble.html","id":"what-is-nimble","chapter":"2 NIMBLE tutorial","heading":"2.2 What is NIMBLE?","text":"NIMBLE stands Numerical Inference statistical Models using Bayesian Likelihood Estimation (Figure 2.1). Briefly speaking, NIMBLE R package implements MCMC algorithms generate samples posterior distribution model parameters. Freed burden coding MCMC algorithms, specify likelihood priors apply Bayes theorem. , NIMBLE makes easy using syntax similar R syntax, make life easier. also direct extension BUGS language also used programs like WinBUGS, OpenBUGS, JAGS.use NIMBLE may ask? short answer NIMBLE capable much just running MCMC algorithms! First, work within R, background NIMBLE translate code C++ (general) faster computation. Second, NIMBLE extends BUGS language writing new functions distributions , borrow written others. Third, NIMBLE gives full control MCMC samplers, may pick algorithms defaults. Fourth, NIMBLE comes library numerical methods MCMC algorithms, including sequential Monte Carlo (particle filtering), Monte Carlo Expectation Maximization (maximum likelihood), Hamiltonian Monte Carlo (like program Stan), Laplace approximation (like program TMB). Last least, development team friendly helpful, based users‚Äô feedbacks, NIMBLE folks work constantly improving package capabilities. NIMBLE users google group open inclusive space everyone can receive help community: https://groups.google.com/g/nimble-users.\nFigure 2.1: Logo NIMBLE R package designed Luke Larson.\n","code":""},{"path":"intronimble.html","id":"start-nimble","chapter":"2 NIMBLE tutorial","heading":"2.3 Getting started","text":"run NIMBLE, need :\n1. Build model consisting likelihood priors.\n2. Read data.\n3. Specify parameters want make inference .\n4. Pick initial values parameters estimated (chain).\n5. Provide MCMC details namely number chains, length burn-period number iterations following burn-.First things first, let‚Äôs forget load nimble package:Note can install nimble like R package, Windows users need install Rtools, Mac users need install Xcode. info help trouble-shooting installation issues can found : https://r-nimble.org/download.Now let‚Äôs go back example animal survival previous chapter. First step build model specifying binomial likelihood uniform prior survival probability theta. use nimbleCode() function wrap code within curly brackets:can check model R object contains code:code , survived released known, theta needs estimated. line survived ~ dbinom(theta, released) states number successes animals survived winter, survived, distributed (‚Äôs ~) binomial released trials probability success survival theta. line theta ~ dunif(0, 1) assigns uniform distribution 0 1 prior survival probability. need, likelihood priors model parameters, NIMBLE knows Bayes theorem. last line lifespan <- - 1/log(theta) calculates quantity derived theta, expected lifespan assuming constant survival. ‚Äôd like know calculation life expectancy, check Cook, Brower, Croze (1967).comments:common distributions readily available NIMBLE. Among others, use later book dbeta, dmultinom dnorm. find need NIMBLE, can write distributions illustrated Section 2.4.common distributions readily available NIMBLE. Among others, use later book dbeta, dmultinom dnorm. find need NIMBLE, can write distributions illustrated Section 2.4.matter order write line code, NIMBLE uses called declarative language building models. brief, write code tells NIMBLE want achieve, get . contrast, imperative language requires write want program step step.matter order write line code, NIMBLE uses called declarative language building models. brief, write code tells NIMBLE want achieve, get . contrast, imperative language requires write want program step step.can think models NIMBLE graphs Figure 2.2. graph made relations (edges) can two types. stochastic relation signaled ~ sign defines random variable model, survived theta. deterministic relation signaled <- sign, like lifespan. Relations define nodes left - children - terms nodes right - parents - relations directed arrows parents children. graphs called directed acyclic graph DAG.\n\n\nFigure 2.2: Graph animal survival model. Survived stochastic node defined parents released theta, lifespan deterministic node value defined exactly value parent theta.\n\ncan think models NIMBLE graphs Figure 2.2. graph made relations (edges) can two types. stochastic relation signaled ~ sign defines random variable model, survived theta. deterministic relation signaled <- sign, like lifespan. Relations define nodes left - children - terms nodes right - parents - relations directed arrows parents children. graphs called directed acyclic graph DAG.\nFigure 2.2: Graph animal survival model. Survived stochastic node defined parents released theta, lifespan deterministic node value defined exactly value parent theta.\nSecond step workflow read data. use list component corresponds known quantity model:can proceed data passed way, know little NIMBLE sees data. NIMBLE distinguishes data constants. Constants values change, e.g.¬†vectors known index values indices used define loops. Data values might want change, basically anything appears left ~. Declaring relevant values constants better computational efficiency, easy forget, fortunately NIMBLE distinguish data constants. suggest move data constants improve efficiency. use distinction data constants chapter, next chapters become important.Third step tell NIMBLE nodes model like keep track , words quantities ‚Äôd like inference . model want survival theta lifespan:general many quantities model, including little interest worth monitoring, full control verbosity prove handy.Fourth step specify initial values model parameters. bare minimum, need initial values nodes appear left side ~ code given data. make sure MCMC algorithm explores posterior distribution, start different chains different parameter values. can specify initial values chain (specify three chains) list put yet another list:Alternatively, can write R function generates random initial values:using function generate random initial values, ‚Äôs always good idea set seed code draw initial values. example like :Setting seed makes code reproducible, really helps need trouble-shoot later. Initialization problems uncommon working NIMBLE, able reproduce initial values useful solving .Fifth last step, need tell NIMBLE number chains run, say n.chain, long burn-period , say n.burnin, number iterations following burn-period used posterior inference:NIMBLE, specify total number iterations, say n.iter, number posterior samples per chain n.iter - n.burnin. NIMBLE also allows discarding samples burn-, procedure known thinning. Thinning fixed 1 default NIMBLE simulations used summarise posterior distributions. Link Eaton (2012) offer discussion pros cons thinning.now ingredients run model, sample posterior distribution model parameters using MCMC simulations. accomplished using function nimbleMCMC():NIMBLE goes several steps explain Section 2.5. Function nimbleMCMC() takes arguments might find useful. example, one setSeed. Just like sampling initial values , setting seed within MCMC call allows run chains (), thus making analyses reproducible problems easier debug (see Section 2.7.5). can also get summary outputs specifying summary = TRUE. Conversely, rather just get MCMC samples back (coda mcmc format) can set samplesAsCodaMCMC = TRUE. Finally, can suppress progress bar find depressing running long simulations progressBar = FALSE. Check ?nimbleMCMC details.Now let‚Äôs inspect mcmc.output:R object mcmc.output list three components, one MCMC chain. Let‚Äôs look chain1 example:component list matrix. rows, 4000 samples posterior distribution theta, corresponds n.iter - n.burnin iterations. columns, quantities monitor, theta lifespan. , can compute posterior mean theta:can also obtain 95% credible interval theta:Let‚Äôs visualise posterior distribution theta histogram:less painful ways posterior inference. book, use R package MCMCvis summarise visualize MCMC outputs, perfectly valid options like ggmcmc, bayesplot basicMCMCplots.Let‚Äôs load package MCMCvis:get common numerical summaries, function MCMCsummary() job:can use caterpillar plot visualise posterior distributions theta MCMCplot():point represents posterior median, thick line 50% credible interval thin line 95% credible interval.Visualization MCMC chain , .e.¬†values posterior samples plotted iteration number, called trace. trace posterior density theta can obtained MCMCtrace():\nuse trace density plots assessing convergence get idea whether may estimation issues (see Section 1.6).can also add diagnostics convergence discussed previous chapter:calculated lifespan directly model lifespan <- -1/log(theta). can also calculate quantity outside NIMBLE. nice -product using MCMC simulations: can obtain posterior distribution quantity function model parameters applying function samples posterior distribution parameters. Especially working big models/data, recommended keep calculations can made ‚Äúpost-hoc‚Äù using posterior samples outside NIMBLE lessens memory load. example, need samples posterior distribution theta, pool three chains :get samples posterior distribution lifespan, apply function calculate lifespan samples posterior distribution survival:usual , can calculate posterior mean 95% credible interval:can also visualise posterior distribution lifespan:Now ‚Äôre good go. convenience summarized steps box . NIMBLE workflow provided nimbleMCMC() allows build models make inference. can achieve software like WinBUGS JAGS.NIMBLE workflow:NIMBLE just another MCMC engine. provides programming environment full control building models estimating parameters. NIMBLE allows write functions distributions build models, choose alternative MCMC samplers code new ones. flexibility often comes faster convergence often faster runtime.honest, learning improvements software takes reading experimentation, might well need use features. ‚Äôs fine. next sections, cover advanced material. may skip sections go back material later need .","code":"\nlibrary(nimble)\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n  # derived quantity\n  lifespan <- -1/log(theta)\n})\nmodel\n## {\n##     survived ~ dbinom(theta, released)\n##     theta ~ dunif(0, 1)\n##     lifespan <- -1/log(theta)\n## }\nmy.data <- list(released = 57, survived = 19)\nparameters.to.save <- c(\"theta\", \"lifespan\")\ninit1 <- list(theta = 0.1)\ninit2 <- list(theta = 0.5)\ninit3 <- list(theta = 0.9)\ninitial.values <- list(init1, init2, init3)\ninitial.values\n## [[1]]\n## [[1]]$theta\n## [1] 0.1\n## \n## \n## [[2]]\n## [[2]]$theta\n## [1] 0.5\n## \n## \n## [[3]]\n## [[3]]$theta\n## [1] 0.9\ninitial.values <- function() list(theta = runif(1,0,1))\ninitial.values()\n## $theta\n## [1] 0.8356\nmy.seed <- 666\nset.seed(my.seed)\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 3\nmcmc.output <- nimbleMCMC(code = model,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nstr(mcmc.output)\n## List of 3\n##  $ chain1: num [1:4000, 1:2] 0.907 0.907 0.907 0.907 0.853 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr [1:2] \"lifespan\" \"theta\"\n##  $ chain2: num [1:4000, 1:2] 0.787 0.894 1.291 1.388 1.388 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr [1:2] \"lifespan\" \"theta\"\n##  $ chain3: num [1:4000, 1:2] 0.745 0.745 0.745 0.886 1.136 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr [1:2] \"lifespan\" \"theta\"\ndim(mcmc.output$chain1)\n## [1] 4000    2\nhead(mcmc.output$chain1)\n##      lifespan  theta\n## [1,]   0.9069 0.3320\n## [2,]   0.9069 0.3320\n## [3,]   0.9069 0.3320\n## [4,]   0.9069 0.3320\n## [5,]   0.8526 0.3095\n## [6,]   0.7987 0.2859\nmean(mcmc.output$chain1[,'theta'])\n## [1] 0.3407\nquantile(mcmc.output$chain1[,'theta'], probs = c(2.5, 97.5)/100)\n##   2.5%  97.5% \n## 0.2219 0.4620\nmcmc.output$chain1[,\"theta\"] %>%\n  as_tibble() %>%\n  ggplot() +\n  geom_histogram(aes(x = value), color = \"white\") +\n  labs(x = \"survival probability\")\nlibrary(MCMCvis)\nMCMCsummary(object = mcmc.output, round = 2)\n##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## lifespan 0.94 0.17 0.66 0.92  1.32    1  2513\n## theta    0.34 0.06 0.22 0.34  0.47    1  2533\nMCMCplot(object = mcmc.output, \n         params = 'theta')\nMCMCtrace(object = mcmc.output,\n          pdf = FALSE, # no export to PDF\n          ind = TRUE, # separate density lines per chain\n          params = \"theta\")\nMCMCtrace(object = mcmc.output,\n          pdf = FALSE,\n          ind = TRUE,\n          Rhat = TRUE, # add Rhat\n          n.eff = TRUE, # add eff sample size\n          params = \"theta\")\ntheta_samples <- c(mcmc.output$chain1[,'theta'], \n                   mcmc.output$chain2[,'theta'],\n                   mcmc.output$chain3[,'theta'])\nlifespan <- -1/log(theta_samples)\nmean(lifespan)\n## [1] 0.9398\nquantile(lifespan, probs = c(2.5, 97.5)/100)\n##   2.5%  97.5% \n## 0.6629 1.3194\nlifespan %>%\n  as_tibble() %>%\n  ggplot() +\n  geom_histogram(aes(x = value), color = \"white\") +\n  labs(x = \"lifespan\")\n# model building\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n  # derived quantity\n  lifespan <- -1/log(theta)\n})\n# read in data\nmy.data <- list(released = 57, survived = 19)\n# specify parameters to monitor\nparameters.to.save <- c(\"theta\", \"lifespan\")\n# pick initial values\ninitial.values <- function() list(theta = runif(1,0,1))\n# specify MCMC details\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 3\n# run NIMBLE\nmcmc.output <- nimbleMCMC(code = model,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n# calculate numerical summaries\nMCMCsummary(object = mcmc.output, round = 2)\n# visualize parameter posterior distribution\nMCMCplot(object = mcmc.output, \n         params = 'theta')\n# check convergence\nMCMCtrace(object = mcmc.output,\n          pdf = FALSE, # no export to PDF\n          ind = TRUE, # separate density lines per chain\n          params = \"theta\")"},{"path":"intronimble.html","id":"functions-in-nimble","chapter":"2 NIMBLE tutorial","heading":"2.4 Programming","text":"NIMBLE can write use functions, use existing R C/C++ functions. allows customize models way want.","code":""},{"path":"intronimble.html","id":"nimble-functions","chapter":"2 NIMBLE tutorial","heading":"2.4.1 NIMBLE functions","text":"NIMBLE provides nimbleFunctions programming. nimbleFunction like R function, plus can compiled faster computation. Going back animal survival example, can write nimbleFunction compute lifespan:Within nimbleFunction, run section gives function executed. written NIMBLE language. theta = double(0) returnType(double(0)) arguments tell NIMBLE input output single numeric values (scalars). Alternatively, double(1) double(2) vectors matrices, logical(), integer() character() logical, integer character values.can use nimbleFunction R:can compile use C++ code faster computation:can also use nimbleFunction model:rest workflow remains :nimbleFunctions, can mimic basic R syntax, linear algebra (e.g.¬†compute eigenvalues), operate vectors matrices (e.g.¬†inverse matrix), use logical operators (e.g.¬†/) flow control (e.g.¬†-else). also long list common less common distributions can used nimbleFunctions.learn everything need know writing nimbleFunctions, make sure read chapter 11 NIMBLE manual https://r-nimble.org/manual/cha-RCfunctions.html.","code":"\ncomputeLifespan <- nimbleFunction(\n    run = function(theta = double(0)) { # type declarations\n        ans <- -1/log(theta)\n        return(ans)\n        returnType(double(0))  # return type declaration\n    } )\ncomputeLifespan(0.8)\n## [1] 4.481\nCcomputeLifespan <- compileNimble(computeLifespan)\nCcomputeLifespan(0.8)\n## [1] 4.481\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n  # derived quantity\n  lifespan <- computeLifespan(theta)\n})\nmy.data <- list(survived = 19, released = 57)\nparameters.to.save <- c(\"theta\", \"lifespan\")\ninitial.values <- function() list(theta = runif(1,0,1))\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 3\nmcmc.output <- nimbleMCMC(code = model,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nMCMCsummary(object = mcmc.output, round = 2)\n##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## lifespan 0.94 0.16 0.66 0.92  1.31    1  2593\n## theta    0.34 0.06 0.22 0.34  0.47    1  2652"},{"path":"intronimble.html","id":"callrfninnimble","chapter":"2 NIMBLE tutorial","heading":"2.4.2 Calling R/C++ functions","text":"‚Äôre like , lazy write functions, can rely scientific community use existing C, C++ R code. trick write nimbleFunction wraps access code can used NIMBLE. example, imagine ‚Äôd like use R function myfunction(), either function wrote , function available favorite R package:Now wrap function using nimbleRcall() nimbleExternalCall() C C++ function:call nimbleRcall() , argument prototype specifies inputs (single numeric value double(0)) R function Rfun generates outputs returnType (single numeric value double(0)).Now can call R function model (nimbleFunctions):rest workflow remains :Evaluating R function within NIMBLE slows MCMC sampling, can live , cost easily offset convenience able use existing R functions.","code":"\nmyfunction <- function(x) {\n  -1/log(x)\n}\nRmyfunction <- nimbleRcall(prototype = function(x = double(0)){}, \n                           Rfun = 'myfunction',\n                           returnType = double(0))\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n  lifespan <- Rmyfunction(theta)\n})\nmy.data <- list(survived = 19, released = 57)\nparameters.to.save <- c(\"theta\", \"lifespan\")\ninitial.values <- function() list(theta = runif(1,0,1))\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 3\nmcmc.output <- nimbleMCMC(code = model,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nMCMCsummary(object = mcmc.output, round = 2)\n##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## lifespan 0.94 0.16 0.68 0.92  1.29    1  2597\n## theta    0.34 0.06 0.23 0.34  0.46    1  2643"},{"path":"intronimble.html","id":"user-defined-distributions","chapter":"2 NIMBLE tutorial","heading":"2.4.3 User-defined distributions","text":"nimbleFunctions can provide user-defined distributions NIMBLE. need write functions density (d) simulation (r) distribution. example, write binomial distribution:need define nimbleFunctions R‚Äôs global environment accessed:can try function simulate single random value (n = 1 default) binomial distribution size 5 probability 0.1:set. can run workflow:nimbleFunctions offers infinite possibilities customize models algorithms. Besides covered already, can write samplers. see example minute, first need tell NIMBLE workflow.","code":"\n# density\ndmybinom <- nimbleFunction(\n  run = function(x = double(0), \n                 size = double(0), \n                 prob = double(0), \n                 log = integer(0, default = 1)) {\n    returnType(double(0))\n    # compute binomial coefficient = size!/[x! (n-x)!] and take log\n    lchoose <- lfactorial(size)-lfactorial(x)-lfactorial(size-x)\n    # binomial density function = \n    # size! / [x! (n-x)!] * prob^x * (1-prob)^(size-x) and take log\n    logProb <- lchoose + x * log(prob) + (size - x) * log(1 - prob)\n    if(log) return(logProb)\n    else return(exp(logProb)) \n  })\n# simulation using the coin flip method (p. 524 in Devroye 1986)\n# note: the n argument is required by NIMBLE \n# but is not used, default is 1\nrmybinom <- nimbleFunction(\n  run = function(n = integer(0, default = 1),\n                 size = double(0),\n                 prob = double(0)) {\n      x <- 0\n      y <- runif(n = size, min = 0, max = 1)\n      for (j in 1:size){\n        if (y[j] < prob){\n          x <- x + 1\n        }else{\n          x <- x\n        }\n      }\n    returnType(double(0))\n    return(x)    \n  })\nassign('dmybinom', dmybinom, .GlobalEnv)\nassign('rmybinom', rmybinom, .GlobalEnv)\nrmybinom(size = 5, prob = 0.1)\n## [1] 0\nmodel <- nimbleCode({\n # likelihood\n survived ~ dmybinom(prob = theta, size = released)\n # prior\n theta ~ dunif(0, 1)\n})\nmy.data <- list(released = 57, survived = 19)\ninitial.values <- function() list(theta = runif(1,0,1))\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 3\nmcmc.output <- nimbleMCMC(code = model,\n                          data = my.data,\n                          inits = initial.values,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nMCMCsummary(mcmc.output)\n##       mean      sd   2.5%    50%  97.5% Rhat n.eff\n## theta 0.34 0.05976 0.2286 0.3378 0.4598    1  2970"},{"path":"intronimble.html","id":"under-the-hood","chapter":"2 NIMBLE tutorial","heading":"2.5 Under the hood","text":"far, used nimbleMCMC() runs default MCMC workflow. perfecly fine applications. However, situations need customize MCMC samplers improve speed convergence. NIMBLE allows look hood using detailed workflow several steps: nimbleModel(), configureMCMC(), buildMCMC(), compileNimble() runMCMC(). Note nimbleMCMC() .write model code, read data pick initial values :First step create model R object (uncompiled model) nimbleModel():can look nodes:can look values stored node:can also calculate log-likelihood initial value theta:ability NIMBLE access nodes model evaluate model likelihood can help identifying bugs code. example, provide negative initial value theta, survival$calculate() returns NA:another example, convey data information animals survived released, ‚Äôll get infinity value log-likelihood:check model correctly initialized code without bugs, call model$calculate() return number NA -Inf:can obtain graph model Figure 2.2 :Second compile model compileNimble():compileNimble(), C++ code generated, compiled loaded back R can used R (compiled model):Now two versions model, survival R Csurvival C++. able separate steps model building parameter estimation strength NIMBLE. gives lot flexibility steps. example, imagine like fit model maximum likelihood, can wrapping model R function gets likelihood maximise function. Using C version model, can write:maximising likelihood (minimising negative log-likelihood), obtain maximum likelihood estimate animal survival, exactly 19 surviving animals 57 released animals 0.33.Third create MCMC configuration model configureMCMC():steps tells nodes monitored default, MCMC samplers assigned . theta monitored, samples posterior distribution simulated random walk sampler similar Metropolis sampler coded previous chapter Section 1.5.3.monitor lifespan addition theta, write:Third, create MCMC function buildMCMC() compile compileNimble():Note models nimbleFunctions need compiled can used specify project.Fourth, run NIMBLE runMCMC():run single chain runMCMC() allows use multiple chains nimbleMCMC().can look samples contains values simulated posterior distribution parameters monitor:, can obtain numerical summaries samplesSummary() (MCMCvis::MCMCsummary()):summarized steps box .Detailed NIMBLE workflow:first glance, using several steps instead nimbleMCMC() seems odds. useful? Mastering whole sequence steps allows play around samplers, changing samplers NIMBLE picks default, even writing samplers.","code":"\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n  # derived quantity\n  lifespan <- -1/log(theta)\n})\nmy.data <- list(survived = 19, released = 57)\ninitial.values <- list(theta = 0.5)\nsurvival <- nimbleModel(code = model,\n                        data = my.data,\n                        inits = initial.values)\nsurvival$getNodeNames()\n## [1] \"theta\"    \"lifespan\" \"survived\"\nsurvival$theta\n## [1] 0.5\nsurvival$survived\n## [1] 19\nsurvival$lifespan \n## [1] 1.443\n# this is -1/log(0.5)\nsurvival$calculate()\n## [1] -5.422\n# this is dbinom(x = 19, size = 57, prob = 0.5, log = TRUE)\nsurvival <- nimbleModel(code = model,\n                        data = my.data,\n                        inits = list(theta = -0.5))\nsurvival$calculate()\n## [1] NaN\nmy.data <- list(survived = 61, released = 57)\ninitial.values <- list(theta = 0.5)\nsurvival <- nimbleModel(code = model,\n                        data = my.data,\n                        inits = initial.values)\nsurvival$calculate()\n## [1] -Inf\nmy.data <- list(survived = 19, released = 57)\ninitial.values <- list(theta = 0.5)\nsurvival <- nimbleModel(code = model,\n                        data = my.data,\n                        inits = initial.values)\nsurvival$calculate()\n## [1] -5.422\nsurvival$plotGraph()\nCsurvival <- compileNimble(survival)\nCsurvival$theta\n## [1] 0.5\n# function for negative log-likelihood to minimize\nf <- function(par) {\n    Csurvival[['theta']] <- par # assign par to theta \n    ll <- Csurvival$calculate() # update log-likelihood w/ par value\n    return(-ll) # return negative log-likelihood\n}\n# evaluate function at 0.5 and 0.9\nf(0.5)\n## [1] 5.422\nf(0.9)\n## [1] 55.41\n# minimize function\nout <- optimize(f, interval = c(0,1))\nround(out$minimum, 2)\n## [1] 0.33\nsurvivalConf <- configureMCMC(survival)\n## ===== Monitors =====\n## thin = 1: theta\n## ===== Samplers =====\n## RW sampler (1)\n##   - theta\nsurvivalConf$addMonitors(c(\"lifespan\"))\n## thin = 1: lifespan, theta\nsurvivalConf\n## ===== Monitors =====\n## thin = 1: lifespan, theta\n## ===== Samplers =====\n## RW sampler (1)\n##   - theta\nsurvivalMCMC <- buildMCMC(survivalConf)\nCsurvivalMCMC <- compileNimble(survivalMCMC, project = survival)\nn.iter <- 5000\nn.burnin <- 1000\nsamples <- runMCMC(mcmc = CsurvivalMCMC, \n                   niter = n.iter,\n                   nburnin = n.burnin)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nhead(samples)\n##      lifespan  theta\n## [1,]   0.9093 0.3330\n## [2,]   0.9093 0.3330\n## [3,]   0.9093 0.3330\n## [4,]   1.2095 0.4374\n## [5,]   1.2095 0.4374\n## [6,]   1.1835 0.4296\nsamplesSummary(samples)\n##            Mean Median St.Dev. 95%CI_low 95%CI_upp\n## lifespan 0.9357 0.9194 0.16117    0.6831    1.2969\n## theta    0.3386 0.3370 0.06128    0.2313    0.4625\n# model building\nmodel <- nimbleCode({\n  survived ~ dbinom(theta, released) # likelihood\n  theta ~ dunif(0, 1) # prior\n  lifespan <- -1/log(theta) # derived quantity\n})\n# read in data\nmy.data <- list(released = 57, survived = 19)\n# pick initial values\ninitial.values <- function() list(theta = runif(1,0,1))\n# create model as an R object (uncompiled model)\nsurvival <- nimbleModel(code = model,\n                        data = my.data,\n                        inits = initial.values())\n# compile model\nCsurvival <- compileNimble(survival)\n# create a MCMC configuration\nsurvivalConf <- configureMCMC(survival)\n# add lifespan to list of parameters to monitor\nsurvivalConf$addMonitors(c(\"lifespan\"))\n# create a MCMC function and compile it\nsurvivalMCMC <- buildMCMC(survivalConf)\nCsurvivalMCMC <- compileNimble(survivalMCMC, project=survival)\n# specify MCMC details\nn.iter <- 5000; n.burnin <- 1000; n.chains <- 2\n# run NIMBLE\nsamples <- runMCMC(mcmc = CsurvivalMCMC, \n                   niter = n.iter,\n                   nburnin = n.burnin,\n                   nchain = n.chains)\n# calculate numerical summaries\nMCMCsummary(object = samples, round = 2)\n# visualize parameter posterior distribution\nMCMCplot(object = samples, params = 'theta')\n# check convergence\nMCMCtrace(object = samples, params = \"theta\",\n          pdf = FALSE, # no export to PDF\n          ind = TRUE) # separate density lines per chain"},{"path":"intronimble.html","id":"mcmc-samplers","chapter":"2 NIMBLE tutorial","heading":"2.6 MCMC samplers","text":"","code":""},{"path":"intronimble.html","id":"change-sampler","chapter":"2 NIMBLE tutorial","heading":"2.6.1 Default samplers","text":"default sampler used NIMBLE example? can answer question inspecting MCMC configuration obtained configureMCMC():Now control MCMC configuration, let‚Äôs mess . start removing default sampler:change slice sampler:Now can resume workflow:NIMBLE implements many samplers, list available ?samplers. example, high correlation (regression) parameters can make independent samplers inefficient. situation, block sampling might help consists proposing candidate values multivariate distribution acknowledges correlation parameters.","code":"\n#survivalConf <- configureMCMC(survival)\nsurvivalConf$printSamplers()\n## [1] RW sampler: theta\nsurvivalConf$removeSamplers(c('theta'))\nsurvivalConf$printSamplers()\nsurvivalConf$addSampler(target = c('theta'),\n                        type = 'slice')\nsurvivalConf$printSamplers()\n## [1] slice sampler: theta\n# create a new MCMC function and compile it:\nsurvivalMCMC2 <- buildMCMC(survivalConf)\n# to compile new functions into existing project, \n# we need to reset nimbleFunctions\nCsurvivalMCMC2 <- compileNimble(survivalMCMC2, \n                                project = survival,\n                                resetFunctions = TRUE) \n# run NIMBLE:\nsamples2 <- runMCMC(mcmc = CsurvivalMCMC2, \n                    niter = n.iter,\n                    nburnin = n.burnin)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n# obtain numerical summaries:\nsamplesSummary(samples2)\n##            Mean Median St.Dev. 95%CI_low 95%CI_upp\n## lifespan 0.9357 0.9231 0.16002    0.6645    1.2826\n## theta    0.3387 0.3385 0.06098    0.2221    0.4586"},{"path":"intronimble.html","id":"user-defined-samplers","chapter":"2 NIMBLE tutorial","heading":"2.6.2 User-defined samplers","text":"Allowing code sampler another topic NIMBLE thrives. example, focus Metropolis algorithm Section 1.5.3 coded R. section, make nimbleFunction can use within model:Compared nimbleFunctions wrote earlier, my_metropolis() contains setup function ) gets dependencies parameter update run function Metropolis, target node, theta example ii) extracts control parameters, scale standard deviation proposal distribution example. run function implements steps Metropolis algorithm: (1) get log-likelihood function evaluated current value, (2) get current value, (3) apply logit transform , (4) propose candidate value perturbing current value normal noise controled standard deviation scale, (5) back-transform candidate value (6) plug model, (7) calculate log-likelihood function candidate value, (8) compute Metropolis ratio log scale, (9) compare output spinner Metropolis ratio decide whether (10) accept candidate value copy model mvSaved (11) reject keep current value copying mvSaved model. nimbleFunction used MCMC sampler, several constraints need respected like contains = sampler_BASE statement using four arguments model, mvSaved, target control setup function. course, NIMBLE implements advanced efficient version Metropolis algorithm, can look https://github.com/cran/nimble/blob/master/R/MCMC_samplers.R#L184.Now user-defined MCMC algorithm, can change default sampler new sampler Section 2.6.1. start scratch:print samplers used default, remove default sampler theta, replace my_metropolis() sampler standard deviation proposal distribution set 0.1, print make sure NIMBLE now uses new sampler:rest workflow unchanged:","code":"\nmy_metropolis <- nimbleFunction(\n  name = 'my_metropolis', # fancy name for our MCMC sampler\n  contains = sampler_BASE,\n  setup = function(model, mvSaved, target, control) {\n    # i) get dependencies for 'target' in 'model'\n    calcNodes <- model$getDependencies(target) \n    # ii) get sd of proposal distribution\n    scale <- control$scale \n  },\n  run = function() {\n    # (1) log-lik at current value\n    initialLP <- model$getLogProb(calcNodes) \n    # (2) current parameter value\n    current <- model[[target]] \n    # (3) logit transform\n    lcurrent <- log(current / (1 - current))\n    # (4) propose candidate value\n    lproposal <- lcurrent  + rnorm(1, mean = 0, scale) \n    # (5) back-transform\n    proposal <- plogis(lproposal)\n    # (6) plug candidate value in model \n    model[[target]] <<- proposal \n    # (7) log-lik at candidate value\n    proposalLP <- model$calculate(calcNodes)\n    # (8) compute lik ratio on log scale\n    lMHR <- proposalLP - initialLP \n    # (9) spin continuous spinner and compare to ratio\n    if(runif(1,0,1) < exp(lMHR)) { \n      # (10) if candidate value is accepted, update current value\n      copy(from = model, to = mvSaved, nodes = calcNodes, \n           logProb = TRUE, row = 1)\n    } else {\n      ## (11) if candidate value is accepted, keep current value\n      copy(from = mvSaved, to = model, nodes = calcNodes, \n           logProb = TRUE, row = 1)\n    }\n  },\n  methods = list(\n    reset = function() {}\n  )\n)\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n})\nmy.data <- list(survived = 19, released = 57)\ninitial.values <- function() list(theta = runif(1,0,1))\nsurvival <- nimbleModel(code = model, \n                        data = my.data, \n                        inits = initial.values())\nCsurvival <- compileNimble(survival)\nsurvivalConf <- configureMCMC(survival)\n## ===== Monitors =====\n## thin = 1: theta\n## ===== Samplers =====\n## RW sampler (1)\n##   - theta\nsurvivalConf$printSamplers()\n## [1] RW sampler: theta\nsurvivalConf$removeSamplers(c('theta'))\nsurvivalConf$addSampler(target = 'theta', \n                        type = 'my_metropolis', \n                        control = list(scale = 0.1)) \n# scale is standard deviation of proposal distribution\nsurvivalConf$printSamplers()\n## [1] my_metropolis sampler: theta,  scale: 0.10000000000000001\nsurvivalMCMC <- buildMCMC(survivalConf)\nCsurvivalMCMC <- compileNimble(survivalMCMC, \n                               project = survival)\nsamples <- runMCMC(mcmc = CsurvivalMCMC, \n                   niter = 5000, \n                   nburnin = 1000)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nsamplesSummary(samples)\n##        Mean Median St.Dev. 95%CI_low 95%CI_upp\n## theta 0.339 0.3377 0.05592    0.2374    0.4528"},{"path":"intronimble.html","id":"tips-and-tricks","chapter":"2 NIMBLE tutorial","heading":"2.7 Tips and tricks","text":"closing chapter NIMBLE, thought ‚Äôd useful section gathering tips tricks make life easier.","code":""},{"path":"intronimble.html","id":"precision-vs-standard-deviation","chapter":"2 NIMBLE tutorial","heading":"2.7.1 Precision vs standard deviation","text":"software like JAGS, normal distribution parameterized mean mu parameter called precision, often denoted tau, inverse variance used . Say use normal prior parameter epsilon epsilon ~ dnorm(mu, tau). ‚Äôd like prior vague, therefore tau small, say 0.01 variance normal distribution large, 1/0.01 = 100 . subtlety source problems (frustration) forget second parameter precision use epsilon ~ dnorm(mu, 100), variance actually 1/100 = 0.01 prior informative, peaked mu. NIMBLE can use parameterisation well natural parameterisation epsilon ~ dnorm(mu, sd = 100) avoids confusion.","code":""},{"path":"intronimble.html","id":"indexing","chapter":"2 NIMBLE tutorial","heading":"2.7.2 Indexing","text":"NIMBLE guess dimensions objects. software like JAGS can write sum.x <- sum(x[]) calculate sum components x. NIMBLE need write sum.x <- sum(x[1:n]) sum components x 1 n.¬†Specifying dimensions can annoying, find useful forces think keep code self-explaining.","code":""},{"path":"intronimble.html","id":"faster-compilation","chapter":"2 NIMBLE tutorial","heading":"2.7.3 Faster compilation","text":"might noticed compilation NIMBLE takes time. large models (lots nodes), compilation can take forever. can set calculate = FALSE nimbleModel() disable calculation deterministic nodes log-likelihood. downside calculate(), might able identify issues help save time long run. can also use useConjugacy = FALSE configureMCMC() disable search conjugate samplers. animal survival example, :","code":"\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n})\nmy.data <- list(survived = 19, released = 57)\ninitial.values <- function() list(theta = runif(1,0,1))\n# first tip is calculate = FALSE\nsurvival <- nimbleModel(code = model, \n                        data = my.data, \n                        inits = initial.values(),\n                        calculate = FALSE) \nCsurvival <- compileNimble(survival)\nsurvivalConf <- configureMCMC(survival)\n## ===== Monitors =====\n## thin = 1: theta\n## ===== Samplers =====\n## RW sampler (1)\n##   - theta\n# second tip is useConjugacy = FALSE\nsurvivalMCMC <- buildMCMC(survivalConf, useConjugacy = FALSE) \nCsurvivalMCMC <- compileNimble(survivalMCMC, \n                               project = survival)\nsamples <- runMCMC(mcmc = CsurvivalMCMC, \n                   niter = 5000, \n                   nburnin = 1000)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nsamplesSummary(samples)\n##         Mean Median St.Dev. 95%CI_low 95%CI_upp\n## theta 0.3402 0.3391 0.06029    0.2258    0.4616"},{"path":"intronimble.html","id":"updating-mcmc-chains","chapter":"2 NIMBLE tutorial","heading":"2.7.4 Updating MCMC chains","text":"Sometimes useful run MCMC chains little bit longer improve convergence. Re-starting run previous section, can use:can extract matrix previous MCMC samples augmented new ones obtain numerical summaries:can check more_samples contains 10000 samples, 4000 call runMCMC() plus 6000 additional samples. Note works using detailed NIMBLE workflow. work nimbleMCMC() wrapper function.","code":"\nniter_ad <- 6000\nCsurvivalMCMC$run(niter_ad, reset = FALSE)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nmore_samples <- as.matrix(CsurvivalMCMC$mvSamples)\nsamplesSummary(more_samples)\n##         Mean Median St.Dev. 95%CI_low 95%CI_upp\n## theta 0.3402 0.3382 0.05975    0.2281    0.4632"},{"path":"intronimble.html","id":"tipreproducibility","chapter":"2 NIMBLE tutorial","heading":"2.7.5 Reproducibility","text":"want results reproducible, can control state R random number generator setSeed argument functions nimbleMCMC() runMCMC(). Going back animal survival example, can check two calls nimbleMCMC() give results setSeed set value. Note need specify seed chain, hence vector three components :Note make workflow reproducible, need set seed within nimbleMCMC() call, also setting initial values using randomized function .","code":"\n# first call to nimbleMCMC()\nmcmc.output1 <- nimbleMCMC(code = model,\n                           data = my.data,\n                           inits = initial.values,\n                           niter = 5000,\n                           nburnin = 1000,\n                           nchains = 3,\n                           summary = TRUE,\n                           setSeed = c(2024, 2025, 2026))\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n# second call to nimbleMCMC()\nmcmc.output2 <- nimbleMCMC(code = model,\n                           data = my.data,\n                           inits = initial.values,\n                           niter = 5000,\n                           nburnin = 1000,\n                           nchains = 3,\n                           summary = TRUE,\n                           setSeed = c(2024, 2025, 2026))\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n# outputs from both calls are the same\nmcmc.output1$summary$all.chains\n##        Mean Median St.Dev. 95%CI_low 95%CI_upp\n## theta 0.339 0.3363 0.06141    0.2245    0.4618\nmcmc.output2$summary$all.chains\n##        Mean Median St.Dev. 95%CI_low 95%CI_upp\n## theta 0.339 0.3363 0.06141    0.2245    0.4618"},{"path":"intronimble.html","id":"parallelization","chapter":"2 NIMBLE tutorial","heading":"2.7.6 Parallelization","text":"speed analyses, can run MCMC chains parallel. package jagsUI accomplishes JAGS users. , use parallel package parallel computation:First create cluster using total amount cores one make sure computer can go working:wrap workflow function run parallel:Now run code using parLapply(), uses cluster nodes execute workflow:call parLapply, specify X = c(2022, 666) ensure reproducibility. use two alues 2022 666 set seed workflow(), means run two instances workflow, two MCMC chains. Note also line set.seed(123) workflow() function ensure reproducibility drawing randomly initial values.‚Äôs good practice close cluster stopCluster() processes continue run background slow processes:inspecting results, can see object output list two components, one MCMC chain:Eventually, can obtain numerical summaries:","code":"\nlibrary(parallel)\nnbcores <- detectCores() - 1\nmy_cluster <- makeCluster(nbcores)\nworkflow <- function(seed, data) {\n  \n  library(nimble)\n  \n  model <- nimbleCode({\n    # likelihood\n    survived ~ dbinom(theta, released)\n    # prior\n    theta ~ dunif(0, 1)\n  })\n  \n  set.seed(123) # for reproducibility\n  initial.values <- function() list(theta = runif(1,0,1))\n  \n  survival <- nimbleModel(code = model, \n                          data = data, \n                          inits = initial.values())\n  Csurvival <- compileNimble(survival)\n  survivalMCMC <- buildMCMC(Csurvival)\n  CsurvivalMCMC <- compileNimble(survivalMCMC)\n  \n  samples <- runMCMC(mcmc = CsurvivalMCMC, \n                     niter = 5000, \n                     nburnin = 1000,\n                     setSeed = seed)\n  \n  return(samples)\n}\noutput <- parLapply(cl = my_cluster, \n                    X = c(2022, 666),\n                    fun = workflow, \n                    data = list(survived = 19, released = 57))\nstopCluster(my_cluster)\nstr(output)\n## List of 2\n##  $ : num [1:4000, 1] 0.393 0.369 0.346 0.346 0.346 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr \"theta\"\n##  $ : num [1:4000, 1] 0.435 0.435 0.435 0.435 0.243 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr \"theta\"\nMCMCsummary(output)\n##         mean      sd   2.5%    50%  97.5% Rhat n.eff\n## theta 0.3361 0.06148 0.2215 0.3335 0.4594    1  1779"},{"path":"intronimble.html","id":"incomplete-and-incorrect-initialization","chapter":"2 NIMBLE tutorial","heading":"2.7.7 Incomplete and incorrect initialization","text":"run nimbleMCMC() nimbleModel(), may get warnings thrown NIMBLE like ‚Äòmodel fully initialized‚Äô ‚Äòvalue NA NaN even trying calculate‚Äô. necessarily error, ‚Äòreflects missing values model variables‚Äô (incomplete initialization). situation, NIMBLE initialize nodes NAs drawing priors, work . possible, try initialize nodes (full initialization). process can bit headache, helps understanding model structure better. Going back animal survival example, let‚Äôs purposedly forget provide initial value theta:see variables initialized, use initializeInfo():Now know theta initialized, can fix issue resume workflow:working larger models, can happen NIMBLE‚Äôs internal simulation produces initial values different parameters (nodes) incompatible violate certain model assumptions. go ahead run MCMC model case, range different warning messages may appear indicate problem. first, may seem intuitive (e.g.¬†‚ÄúLog probability -Inf‚Äù, ‚ÄúLog probability NaN‚Äù, ‚ÄúSlice sampler reached maximum number contractions‚Äù, etc.), signals may want double-check initialization.","code":"\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n})\n#initial.values <- list(theta = runif(1,0,1))\nsurvival <- nimbleModel(code = model, \n                        data = list(survived = 19, released = 57))\n# survival$calculate() # gives NA\nsurvival$initializeInfo()\nsurvival$theta <- 0.5 # assign initial value to theta\nsurvival$calculate() \n## [1] -5.422\n\nCsurvival <- compileNimble(survival)\nsurvivalMCMC <- buildMCMC(Csurvival)\n## ===== Monitors =====\n## thin = 1: theta\n## ===== Samplers =====\n## RW sampler (1)\n##   - theta\nCsurvivalMCMC <- compileNimble(survivalMCMC)\n\nsamples <- runMCMC(mcmc = CsurvivalMCMC, \n                   niter = 5000, \n                   nburnin = 1000)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n\nsamplesSummary(samples)\n##         Mean Median St.Dev. 95%CI_low 95%CI_upp\n## theta 0.3402  0.338 0.06025    0.2277    0.4608"},{"path":"intronimble.html","id":"vectorization","chapter":"2 NIMBLE tutorial","heading":"2.7.8 Vectorization","text":"Vectorization process replacing loop vector instead processing single value time, process set values . example, instead writing:write:Vectorization can make code efficient manipulating one vector node x[1:n] instead n nodes x[1], ‚Ä¶, x[n]. example, may look vectorized flavor binomial distribution written Pierre Dupont https://github.com/nimble-dev/nimbleSCR/blob/master/nimbleSCR/R/dbinom_vector.R. Note per now, vectorization works deterministic nodes (relationships <-) stochastic ones (relationships ~).","code":"\nfor(i in 1:n){ \n  x[i] <- mu + epsilon[i] \n}\nx[1:n] <- mu + epsilon[1:n]"},{"path":"intronimble.html","id":"summary-1","chapter":"2 NIMBLE tutorial","heading":"2.8 Summary","text":"NIMBLE R package implements MCMC algorithms generate samples posterior distribution model parameters. specify likelihood priors using BUGS language apply Bayes theorem.NIMBLE R package implements MCMC algorithms generate samples posterior distribution model parameters. specify likelihood priors using BUGS language apply Bayes theorem.NIMBLE just another MCMC engine. provides programming environment full control building models estimating parameters.NIMBLE just another MCMC engine. provides programming environment full control building models estimating parameters.core NIMBLE nimbleFunctions can write compile faster computation. nimbleFunctions can mimic basic R syntax, work vectors matrices, use logical operators flow control, specify many distributions.core NIMBLE nimbleFunctions can write compile faster computation. nimbleFunctions can mimic basic R syntax, work vectors matrices, use logical operators flow control, specify many distributions.two workflows run NIMBLE. situations, nimbleMCMC() serve well. need control, can adopt detailed workflow nimbleModel(), configureMCMC(), buildMCMC(), compileNimble() runMCMC().two workflows run NIMBLE. situations, nimbleMCMC() serve well. need control, can adopt detailed workflow nimbleModel(), configureMCMC(), buildMCMC(), compileNimble() runMCMC().full control workflow, can change default MCMC samplers even write samplers.full control workflow, can change default MCMC samplers even write samplers.","code":""},{"path":"intronimble.html","id":"suggested-reading-1","chapter":"2 NIMBLE tutorial","heading":"2.9 Suggested reading","text":"chapter, scratched surface NIMBLE capable . list pointers help going NIMBLE.NIMBLE folks make lot useful resources available official website https://r-nimble.org.NIMBLE folks make lot useful resources available official website https://r-nimble.org.NIMBLE manual https://r-nimble.org/manual/cha-welcome-nimble.html reads like book clear explanations relevant examples.NIMBLE manual https://r-nimble.org/manual/cha-welcome-nimble.html reads like book clear explanations relevant examples.can learn lot going examples https://r-nimble.org/examples.html training material NIMBLE workshops https://github.com/nimble-training.can learn lot going examples https://r-nimble.org/examples.html training material NIMBLE workshops https://github.com/nimble-training.can keep NIMBLE cheatsheet https://r-nimble.org/NimbleCheatSheet.pdf near remind workflow, write use models, functions distributions available.can keep NIMBLE cheatsheet https://r-nimble.org/NimbleCheatSheet.pdf near remind workflow, write use models, functions distributions available.questions, feel free get touch community NIMBLE users emailing discussion group https://groups.google.com/forum/#!forum/nimble-users. great place learn, folks take time answer questions kind provide constructive answers. possible, make sure provide reproducible example illustrating problem.questions, feel free get touch community NIMBLE users emailing discussion group https://groups.google.com/forum/#!forum/nimble-users. great place learn, folks take time answer questions kind provide constructive answers. possible, make sure provide reproducible example illustrating problem.can cite following reference using NIMBLE publication:can cite following reference using NIMBLE publication:de Valpine, P., D. Turek, C. J. Paciorek, C. Anderson-Bergman, D. Temple Lang, R. Bodik (2017). Programming Models: Writing Statistical Algorithms General Model Structures NIMBLE. Journal Computational Graphical Statistics 26 (2): 403‚Äì13.Last, packages process NIMBLE results developed people whose work acknowledged: see Youngflesh (2018) MCMCvis, Turek (2022) basicMCMCplots, Gabry Mahr (2022) bayesplot Fern√°ndez--Marƒ±ÃÅn (2016) ggmcmc.","code":""},{"path":"hmmcapturerecapture.html","id":"hmmcapturerecapture","chapter":"3 Hidden Markov models","heading":"3 Hidden Markov models","text":"","code":""},{"path":"hmmcapturerecapture.html","id":"introduction-3","chapter":"3 Hidden Markov models","heading":"3.1 Introduction","text":"third chapter, learn basics Markov models fit longitudinal data using NIMBLE. real life however, individuals may go undetected status unknown. also learn manipulate extension Markov models hidden states, -called hidden Markov models.","code":""},{"path":"hmmcapturerecapture.html","id":"longitudinal-data","chapter":"3 Hidden Markov models","heading":"3.2 Longitudinal data","text":"Let‚Äôs get back survival example, denote \\(z_i\\) state individual \\(\\) \\(z_i = 1\\) alive \\(z_i = 0\\) dead. total \\(z = \\displaystyle{\\sum_{=1}^{n}{z_i}}\\) survivors \\(n\\) released animals winter survival probability \\(\\phi\\). model far combination binomial likelihood Beta prior parameters 1 1, also uniform distribution 0 1. can written :\\[\\begin{align*}\n   z &\\sim \\text{Binomial}(n, \\phi) &\\text{[likelihood]}\n   \\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\\n\\end{align*}\\]binomial distribution just sum independent Bernoulli outcomes, can rewrite model :\\[\\begin{align*}\n   z_i &\\sim \\text{Bernoulli}(\\phi), \\; = 1, \\ldots, N &\\text{[likelihood]}\n   \\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\\n\\end{align*}\\]like flipping coin individual get survivor probability \\(\\phi\\).set , consider single winter. many species, need collect data long term get representative estimate survival. Therefore say \\(T = 5\\) winters?Let us denote \\(z_{,t} = 1\\) individual \\(\\) alive winter \\(t\\), \\(z_{,t} = 2\\) dead. longitudinal data look like table . row individual \\(\\), columns winters \\(t\\), sampling occasions. Variable \\(z\\) indexed \\(\\) \\(t\\), takes value 1 individual \\(\\) alive winter \\(t\\), 2 otherwise.","code":"## # A tibble: 57 √ó 6\n##       id `winter 1` `winter 2` `winter 3` `winter 4`\n##    <int>      <int>      <int>      <int>      <int>\n##  1     1          1          1          1          1\n##  2     2          1          1          1          1\n##  3     3          1          1          1          1\n##  4     4          1          1          1          1\n##  5     5          1          1          1          1\n##  6     6          1          1          2          2\n##  7     7          1          1          1          1\n##  8     8          1          2          2          2\n##  9     9          1          1          1          1\n## 10    10          1          2          2          2\n## # ‚Ñπ 47 more rows\n## # ‚Ñπ 1 more variable: `winter 5` <int>"},{"path":"hmmcapturerecapture.html","id":"a-markov-model-for-longitudinal-data","chapter":"3 Hidden Markov models","heading":"3.3 A Markov model for longitudinal data","text":"Let‚Äôs think model data. objective remains , estimating survival. build model, ‚Äôll make assumptions, go components write likelihood. Note already encountered Markov models Section 1.5.2.","code":""},{"path":"hmmcapturerecapture.html","id":"assumptions","chapter":"3 Hidden Markov models","heading":"3.3.1 Assumptions","text":"First, assume state animal given winter, alive dead, dependent state winter . words, future depends present, past. Markov process.Second, animal alive given winter, probability survives next winter \\(\\phi\\). probability dies \\(1 - \\phi\\).Third, animal dead winter, remains dead, unless believe zombies.Markov process can represented way:example Markov process , example:animal remains alive first two time intervals \\((z_{,1} = z_{,2} = z_{,3} = 1)\\) probability \\(\\phi\\) dies fourth time interval \\((z_{,4} = 2)\\) probability \\(1-\\phi\\) remains dead onwards \\((z_{,5} = 2)\\) probability 1.","code":""},{"path":"hmmcapturerecapture.html","id":"transition-matrix","chapter":"3 Hidden Markov models","heading":"3.3.2 Transition matrix","text":"might figured already (, problem), core Markov process made transition probabilities states alive dead. example, probability transitioning state alive \\(t-1\\) state alive \\(t\\) \\(\\Pr(z_{,t} = 1 | z_{,t-1} = 1) = \\gamma_{1,1}\\). survival probability \\(\\phi\\). probability dying interval \\((t-1, t)\\) \\(\\Pr(z_{,t} = 2 | z_{,t-1} = 1) = \\gamma_{1,2} = 1 - \\phi\\). Now animal dead \\(t-1\\), \\(\\Pr(z_t = 1 | z_{t-1} = 2) = 0\\) \\(\\Pr(z_{,t} = 2 | z_{,t-1} = 2) = 1\\).can gather probabilities transition states one occasion next matrix, say \\(\\Gamma\\), call transition matrix:\\[\\begin{align*}\n\\Gamma =\n\\left(\\begin{array}{cc}\n\\gamma_{1,1} & \\gamma_{1,2}\\\\\n\\gamma_{2,1} & \\gamma_{2,2}\n\\end{array}\\right) =\n\\left(\\begin{array}{cc}\n\\phi & 1 - \\phi\\\\\n0 & 1\n\\end{array}\\right)\n\\end{align*}\\]try remember states \\(t-1\\) rows, states \\(t\\) columns, often write:\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=1 & z_t=2 \\\\[0.3em] \\hdashline\n\\phi & 1-\\phi \\\\\n0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=1 \\; \\mbox{(alive)} \\\\ z_{t-1}=2 \\; \\mbox{(dead)}\n    \\end{matrix}\n\\end{matrix}\\]Take time need navigate matrix, get familiar . example, may start alive \\(t\\) (first row) end dead \\(t+1\\) (first column) probability \\(1-\\phi\\).","code":""},{"path":"hmmcapturerecapture.html","id":"initial-states","chapter":"3 Hidden Markov models","heading":"3.3.3 Initial states","text":"Markov process start somewhere. need probabilities initial states, .e.¬†states individual \\(t = 1\\). gather probability state (alive 1 dead 2) first winter vector. use \\(\\delta = \\left(\\Pr(z_{,1} = 1), \\Pr(z_{,1} = 2)\\right)\\). simplicity, assume individuals marked released first winter, hence alive first captured, means state alive 1 sure. Therefore \\(\\delta = \\left(1, 0\\right)\\).","code":""},{"path":"hmmcapturerecapture.html","id":"likelihood","chapter":"3 Hidden Markov models","heading":"3.3.4 Likelihood","text":"Now built Markov model, need likelihood apply Bayes theorem. likelihood probability data, given model. data \\(z\\), therefore need \\(\\Pr(z) = \\Pr(z_1, z_2, \\ldots, z_{T-2}, z_{T-1}, z_T)\\).‚Äôre gonna work backward, starting last sampling occasion. Using conditional probabilities, likelihood can written product probability \\(z_T\\) .e.¬†‚Äôre alive last occasion given past history, states previous occasions, times probability past history:\\[\\begin{align*}\n\\Pr(z) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\color{blue}{\\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1)} \\\\\n\\end{align*}\\]Markov model, ‚Äôre memory less, probabilty next state, \\(z_T\\), depends current state, \\(z_{T-1}\\), previous states:\\[\\begin{align*}\n\\Pr(z) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\color{blue}{\\Pr(z_T | z_{T-1})} \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n\\end{align*}\\]can apply reasoning \\(T-1\\). First use conditional probabilities:\\[\\begin{align*}\n\\Pr(z) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\color{blue}{\\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n\\end{align*}\\]apply Markovian property:\\[\\begin{align*}\n\\Pr(z) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\color{blue}{\\Pr(z_{T-1} | z_{T-2})} \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n\\end{align*}\\]\\(z_2\\). end expression likelihood:\\[\\begin{align*}\n\\Pr(z) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\ldots \\\\\n                &= \\color{blue}{\\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\ldots \\Pr(z_{2} | z_{1}) \\Pr(z_{1})}\\\\\n\\end{align*}\\]product conditional probabilities states given previous states, probability initial states \\(\\Pr(z_1)\\). Using compact notation product conditional probabilities, get:\\[\\begin{align*}\n\\Pr(z) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\ldots \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\ldots \\Pr(z_{2} | z_{1}) \\Pr(z_{1})\\\\\n                &= \\color{blue}{\\Pr(z_{1}) \\prod_{t=2}^T{\\Pr(z_{t} | z_{t-1})}}\\\\\n\\end{align*}\\]product, can recognize transition parameters \\(\\gamma\\) defined , likelihood Markov model can written :\\[\\begin{align*}\n\\Pr(z) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_{1}) \\prod_{t=2}^T{\\gamma_{z_{t-1},z_{t}}}\\\\\n\\end{align*}\\]","code":""},{"path":"hmmcapturerecapture.html","id":"example","chapter":"3 Hidden Markov models","heading":"3.3.5 Example","text":"realise calculations bit difficult follow. Let‚Äôs take example fix ideas. Let‚Äôs assume animal alive, alive time 2 dies time 3. \\(z = (1, 1, 2)\\). contribution animal likelihood? Let‚Äôs apply formula just derived:\\[\\begin{align*}\n\\Pr(z = (1, 1, 2)) &= \\Pr(z_1 = 1) \\; \\gamma_{z_{1} = 1, z_{2} = 1} \\; \\gamma_{z_{2} = 1, z_{3} = 2}\\\\\n                            &= 1 \\; \\phi \\; (1 - \\phi).\n\\end{align*}\\]probability sequence alive, alive dead probability alive first, stay alive, eventually die. probability alive first occasion 1, contribution individual likelihood \\(\\phi (1 - \\phi)\\).","code":""},{"path":"hmmcapturerecapture.html","id":"bayesian-formulation","chapter":"3 Hidden Markov models","heading":"3.4 Bayesian formulation","text":"implementing model NIMBLE, provide Bayesian formulation model. first note likelihood product conditional probabilities binary events (alive dead). Usually binary events associated Bernoulli distribution. however, use extension several outcomes (coin two sides dice two faces) known categorical distribution. categorical distribution multinomial distribution single draw. get better idea categorical distribution works, let‚Äôs simulate rcat() function. Consider example random value drawn categorical distribution probability 0.1, 0.3 0.6. Think dice three faces, face 1 probability 0.1 occurring, face 2 probability 0.3 face 3 probability 0.6, sum probabilities 1. expect get 3 often 2 rarely 1:Alternatively, can use sample() function sample(x = 1:3, size = 1, replace = FALSE, prob = c(0.1, 0.3, 0.6)). another example sample 20 times categorical distribution probabilities 0.1, 0.1, 0.4, 0.2 0.2, hence dice 5 faces:chapter, familiarise categorical distribution binary situations, make transition states just alive dead smoother next chapters.Initial state categorical random variable probability \\(\\delta\\). dice two faces, coin, probability alive, one minus probability dead. course, want Markov chain start, ‚Äôd better say ‚Äôs alive \\(\\delta\\) just \\((1,0)\\):\\[\\begin{align*}\n   z_1 &\\sim \\text{Categorical}(\\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n\\end{align*}\\]Now main part dynamic states. state \\(z_t\\) \\(t\\) depends known state \\(z_{t-1}\\) \\(t-1\\), categorical random variable probabilities given row \\(z_{t-1}\\) transition matrix \\(\\Gamma = \\gamma_{z_{t-1},z_{t}}\\):\\[\\begin{align*}\n   z_1 &\\sim \\text{Categorical}(\\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Categorical}(\\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood, }t > 1 \\text{]}\\\\\n\\end{align*}\\]example, individual \\(\\) alive \\((t-1,t)\\) .e.¬†\\(z_{t-1} = 1\\), need first row \\(\\Gamma\\),\\[\\begin{align*}\n\\Gamma =\n\\left(\\begin{array}{cc}\n\\color{blue}{\\phi} & \\color{blue}{1 - \\phi}\\\\\n0 & 1\n\\end{array}\\right)\n\\end{align*}\\]\\(\\color{blue}{\\gamma_{z_{t-1} = 1,z_{t}} = (\\phi, 1-\\phi)}\\) \\(z_t | z_{t-1} = 1 \\sim \\text{Categorical}((\\phi, 1-\\phi))\\).Otherwise, individual \\(\\) dies \\((t-1,t)\\) .e.¬†\\(z_{t-1} = 2\\), need second row \\(\\Gamma\\):\\[\\begin{align*}\n\\Gamma =\n\\left(\\begin{array}{cc}\n\\phi & 1 - \\phi\\\\\n\\color{blue}{0} & \\color{blue}{1}\n\\end{array}\\right)\n\\end{align*}\\]\\(\\color{blue}{\\gamma_{z_{t-1} = 2,z_{t}} = (0, 1)}\\) \\(z_t | z_{t-1} = 2 \\sim \\text{Categorical}((0, 1))\\) (individual dead, remains dead probability 1).also need prior survival. Without surprise, use uniform distribution 0 1, also Beta distribution parameters 1 1. Overall model :\\[\\begin{align*}\n   z_1 &\\sim \\text{Categorical}(\\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Categorical}(\\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood, }t > 1 \\text{]}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\\n\\end{align*}\\]","code":"\nrcat(n = 1, prob = c(0.1, 0.3, 0.6))\n## [1] 3\nrcat(n = 20, prob = c(0.1, 0.1, 0.4, 0.2, 0.2))\n##  [1] 5 3 4 5 4 3 4 2 2 3 1 3 5 5 3 4 2 3 2 3"},{"path":"hmmcapturerecapture.html","id":"nimble-implementation","chapter":"3 Hidden Markov models","heading":"3.5 NIMBLE implementation","text":"implement NIMBLE Markov model just built? need put place bricks running model. Let‚Äôs start prior survival, vector initial state probabilities transition matrix:Alternatively, can define vectors matrices NIMBLE like R. can write:Now two important dimensions model, along need repeat tasks, namely individual time. time, describe successive events survival using categorical distribution dcat(), say individual \\(\\):efficient way write piece code using loop, sequence instructions repeat. , condense previous code :Now just need individuals. use another loop:Puting everything together, NIMBLE code Markov model :Note example, \\(\\delta\\) used placeholder complex models build chapters come. , simply write z[,1] <- 1.Note also replace dcat() dbern() everywhere code binary events alive/dead. make difference? Although dcat() uses less efficient samplers dbern(), dcat() convenient model building accommodate two outcomes, feature become handy next chapters.Now ‚Äôre ready resume NIMBLE workflow. First read data. code used simulate \\(z\\) survival \\(\\phi = 0.8\\) follows:Note resemblance model NIMBLE code . loops indices change, use constants explained Section 2.3:also specify initial values survival function:single parameter monitor:run 2 chains 5000 iterations including 1000 iterations burnin:Let‚Äôs run NIMBLE:Let‚Äôs calculate usual posterior numerical summaries survival:Posterior mean median close \\(0.8\\). fortunate since data simulated (actual) survival \\(\\phi = 0.8\\).","code":"markov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n...markov.survival <- nimbleCode({\n  # prior\n  phi ~ dunif(0, 1) \n  # vector of initial state probabilities\n  delta[1:2] <- c(1, 0) \n  # transition matrix\n  gamma[1:2,1:2] <- matrix( c(phi, 0, 1 - phi, 1), nrow = 2) \n...\nz[i,1] ~ dcat(delta[1:2])           # t = 1\nz[i,2] ~ dcat(gamma[z[i,1], 1:2])   # t = 2\nz[i,3] ~ dcat(gamma[z[i,2], 1:2])   # t = 3\n...\nz[i,T] ~ dcat(gamma[z[i,T-1], 1:2]) # t = T\nz[i,1] ~ dcat(delta[1:2])             # t = 1\nfor (t in 2:T){ # loop over time t\n  z[i,t] ~ dcat(gamma[z[i,t-1], 1:2]) # t = 2,...,T\n}\nfor (i in 1:N){ # loop over individual i\n  z[i,1] ~ dcat(delta[1:2]) # t = 1\n  for (j in 2:T){ # loop over time t\n    z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) # t = 2,...,T\n  } # t\n} # i\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  # likelihood\n  for (i in 1:N){ # loop over individual i\n    z[i,1] ~ dcat(delta[1:2]) # t = 1\n    for (j in 2:T){ # loop over time t\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) # t = 2,...,T\n    } # t\n  } # i\n})\n# 1 = alive, 2 = dead\nnind <- 57\nnocc <- 5\nphi <- 0.8 # survival probability\ndelta <- c(1,0) # (Pr(alive at t = 1), Pr(dead at t = 1))\nGamma <- matrix(NA, 2, 2) # transition matrix\nGamma[1,1] <- phi      # Pr(alive t -> alive t+1)\nGamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\nGamma[2,1] <- 0        # Pr(dead t -> alive t+1)\nGamma[2,2] <- 1        # Pr(dead t -> dead t+1)\nz <- matrix(NA, nrow = nind, ncol = nocc)\nset.seed(2022)\nfor (i in 1:nind){\n  z[i,1] <- rcat(n = 1, prob = delta) # 1 for sure\n  for (t in 2:nocc){\n    z[i,t] <- rcat(n = 1, prob = Gamma[z[i,t-1],1:2]) \n  }\n}\nhead(z) \n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    1    1    1    1\n## [2,]    1    1    1    1    1\n## [3,]    1    1    1    1    1\n## [4,]    1    1    1    1    2\n## [5,]    1    1    1    1    1\n## [6,]    1    1    2    2    2\nmy.data <- list(z = z)\nmy.constants <- list(N = 57, T = 5)\ninitial.values <- function() list(phi = runif(1,0,1))\ninitial.values()\n## $phi\n## [1] 0.6503\nparameters.to.save <- c(\"phi\")\nparameters.to.save\n## [1] \"phi\"\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nmcmc.output <- nimbleMCMC(code = markov.survival,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi 0.79 0.03 0.73 0.79  0.85    1  1751"},{"path":"hmmcapturerecapture.html","id":"hidden-markov-models","chapter":"3 Hidden Markov models","heading":"3.6 Hidden Markov models","text":"","code":""},{"path":"hmmcapturerecapture.html","id":"capturerecapturedata","chapter":"3 Hidden Markov models","heading":"3.6.1 Capture-recapture data","text":"Unfortunately, data alive dead states data wish . real life, animals monitored exhaustively, like humans medical trial. use capture-recapture protocols, animals captured, individually marked, released alive. , animals may detected , go undetected. Whenever animals go undetected, might alive missed, dead therefore detected. issue usually referred imperfect detection. consequence imperfect detection, Markov process survival partially observed: know animal alive detect , animal goes undetected, whether alive dead unknown . hidden Markov models (HMMs) come .Let‚Äôs get back data previous section. truth \\(z\\) contains fate individuals \\(z = 1\\) alive, \\(z = 2\\) dead:Unfortunately, partial access \\(z\\). observe \\(y\\) detections non-detections. \\(z\\) \\(y\\) connected?easiest connection dead animals go undetected sure. Therefore animal dead .e.¬†\\(z = 2\\), detected, therefore \\(y = 0\\):Now alive animals may detected . animal alive \\(z = 1\\), detected \\(y = 1\\) probability \\(p\\) \\(y = 0\\) probability \\(1-p\\). example, first detection coincides first winter individuals.Compare previous \\(z\\) table. 1‚Äôs alive become 0‚Äôs non-detection, 1‚Äôs alive remained 1‚Äôs detection. \\(y\\) table observe real life. hope convinced make connection observations, \\(y\\), true states, \\(z\\), need describe observations made (emitted HMM terminology) states.","code":"## # A tibble: 57 √ó 6\n##       id `winter 1` `winter 2` `winter 3` `winter 4`\n##    <int>      <int>      <int>      <int>      <int>\n##  1     1          1          1          1          1\n##  2     2          1          1          1          1\n##  3     3          1          1          1          1\n##  4     4          1          1          1          1\n##  5     5          1          1          1          1\n##  6     6          1          1          2          2\n##  7     7          1          1          1          1\n##  8     8          1          2          2          2\n##  9     9          1          1          1          1\n## 10    10          1          2          2          2\n## # ‚Ñπ 47 more rows\n## # ‚Ñπ 1 more variable: `winter 5` <int>## # A tibble: 57 √ó 6\n##       id `winter 1` `winter 2` `winter 3` `winter 4`\n##    <int>      <int>      <int>      <int>      <int>\n##  1     1          1          1          1          1\n##  2     2          1          1          1          1\n##  3     3          1          1          1          1\n##  4     4          1          1          1          1\n##  5     5          1          1          1          1\n##  6     6          1          1          0          0\n##  7     7          1          1          1          1\n##  8     8          1          0          0          0\n##  9     9          1          1          1          1\n## 10    10          1          0          0          0\n## # ‚Ñπ 47 more rows\n## # ‚Ñπ 1 more variable: `winter 5` <int>## # A tibble: 57 √ó 6\n##       id `winter 1` `winter 2` `winter 3` `winter 4`\n##    <int>      <dbl>      <dbl>      <dbl>      <dbl>\n##  1     1          1          0          0          0\n##  2     2          1          0          1          0\n##  3     3          1          0          0          0\n##  4     4          1          1          1          1\n##  5     5          1          1          1          1\n##  6     6          1          0          0          0\n##  7     7          1          0          1          1\n##  8     8          1          1          1          1\n##  9     9          1          1          1          1\n## 10    10          1          1          0          0\n## # ‚Ñπ 47 more rows\n## # ‚Ñπ 1 more variable: `winter 5` <dbl>"},{"path":"hmmcapturerecapture.html","id":"observation-matrix","chapter":"3 Hidden Markov models","heading":"3.6.2 Observation matrix","text":"novelty HMMs link observations states. link made observation probabilities. example, probability detecting animal \\(\\) \\(t\\) given alive \\(t\\) \\(\\Pr(y_{,t}=2|z_{,t}=1)=\\omega_{1,2}\\). detection probability \\(p\\). individual \\(\\) dead \\(t\\), missed sure, \\(\\Pr(y_{,t}=1|z_{,t}=2)=\\omega_{2,1}=1\\).can gather observation probabilities observation matrix \\(\\Omega\\). rows states alive \\(z = 1\\) dead \\(z = 2\\), columns observations non-detected \\(y = 1\\) detected \\(y = 2\\) (previously coded 0 1 respectively):\\[\\begin{align*}\n\\Omega =\n\\left(\\begin{array}{cc}\n\\omega_{1,1} & \\omega_{1,2}\\\\\n\\omega_{2,1} & \\omega_{2,2}\n\\end{array}\\right) =\n\\left(\\begin{array}{cc}\n1 - p & p\\\\\n1 & 0\n\\end{array}\\right)\n\\end{align*}\\]survival models use throughout book, condition fate individuals first detection, boils set corresponding detection probability 1.observation matrix :\\[\\begin{matrix}\n& \\\\\n\\Omega =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=1 \\mbox{ (non-detected)} & y_t=2 \\mbox{ (detected)} \\\\[0.3em] \\hdashline\n1 - p & p\\\\\n1 & 0\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& & \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=1 \\; \\mbox{(alive)}\\\\ z_{t}=2 \\; \\mbox{(dead)}\n    \\end{matrix}\n\\end{matrix}\\]","code":""},{"path":"hmmcapturerecapture.html","id":"hidden-markov-model","chapter":"3 Hidden Markov models","heading":"3.6.3 Hidden Markov model","text":"hidden Markov model can represented way:States \\(z\\) gray. Observations \\(y\\) white. individuals first captured first winter \\(t = 1\\), therefore alive \\(z_1 = 1\\) detected \\(y_1 = 2\\).hidden Markov model just two time series running parallel. One states Markovian property, observations generated states. HMM special case state-space models latent states discrete.look example , individual detected first sampling occasion, detected , missed rest study. occasion \\(t=3\\) individual alive \\(z_3=1\\) went undetected \\(y_3=1\\), occasions \\(t=4\\) \\(t=5\\) went undetected \\(y_4=y_5=1\\) dead \\(z_4=z_5=2\\). condition first detection, link state observation \\(t=1\\) deterministic \\(p = 1\\).","code":""},{"path":"hmmcapturerecapture.html","id":"likelihoodhmm","chapter":"3 Hidden Markov models","heading":"3.6.4 Likelihood","text":"Bayesian framework, usually work -called complete likelihood, probability observed data \\(y\\) latent states \\(z\\) given parameters model, survival detection probabilities \\(\\phi\\) \\(p\\). complete likelihood individual \\(\\) :\\[\\begin{align*}\n\\Pr({y}_i, {z}_i) &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T}, z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n\\end{align*}\\]Using definition conditional probability, :\\[\\begin{align*}\n\\Pr({y}_i, {z}_i) &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T}, z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n                  &= \\color{blue}{\\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T} | z_{,1}, z_{,2}, \\ldots, z_{,T}) \\Pr(z_{,1}, z_{,2}, \\ldots, z_{,T})}\\\\\n\\end{align*}\\]using independence \\(y\\) conditional \\(z\\), likelihood Markov chain, get :\\[\\begin{align*}\n\\Pr({y}_i, {z}_i) &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T}, z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n                  &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T} | z_{,1}, z_{,2}, \\ldots, z_{,T}) \\Pr(z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n                &= \\color{blue}{\\left(\\prod_{t=1}^T{\\Pr{(y_{,t} | z_{,t})}}\\right) \\left(\\Pr(z_{,1}) \\prod_{t=2}^T{\\Pr{(z_{,t} | z_{,t-1})}}\\right)}\\\\\n\\end{align*}\\]Finally, recognizing observation transition probabilities, complete likelihood individual \\(\\) :\\[\\begin{align*}\n\\Pr({y}_i, {z}_i) &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T}, z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n                  &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T} | z_{,1}, z_{,2}, \\ldots, z_{,T}) \\Pr(z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n                &= \\color{blue}{\\left(\\prod_{t=1}^T{\\omega_{z_{,t}, y_{,t}}}\\right) \\left(\\Pr(z_{,1}) \\prod_{t=2}^T{\\gamma_{z_{,t-1},z_{,t}}}\\right)}\\\\\n\\end{align*}\\]obtain complete likelihood whole dataset, need multiply individual likelihood animal \\(\\displaystyle{\\prod_{=1}^N{\\Pr({y}_i,{z}_i)}}\\). several individuals contribution, calculating individual contribution can greatly reduce computational burden, illustrated Section 3.9.Bayesian approach MCMC methods allows treating latent states \\(z_{,t}\\) parameters, estimated . However, likelihood rather complex large number latent states \\(z_{,t}\\), comes computational costs slow mixing. situations latent states focus ecological inference need estimated (see Suggested reading ). However, needed, might want get rid latent states rely -called marginal likelihood. , can avoid sampling latent states, focus ecological parameters, often speeds computations improves mixing shown Section 3.8. Actually, can even estimate latent states afterwards, illustrated Section 3.10.","code":""},{"path":"hmmcapturerecapture.html","id":"fittinghmmnimble","chapter":"3 Hidden Markov models","heading":"3.7 Fitting HMM with NIMBLE","text":"denote first time first detection, model far written follows:\\[\\begin{align*}\n   z_{\\text{first}} &\\sim \\text{Categorical}(1, \\delta) &\\text{[likelihood]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Categorical}(1, \\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood, t>first]}\\\\\n   y_t | z_{t} &\\sim \\text{Categorical}(1, \\omega_{z_{t}}) &\\text{[likelihood, t>first]}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\\n  p &\\sim \\text{Beta}(1, 1) &\\text{[prior }p \\text{]} \\\\\n\\end{align*}\\]observation layer \\(y\\)‚Äôs, conditional \\(z\\)‚Äôs. also consider uniform priors detection survival probabilities. implement model NIMBLE?start priors survival detection probabilities:define initial states, transition observation matrices:likelihood:loop time individual (j 2:T){} starts first time individuals detected (time 2 ), work conditional first detection.Overall, code looks like:Now specify constants:data made 0‚Äôs non-detections 1‚Äôs detections. simulate \\(y\\), code used:use categorical distribution, need code 1‚Äôs 2‚Äôs. simply add 1 get correct format, \\(y = 1\\) non-detection \\(y = 2\\) detection:Now let‚Äôs write function initial values:initial values latent states, assumed whenever individual non-detected, alive, zinits <- y + 1, make sure dead individuals alive zinits[zinits == 2] <- 1.specify parameters ‚Äôd like monitor:provide MCMC details:last, ‚Äôre ready run NIMBLE:can look numerical summaries:estimates survival detection close true survival \\(\\phi = 0.8\\) detection \\(p = 0.6\\) simulated data.","code":"hmm.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n...\n...\n  # parameters\n  delta[1] <- 1          # Pr(alive t = first) = 1\n  delta[2] <- 0          # Pr(dead t = first) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n......\n    # likelihood\n    for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nhmm.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n  # likelihood\n  delta[1] <- 1          # Pr(alive t = first) = 1\n  delta[2] <- 0          # Pr(dead t = first) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y), T = 5)\nmy.constants\n## $N\n## [1] 57\n## \n## $T\n## [1] 5\nset.seed(2022) # for reproducibility\nnocc <- 5 # nb of winters or sampling occasions\nnind <- 57 # nb of animals\np <- 0.6 # detection prob\nphi <- 0.8 # survival prob\n# Vector of initial states probabilities\ndelta <- c(1,0) # all individuals are alive in first winter\n# Transition matrix\nGamma <- matrix(NA, 2, 2)\nGamma[1,1] <- phi      # Pr(alive t -> alive t+1)\nGamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\nGamma[2,1] <- 0        # Pr(dead t -> alive t+1)\nGamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n# Observation matrix \nOmega <- matrix(NA, 2, 2)\nOmega[1,1] <- 1 - p      # Pr(alive t -> non-detected t)\nOmega[1,2] <- p          # Pr(alive t -> detected t)\nOmega[2,1] <- 1          # Pr(dead t -> non-detected t)\nOmega[2,2] <- 0          # Pr(dead t -> detected t)\n# Matrix of states\nz <- matrix(NA, nrow = nind, ncol = nocc)\ny <- z\ny[,1] <- 2 # all individuals are detected in first winter, \n           # as we condition on first detection\nfor (i in 1:nind){\n  z[i,1] <- rcat(n = 1, prob = delta) # 1 for sure\n  for (t in 2:nocc){\n    # state at t given state at t-1\n    z[i,t] <- rcat(n = 1, prob = Gamma[z[i,t-1],1:2]) \n    # observation at t given state at t\n    y[i,t] <- rcat(n = 1, prob = Omega[z[i,t],1:2]) \n  }\n}\ny\ny <- y - 1 # non-detection = 0, detection = 1\nmy.data <- list(y = y + 1)\nzinits <- y + 1 # non-detection -> alive\nzinits[zinits == 2] <- 1 # dead -> alive\ninitial.values <- function() list(phi = runif(1,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"phi\", \"p\")\nparameters.to.save\n## [1] \"phi\" \"p\"\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nstart_time <- Sys.time()\nmcmc.output <- nimbleMCMC(code = hmm.survival,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\nend_time <- Sys.time()\nend_time - start_time## Time difference of 43.43 secs\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.61 0.06 0.50 0.61  0.72    1   740\n## phi 0.75 0.04 0.67 0.75  0.83    1   805"},{"path":"hmmcapturerecapture.html","id":"marginalization","chapter":"3 Hidden Markov models","heading":"3.8 Marginalization","text":"situations, interested inferring hidden states \\(z_{,t}\\), bother estimating ? good news can get rid states, marginal likelihood function survival detection probabilities \\(\\phi\\) \\(p\\) .","code":""},{"path":"hmmcapturerecapture.html","id":"brute-force-approach","chapter":"3 Hidden Markov models","heading":"3.8.1 Brute-force approach","text":"Using formula total probability, get marginal likelihood summing possible states complete likelihood:\\[\\begin{align*}\n\\Pr({y}_i) &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T})\\\\\n                &= \\sum_{{z}_i} \\Pr({y}_i, {z}_i)\\\\\n                &= \\sum_{z_{,1}} \\cdots \\sum_{z_{,T}} \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T}, z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n\\end{align*}\\]Going steps deriving complete likelihood, obtain marginal likelihood:\\[\\begin{align*}\n\\Pr({y}_i) &= \\sum_{z_{,1}} \\cdots \\sum_{z_{,T}} \\left(\\prod_{t=1}^T{\\omega_{z_{,t}, y_{,t}}}\\right) \\left(\\Pr(z_{,1}) \\prod_{t=2}^T{\\gamma_{z_{,t-1},z_{,t}}}\\right)\\\\\n\\end{align*}\\]Let‚Äôs go example. Let‚Äôs imagine \\(T = 3\\) winters, ‚Äôd like write likelihood individual encounter history detected, detected non-detected. Remember non-detected coded 1 detected coded 2, alive coded 1 dead coded 2. need calculate \\(\\Pr(y_1 = 2, y_2 = 2, y_3 = 1)\\) , according formula , given :\\[\\begin{align*}\n\\begin{split}\n\\Pr(y_1 = 2, y_2 = 2, y_3 = 1) &= \\sum_{=1}^{2} \\sum_{j=1}^{2} \\sum_{k=1}^{2} \\Pr(y_1 = 2 | z_1 = ) \\\\\n& \\qquad \\Pr(y_2 = 2 | z_2 = j) \\Pr(y_3 = 1 | z_3 = k) \\\\\n& \\qquad \\Pr(z_1=) \\Pr(z_2 = j | z_1 = ) \\\\\n& \\qquad \\Pr(z_3 = k | z_2 = j)\n\\end{split}\n\\end{align*}\\]Expliciting sums \\(\\Pr(y_1 = 2, y_2 = 2, y_3 = 1)\\), get long ugly expression:\\[\\begin{align*}\n\\begin{split}\n\\Pr(y_1 = 2, y_2 = 2, y_3 = 1) &= \\\\\n& \\Pr(y_1 = 2 | z_1 = 1) \\Pr(y_2 = 2 | z_2 = 1) \\Pr(y_3 = 1 | z_3 = 1) \\times \\\\\n& \\qquad \\Pr(z_1 = 1) \\Pr(z_2 = 1 | z_1 = 1) \\Pr(z_3 = 1 | z_2 = 1) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 2) \\Pr(y_2 = 2 | z_2 = 1) \\Pr(y_3 = 1 | z_3 = 1) \\times\\\\\n& \\qquad \\Pr(z_1 = 2) \\Pr(z_2 = 1 | z_1 = 2) \\Pr(z_3 = 1 | z_2 = 1) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 1) \\Pr(y_2 = 2 | z_2 = 2) \\Pr(y_3 = 1 | z_3 = 1) \\times\\\\\n& \\qquad \\Pr(z_1 = 1) \\Pr(z_2 = 2 | z_1 = 1) \\Pr(z_3 = 1 | z_2 = 2) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 2) \\Pr(y_2 = 2 | z_2 = 2) \\Pr(y_3 = 1 | z_3 = 1) \\times\\\\\n& \\qquad \\Pr(z_1 = 2) \\Pr(z_2 = 2 | z_1 = 2) \\Pr(z_3 = 1 | z_2 = 2) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 1) \\Pr(y_2 = 2 | z_2 = 1) \\Pr(y_3 = 1 | z_3 = 2) \\times\\\\\n& \\qquad \\Pr(z_1 = 1) \\Pr(z_2 = 1 | z_1 = 1) \\Pr(z_3 = 2 | z_2 = 1) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 2) \\Pr(y_2 = 2 | z_2 = 1) \\Pr(y_3 = 1 | z_3 = 2) \\times\\\\\n& \\qquad \\Pr(z_1 = 2) \\Pr(z_2 = 1 | z_1 = 2) \\Pr(z_3 = 2 | z_2 = 1) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 1) \\Pr(y_2 = 2 | z_2 = 2) \\Pr(y_3 = 1 | z_3 = 2) \\times\\\\\n& \\qquad \\Pr(z_1 = 1) \\Pr(z_2 = 2 | z_1 = 1) \\Pr(z_3 = 2 | z_2 = 2) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 2) \\Pr(y_2 = 2 | z_2 = 2) \\Pr(y_3 = 1 | z_3 = 2) \\times\\\\\n& \\qquad \\Pr(z_1 = 2) \\Pr(z_2 = 2 | z_1 = 2) \\Pr(z_3 = 2 | z_2 = 2)\\\\\n\\end{split}\n\\end{align*}\\]can simplify expression noticing ) individuals alive sure marked released first winter, \\(\\Pr(z_1=2) = 0\\) ii) dead individuals non-detected sure, \\(\\Pr(y_t = 2|z_t = 2) = 0\\), lead :\\[\\begin{align*}\n\\begin{split}\n\\Pr(y_1 = 2, y_2 = 2, y_3 = 1) &= \\\\\n& \\Pr(y_1 = 2 | z_1 = 1) \\Pr(y_2 = 2 | z_2 = 1) \\Pr(y_3 = 1 | z_3 = 1) \\times \\\\\n& \\qquad \\Pr(z_1 = 1) \\Pr(z_2 = 1 | z_1 = 1) \\Pr(z_3 = 1 | z_2 = 1) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 1) \\Pr(y_2 = 2 | z_2 = 1) \\Pr(y_3 = 1 | z_3 = 2) \\times\\\\\n& \\qquad \\Pr(z_1 = 1) \\Pr(z_2 = 1 | z_1 = 1) \\Pr(z_3 = 2 | z_2 = 1)\\\\\n\\end{split}\n\\end{align*}\\]individuals captured first winter, \\(\\Pr(y_1 = 2 | z_1 = 1) = 1\\), get:\\[\\begin{align*}\n\\Pr(y_1 = 2, y_2 = 2, y_3 = 1) =  1 (1-p) \\times 1 \\phi \\phi + 1 p 1 \\times 1 \\phi (1-\\phi)\n\\end{align*}\\]end \\(\\Pr(y_1 = 2, y_2 = 2, y_3 = 1) = \\phi p (1 - p\\phi)\\).latent states longer involved likelihood individual. However, even rather simple example, marginal likelihood quite complex evaluate involves many operations. \\(T\\) length encounter histories \\(N\\) number hidden states (two alive dead, deal states chapters come), need calculate sum \\(N^T\\) terms (sums formula ), two products \\(T\\) factors (products formula ), hence \\(2TN^T\\) calculations total. can check simple example , \\(T^N = 2^3 = 8\\) terms summed, product \\(2T = 2 \\times 3 = 6\\) terms. means number operations increases exponentially number states increases. cases, complexity precludes using method get rid states. Fortunately, another algorithm HMM toolbox useful calculate marginal likelihood efficiently.","code":""},{"path":"hmmcapturerecapture.html","id":"forward-algorithm","chapter":"3 Hidden Markov models","heading":"3.8.2 Forward algorithm","text":"brute-force approach, products computed several times calculate marginal likelihood. store products use later computing probability observation sequence? precisely forward algorithm .introduce \\(\\alpha_t(j)\\) probability latent state \\(z\\) state \\(j\\) \\(t\\) seeing first \\(j\\) observations \\(y_1, \\ldots, y_t\\), \\(\\alpha_t(j) = \\Pr(y_1, \\ldots, y_t, z_t = j)\\).Using law total probability, can write marginal likelihood function \\(\\alpha_T(j)\\), namely \\(\\Pr({y}) = \\displaystyle{\\sum_{j=1}^N\\Pr(y_1, \\ldots, y_t, z_t = j)} = \\displaystyle{\\sum_{j=1}^N\\alpha_T(j)}\\).calculate \\(\\alpha_T(j)\\)s? magic forward algorithm happens. use recurrence relationship saves us many computations.recurrence states :\\[\\begin{align*}\n\\alpha_t(j) &= \\sum_{=1}^N \\alpha_{t-1}() \\gamma_{,j} \\omega_{j,y_t}\n\\end{align*}\\]obtain recurrence? First, using law total probability \\(z_{t-1}\\), :\n\\[\\begin{align*}\n\\alpha_t(j) &= \\sum_{=1}^N \\Pr(y_1, \\ldots, y_t, z_{t-1} = , z_t = j)\\\\\n\\end{align*}\\]Second, using conditional probabilities, get:\n\\[\\begin{align*}\n\\alpha_t(j) &= \\sum_{=1}^N \\Pr(y_t | z_{t-1} = , z_t = j, y_1, \\ldots, y_t) \\Pr(z_{t-1} = , z_t = j, y_1, \\ldots, y_t)\n\\end{align*}\\]Third, using conditional probabilities , second term product, get:\n\\[\\begin{align*}\n\\alpha_t(j) &= \\sum_{=1}^N \\Pr(y_t | z_{t-1} = , z_t = j, y_1, \\ldots, y_t) \\times \\\\ & \\Pr(z_t = j | z_{t-1} = , y_1, \\ldots, y_t) \\Pr(z_{t-1} = , y_1, \\ldots, y_t)\n\\end{align*}\\], using conditional independence, simplifies :\\[\\begin{align*}\n\\alpha_t(j) &= \\sum_{=1}^N \\Pr(y_t | z_t = j) \\Pr(z_t = j | z_{t-1} = ) \\Pr(z_{t-1} = , y_1, \\ldots, y_t)\n\\end{align*}\\]Recognizing \\(\\Pr(y_{t}|z_{t}=j)=\\omega_{j,y_t}\\), \\(\\Pr(z_{t} = j | z_{t-1} = ) = \\gamma_{,j}\\) \\(\\Pr(z_{t-1} = , y_1, \\ldots, y_t) = \\alpha_{t-1}()\\), obtain recurrence.practice, forward algorithm works follows. First initialize procedure calculating states \\(j=1,\\ldots,N\\) quantities \\(\\alpha_1(j) = Pr(z_1 = j) \\omega_{j,y_1}\\). compute states \\(j=1,\\ldots,N\\) relationship \\(\\alpha_t(j) = \\displaystyle{\\sum_{=1}^N \\alpha_{t-1}() \\gamma_{,j} \\omega_{j,y_t}}\\) \\(t = 2, \\ldots, T\\). Finally, compute marginal likelihood \\(\\Pr({y}) = \\displaystyle{\\sum_{j=1}^N\\alpha_T(j)}\\). time \\(t\\), need calculate \\(N\\) values \\(\\alpha_t(j)\\), \\(\\alpha_t(j)\\) sum \\(N\\) products \\(\\alpha_{t-1}\\), \\(\\gamma_{,j}\\) \\(\\omega_{j,y_t}\\), hence \\(TN^2\\) computations total, much less \\(2TN^T\\) calculations brute-force approach.Going back example, wish calculate \\(\\Pr(y_1 = 2, y_2 = 2, y_3 = 1)\\). First initialize compute \\(\\alpha_1(1)\\) \\(\\alpha_1(2)\\). :\\[\\begin{align*}\n\\alpha_1(1) = \\Pr(z_1=1) \\omega_{1,y_1=2} = 1\n\\end{align*}\\]animals alive captured first winter. also :\\[\\begin{align*}\n\\alpha_1(2) = \\Pr(z_1=2) \\omega_{2,y_1=2} = 0\n\\end{align*}\\]compute \\(\\alpha_2(1)\\) \\(\\alpha_2(2)\\). :\\[\\begin{align*}\n\\alpha_2(1) &= \\sum_{=1}^2 \\alpha_1() \\gamma_{,1} \\omega_{1,y_2=2}\\\\\n            &= \\gamma_{1,1} \\omega_{1,y_2=2}\\\\\n            &= \\phi p\n\\end{align*}\\]\\(\\alpha_1(2) = 0\\). Also, :\\[\\begin{align*}\n\\alpha_2(2) &= \\sum_{=1}^2 \\alpha_1() \\gamma_{,2} \\omega_{2,y_2=2}\\\\\n            &= \\gamma_{1,2} \\omega_{2,y_2=2}\\\\\n            &= (1-\\phi) 0\n\\end{align*}\\]Finally compute \\(\\alpha_3(1)\\) \\(\\alpha_3(2)\\). :\\[\\begin{align*}\n\\alpha_3(1) &= \\sum_{=1}^2 \\alpha_2() \\gamma_{,1} \\omega_{1,y_3=1}\\\\\n            &= \\alpha_2(1) \\gamma_{1,1} \\omega_{1,y_3=1}\\\\\n            &= \\phi p \\phi (1-p)\n\\end{align*}\\]:\\[\\begin{align*}\n\\alpha_3(2) &= \\sum_{=1}^2 \\alpha_2() \\gamma_{,2} \\omega_{2,y_3=1}\\\\\n            &= \\alpha_2(1) \\gamma_{1,2} \\omega_{2,y_3=1}\\\\\n            &= \\phi p (1-\\phi) 1\n\\end{align*}\\]Eventually, compute \\(\\Pr(y_1=2,y_2=2,y_3=1)\\):\\[\\begin{align*}\n\\Pr(y_1=2,y_2=2,y_3=1) &= \\alpha_3(1) + \\alpha_3(2)\\\\\n            &= \\phi p (\\phi) (1-p) + \\phi p (1-\\phi)\\\\\n            &= \\phi p (1-\\phi p)\n\\end{align*}\\]can check total \\(3 \\times 2^2 = 12\\) operations.","code":""},{"path":"hmmcapturerecapture.html","id":"nimblemarginalization","chapter":"3 Hidden Markov models","heading":"3.8.3 NIMBLE implementation","text":"","code":""},{"path":"hmmcapturerecapture.html","id":"diymarginalisation","chapter":"3 Hidden Markov models","heading":"3.8.3.1 Do it yourself","text":"NIMBLE, use functions implement forward algorithm. differences theory ) work log scale numerical stability ii) use matrix formulation recurrence.First write density function:passing, function maximize frequentist approach (see Section 2.5). write function simulate values HMM:assign functions global R environment:Now resume workflow:run NIMBLE:numerical summaries similar obtained complete likelihood, effective samples sizes larger denoting better mixing:","code":"\ndHMMhomemade <- nimbleFunction(\n  run = function(x = double(1), \n                 probInit = double(1), # vector of initial states\n                 probObs = double(2), # observation matrix\n                 probTrans = double(2), # transition matrix\n                 len = double(0, default = 0), # nb sampling occ\n                 log = integer(0, default = 0)) {\n    alpha <- probInit[1:2] # * probObs[1:2,x[1]] == 1 due to \n                           # conditioning on first detection\n    for (t in 2:len) {\n    alpha[1:2]<-(alpha[1:2]%*%probTrans[1:2,1:2])*probObs[1:2,x[t]]\n    }\n    logL <- log(sum(alpha[1:2]))\n    returnType(double(0))\n    if (log) return(logL)\n    return(exp(logL))\n  }\n)\nrHMMhomemade <- nimbleFunction(\n  run = function(n = integer(),\n                 probInit = double(1),\n                 probObs = double(2),\n                 probTrans = double(2),\n                 len = double(0, default = 0)) {\n    returnType(double(1))\n    z <- numeric(len)\n    # all individuals alive at t = 0\n    z[1] <- rcat(n = 1, prob = probInit[1:2]) \n    y <- z\n    y[1] <- 2 # all individuals are detected at t = 0\n    for (t in 2:len){\n      # state at t given state at t-1\n      z[t] <- rcat(n = 1, prob = probTrans[z[t-1],1:2]) \n      # observation at t given state at t\n      y[t] <- rcat(n = 1, prob = probObs[z[t],1:2]) \n    }\n    return(y)\n  })\nassign('dHMMhomemade', dHMMhomemade, .GlobalEnv)\nassign('rHMMhomemade', rHMMhomemade, .GlobalEnv)\n# code\nhmm.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n  # likelihood\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    y[i,1:T] ~ dHMMhomemade(probInit = delta[1:2], \n                            probObs = omega[1:2,1:2], # observation\n                            probTrans = gamma[1:2,1:2], # transition\n                            len = T) # nb of sampling occasions\n  }\n})\n# constants\nmy.constants <- list(N = nrow(y), T = 5)\n# data\nmy.data <- list(y = y + 1)\n# initial values - no need to specify values for z anymore\ninitial.values <- function() list(phi = runif(1,0,1),\n                                  p = runif(1,0,1))\n# parameters to save\nparameters.to.save <- c(\"phi\", \"p\")\n# MCMC details\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nstart_time <- Sys.time()\nmcmc.output <- nimbleMCMC(code = hmm.survival,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nend_time <- Sys.time()\nend_time - start_time\n## Time difference of 39.62 secs\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.61 0.06 0.49 0.61  0.72    1  1211\n## phi 0.76 0.04 0.67 0.76  0.84    1  1483"},{"path":"hmmcapturerecapture.html","id":"nimbleecologyintro","chapter":"3 Hidden Markov models","heading":"3.8.3.2 Do it with nimbleEcology","text":"Writing NIMBLE functions easy. Fortunately, NIMBLE folks got covered. developed package nimbleEcology implements popular ecological models latent states.use function dHMMo provides distribution hidden Markov model time-independent transition matrix time-dependent observation matrix. time-dependent observation matrix? need tell NIMBLE detection first encounter 1.load package:NIMBLE code :may see longer states code use marginalized likelihood. dHMMo takes several arguments, including init vector initial state probabilities, probObs observation matrix, probTrans transition matrix len number sampling occasions.Next steps similar workflow used . difference need specify initial values latent states:Now run NIMBLE:Now display numerical summaries posterior distributions:results similar obtained previously home-made marginalized likelihood (Section 3.8.3.1), full likelihood (3.7).","code":"\nlibrary(nimbleEcology)\nhmm.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n  # likelihood\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  omega[1,1,1] <- 0        # Pr(alive first -> non-detected first)\n  omega[1,2,1] <- 1        # Pr(alive first -> detected first)\n  omega[2,1,1] <- 1        # Pr(dead first -> non-detected first)\n  omega[2,2,1] <- 0        # Pr(dead first -> detected first)\n  for (t in 2:5){\n    omega[1,1,t] <- 1 - p    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  for (i in 1:N){\n    y[i,1:5] ~ dHMMo(init = delta[1:2], # initial state probs\n                     probObs = omega[1:2,1:2,1:5], # obs matrix\n                     probTrans = gamma[1:2,1:2], # trans matrix\n                     len = 5, # nb of sampling occasions\n                     checkRowSums = 0) # skip validity checks\n  }\n})\n# constants\nmy.constants <- list(N = nrow(y))\n# data\nmy.data <- list(y = y + 1)\n# initial values - no need to specify values for z anymore\ninitial.values <- function() list(phi = runif(1,0,1),\n                                  p = runif(1,0,1))\n# parameters to save\nparameters.to.save <- c(\"phi\", \"p\")\n# MCMC details\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nstart_time <- Sys.time()\nmcmc.output <- nimbleMCMC(code = hmm.survival,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nend_time <- Sys.time()\nend_time - start_time\n## Time difference of 50.25 secs\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.61 0.06 0.49 0.61  0.72    1  1453\n## phi 0.76 0.04 0.67 0.76  0.84    1  1359"},{"path":"hmmcapturerecapture.html","id":"pooled-likelihood","chapter":"3 Hidden Markov models","heading":"3.9 Pooled encounter histories","text":"can go one step make convergence even faster. mentionned earlier Section 3.6.4, likelihood HMM fitted capture-recapture data often involves individuals share encounter histories. Instead repeating calculations several times, likelihood contribution shared say \\(x\\) individuals raised power \\(x\\) likelihood whole dataset, hence making operations . idea used routine capture-recapture software. Bayesian software, however, knowledge trick implemented NIMBLE (Turek, de Valpine, Paciorek 2016). grateful Chlo√© Nater pointing .section, amend NIMBLE functions wrote marginalizing latent states Section 3.8 express likelihood using pooled encounter histories. use vector size contains number individuals encounter history.density function function dHMMhomemade add size argument, raise individual likelihood power size, multiply size work log scale log(sum(alpha[1:2])) * size:rHMMhomemade function renamed rHMMpooled compatibility remains unchanged:assign two function global R environment can use :can now plug pooled HMM density function NIMBLE code:running NIMBLE, need actually pool individuals encounter history together:example, 21 individuals encounter history (1, 0, 0, 0, 0).Now can resume NIMBLE workflow:results obtained previously. gain computation times bigger complex models.pooled likelihood yet implemented nimbleEcology, can hack code function dHMMo https://github.com/nimble-dev/nimbleEcology/blob/master/R/dHMM.R implement adding size argument.","code":"\ndHMMpooled <- nimbleFunction(\n  run = function(x = double(1), \n                 probInit = double(1),\n                 probObs = double(2),\n                 probTrans = double(2),\n                 len = double(0),\n                 size = double(0),\n                 log = integer(0, default = 0)) {\n    alpha <- probInit[1:2]\n    for (t in 2:len) {\n    alpha[1:2]<-(alpha[1:2]%*%probTrans[1:2,1:2])*probObs[1:2,x[t]]\n    }\n    logL <- log(sum(alpha[1:2])) * size\n    returnType(double(0))\n    if (log) return(logL)\n    return(exp(logL))\n  }\n)\nrHMMpooled <- nimbleFunction(\n  run = function(n = integer(),\n                 probInit = double(1),\n                 probObs = double(2),\n                 probTrans = double(2),\n                 len = double(0),\n                 size = double(0)) {\n    returnType(double(1))\n    z <- numeric(len)\n    # all individuals alive at t = 0\n    z[1] <- rcat(n = 1, prob = probInit[1:2]) \n    y <- z\n    y[1] <- 2 # all individuals are detected at t = 0\n    for (t in 2:len){\n      # state at t given state at t-1\n      z[t] <- rcat(n = 1, prob = probTrans[z[t-1],1:2]) \n      # observation at t given state at t\n      y[t] <- rcat(n = 1, prob = probObs[z[t],1:2]) \n    }\n    return(y)\n  })\nassign('dHMMpooled', dHMMpooled, .GlobalEnv)\nassign('rHMMpooled', rHMMpooled, .GlobalEnv)\nhmm.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n  # likelihood\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    y[i,1:T] ~ dHMMpooled(probInit = delta[1:2], \n                          probObs = omega[1:2,1:2], # obs matrix\n                          probTrans = gamma[1:2,1:2], # trans matrix\n                          len = T, # nb of sampling occasions\n                          size = size[i]) # number of individuals \n                                          # with encounter history i\n  }\n})\ny_pooled <- y %>% \n  as_tibble() %>% \n  group_by_all() %>% # group\n  summarise(size = n()) %>% # count\n  relocate(size) %>% # put size in front\n  arrange(-size) %>% # sort along size\n  as.matrix()\ny_pooled\n##       size winter 1 winter 2 winter 3 winter 4 winter 5\n##  [1,]   21        1        0        0        0        0\n##  [2,]    8        1        1        0        0        0\n##  [3,]    8        1        1        1        1        0\n##  [4,]    4        1        1        0        0        1\n##  [5,]    4        1        1        1        0        0\n##  [6,]    2        1        0        0        1        0\n##  [7,]    2        1        0        1        1        0\n##  [8,]    2        1        1        0        1        0\n##  [9,]    1        1        0        1        0        0\n## [10,]    1        1        0        1        0        1\n## [11,]    1        1        0        1        1        1\n## [12,]    1        1        1        0        1        1\n## [13,]    1        1        1        1        0        1\n## [14,]    1        1        1        1        1        1\nmy.constants <- list(N = nrow(y_pooled), \n                     T = 5, \n                     size = y_pooled[,'size'])\nmy.data <- list(y = y_pooled[,-1] + 1) # delete size from dataset\ninitial.values <- function() list(phi = runif(1,0,1),\n                                  p = runif(1,0,1))\nparameters.to.save <- c(\"phi\", \"p\")\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nstart_time <- Sys.time()\nmcmc.output <- nimbleMCMC(code = hmm.survival,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nend_time <- Sys.time()\nend_time - start_time\n## Time difference of 42.68 secs\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.61 0.06 0.49 0.61  0.72    1  1455\n## phi 0.76 0.04 0.67 0.76  0.84    1  1524"},{"path":"hmmcapturerecapture.html","id":"decoding","chapter":"3 Hidden Markov models","heading":"3.10 Decoding after marginalization","text":"need infer latent states, afford computation times complete likelihood Section 3.6.4, can still use marginal likelihood forward algorithm Section 3.8.2. need extra step decode latent states Viterbi algorithm. Viterbi algorithm allows compute sequence states likely generated sequence observations.","code":""},{"path":"hmmcapturerecapture.html","id":"viterbi-theory","chapter":"3 Hidden Markov models","heading":"3.10.1 Theory","text":"simulated dataset, animal #15 encounter history (2, 1, 1, 1, 1) generated sequence states (1, 1, 2, 2, 2) survival probability \\(\\phi = 0.8\\) detection probability \\(p = 0.6\\).Imagine know truth. chance animal #15 alive throughout study observing encounter history detected first winter, missed subsequent winter? chance alive first winter detected alive 1. chance alive second winter non-detected \\(0.8 \\times (1-0.6) = 0.32\\). goes third, fourth fifth winters. total, probability alive throughout study animal encounter history (2, 1, 1, 1, 1) \\(1 \\times 0.32 \\times 0.32 \\times 0.32 \\times 0.32 = 0.01048576\\).Now chance animal #15 alive, dead rest study, observing encounter history (2, 1, 1, 1, 1)? chance alive first second winters, dead observing encounter history? . need enumerate possible sequences states compute probability , choose probable sequence, maximum probability. example, need compute \\(2^5 = 32\\) probabilities, \\(N^T\\) general. Needless say, calculations quickly become cumbersome, impossible, number states /number sampling occasions increases.Viterbi algorithm comes . idea decompose overall complex problem sequence smallers problems easier solve. dynamic programming rings bell, Viterbi algorithm look familiar . Viterbi algorithm based fact optimal path winter state can deduced optimal path previous winter state.first winter, probability alive detected 1, probability dead detected 0. Now probability alive second winter non-detected? animal alive first winter, remains alive missed probability \\(1 \\times \\phi (1-p) = 0.32\\). dead first winter, probability 0. maximum probability 0.32 obviously probable scenario alive second winter alive first winter. dead second winter? animal alive first winter, probability \\(1 \\times (1-\\phi) \\times 1 = 0.2\\). dead, probability \\(0 \\times 0 \\times (1-p) = 0\\). maximum probability 0.2 obviously probable scenario dead second winter alive first winter. calculations third, fourth fifth winters, get probabilities:Finally, get (decode) optimal path, work backwards trace back previous value yielded maximum probability. probable state last winter dead (1 > 0.05308416), dead fourth winter (1 > 0.110592), dead third winter (1 > 0.2304), alive second winter (1 > 0.48) alive firt winter (1 > 0). According Viterbi algorithm, sequence states likelily generated sequence observations (2, 1, 1, 1, 1) alive dead, dead, dead dead (1 2 2 2 2). differs slightly actual sequence states (1, 1, 2, 2, 2) state second winter decoded dead animal #15 dies third winter.contrast brute force approach, calculations duplicated stored used like forward algorithm. Briefly speaking, Viterbi algorithm works like forward algorithm sums replaced calculating maximums.practice, Viterbi algorithm works illustrated Figure 3.1. First initialize procedure calculating \\(t=1\\) states \\(j=1,\\ldots,N\\) values \\(\\nu_1(j) = Pr(z_1 = j) \\omega_{j,y_1}\\). compute states \\(j=1,\\ldots,N\\) values \\(\\nu_t(j) = \\displaystyle{\\max_{=1,\\ldots,N} \\nu_{t-1}() \\gamma_{,j} \\omega_{j,y_t}}\\) \\(t = 2, \\ldots, T\\). time \\(t\\) determine probability best path ending states \\(j=1,\\ldots,N\\). Finally, compute probability best global path \\(\\displaystyle{\\max_{j=1,\\ldots,N}\\nu_T(j)}\\).\nFigure 3.1: Graphical representation Viterbi algorithm \\(\\phi = 0.8\\) \\(p = 0.6\\). States alive \\(z = 1\\) dead \\(z = 2\\) observations non-detected \\(y = 1\\) detected \\(y = 2\\). done properly w/ tikz.\n","code":""},{"path":"hmmcapturerecapture.html","id":"implementation","chapter":"3 Hidden Markov models","heading":"3.10.2 Implementation","text":"Let‚Äôs write R function implement Viterbi algorithm. parameters, function take transition observation matrices, vector initial state probabilities observed sequence detections non-detections aim compute sequence states likely generated:Note instead writing R function, use built-function existing R package implement Viterbi algorithm (example, viterbi() function HMM depmixS4 packages), call NIMBLE seen Section 2.4.2. difficulty HMM capture-recapture data specific features make standard functions adapted requires coding Viterbi function. particular, deal detection first encounter, estimated always one individual captured marked released first time. Also, transition observation matrices always homogeneous may depend time.Let‚Äôs test getViterbi() function previous example. Remember animal #15 encounter history (2, 1, 1, 1, 1) generated sequence states (1, 1, 2, 2, 2). Applying function animal encounter history, get:Viterbi algorithm pretty well recovering latent states, despite incorrectly decoding death second winter individual #15 dies third winter. obtained results implementing Viterbi algorithm hand Section 3.10.1.Now function implements Viterbi algorithm, can use MCMC outputs. two options, either apply Viterbi MCMC iteration compute posterior median mode path individual, compute posterior mean median transition observation matrices apply Viterbi individual encounter history.options, need values posterior distributions survival detection probabilities:","code":"\n# getViterbi() returns sequence of states that most \n# likely generated sequence of observations\n# adapted from https://github.com/vbehnam/viterbi\ngetViterbi <- function(Omega, Gamma, delta, y) {\n# Omega: transition matrix\n# Gamma: observation matrix\n# delta: vector of initial state probabilities\n# y: observed sequence of detections and non-detections\n  \n# get number of states and sampling occasions\nN <- nrow(Gamma)\nT <- length(y)\n  \n# nu is the corresponding likelihood\nnu <- matrix(0, nrow = N, ncol = T)\n# zz contains the most likely states up until this point\nzz <- matrix(0, nrow = N, ncol = T)\nfirstObs <- y[1]\n  \n# fill in first columns of both matrices\n#nu[,1] <- initial * emission[,firstObs]\n#zz[,1] <- 0\nnu[,1] <- c(1,0) # initial = (1, 0) * emission[,firstObs] = (1, 0)\nzz[,1] <- 1 # alive at first occasion\n\nfor (i in 2:T) {\n    for (j in 1:N) {\n      obs <- y[i]\n      # initialize to -1, then overwritten by \n      # for loop coz all possible values are >= 0\n      nu[j,i] <- -1\n      # loop to find max and argmax for k\n      for (k in 1:N) {\n        value <- nu[k,i-1] * Gamma[k,j] * Omega[j,obs]\n        if (value > nu[j,i]) {\n          # maximizing for k\n          nu[j,i] <- value\n          # argmaximizing for k\n          zz[j,i] <- k\n        }\n      }\n    }\n  }\n  # mlp = most likely path\n  mlp <- numeric(T)\n  # argmax for stateSeq[,T]\n  am <- which.max(nu[,T])\n  mlp[T] <- zz[am,T]\n  \n  # backtrace using backpointers\n  for (i in T:2) {\n    zm <- which.max(nu[,i])\n    mlp[i-1] <- zz[zm,i]\n  }\n  return(mlp)\n}\ndelta # Vector of initial states probabilities\n## [1] 1 0\nGamma # Transition matrix\n##      [,1] [,2]\n## [1,]  0.8  0.2\n## [2,]  0.0  1.0\nOmega # Observation matrix\n##      [,1] [,2]\n## [1,]  0.4  0.6\n## [2,]  1.0  0.0\ngetViterbi(Omega = Omega, \n           Gamma = Gamma, \n           delta = delta, \n           y = y[15,] + 1)\n## [1] 1 2 2 2 2\nphi <- c(mcmc.output$chain1[,'phi'], mcmc.output$chain2[,'phi'])\np <- c(mcmc.output$chain1[,'p'], mcmc.output$chain2[,'p'])"},{"path":"hmmcapturerecapture.html","id":"compute-average","chapter":"3 Hidden Markov models","heading":"3.10.3 Compute first, average after","text":"First option apply Viterbi MCMC sample, compute median MCMC Viterbi paths observed sequence:\nFigure 3.2: Comparison actual sequences states sequences states decoded Viterbi average first, compute method.\nDecoding correct except alive actual state often decoded dead state Viterbi algorithm. Note compute Viterbi paths run NIMBLE. turn R function getViterbi() NIMBLE function plug model code apply Viterbi. make difference except perhaps increase MCMC computation times.","code":"\nniter <- length(p)\nT <- 5\nres <- matrix(NA, nrow = nrow(y), ncol = T)\nfor (i in 1:nrow(y)){\n  res_mcmc <- matrix(NA, nrow = niter, ncol = T)\n  for (j in 1:niter){\n    # Initial states\n    delta <- c(1, 0)\n    # Transition matrix\n    transition <- matrix(NA, 2, 2)\n    transition[1,1] <- phi[j]      # Pr(alive t -> alive t+1)\n    transition[1,2] <- 1 - phi[j]  # Pr(alive t -> dead t+1)\n    transition[2,1] <- 0        # Pr(dead t -> alive t+1)\n    transition[2,2] <- 1        # Pr(dead t -> dead t+1)\n    # Observation matrix \n    emission <- matrix(NA, 2, 2)\n    emission[1,1] <- 1 - p[j]      # Pr(alive t -> non-detected t)\n    emission[1,2] <- p[j]          # Pr(alive t -> detected t)\n    emission[2,1] <- 1          # Pr(dead t -> non-detected t)\n    emission[2,2] <- 0          # Pr(dead t -> detected t)\n    res_mcmc[j,1:T] <- getViterbi(Omega = emission, \n                                  Gamma = transition, \n                                  delta = delta, \n                                  y = y[i,] + 1)\n  }\n  res[i, 1:length(y[1,])] <- apply(res_mcmc, 2, median)\n}"},{"path":"hmmcapturerecapture.html","id":"average-first-compute-after","chapter":"3 Hidden Markov models","heading":"3.10.4 Average first, compute after","text":"Second option compute posterior mean observation transition matrices, apply Viterbi:\nFigure 3.3: Comparison actual sequences states sequences states decoded Viterbi compute first, average approach.\nresults similar obtained Section 3.10.3, Figure 3.3 indisguishable Figure 3.2.","code":"\n# Initial states\ndelta <- c(1, 0)\n# Transition matrix\ntransition <- matrix(NA, 2, 2)\ntransition[1,1] <- mean(phi)      # Pr(alive t -> alive t+1)\ntransition[1,2] <- 1 - mean(phi)  # Pr(alive t -> dead t+1)\ntransition[2,1] <- 0              # Pr(dead t -> alive t+1)\ntransition[2,2] <- 1              # Pr(dead t -> dead t+1)\n# Observation matrix \nemission <- matrix(NA, 2, 2)\nemission[1,1] <- 1 - mean(p)      # Pr(alive t -> non-detected t)\nemission[1,2] <- mean(p)          # Pr(alive t -> detected t)\nemission[2,1] <- 1                # Pr(dead t -> non-detected t)\nemission[2,2] <- 0                # Pr(dead t -> detected t)\nres <- matrix(NA, nrow = nrow(y), ncol = T)\nfor (i in 1:nrow(y)){\n  res[i, 1:length(y[1,]) ] <- getViterbi(Omega = emission, \n                                         Gamma = transition, \n                                         delta = delta, \n                                         y = y[i,] + 1)\n}"},{"path":"hmmcapturerecapture.html","id":"summary-2","chapter":"3 Hidden Markov models","heading":"3.11 Summary","text":"HMM model consists two parts: ) unobserved sequence discrete random variables - states - satisfying Markovian property (future states depends current states past states) ii) observed sequence discrete random variables - observations - depending current state.HMM model consists two parts: ) unobserved sequence discrete random variables - states - satisfying Markovian property (future states depends current states past states) ii) observed sequence discrete random variables - observations - depending current state.Bayesian approach together MCMC simulations allow estimating survival detection probabilities well individual latent states alive dead complete likelihood. can afford computation times, using complete likelihood easiest path model fitting.Bayesian approach together MCMC simulations allow estimating survival detection probabilities well individual latent states alive dead complete likelihood. can afford computation times, using complete likelihood easiest path model fitting.need infer latent states, can use marginal likelihood via forward algorithm. avoiding sample latent states, usually get better mixing faster convergence.need infer latent states, can use marginal likelihood via forward algorithm. avoiding sample latent states, usually get better mixing faster convergence.need infer latent states, afford computation times complete likelihood, can go marginal likelihood conjunction Viterbi algorithm decode latent states.need infer latent states, afford computation times complete likelihood, can go marginal likelihood conjunction Viterbi algorithm decode latent states.computational burden still issue, individuals share encounter history, can use pooled likelihood speed marginal likelihood evaluation MCMC convergence.computational burden still issue, individuals share encounter history, can use pooled likelihood speed marginal likelihood evaluation MCMC convergence.","code":""},{"path":"hmmcapturerecapture.html","id":"suggested-reading-2","chapter":"3 Hidden Markov models","heading":"3.12 Suggested reading","text":"landmark paper HMM Rabiner (1989).landmark paper HMM Rabiner (1989).Check Jurafsky Martin (2023) nice introduction HMM Zucchini, MacDonald, Langrock (2016) excellent book covers theory applications.Check Jurafsky Martin (2023) nice introduction HMM Zucchini, MacDonald, Langrock (2016) excellent book covers theory applications.paper McClintock et al. (2020) reviews applications HMM ecology.paper McClintock et al. (2020) reviews applications HMM ecology.package nimbleEcology developed Goldstein et al. (2021); see Ponisio et al. (2020) application occupancy N‚Äìmixture models.package nimbleEcology developed Goldstein et al. (2021); see Ponisio et al. (2020) application occupancy N‚Äìmixture models.","code":""},{"path":"introduction-4.html","id":"introduction-4","chapter":"Introduction","heading":"Introduction","text":"second part Transitions teach capture-recapture models open populations, reproducible R code ease learning process. code data available https://github.com/oliviergimenez/banana-book/tree/master/appendix.","code":""},{"path":"survival.html","id":"survival","chapter":"4 Alive and dead","heading":"4 Alive and dead","text":"","code":""},{"path":"survival.html","id":"introduction-5","chapter":"4 Alive and dead","heading":"4.1 Introduction","text":"fourth chapter, learn Cormack-Jolly-Seber model allows estimating survival based capture-recapture data. also see deal covariates try explain temporal /individual variation survival. chapter also opportunity introduce tools compare models assess quality fit data.","code":""},{"path":"survival.html","id":"the-cormack-jolly-seber-cjs-model","chapter":"4 Alive and dead","heading":"4.2 The Cormack-Jolly-Seber (CJS) model","text":"Chapter 3, introduced capture-recapture model constant survival detection probabilities formulated HMM fitted data NIMBLE. Historically, however, slightly complicated model first proposed ‚Äì -called Cormack-Jolly-Seber (CJS) model ‚Äì survival recapture probabilities time-varying. feature CJS model useful account variation due environmental conditions survival sampling effort detection. Schematically CJS model can represented way:Note states (gray) observations (white) change. still \\(z = 1\\) alive, \\(z = 2\\) dead, \\(y = 1\\) non-detected, \\(y = 2\\) detected.Parameters now indexed time. survival probability defined probability staying alive (‚Äúah, ha, ha, ha, stayin‚Äô alive‚Äù like Bee Gees say) interval \\(t\\) \\(t+1\\), \\(\\phi_t = \\Pr(z_{t+1} = 1 | z_t = 1)\\). detection probability defined probability observed \\(t\\) given ‚Äôre alive \\(t\\), \\(p_t = \\Pr(y_{t} = 1 | z_t = 1)\\). important bear mind later (see Section 4.8) survival operates interval detection occurs specific time.CJS model named three statisticians ‚Äì Richard Cormack, George Jolly George Seber ‚Äì published independently paper introducing less approach, year apart ! fact, Richard Cormack George Jolly working corridor Scotland back 1960‚Äôs. meet every day coffee play game together, never mention work aware ‚Äôs work.","code":""},{"path":"survival.html","id":"crdataeg","chapter":"4 Alive and dead","heading":"4.3 Capture-recapture data","text":"turn fitting CJS model actual data, let‚Äôs talk capture-recapture minute. said Section 3.6.1 animals individually marked. can accomplished two ways, either artificial marks like rings birds ear tags mammals, (non-invasive) natural marks like coat patterns feces DNA sequencing (Figure 4.1).\nFigure 4.1: Animal individual marking. Top-left: rings (credit: Emannuelle Cam Jean-Yves Monat); Top-right: ear-tags (credit: Kelly Powell); Bottom left: coat patterns (credit: Fridolin Zimmermann); Bottom right: ADN feces (credit: Alexander Kopatz)\nThroughout chapter, use data White-throated Dipper (Cinclus cinclus; dipper hereafter) kindly provided Gilbert Marzolin (Figure 4.2). total, 294 dippers known sex wing length captured recaptured 1981 1987 March-June period. Birds least 1 year old initially banded.\nFigure 4.2: White-throated Dipper (Cinclus cinclus). Credit: Gilbert Marzolin.\ndata look like:first seven columns years Gilbert went field captured birds. 0 stands non-detection, 1 detection. eighth column informs sex bird, F female M male. last column gives measure wing length first time bird captured.","code":"\ndipper <- read_csv(\"dipper.csv\")\ndipper## # A tibble: 294 √ó 9\n##    year_1981 year_1982 year_1983 year_1984 year_1985\n##        <dbl>     <dbl>     <dbl>     <dbl>     <dbl>\n##  1         1         1         1         1         1\n##  2         1         1         1         1         1\n##  3         1         1         1         1         0\n##  4         1         1         1         1         0\n##  5         1         1         0         1         1\n##  6         1         1         0         0         0\n##  7         1         1         0         0         0\n##  8         1         1         0         0         0\n##  9         1         1         0         0         0\n## 10         1         1         0         0         0\n## # ‚Ñπ 284 more rows\n## # ‚Ñπ 4 more variables: year_1986 <dbl>, year_1987 <dbl>,\n## #   sex <chr>, wing_length <dbl>"},{"path":"survival.html","id":"fitting-the-cjs-model-to-the-dipper-data-with-nimble","chapter":"4 Alive and dead","heading":"4.4 Fitting the CJS model to the dipper data with NIMBLE","text":"write NIMBLE code corresponding CJS model, need make adjustments NIMBLE code model constant parameters Section 3.7. main modification concerns observation transition matrices need make time-varying. matrices therefore become arrays inherit third dimension time, besides rows columns. Also need priors time-varying survival phi[t] ~ dunif(0, 1) detection p[t] ~ dunif(0, 1) probabilities. write:likelihood change, except time-varying observation transition matrices need used appropriately. Also, now deal several cohorts animals first captured, marked released year (contrast single cohort Chapter 3), need start loop time first capture individual. Therefore, write:first capture, individuals alive z[,first[]] ~ dcat(delta[1:2]) detection 1, first capture (j (first[]+1):T) apply transition observation matrices.\nOverall, code looks like:extract detections non-detections data:get occasion first capture individuals, finding position detections encounter history ((x !=0)), keeping first one:Now specify constants:put data list. add 1 data code non-detections 1‚Äôs detections 2‚Äôs (see Section 3.7).Let‚Äôs write function initial values. latent states, go easy way, say individuals alive study period:specify parameters like monitor, survival detection probabilities :provide MCMC details:run NIMBLE:may look numerical summaries:much time variation detection probability estimated high around 0.90. Note p[1] corresponds detection probability 1982 \\(p_2\\), p[2] detection 1983 therefore \\(p_3\\), . dippers seem experienced decrease survival years 1982-1983 (phi[2]) 1983-1984 (phi[4]). get back Section 4.8.may noticed small effective sample size last survival (phi[6]) detection (p[6]) probabilities. Let‚Äôs look mixing parameter phi[6] example:Clearly mixing (left panel plot ) bad big overlap prior posterior parameter (right panel) suggesting prior well updated data. going ? inspect likelihood CJS model, realize two parameters \\(\\phi_6\\) \\(p_7\\) appear product \\(\\phi_6 p_7\\) estimated separately. words, one parameters redundant, ‚Äôd need extra sampling occasion able disentangle . big issue long ‚Äôre aware attempt ecologically interpret parameters.","code":"\n...\n# parameters\n  delta[1] <- 1                 # Pr(alive t = 1) = 1\n  delta[2] <- 0                 # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1)        # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1           # Pr(dead t -> dead t+1)\n    p[t] ~ dunif(0, 1)          # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1           # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0           # Pr(dead t -> detected t)\n  }\n...\n...\n# likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n...\nhmm.phitpt <- nimbleCode({\n  # parameters\n  delta[1] <- 1                 # Pr(alive t = 1) = 1\n  delta[2] <- 0                 # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1)        # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1           # Pr(dead t -> dead t+1)\n    p[t] ~ dunif(0, 1)          # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1           # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0           # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})\ny <- dipper %>%\n  select(year_1981:year_1987) %>%\n  as.matrix()\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nmy.constants <- list(N = nrow(y),   # number of animals\n                     T = ncol(y),   # number of sampling occasions\n                     first = first) # first capture for all animales\nmy.data <- list(y = y + 1)\nzinits <- y + 1 # non-detection -> alive\nzinits[zinits == 2] <- 1 # dead -> alive\ninitial.values <- function() list(phi = runif(my.constants$T-1,0,1),\n                                  p = runif(my.constants$T-1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"phi\", \"p\")\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nmcmc.phitpt <- nimbleMCMC(code = hmm.phitpt,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\nMCMCsummary(mcmc.phitpt, params = c(\"phi\",\"p\"), round = 2)\n##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi[1] 0.72 0.13 0.45 0.72  0.96 1.00   553\n## phi[2] 0.45 0.07 0.32 0.45  0.60 1.01  1175\n## phi[3] 0.48 0.06 0.36 0.48  0.60 1.00  1320\n## phi[4] 0.63 0.06 0.51 0.63  0.75 1.01  1041\n## phi[5] 0.60 0.06 0.49 0.60  0.71 1.01  1030\n## phi[6] 0.70 0.14 0.49 0.69  0.97 1.00    86\n## p[1]   0.67 0.13 0.39 0.67  0.90 1.00   923\n## p[2]   0.87 0.08 0.68 0.88  0.98 1.00   690\n## p[3]   0.88 0.06 0.73 0.89  0.97 1.00   840\n## p[4]   0.88 0.06 0.75 0.89  0.96 1.02   860\n## p[5]   0.90 0.05 0.79 0.91  0.98 1.01   740\n## p[6]   0.76 0.14 0.51 0.77  0.98 1.00    95\npriors <- runif(3000, 0, 1)\nMCMCtrace(object = mcmc.phitpt,\n          ISB = FALSE,\n          exact = TRUE, \n          params = c(\"phi[6]\"),\n          pdf = FALSE, \n          priors = priors)"},{"path":"survival.html","id":"cjsderivatives","chapter":"4 Alive and dead","heading":"4.5 CJS model derivatives","text":"Besides model considered constant parameters (see Chapter 3) CJS model time-varying parameters, might want fit -models time variation either detection survival.realize actually fit model constant parameters Chapter 3. Let‚Äôs . familiar process now:Let‚Äôs now turn model time-varying survival constant detection. modify CJS model NIMBLE code longer observation matrix time-specific. ‚Äôm just providing model code save space:obtain following numerical summaries parameters, confirming high detection temporal variation survival:Now model time-varying detection constant survival, NIMBLE code constant time transition matrix:Numerical summaries parameters :note two models longer parameter redundancy issues.move next section, might ask fit models nimbleEcology Section 3.8.3. Conveniently specific NIMBLE functions marginalized likelihood CJS model derivatives. function named generically dCJSxx() first x survival second x detection x can s scalar constant v vector time-dependent. example, implement model constant survival detection probabilities, use dCJSss():left four models, saying different story data, temporal variation either survival detection probability. quantify plausible four ecological hypotheses? Rendez-vous next section.","code":"\n# NIMBLE code \nhmm.phip <- nimbleCode({\n  phi ~ dunif(0, 1)      # prior survival\n  p ~ dunif(0, 1)        # prior detection\n  # likelihood\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\n# occasions of first capture\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\n# constants\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first)\n# data\nmy.data <- list(y = y + 1)\n# initial values\nzinits <- y + 1 # non-detection -> alive\nzinits[zinits == 2] <- 1 # dead -> alive\ninitial.values <- function() list(phi = runif(1,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\n# parameters to monitor\nparameters.to.save <- c(\"phi\", \"p\")\n# MCMC details\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\n# run NIMBLE\nmcmc.phip <- nimbleMCMC(code = hmm.phip, \n                        constants = my.constants,\n                        data = my.data,              \n                        inits = initial.values,\n                        monitors = parameters.to.save,\n                        niter = n.iter,\n                        nburnin = n.burnin, \n                        nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n# numerical summaries\nMCMCsummary(mcmc.phip, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.90 0.03 0.83 0.90  0.94 1.00   661\n## phi 0.56 0.02 0.51 0.56  0.61 1.01  1633\nhmm.phitp <- nimbleCode({\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1)        # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1           # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi[1] 0.63 0.11 0.41 0.63  0.84    1  1407\n## phi[2] 0.46 0.07 0.33 0.46  0.60    1  1350\n## phi[3] 0.48 0.06 0.37 0.48  0.59    1  1586\n## phi[4] 0.62 0.06 0.51 0.62  0.73    1  1528\n## phi[5] 0.61 0.06 0.50 0.61  0.71    1  1463\n## phi[6] 0.59 0.06 0.48 0.59  0.71    1  1101\n## p      0.89 0.03 0.82 0.89  0.94    1   595\nhmm.phipt <- nimbleCode({\n  phi ~ dunif(0, 1)      # prior survival\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    p[t] ~ dunif(0, 1)       # prior detection\n    omega[1,1,t] <- 1 - p[t] # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]     # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})##      mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi  0.56 0.03 0.51 0.56  0.61 1.00  1296\n## p[1] 0.74 0.12 0.49 0.74  0.93 1.00  1369\n## p[2] 0.84 0.08 0.66 0.85  0.98 1.01   744\n## p[3] 0.84 0.07 0.68 0.85  0.96 1.00   722\n## p[4] 0.89 0.05 0.77 0.89  0.97 1.00   962\n## p[5] 0.92 0.04 0.81 0.92  0.98 1.00  1123\n## p[6] 0.90 0.07 0.74 0.91  1.00 1.01   378\n# load nimbleEcology in case we forgot previously\nlibrary(nimbleEcology)\n# data\ny <- dipper %>%\n  select(year_1981:year_1987) %>%\n  as.matrix()\ny <- y[ first != ncol(y), ] # get rid of individuals for which \n                            # first detection = last capture\n# NIMBLE code\nhmm.phip.nimbleecology <- nimbleCode({\n  phi ~ dunif(0, 1) # survival prior\n  p ~ dunif(0, 1)   # detection prior\n  # likelihood\n  for (i in 1:N){\n    y[i, first[i]:T] ~ dCJS_ss(probSurvive = phi, \n                               probCapture = p, \n                               len = T - first[i] + 1)\n  }\n})\n# occasions of first capture\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\n# constants\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first)\n# data\nmy.data <- list(y = y) # 0 = non-detected, 1 = detected\n# initial values: marginalized likelihood, hence no latent states \n# therefore no need for initial values for latent states\ninitial.values <- function() list(phi = runif(1,0,1),\n                                  p = runif(1,0,1))\n# parameters to monitor\nparameters.to.save <- c(\"phi\", \"p\")\n# MCMC details\nn.iter <- 2500\nn.burnin <- 1000\nn.chains <- 2\n# run NIMBLE\nmcmc.phip.nimbleecology <- nimbleMCMC(code = hmm.phip.nimbleecology, \n                        constants = my.constants,\n                        data = my.data,              \n                        inits = initial.values,\n                        monitors = parameters.to.save,\n                        niter = n.iter,\n                        nburnin = n.burnin, \n                        nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n# numerical summaries\nMCMCsummary(mcmc.phip.nimbleecology, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.90 0.03 0.83 0.90  0.94 1.00   668\n## phi 0.56 0.02 0.51 0.56  0.61 1.01   723"},{"path":"survival.html","id":"waic","chapter":"4 Alive and dead","heading":"4.6 Model comparison with WAIC","text":"four models best supported data? address question, need remember used observed data fit models. really matters well model perform predicting future data, property known predictive accuracy. natural measure predictive accuracy likelihood, often referred context model comparison predictive density. practice, however, know true process future data, predictive density can estimated, bias.may heard Akaike Information Criterion (AIC) frequentist framework, Deviance Information Criterion (DIC) Bayesian framework. , also consider Widely Applicable Information Criterion Watanabe Information Criterion (WAIC). AIC, DIC WAIC aim provide approximation predictive accuracy.AIC predictive measure choice frequentist framework ecologists, DIC around time Bayesian applications due availability popular BUGS pieces software. However, AIC BIC use point estimate unknown parameters, access entire (posterior) distribution Bayesian approach. Also, DIC shown misbehave posterior distribution well summarized mean. fully Bayesian approach like use entire posterior distribution evaluate predictive performance, exactly WAIC .Conveniently, NIMBLE calculates WAIC . modification need make add WAIC = TRUE call nimbleMCMC() function. example, CJS model, write:re-ran four models calculate WAIC value themLower values WAIC imply higher predictive accuracy, thefore favor model constant parameters.","code":"\nmcmc.phitpt <- nimbleMCMC(code = hmm.phitpt,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains,\n                          WAIC = TRUE) \ndata.frame(model = c(\"both survival & detection constant\",\n                     \"time-dependent survival, constant detection\",\n                     \"constant survival, time-dependent detection\",\n                     \"both survival & detection time-dependent\"),\n           WAIC = c(mcmc.phip$WAIC$WAIC,\n                    mcmc.phitp$WAIC$WAIC,\n                    mcmc.phipt$WAIC$WAIC,\n                    mcmc.phitpt$WAIC$WAIC))##                                         model  WAIC\n## 1          both survival & detection constant 266.7\n## 2 time-dependent survival, constant detection 273.0\n## 3 constant survival, time-dependent detection 270.9\n## 4    both survival & detection time-dependent 308.9"},{"path":"survival.html","id":"gof","chapter":"4 Alive and dead","heading":"4.7 Goodness of fit","text":"previous section, Section 4.6, compared models based predictive accuracy ‚Äì assessed relative fit. However, even though able rank models according predictive accuracy, happen models actually poor predictive performance ‚Äì absolute fit.assess goodness fit CJS model capture-recapture data?","code":""},{"path":"survival.html","id":"posterior-predictive-checks","chapter":"4 Alive and dead","heading":"4.7.1 Posterior predictive checks","text":"Bayesian framework, use posterior predictive checks assess absolute model fit. basic idea compare observed data replicated data generated model. model good fit data, replicated data predicted model look similar observed data. make comparison tractable, summary statistics generally used. CJS model, often done m-array, records number individuals released given year first recaptured subsequent years. examples, see K√©ry Schaub (2011), Paganin de Valpine (2025), NIMBLE website https://r-nimble.org/examples/posterior_predictive.html.Posterior predictive checks powerful tools. However, long-established procedures evaluating absolute fit diagnosing violations specific CJS model assumptions, shame ignore .","code":""},{"path":"survival.html","id":"classical-tests","chapter":"4 Alive and dead","heading":"4.7.2 Classical tests","text":"focus two assumptions ecological interpretation: transience trap-dependence. transience test evaluates whether newly encountered individuals likely detected previously encountered ones. signal transience often seen excess individuals never seen . trap-dependence test evaluates whether individuals detected given occasion likely detected next occasion . Trap-dependence often seen effect trapping detection. Although tests commonly referred test transience test trap-dependence, keep mind transience trap-dependence two possible reasons tests may reveal lack fit.tests implemented package R2ucare, illustrate use dipper data.load package R2ucare:get capture-recapture data:may perform test specifically assess transient effect:trap-dependence:None tests significant, tests significant?\nTransience can occur different reasons. animals may simply pass without belonging study population (true transients). Others may reproduce die permanently disperse, reflecting cost first reproduction. cases, marking may cause individuals die leave area. Whatever cause, transient individuals never detected initial capture, probability local survival zero initial capture.suggests way account transience modeling two-age class effect survival, age refers biological age time since first capture. first age class, Age 1, corresponds newly marked interval immediately following capture. transients live: true transients, never seen local survival marking effectively 0. second age class, Age 2+ corresponds established residents subsequent intervals individuals remained study population beyond first interval.allow survival differ two ages, defining \\(\\phi_1\\) apparent survival first interval initial capture, \\(\\phi_{2+}\\) apparent survival subsequent intervals. transients, \\(\\phi_1\\) pulled lower \\(\\phi_{2+}\\), since first interval mixes true residents (survive locally probability \\(\\phi_{2+}\\)) transients (never survive locally next occasion). useful quantity compute transient proportion \\(\\tau\\), defined \\(\\displaystyle \\tau = 1 - \\frac{\\phi_{1}}{\\phi_{2+}}\\).later see Section 4.8.5 encode age effect survival, use approach just described account transience Section 7.2. Note also transience can represented states HMM (see Genovart Pradel 2019 details).Trap-dependence may arise several ways. can occur animals directly affected trapping, either positively negatively (true trap-dependence). may also result observers visiting parts study area often individuals detected (preferential sampling), habitat heterogeneity, patches accessible individuals located higher detection probabilities (access bias). Trap-dependence can also reflect individual differences age, sex, social status influence movements activity patterns thus detection probability (individual heterogeneity). Finally, may arise temporary emigration non-random, instance individuals skip reproduction (skipped reproduction).short, trap-dependence designates form correlation detection events. address issue, correlation needs accounted , show case study Section 7.2.","code":"\n# To install the R2ucare package:\n# if(!require(devtools)) install.packages(\"devtools\")\n# devtools::install_github(\"oliviergimenez/R2ucare\")\nlibrary(R2ucare)\n# capture-recapture data\ndipper <- read_csv(\"dat/dipper.csv\")\n# get encounter histories\ny <- dipper %>%\n  select(year_1981:year_1987) %>%\n  as.matrix()\n# number of birds with a particular capture-recapture history\nsize <- rep(1, nrow(y))\ntest3sr(y, size)\n## $test3sr\n##      stat        df     p_val sign_test \n##     1.773     5.000     0.880    -0.054 \n## \n## $details\n##   component  stat p_val signed_test  test_perf\n## 1         2  0.08 0.778       0.283 Chi-square\n## 2         3 0.232  0.63       0.482 Chi-square\n## 3         4 0.847 0.358       -0.92 Chi-square\n## 4         5 0.288 0.592      -0.537 Chi-square\n## 5         6 0.326 0.568       0.571 Chi-square\ntest2ct(y, size)\n## $test2ct\n##      stat        df     p_val sign_test \n##     9.463     4.000     0.051    -1.538 \n## \n## $details\n##   component dof  stat p_val signed_test test_perf\n## 1         2   1     0     1           0    Fisher\n## 2         3   1     0     1           0    Fisher\n## 3         4   1     0     1           0    Fisher\n## 4         5   1 9.463 0.002      -3.076    Fisher"},{"path":"survival.html","id":"design-considerations","chapter":"4 Alive and dead","heading":"4.7.3 Design considerations","text":"far, considered assumptions related model. also assumptions tied study design. particular, talk survival, always reference study area, need clear means. estimate usually called apparent survival, true survival. Apparent survival product true survival site fidelity, therefore always lower true survival unless fidelity equals one.design assumptions worth noting, list . Marks lost, individual identity recorded without error (false positives), captured animals represent random sample population.","code":""},{"path":"survival.html","id":"covariates","chapter":"4 Alive and dead","heading":"4.8 Covariates","text":"models considered far, survival detection probabilities may vary time, include ecological drivers might explain variation. Luckily, spirit generalized linear models, can make parameters dependent external covariates time, environmental conditions survival sampling effort detection.Besides variation time, also cover individual variation parameters, example survival vary according sex phenotypic characteristics (e.g.¬†size body mass).Let‚Äôs illustrate use covariates dipper example.","code":""},{"path":"survival.html","id":"temporal-covariates","chapter":"4 Alive and dead","heading":"4.8.1 Temporal covariates","text":"","code":""},{"path":"survival.html","id":"discrete","chapter":"4 Alive and dead","heading":"4.8.1.1 Discrete","text":"major flood occurred 1983 breeding season (October 1982 May 1983). captures breeding season occurred flood, survival two years 1982-1983 1983-1984 likely affected. Indeed survival species living along feeding river two flood years likely lower nonflood years. use discrete categorical covariate, group.Let‚Äôs use covariate flood contains 1s 2s, indicating whether flood nonflood year year: 1 nonflood year, 2 flood year.write model code:use nested indexing specifying survival transition matrix. E.g. year \\(t = 2\\), phi[flood[t]] gives phi[flood[2]] phi[2] flood[2] 2 (flood year).Let‚Äôs provide constants list:Now function generate initial values:parameters monitored:MCMC details:‚Äôre set, run NIMBLE:numerical summaries given :look numerical summaries, see expected, survival flood years (phi[2]) much lower survival non-flood years (phi[1]). formally test difference considering difference phi[1] - phi[2]. Alternatively, can done afterwards calculating probability difference positive (phi[1] > phi[2]). Using single chain convenience, :important point formulated ecological hypothesis translated model. next step consist calculating WAIC model compare four model fitted far (see Section 4.6).Another method include discrete covariate consists considering effect difference levels. example, consider survival nonflood years reference test difference survival flood years., write survival linear function covariate scale, e.g.¬†\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 \\;\\text{flood}_t\\) \\(\\beta\\)‚Äôs regression coefficients need estimate (intercept \\(\\beta_1\\) slope \\(\\beta_2\\)), \\(\\text{logit}(x) = \\log \\displaystyle{\\left(\\frac{x}{1-x}\\right)}\\) logit function. logit function lives \\(-\\infty\\) \\(+\\infty\\), sends values 0 1 onto real line. example \\(\\log(0.2/(1-0.2))=-1.39\\), \\(\\log(0.5/(1-0.5))=0\\) \\(\\log(0.8/(1-0.8))=1.39\\). use logit function? survival probability bounded 0 1, used directly \\(\\phi_t = \\beta_1 + \\beta_2 \\;\\text{flood}_t\\) might end estimates regression coefficients make survival bound. Therefore, consider survival linear function covariates scale logit function, working real line, back-transform using inverse-logit (reciprocal function) obtain survival natural scale. inverse-logit function \\(\\displaystyle{\\text{logit}^{-1}(x) = \\frac{\\exp(x)}{1+\\exp(x)} = \\frac{1}{1+\\exp(-x)}}\\). logit function often called link function like generalized linear models. link functions exist, ‚Äôll see example Section 5.4.2.Another point attention prior assign regression coefficients. longer assign prior survival directly like previously, need assign prior \\(\\beta\\)‚Äôs induce prior survival. sometimes, priors regression coefficients non-informative, prior survival . Consider example case single intercept covariate. assign prior regression coefficient normal distribution mean 0 large standard deviation (left figure ), first reflex, end informative prior survival bathtub shape, putting much importance low high values (right figure ):Now go lower standard deviation intercept prior (left figure ), e.g.¬†1.5, prior survival non-informative, looking like uniform distribution 0 1 (right figure ):Now let‚Äôs go back model. first define flood covariate 0 nonflood year, 1 flood year:write NIMBLE code:wrote \\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 \\; \\text{flood}_t\\), meaning survival nonflood years (\\(\\text{flood}_t = 0\\)) \\(\\text{logit}(\\phi_t) = \\beta_1\\) survival flood years (\\(\\text{flood}_t = 1\\)) \\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2\\). see \\(\\beta_1\\) survival nonflood years (logit scale) \\(\\beta_2\\) difference survival flood years survival nonflood years (, logit scale). passing assigned prior \\(\\beta_1\\) \\(\\beta_2\\) certain situations, might think twice \\(\\beta_2\\) difference two survival probabilities (logit scale).Let‚Äôs put constants list:function generating initial values:parameters monitored:Finaly, run NIMBLE:may check get numerical summaries survival nonflood years (phi[1], phi[4], phi[5] phi[6]) flood years (phi[2] phi[3]):may also check go \\(\\beta\\)‚Äôs survival probabilities \\(\\phi\\). Let‚Äôs get draws posterior distribution \\(\\beta\\)‚Äôs first:apply inverse-logit function get survival nonflood years, e.g.¬†posterior mean credible interval:thing survival flood years:","code":"\nflood <- c(1, # 1981-1982 (nonflood)\n           2, # 1982-1983 (flood)\n           2, # 1983-1984 (flood)\n           1, # 1984-1985 (nonflood)\n           1, # 1985-1986 (nonflood)\n           1) # 1986-1987 (nonflood)\nhmm.phifloodp <- nimbleCode({\n  delta[1] <- 1                        # Pr(alive t = 1) = 1\n  delta[2] <- 0                        # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    gamma[1,1,t] <- phi[flood[t]]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[flood[t]]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0                  # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1                  # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1)        # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  phi[1] ~ dunif(0, 1)   # prior for survival in nonflood years\n  phi[2] ~ dunif(0, 1)   # prior for survival in flood years\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y),\n                     T = ncol(y),\n                     first = first,\n                     flood = flood)\ninitial.values <- function() list(phi = runif(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"p\", \"phi\")\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nmcmc.phifloodp <- nimbleMCMC(code = hmm.phifloodp, \n                             constants = my.constants,\n                             data = my.data,              \n                             inits = initial.values,\n                             monitors = parameters.to.save,\n                             niter = n.iter,\n                             nburnin = n.burnin, \n                             nchains = n.chains)\nMCMCsummary(mcmc.phifloodp, round = 2)##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p      0.89 0.03 0.83 0.90  0.95    1   609\n## phi[1] 0.61 0.03 0.55 0.61  0.67    1  1474\n## phi[2] 0.47 0.04 0.38 0.47  0.56    1  1700\nphi1 <- mcmc.phifloodp$chain1[,'phi[1]']\nphi2 <- mcmc.phifloodp$chain1[,'phi[2]']\nmean(phi1 - phi2 > 0)\n## [1] 0.9952\n# 1000 random values from a N(0,10)\nintercept <- rnorm(1000, mean = 0, sd = 10) \n# plogis() is the inverse-logit function in R\nsurvival <- plogis(intercept) \ndf <- data.frame(intercept = intercept, survival = survival)\nplot1 <- df %>%\n  ggplot(aes(x = intercept)) +\n  geom_density() +\n  labs(x = \"prior on intercept\")\nplot2 <- df %>%\n  ggplot(aes(x = survival)) +\n  geom_density() +\n  labs(x = \"prior on survival\")\nplot1 + plot2\nset.seed(123)\n# 1000 random values from a N(0,1.5)\nintercept <- rnorm(1000, mean = 0, sd = 1.5) \n# plogis() is the inverse-logit function in R\nsurvival <- plogis(intercept) \ndf <- data.frame(intercept = intercept, survival = survival)\nplot1 <- df %>%\n  ggplot(aes(x = intercept)) +\n  geom_density() +\n  labs(x = \"prior on intercept\")\nplot2 <- df %>%\n  ggplot(aes(x = survival)) +\n  geom_density() +\n  labs(x = \"prior on survival\")\nplot1 + plot2\nflood <- c(0, # 1981-1982 (nonflood)\n           1, # 1982-1983 (flood)\n           1, # 1983-1984 (flood)\n           0, # 1984-1985 (nonflood)\n           0, # 1985-1986 (nonflood)\n           0) # 1986-1987 (nonflood)\nhmm.phifloodp <- nimbleCode({\n  delta[1] <- 1                 # Pr(alive t = 1) = 1\n  delta[2] <- 0                 # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    logit(phi[t]) <- beta[1] + beta[2] * flood[t]\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1           # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1)               # prior detection\n  omega[1,1] <- 1 - p           # Pr(alive t -> non-detected t)\n  omega[1,2] <- p               # Pr(alive t -> detected t)\n  omega[2,1] <- 1               # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0               # Pr(dead t -> detected t)\n  beta[1] ~ dnorm(0, sd = 1.5)  # prior intercept\n  beta[2] ~ dnorm(0, sd = 1.5)  # prior slope\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y),\n                     T = ncol(y),\n                     first = first,\n                     flood = flood)\ninitial.values <- function() list(beta = rnorm(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"beta\", \"p\", \"phi\")\nmcmc.phifloodp <- nimbleMCMC(code = hmm.phifloodp, \n                             constants = my.constants,\n                             data = my.data,              \n                             inits = initial.values,\n                             monitors = parameters.to.save,\n                             niter = n.iter,\n                             nburnin = n.burnin, \n                             nchains = n.chains)\nMCMCsummary(mcmc.phifloodp, round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.44 0.13  0.17  0.44  0.69 1.01   725\n## beta[2] -0.54 0.22 -0.96 -0.54 -0.11 1.00   770\n## p        0.89 0.03  0.83  0.89  0.94 1.00   631\n## phi[1]   0.61 0.03  0.54  0.61  0.67 1.01   724\n## phi[2]   0.47 0.04  0.39  0.47  0.56 1.00  1597\n## phi[3]   0.47 0.04  0.39  0.47  0.56 1.00  1597\n## phi[4]   0.61 0.03  0.54  0.61  0.67 1.01   724\n## phi[5]   0.61 0.03  0.54  0.61  0.67 1.01   724\n## phi[6]   0.61 0.03  0.54  0.61  0.67 1.01   724\nbeta1 <- c(mcmc.phifloodp$chain1[,'beta[1]'], # beta1 chain 1\n           mcmc.phifloodp$chain2[,'beta[1]']) # beta1 chain 2\nbeta2 <- c(mcmc.phifloodp$chain1[,'beta[2]'], # beta2 chain 1\n           mcmc.phifloodp$chain2[,'beta[2]']) # beta2 chain 2\nmean(plogis(beta1))\n## [1] 0.6066\nquantile(plogis(beta1), probs = c(2.5, 97.5)/100)\n##   2.5%  97.5% \n## 0.5435 0.6651\nmean(plogis(beta1 + beta2))\n## [1] 0.4744\nquantile(plogis(beta1 + beta2), probs = c(2.5, 97.5)/100)\n##   2.5%  97.5% \n## 0.3895 0.5606"},{"path":"survival.html","id":"continuous","chapter":"4 Alive and dead","heading":"4.8.1.2 Continuous","text":"Instead discrete covariate varying time, may want consider continuous covariate, say \\(x_t\\), \\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\). example, let‚Äôs investigate effect water flow dipper survival, reflect flood occurred 1983 breeding season.build covariate water flow liters per second measured March May period year, starting year 1982:need water flow 1981 write probability \\(\\phi_t\\) alive year \\(t + 1\\) given bird alive year \\(t\\) linear function water flow year \\(t + 1\\).may noticed high value water flow 1983, twice much years, corresponding flood. Importantly, standardize covariate improve convergence:Now write model code:put constants list:Initial values usual:parameters monitored:Eventually, run NIMBLE:can look results caterpillar plot regression parameters:posterior distribution slope (beta[2]) centered negative values, suggesting water flow increases, survival decreases.Let‚Äôs inspect time-dependent survival probability:Survival 1982 1983 (phi[2]) greatly affected much lower average. decrease corresponds high water flow 1983 flood. results line previous findings obtained considering discrete covariate nonflood vs.¬†flood years.","code":"\n# water flow in L/s\nwater_flow <- c(443,  # March-May 1982\n                1114, # March-May 1983\n                529,  # March-May 1984\n                434,  # March-May 1985\n                627,  # March-May 1986\n                466)  # March-May 1987\nwater_flow_st <- (water_flow - mean(water_flow))/sd(water_flow)\nhmm.phiflowp <- nimbleCode({\n  delta[1] <- 1                 # Pr(alive t = 1) = 1\n  delta[2] <- 0                 # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    logit(phi[t]) <- beta[1] + beta[2] * flow[t] \n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1           # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1)               # prior detection\n  omega[1,1] <- 1 - p           # Pr(alive t -> non-detected t)\n  omega[1,2] <- p               # Pr(alive t -> detected t)\n  omega[2,1] <- 1               # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0               # Pr(dead t -> detected t)\n  beta[1] ~ dnorm(0, 1.5)       # prior intercept\n  beta[2] ~ dnorm(0, 1.5)       # prior slope\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y),\n                     T = ncol(y),\n                     first = first,\n                     flow = water_flow_st)\ninitial.values <- function() list(beta = rnorm(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"beta\", \"p\", \"phi\")\nmcmc.phiflowp <- nimbleMCMC(code = hmm.phiflowp, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin, \n                          nchains = n.chains)\nMCMCplot(object = mcmc.phiflowp, params = \"beta\")\nMCMCplot(object = mcmc.phiflowp, params = \"phi\", ISB = TRUE)"},{"path":"survival.html","id":"individual-covariates","chapter":"4 Alive and dead","heading":"4.8.2 Individual covariates","text":"previous section, learnt explain temporal heterogeneity survival detection. Heterogeneity also originate individual differences animals. may think diffence survival males females discrete covariate example, size body mass examples continuous covariate. Let‚Äôs illustrate discrete continuous covariates dipper.","code":""},{"path":"survival.html","id":"discrete-1","chapter":"4 Alive and dead","heading":"4.8.2.1 Discrete","text":"first consider covariate sex contains 1‚Äôs 2‚Äôs indicating sex bird: 1 male, 2 female. implement model sex effect using nested indexing, similarly model flood vs.¬†nonflood years. section NIMBLE code needs amended :running NIMBLE, get:Male survival (phi[1]) looks similar female survival (phi[2]).","code":"\n...\nfor (i in 1:N){\n  gamma[1,1,i] <- phi[sex[i]]      # Pr(alive t -> alive t+1)\n  gamma[1,2,i] <- 1 - phi[sex[i]]  # Pr(alive t -> dead t+1)\n  gamma[2,1,i] <- 0                # Pr(dead t -> alive t+1)\n  gamma[2,2,i] <- 1                # Pr(dead t -> dead t+1)\n}\nphi[1] ~ dunif(0,1) # male survival\nphi[2] ~ dunif(0,1) # female survival\n...\nMCMCsummary(object = mcmc.phisexp.ni, round = 2)##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p      0.90 0.03 0.84 0.90  0.95    1   643\n## phi[1] 0.57 0.03 0.50 0.57  0.64    1  1668\n## phi[2] 0.55 0.03 0.48 0.55  0.62    1  1482"},{"path":"survival.html","id":"continuous-1","chapter":"4 Alive and dead","heading":"4.8.2.2 Continuous","text":"Besides discrete individual covariates, might want continuous individual covariates, e.g.¬†wing length dipper example. Note ‚Äôre considering individual trait takes value whatever occasion. consider wing length , precisely measurement first detection. first standardize covariate:Now write model:put constants list:write function generating initial values:run NIMBLE:Let‚Äôs inspect numerical summaries regression parameters:Wing length seem explain much individual--individual variation survival ‚Äì posterior distribution slope (beta[2]) centered 0 can see credible interval.Let‚Äôs plot relationship survival wing length. First, gather values generated posterior distribution regression parameters two chains:define grid values wing length, predict survival MCMC iteration:Now calculate posterior mean credible interval (note ordering):Now time visualize:flat relationship survival wing length confirmed.","code":"\nwing.length.st <- as.vector(scale(dipper$wing_length))\nhead(wing.length.st)\n## [1]  0.7581 -0.8671  0.5260 -1.5637 -1.3315  1.2225\nhmm.phiwlp <- nimbleCode({\n    p ~ dunif(0, 1)             # prior detection\n    omega[1,1] <- 1 - p         # Pr(alive t -> non-detected t)\n    omega[1,2] <- p             # Pr(alive t -> detected t)\n    omega[2,1] <- 1             # Pr(dead t -> non-detected t)\n    omega[2,2] <- 0             # Pr(dead t -> detected t)\n  for (i in 1:N){\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i]\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5)\n  beta[2] ~ dnorm(mean = 0, sd = 1.5)\n  delta[1] <- 1                 # Pr(alive t = 1) = 1\n  delta[2] <- 0                 # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first,\n                     winglength = wing.length.st)\ninitial.values <- function() list(beta = rnorm(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nmcmc.phiwlp <- nimbleMCMC(code = hmm.phiwlp, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin, \n                          nchains = n.chains)\nMCMCsummary(mcmc.phiwlp, params = \"beta\", round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.25 0.10  0.04  0.25  0.45    1  1472\n## beta[2] -0.02 0.09 -0.20 -0.02  0.17    1  1555\nbeta1 <- c(mcmc.phiwlp$chain1[,'beta[1]'], # intercept, chain 1\n           mcmc.phiwlp$chain2[,'beta[1]']) # intercept, chain 2\nbeta2 <- c(mcmc.phiwlp$chain1[,'beta[2]'], # slope, chain 1\n           mcmc.phiwlp$chain2[,'beta[2]']) # slope, chain 2\npredicted_survival <- matrix(NA, \n                             nrow = length(beta1), \n                             ncol = length(my.constants$winglength))\nfor (i in 1:length(beta1)){\n  for (j in 1:length(my.constants$winglength)){\n    predicted_survival[i,j] <- plogis(beta1[i] + \n                               beta2[i] * my.constants$winglength[j])\n  }\n}\nmean_survival <- apply(predicted_survival, 2, mean)\nlci <- apply(predicted_survival, 2, quantile, prob = 2.5/100)\nuci <- apply(predicted_survival, 2, quantile, prob = 97.5/100)\nord <- order(my.constants$winglength)\ndf <- data.frame(wing_length = my.constants$winglength[ord],\n                 survival = mean_survival[ord],\n                 lci = lci[ord],\n                 uci = uci[ord])\ndf %>%\n  ggplot() + \n  aes(x = wing_length, y = survival) + \n  geom_line() + \n  geom_ribbon(aes(ymin = lci, ymax = uci), \n              fill = \"grey70\", \n              alpha = 0.5) + \n  ylim(0,1) + \n  labs(x = \"wing length\", y = \"estimated survival\")"},{"path":"survival.html","id":"several-covariates","chapter":"4 Alive and dead","heading":"4.8.3 Several covariates","text":"may wish effect sex wing length model. Let‚Äôs consider additive effect covariates. use covariate sex takes value 0 male, 1 female. \\(\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2 \\text{sex}_i + \\beta_3 \\text{winglength}_i\\) bird \\(\\), male survival \\(\\beta_1 + \\beta_3 \\text{winglength}_i\\) female survival \\(\\beta_1 + \\beta_2 + \\beta_3 \\text{winglength}_i\\) (logit scale). relationship survival wing length parallel males females, logit scale, gap two measured \\(\\beta_2\\) (hence term additive effect).NIMBLE code :put constants data lists:write fuction generate initial values:specify parameters monitored:MCMC details (note need increase number iterations achieve satisfying effective sample sizes):now run NIMBLE:Let‚Äôs display numerical summaries parameters:slope beta[3] males females. Although posterior mean negative, crebible interval suggests posterior distribution largely encompasses 0, therefore weak signal, .Let‚Äôs visualize survival function wing length sexes. First put together values two chains generated posterior distributions regression parameters:get survival estimates MCMC iteration:, may calculate posterior mean credible intervals:Now plot:Note two curves exactly parallel back-transformed linear part relationship survival wing length. may check parallelism occurs logit scale:","code":"\nhmm.phisexwlp <- nimbleCode({\n  p ~ dunif(0, 1)               # prior detection\n  omega[1,1] <- 1 - p           # Pr(alive t -> non-detected t)\n  omega[1,2] <- p               # Pr(alive t -> detected t)\n  omega[2,1] <- 1               # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0               # Pr(dead t -> detected t)\n  for (i in 1:N){\n    logit(phi[i])<-beta[1]+beta[2]*sex[i]+beta[3]*winglength[i]\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5) # intercept male\n  beta[2] ~ dnorm(mean = 0, sd = 1.5) # diff bw male and female\n  beta[3] ~ dnorm(mean = 0, sd = 1.5) # slope wing length\n  delta[1] <- 1                 # Pr(alive t = 1) = 1\n  delta[2] <- 0                 # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nwing.length.st <- as.vector(scale(dipper$wing_length))\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first,\n                     winglength = wing.length.st,\n                     sex = if_else(dipper$sex == \"M\", 0, 1))\nmy.data <- list(y = y + 1)\nzinits <- y\nzinits[zinits == 0] <- 1\ninitial.values <- function() list(beta = rnorm(3,0,2),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"beta\", \"p\")\nn.iter <- 5000*4\nn.burnin <- 1000\nn.chains <- 2\nmcmc.phisexwlp <- nimbleMCMC(code = hmm.phisexwlp, \n                             constants = my.constants,\n                             data = my.data,              \n                             inits = initial.values,\n                             monitors = parameters.to.save,\n                             niter = n.iter,\n                             nburnin = n.burnin, \n                             nchains = n.chains)\nMCMCsummary(mcmc.phisexwlp, round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.52 0.24  0.05  0.52  0.99    1   466\n## beta[2] -0.53 0.43 -1.37 -0.53  0.30    1   447\n## beta[3] -0.25 0.21 -0.65 -0.25  0.16    1   530\n## p        0.90 0.03  0.83  0.90  0.95    1  3141\nbeta1 <- c(mcmc.phisexwlp$chain1[,'beta[1]'], # beta1 chain 1\n           mcmc.phisexwlp$chain2[,'beta[1]']) # beta1 chain 2\nbeta2 <- c(mcmc.phisexwlp$chain1[,'beta[2]'], # beta2 chain 1\n           mcmc.phisexwlp$chain2[,'beta[2]']) # beta2 chain 2\nbeta3 <- c(mcmc.phisexwlp$chain1[,'beta[3]'], # beta3 chain 1\n           mcmc.phisexwlp$chain2[,'beta[3]']) # beta3 chain 2\npredicted_survivalM <- matrix(NA, nrow = length(beta1), \n                              ncol=length(my.constants$winglength))\npredicted_survivalF <- matrix(NA, nrow = length(beta1), \n                              ncol=length(my.constants$winglength))\nfor (i in 1:length(beta1)){\n  for (j in 1:length(my.constants$winglength)){\n    predicted_survivalM[i,j] <- plogis(beta1[i] + \n                                beta3[i]*my.constants$winglength[j]) \n    predicted_survivalF[i,j] <- plogis(beta1[i] + \n                                beta2[i] + \n                                beta3[i]*my.constants$winglength[j])\n  }\n}\nmean_survivalM <- apply(predicted_survivalM, 2, mean)\nlciM <- apply(predicted_survivalM, 2, quantile, prob = 2.5/100)\nuciM <- apply(predicted_survivalM, 2, quantile, prob = 97.5/100)\nmean_survivalF <- apply(predicted_survivalF, 2, mean)\nlciF <- apply(predicted_survivalF, 2, quantile, prob = 2.5/100)\nuciF <- apply(predicted_survivalF, 2, quantile, prob = 97.5/100)\nord <- order(my.constants$winglength)\ndf <- data.frame(wing_length = c(my.constants$winglength[ord], \n                                 my.constants$winglength[ord]),\n                 survival = c(mean_survivalM[ord], \n                              mean_survivalF[ord]),\n                 lci = c(lciM[ord],lciF[ord]),\n                 uci = c(uciM[ord],uciF[ord]),\n                 sex = c(rep(\"male\", length(mean_survivalM)), \n                         rep(\"female\", length(mean_survivalF))))\ndf %>%\n  ggplot() + \n  aes(x = wing_length, y = survival, color = sex) + \n  geom_line() + \n  geom_ribbon(aes(ymin = lci, ymax = uci, fill = sex), alpha = 0.5) + \n  ylim(0,1) + \n  labs(x = \"wing length\", \n       y = \"estimated survival\", \n       color = \"\", fill = \"\")\npredicted_lsurvivalM <- matrix(NA, nrow = length(beta1), \n                              ncol = length(my.constants$winglength))\npredicted_lsurvivalF <- matrix(NA, nrow = length(beta1), \n                              ncol = length(my.constants$winglength))\nfor (i in 1:length(beta1)){\n  for (j in 1:length(my.constants$winglength)){\n    predicted_lsurvivalM[i,j] <- beta1[i] + \n      beta3[i] * my.constants$winglength[j] \n    predicted_lsurvivalF[i,j] <- beta1[i] + beta2[i] + \n      beta3[i] * my.constants$winglength[j]\n  }\n}\nmean_lsurvivalM <- apply(predicted_lsurvivalM, 2, mean)\nmean_lsurvivalF <- apply(predicted_lsurvivalF, 2, mean)\nord <- order(my.constants$winglength)\ndf <- data.frame(wing_length = c(my.constants$winglength[ord], \n                                 my.constants$winglength[ord]),\n                 survival = c(mean_lsurvivalM[ord], \n                              mean_lsurvivalF[ord]),\n                 sex = c(rep(\"male\", length(mean_lsurvivalM)), \n                         rep(\"female\", length(mean_lsurvivalF))))\ndf %>%\n  ggplot() + \n  aes(x = wing_length, y = survival, color = sex) + \n  geom_line() + \n  ylim(-2,2) + \n  labs(x = \"wing length\", \n       y = \"estimated survival (on the logit scale)\", \n       color = \"\")"},{"path":"survival.html","id":"randomeffects","chapter":"4 Alive and dead","heading":"4.8.4 Random effects","text":"individual variation survival fully explained covariates, may add random effects \\(\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2 x_i + \\varepsilon_i\\) \\(\\varepsilon_i \\sim N(0,\\sigma^2)\\). consider individual variation section, reasoning holds temporal variation. essence, treating individual survival probabilities \\(\\phi_i\\) sample population survival probabilities, assume normal distribution mean linear component (without covariate) standard deviation \\(\\sigma\\). variation unexplained covariate \\(x_i\\) measured variation \\(\\sigma\\) residuals \\(\\varepsilon_i\\).important? Ignoring individual heterogeneity generated individuals contrasted performances life may mask senescence hamper understanding life history trade-offs. Overall, failing incorporate unexplained residual variance may induce bias parameter estimates lead detecting effect covariate often .Let‚Äôs go back dipper example wing length covariate, write NIMBLE code:prior standard deviation random effect uniform 0 10.now write function generating initial values:specify parameters monitored:increase number iterations length burn-period reach better convergence:finally, run NIMBLE:inspect numerical summaries:effective sample size standard deviation random effect low. Let‚Äôs try something else, means MCMC chains exploring parameter space inefficiently. common strategy address problem reparameterize model using non-centered formulation.centered parameterization ‚Äôve used far, random effect expressed directly terms variance (standard deviation). often creates strong correlations random effects variance parameter, turn can slow mixing reduce effective sample size. non-centered parameterization, instead separate structure random effect scale. practice, introduce standardized random effect \\(\\varepsilon_i \\sim N(0,1)\\) multiply standard deviation \\(\\sigma\\). decouples randomness scale parameter usually improves sampling efficiency. code, looks like:running NIMBLE, inspect numerical summaries, see effective sample sizes much better:","code":"\nhmm.phiwlrep <- nimbleCode({\n    p ~ dunif(0, 1)             # prior detection\n    omega[1,1] <- 1 - p         # Pr(alive t -> non-detected t)\n    omega[1,2] <- p             # Pr(alive t -> detected t)\n    omega[2,1] <- 1             # Pr(dead t -> non-detected t)\n    omega[2,2] <- 0             # Pr(dead t -> detected t)\n  for (i in 1:N){\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i] + eps[i]\n    eps[i] ~ dnorm(mean = 0, sd = sdeps)\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5)\n  beta[2] ~ dnorm(mean = 0, sd = 1.5)\n  sdeps ~ dunif(0, 10)\n  delta[1] <- 1                 # Pr(alive t = 1) = 1\n  delta[2] <- 0                 # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\ninitial.values <- function() list(beta = rnorm(2,0,1.5),\n                                  sdeps = runif(1,0,3),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"beta\", \"sdeps\", \"p\")\nn.iter <- 10000\nn.burnin <- 5000\nn.chains <- 2\nmcmc.phiwlrep <- nimbleMCMC(code = hmm.phiwlrep, \n                            constants = my.constants,\n                            data = my.data,              \n                            inits = initial.values,\n                            monitors = parameters.to.save,\n                            niter = n.iter,\n                            nburnin = n.burnin, \n                            nchains = n.chains)\nMCMCsummary(mcmc.phiwlrep, round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.22 0.12 -0.02  0.22  0.44 1.24  1335\n## beta[2] -0.01 0.10 -0.20 -0.01  0.19 1.02  1894\n## p        0.90 0.03  0.84  0.90  0.95 1.03   752\n## sdeps    0.27 0.25  0.01  0.16  0.83 4.68    12...\n  for (i in 1:N){\n    logit(phi[i])<-beta[1]+beta[2]*winglength[i] + sdeps * eps[i]\n    eps[i] ~ dnorm(mean = 0, sd = 1)\n...\nMCMCsummary(mcmc.phiwlrep, round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.21 0.12 -0.04  0.21  0.43 1.00  1202\n## beta[2] -0.01 0.10 -0.20 -0.01  0.19 1.00  1789\n## p        0.90 0.03  0.83  0.90  0.95 1.01   790\n## sdeps    0.40 0.26  0.02  0.37  0.95 1.01   170"},{"path":"survival.html","id":"agecov","chapter":"4 Alive and dead","heading":"4.8.5 Individual time-varying covariates","text":"far, allowed covariates vary along single dimension, either time individual. need consider covariate varies one animal , time. Think age example, value specific individual, (sadly) changes time.Age particular meaning capture-recapture framework. time elapsed since first encounter, proxy true age, true age. age known first encounter, true age. example, dippers marked young, true biological age bird.convenient thing age missing value age \\(t+1\\) just age \\(t\\) add 1. suggests way code age effect NIMBLE follows:used equals(t, first[]) renders 1 \\(t\\) first encounter first[] 0 otherwise. Therefore distinguish survival first interval first encounter \\(\\phi_1\\) (logit(phi[,t]) <- beta[1] + beta[2]) survival afterwards \\(\\phi_{1+}\\) (logit(phi[,t]) <- beta[1]).put constants list:data list:write function generate initial values:specify parameters monitored:now run NIMBLE:display results:Age time elapsed since first encounter seem effect survival .Another method include age effect create individual time covariate use nested indexing (flood/nonflood example) distinguish survival interval first detection survival afterwards:Now may write NIMBLE code model. just need remember survival longer defined logit scale previous model, simply use uniform priors:put constants list, including age covariate:re-write function generate initial values:run NIMBLE:display numerical summaries model parameters, acknowledge obtain similar results parameterization:Like mentioned earlier, age easy deal contain missing values. Now think size body mass minute. problem record size body mass animal non-detected. easiest way cope individual time-varying covariates discretize e.g.¬†small, medium large Chapter 5. Another option come model covariate fill missing values simulating model.","code":"\nhmm.phiage.in <- nimbleCode({\n  p ~ dunif(0, 1)                     # prior detection\n  omega[1,1] <- 1 - p                 # Pr(alive t -> non-detected t)\n  omega[1,2] <- p                     # Pr(alive t -> detected t)\n  omega[2,1] <- 1                     # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0                     # Pr(dead t -> detected t)\n  for (i in 1:N){\n    for (t in first[i]:(T-1)){\n    # phi1 = beta1 + beta2; phi1+ = beta1\n    logit(phi[i,t]) <- beta[1] + beta[2] * equals(t, first[i]) \n    gamma[1,1,i,t] <- phi[i,t]        # Pr(alive t -> alive t+1)\n    gamma[1,2,i,t] <- 1 - phi[i,t]    # Pr(alive t -> dead t+1)\n    gamma[2,1,i,t] <- 0               # Pr(dead t -> alive t+1)\n    gamma[2,2,i,t] <- 1               # Pr(dead t -> dead t+1)\n    }\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5) # phi1+\n  beta[2] ~ dnorm(mean = 0, sd = 1.5) # phi1 - phi1+\n  phi1plus <- plogis(beta[1])         # phi1+\n  phi1 <- plogis(beta[1] + beta[2])   # phi1\n  delta[1] <- 1                       # Pr(alive t = 1) = 1\n  delta[2] <- 0                       # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first)\nmy.data <- list(y = y + 1)\nzinits <- y\nzinits[zinits == 0] <- 1\ninitial.values <- function() list(beta = rnorm(2,0,5),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"phi1\", \"phi1plus\", \"p\")\nmcmc.phi.age.in <- nimbleMCMC(code = hmm.phiage.in, \n                              constants = my.constants,\n                              data = my.data,              \n                              inits = initial.values,\n                              monitors = parameters.to.save,\n                              niter = n.iter,\n                              nburnin = n.burnin, \n                              nchains = n.chains)\nMCMCsummary(mcmc.phi.age.in, round = 2)##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p        0.90 0.03 0.83 0.90  0.95 1.00   738\n## phi1     0.56 0.03 0.49 0.56  0.62 1.00  1624\n## phi1plus 0.57 0.04 0.49 0.57  0.64 1.01   506\nage <- matrix(NA, nrow = nrow(y), ncol = ncol(y) - 1)\nfor (i in 1:nrow(age)){\n  for (j in 1:ncol(age)){\n    if (j == first[i]) age[i,j] <- 1 # age = 1\n    if (j > first[i]) age[i,j] <- 2  # age > 1\n  }\n}\nhmm.phiage.out <- nimbleCode({\n  p ~ dunif(0, 1)                   # prior detection\n  omega[1,1] <- 1 - p               # Pr(alive t -> non-detected t)\n  omega[1,2] <- p                   # Pr(alive t -> detected t)\n  omega[2,1] <- 1                   # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0                   # Pr(dead t -> detected t)\n  for (i in 1:N){\n    for (t in first[i]:(T-1)){\n    phi[i,t] <- beta[age[i,t]]      # beta1 = phi1, beta2 = phi1+\n    gamma[1,1,i,t] <- phi[i,t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i,t] <- 1 - phi[i,t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i,t] <- 0             # Pr(dead t -> alive t+1)\n    gamma[2,2,i,t] <- 1             # Pr(dead t -> dead t+1)\n    }\n  }\n  beta[1] ~ dunif(0, 1) # phi1\n  beta[2] ~ dunif(0, 1) # phi1+\n  phi1 <- beta[1]\n  phi1plus <- beta[2]\n  delta[1] <- 1                     # Pr(alive t = 1) = 1\n  delta[2] <- 0                     # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first,\n                     age = age)\nzinits <- y\nzinits[zinits == 0] <- 1\ninitial.values <- function() list(beta = runif(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nmcmc.phi.age.out <- nimbleMCMC(code = hmm.phiage.out, \n                               constants = my.constants,\n                               data = my.data,              \n                               inits = initial.values,\n                               monitors = parameters.to.save,\n                               niter = n.iter,\n                               nburnin = n.burnin, \n                               nchains = n.chains)\nMCMCsummary(mcmc.phi.age.out, round = 2)##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p        0.90 0.03 0.84 0.90  0.95 1.01   793\n## phi1     0.55 0.03 0.48 0.55  0.62 1.01  1736\n## phi1plus 0.57 0.04 0.50 0.57  0.64 1.00  2064"},{"path":"survival.html","id":"elicitprior","chapter":"4 Alive and dead","heading":"4.9 Why Bayes? Incorporate prior information","text":"","code":""},{"path":"survival.html","id":"prior-elicitation","chapter":"4 Alive and dead","heading":"4.9.1 Prior elicitation","text":"close section, ‚Äôd like cover one last topic. Think CJS model constant parameters. far, assumed non-informative prior survival \\(\\text{Beta}(1,1) = \\text{Uniform}(0,1)\\). prior, seen Section 4.5 mean posterior survival \\(\\phi = 0.56\\) credible interval \\([0.52,0.62]\\).thing know lot passerines shame able use information act start scratch know nothing.illustrate incorporate prior information acknowledging species similar body masses similar survival. gathering information several European passerines dipper, let‚Äôs assume built regression survival vs.¬†body mass ‚Äì allometric relationship.Now knowing dippers weigh average 59.8g, ‚Äôre position build prior dipper survival probability predicting value using regression. obtain predicted survival 0.57 standard deviation 0.075. Using informative prior phi ~ dnorm(0.57, sd = 0.073) NIMBLE instead phi ~ dunif(0,1), get mean posterior \\(0.56\\) credible interval \\([0.52, 0.61]\\). ‚Äôs barely difference non-informative prior, quite disappointment.Now let‚Äôs assume three first years data, happened? fit model constant parameters non-informative informative priors dataset delete final 4 years data. Now benefit using prior information becomes clear credible interval prior information ignored width 0.53, twice much prior information used (0.24), illustrating increased precision provided prior. may assess visually gain precision comparing survival posterior distributions without informative prior:aim get estimate survival, Gilbert conduct data collection 3 years, reached precision 7 years data using prior information derived body mass. brief, prior information worth 4 years field data. course, assuming ecological question remains whether 3 7 years data, unlikely case, long-term data, much can ask, ‚Äújust‚Äù annual survival probability .","code":""},{"path":"survival.html","id":"moment-matching","chapter":"4 Alive and dead","heading":"4.9.2 Moment matching","text":"prior phi ~ dnorm(0.57, sd = 0.073) entirely satisfying constrained positive less one, minimum probability (survival) well defined. specific example, prior distribution centered positive values far 0, standard deviation small enough chances get values smaller 0 higher 1 null (convince , just type hist(rnorm(1000, mean = 0.57, sd = 0.073)) R). Can better? answer yes.Remember Beta distribution? Recall Beta distribution continuous distribution values 0 1, convenient specify priors survival detection probabilities. Besides know everything Beta distribution, particular mean variance. \\(X \\sim Beta(\\alpha,\\beta)\\), mean (variance) \\(X\\) \\(\\mu = \\text{E}(X) = \\frac{\\alpha}{\\alpha + \\beta}\\) \\(\\sigma^2 = \\text{Var}(X) = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\).capture-recapture example, know priori mean probability ‚Äôre interested \\(\\mu = 0.57\\) variance \\(\\sigma^2 = 0.073^2\\). Parameters \\(\\mu\\) \\(\\sigma^2\\) seen moments \\(Beta(\\alpha,\\beta)\\) distribution. Now look values \\(\\alpha\\) \\(\\beta\\) match observed moments Beta distribution \\(\\mu\\) \\(\\sigma^2\\). need another set equations:\\[\\alpha = \\bigg(\\frac{1-\\mu}{\\sigma^2}- \\frac{1}{\\mu} \\bigg)\\mu^2\\]\n\\[\\beta = \\alpha \\bigg(\\frac{1}{\\mu}-1\\bigg)\\]\nmodel, means:Now simply use phi ~ dbeta(25.6,19.3) prior instead phi ~ dnorm(0.57, sd = 0.073).","code":"\n(alpha <- ( (1 - 0.57)/(0.073*0.073) - (1/0.57) )*0.57^2)\n## [1] 25.65\n(beta <- alpha * ( (1/0.57) - 1))\n## [1] 19.35"},{"path":"survival.html","id":"summary-3","chapter":"4 Alive and dead","heading":"4.10 Summary","text":"CJS model HMM time-varying parameters account variation due environmental conditions survival sampling effort detection.CJS model HMM time-varying parameters account variation due environmental conditions survival sampling effort detection.Covariates can considered try explain temporal /individual variation survival detection probabilities. needed, random effects can added cope unexplained variation.Covariates can considered try explain temporal /individual variation survival detection probabilities. needed, random effects can added cope unexplained variation.model comparison, WAIC can used evaluate relative predictive performance capture-recapture models.model comparison, WAIC can used evaluate relative predictive performance capture-recapture models.Statistical models rely assumptions, CJS model makes exception. procedures assess goodness fit CJS model capture-recapture data.Statistical models rely assumptions, CJS model makes exception. procedures assess goodness fit CJS model capture-recapture data.","code":""},{"path":"survival.html","id":"suggested-reading-3","chapter":"4 Alive and dead","heading":"4.11 Suggested reading","text":"Buckland (2016) provides historical perspective CJS model anecdotes. monography Lebreton et al. (1992) must-read better understand CJS model applications. HMM formulation CJS model proposed Gimenez et al. (2007) Royle (2008).Buckland (2016) provides historical perspective CJS model anecdotes. monography Lebreton et al. (1992) must-read better understand CJS model applications. HMM formulation CJS model proposed Gimenez et al. (2007) Royle (2008).Gimenez, Morgan, Brooks (2009) deals parameter redundancy capture-recapture models Bayesian framework. exhaustive treatment, see Cole (2020) excellent book.Gimenez, Morgan, Brooks (2009) deals parameter redundancy capture-recapture models Bayesian framework. exhaustive treatment, see Cole (2020) excellent book.Relative model comparison, warmly recommend McElreath (2020) better understand WAIC, accompanying video, see https://www.youtube.com/watch?v=vSjL2Zc-gEQ. paper Gelman, Hwang, Vehtari (2014) also much helpful.Relative model comparison, warmly recommend McElreath (2020) better understand WAIC, accompanying video, see https://www.youtube.com/watch?v=vSjL2Zc-gEQ. paper Gelman, Hwang, Vehtari (2014) also much helpful.posterior predictive checks, may check Conn et al. (2018). R2ucare package introduced Gimenez et al. (2018).posterior predictive checks, may check Conn et al. (2018). R2ucare package introduced Gimenez et al. (2018).Temporal heterogeneity addressed papers Grosbois et al. (2008) Frederiksen et al. (2014), individual heterogeneity reviewed Gimenez, Cam, Gaillard (2018).Temporal heterogeneity addressed papers Grosbois et al. (2008) Frederiksen et al. (2014), individual heterogeneity reviewed Gimenez, Cam, Gaillard (2018).Regarding covariates, use formalization linear models sticked intuitive (hopefully) illustration use covariates. details can found Chapter 6 Cooch White (2017).Regarding covariates, use formalization linear models sticked intuitive (hopefully) illustration use covariates. details can found Chapter 6 Cooch White (2017).example incorporate prior information McCarthy Masters (2005).example incorporate prior information McCarthy Masters (2005).","code":""},{"path":"dispersal.html","id":"dispersal","chapter":"5 Sites and states","heading":"5 Sites and states","text":"","code":""},{"path":"dispersal.html","id":"introduction-6","chapter":"5 Sites and states","heading":"5.1 Introduction","text":"fifth chapter, learn Arnason-Schwarz model allows estimating transitions sites states based capture-recapture data. also see deal uncertainty assignment states individuals.","code":""},{"path":"dispersal.html","id":"ASmodel","chapter":"5 Sites and states","heading":"5.2 The Arnason-Schwarz (AS) model","text":"Chapter 4, got acquainted Cormack-Jolly-Seber (CJS) model accommodates transitions states alive dead accounting imperfect detection. often case besides alive, detailed information collected state animals detected. example, study area split several discrete sites, may record animal detected, state now alive particular site. Arnason-Schwarz () model can viewed extension CJS model estimate movements sites top survival. model named two statisticians ‚Äì Neil Arnason Carl Schwarz ‚Äì came idea.","code":""},{"path":"dispersal.html","id":"theory","chapter":"5 Sites and states","heading":"5.2.1 Theory","text":"Let‚Äôs assume now two sites, say 1 2. way usually think analyzing data start detections non-detections infer transitions sites movements. Schematically, animal detected site 1 site 2, obviously means alive site, whereas detected, may dead alive either site. Schematically, :Observations states indeed closely related, perfect states observations correspondence, HMM framework help make distinction clear, turn make modelling easier. Usually, focus energy observations ‚Äôd really like spend time thinking ecological processes observed imperfectly. HMM framework, build model, think states dynamic time, states emit observations ‚Äôre given make. Going back example, animal alive either site, may get detected site go undetected. animal dead, goes undetected sure. Schematically, obtain:\\(z = 1\\) alive site 1, \\(z = 2\\) alive site 2 \\(z = 3\\) dead. code \\(y = 1\\) non-detected, \\(y = 2\\) detected site 1 \\(y = 3\\) detected site 2. parameters :\n- \\(\\pi^r\\) probability newly encountered individual state \\(r\\);\n- \\(p_t^r\\) probability detection \\(t\\) bird site \\(r\\) \\(t\\);\n- \\(\\phi_t^r\\) survival probability birds site \\(r\\) \\(t\\) \\(t+1\\);\n- \\(\\psi_t^{rs}\\) probability site \\(s\\) time \\(t+1\\) animals site \\(r\\) \\(t\\) survived \\(t+1\\), short movement conditional survival.parameters can modelled functions covariates Section 4.8. now drop time index simplicity.follow presentation HMM Chapter 3. Let‚Äôs start vector initial states. first encounter, animal may alive site 1 probability \\(\\pi^1\\) site 2 complementary probability \\(1 - \\pi^{1}\\), dead. Therefore, :\\[\\begin{matrix}\n& \\\\\n\\delta =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=1 & z_t=2 & z_t=3 \\\\[0.3em] \\hdashline\n\\pi^1 & 1 - \\pi^{1} & 0\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\end{matrix}\n\\end{matrix}\\]move transition matrix connects states \\(t-1\\) rows states \\(t\\) columns. example, probability moving site 1 \\(t-1\\) site \\(2\\) \\(t\\) product survival probability site 1 time interval, times probability moving site 1 2 animals survived. :\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_{t}=1 & z_{t}=2 & z_{t}=3 \\\\[0.3em] \\hdashline\n\\phi^1 (1-\\psi^{12}) & \\phi^1 \\psi^{12} & 1 - \\phi^1\\\\\n\\phi^2 \\psi^{21} & \\phi^2 (1-\\psi^{21}) & 1 - \\phi^2\\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=1 \\\\ z_{t-1}=2 \\\\ z_{t-1}=3\n    \\end{matrix}\n\\end{matrix}\\]Finally, observation matrix relates states animal \\(t\\) rows observations \\(t\\) columns. animal dead (\\(z_t=3\\)), detected (\\(\\Pr(y_t=1|z_t=3)=\\Pr(y_t=2|z_t=3)=0\\) \\(\\Pr(y_t=3|z_t=3)=1\\)), whereas alive either site, can detected . :\\[\\begin{matrix}\n& \\\\\n\\Omega =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=1 & y_t=2 & y_t=3 \\\\[0.3em] \\hdashline\n1 - p^1 & p^1 & 0\\\\\n1 - p^2 & 0 & p^2\\\\\n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=1 \\\\ z_{t}=2 \\\\ z_{t}=3\n    \\end{matrix}\n\\end{matrix}\\]vector initial state probabilities sums one, well rows transition observation matrices.","code":""},{"path":"dispersal.html","id":"ASmodelfitting","chapter":"5 Sites and states","heading":"5.3 Fitting the AS model","text":"","code":""},{"path":"dispersal.html","id":"geese-data","chapter":"5 Sites and states","heading":"5.3.1 Geese data","text":"introduce chapter, use data Canada goose (Branta canadensis; geese hereafter) kindly provided Jay Hestbeck (Figure 4.2).\nFigure 5.1: Canada goose (Branta canadensis). Credit: Max McCarthy.\ntotal, 21277 geese captured, marked coded neck bands recaptured 1984 1989 wintering locations. Specifically, geese monitored Atlantic flyway, large areas along East coast USA, namely 3 sites mid‚ÄìAtlantic (New York, Pennsylvania, New Jersey), Chesapeake (Delaware, Maryland, Virginia), Carolinas (North South Carolina). Birds adults sub-adults banded.may see data :six columns years geese captured, banded recapture. 0 stands non-detection, detections coded 3 wintering sites 1, 2 3 mid‚ÄìAtlantic, Chesapeake Carolinas respectively. subsample 500 individuals whole dataset use illustration .","code":"\ny <- read_csv(\"geese.csv\") %>% as.matrix()\nhead(y)##      year_1984 year_1985 year_1986 year_1987 year_1988\n## [1,]         0         2         2         0         0\n## [2,]         0         0         0         0         0\n## [3,]         0         0         0         1         0\n## [4,]         0         0         2         0         0\n## [5,]         0         3         0         0         3\n## [6,]         0         0         0         2         0\n##      year_1989\n## [1,]         0\n## [2,]         2\n## [3,]         0\n## [4,]         0\n## [5,]         2\n## [6,]         0"},{"path":"dispersal.html","id":"nimble-implementation-1","chapter":"5 Sites and states","heading":"5.3.2 NIMBLE implementation","text":"write NIMBLE code corresponding model, make life easier start 2 sites ‚Äì drop Carolinas wintering site now. replace 3‚Äôs 0‚Äôs dataset:Also consider parameters constant time.start comments define quantities ‚Äì parameters, states observations ‚Äì use NIMBLE code:specify priors survival, transition detection probabilities:now write vector initial state probabilities:Actually, initial state known exactly: alive site initial capture, \\(\\pi^1\\) proportion individuals first captured site 1, need make explicit model estimate . Therefore, likelihood, instead z[,first[]] ~ dcat(delta[1:3]), can use z[,first[]] <- y[,first[]] - 1 just forget \\(\\pi^1\\), now. Note trick applies CJS model.write transition matrix:way, observation matrix :last, ready specify likelihood , magic HMM, likelihood CJS model, vector initial states, transition observation matrices changed:need provide NIMBLE constants, data, initial values, parameters monitor MCMC details:Now may run NIMBLE:may look results via caterpillar plot:Remember mid‚ÄìAtlantic site 1, Chesapeake site 2. Detection mid‚ÄìAtlantic (around 0.5) higher Cheasapeake (around 0.4) although comes uncertainty (wider credible interval). Survival sites estimated around 0.6‚Äì0.7. Note going multisite, make parameters site-specific differences might reflect habitat quality example. Now novelty lies capability estimate movements site 1 site 2 site 2 site 1 winter next. annual probability remaining site two successive winters, used measure site fidelity, lower mid‚ÄìAtlantic (\\(1-\\psi_{12}\\) around 0.8) Chesapeake (\\(1-\\psi_{21}\\) around 0.9). estimated probability moving Chesapeake mid‚ÄìAtlantic four times high probability moving opposite direction.may also look numerical summaries, confirm ecological interpretation model parameter estimates:add time-dependence demographic parameters, e.g.¬†survival movements, assess effect winter harshness temporal covariates; Individual covariates also considered. See Section 4.8.move next section, illustrate use nimbleEcology fit geese data 2 sites (see Section 3.8.3). Using function dHMM() implements HMM time-independent observation transition matrices, :obtain:differences whatsoever parameters estimates compared obtained earlier.","code":"\ny[y==3] <- 0\n# remove rows with 0's\nmask <- apply(y, 1, sum)\ny <- y[mask!=0,]multisite <- nimbleCode({\n  # -------------------------------------------------\n  # Parameters:\n  # phi1: survival probability site 1\n  # phi2: survival probability site 2\n  # psi12: movement probability from site 1 to site 2\n  # psi21: movement probability from site 2 to site 1\n  # p1: detection probability site 1\n  # p2: detection probability site 2\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive at site 1\n  # 2 alive at site 2\n  # 3 dead\n  # Observations (y):\n  # 1 not seen\n  # 2 seen at site 1\n  # 3 seen at site 2\n  # -------------------------------------------------\n...multisite <- nimbleCode({\n...\n  # Priors\n  phi1 ~ dunif(0, 1)\n  phi2 ~ dunif(0, 1)\n  psi12 ~ dunif(0, 1)\n  psi21 ~ dunif(0, 1)\n  p1 ~ dunif(0, 1)\n  p2 ~ dunif(0, 1)\n...multisite <- nimbleCode({\n...\n  # initial state probabilities\n  delta[1] <- pi1          # Pr(alive in 1 at t = first)\n  delta[2] <- 1 - pi1      # Pr(alive in 2 at t = first)\n  delta[3] <- 0            # Pr(dead at t = first) = 0\n...multisite <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  # (read as gamma[z(t),z(t+1)] = gamma[fromState,toState])\n\n  gamma[1,1] <- phi1 * (1 - psi12)\n  gamma[1,2] <- phi1 * psi12\n  gamma[1,3] <- 1 - phi1\n  gamma[2,1] <- phi2 * psi21\n  gamma[2,2] <- phi2 * (1 - psi21)\n  gamma[2,3] <- 1 - phi2\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n...multisite <- nimbleCode({\n...\n  # probabilities of y(t) given z(t)\n  # (read as omega[y(t),z(t)] = omega[Observation,State])\n\n  omega[1,1] <- 1 - p1     # Pr(alive 1 t -> non-detected t)\n  omega[1,2] <- p1         # Pr(alive 1 t -> detected site 1 t)\n  omega[1,3] <- 0          # Pr(alive 1 t -> detected site 2 t)\n  omega[2,1] <- 1 - p2     # Pr(alive 2 t -> non-detected t)\n  omega[2,2] <- 0          # Pr(alive 2 t -> detected site 1 t)\n  omega[2,3] <- p2         # Pr(alive 2 t -> detected site 2 t)\n  omega[3,1] <- 1          # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0          # Pr(dead t -> detected site 1 t)\n  omega[3,3] <- 0          # Pr(dead t -> detected site 2 t)\n...\nmultisite <- nimbleCode({\n...\n  # likelihood\n  for (i in 1:N){\n    # latent state at first capture\n    z[i,first[i]] <- y[i,first[i]] - 1\n    for (t in (first[i]+1):K){\n      # z(t) given z(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # y(t) given z(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:3])\n    }\n  }\n})\n# occasions of first capture\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\n# constants\nmy.constants <- list(first = first, \n                     K = ncol(y), \n                     N = nrow(y))\n# data\nmy.data <- list(y = y + 1)\n# initial values \nzinits <- y # say states are observations, detections in A or B   \n            # are taken as alive in same sites \n# non-detections become alive in site A or B\nzinits[zinits==0] <- sample(c(1,2), sum(zinits==0), replace = TRUE) \ninitial.values <- function(){list(phi1 = runif(1, 0, 1), \n                                  phi2 = runif(1, 0, 1), \n                                  psi12 = runif(1, 0, 1), \n                                  psi21 = runif(1, 0, 1), \n                                  p1 = runif(1, 0, 1), \n                                  p2 = runif(1, 0, 1), \n                                  pi1 = runif(1, 0, 1),\n                                  z = zinits)}\n# parameters to monitor\nparameters.to.save <- c(\"phi1\", \"phi2\",\"psi12\", \"psi21\", \n                        \"p1\", \"p2\", \"pi1\")\n# MCMC details\nn.iter <- 20000\nn.burnin <- 1000\nn.chains <- 2\nmcmc.multisite <- nimbleMCMC(code = multisite, \n                             constants = my.constants,\n                             data = my.data,              \n                             inits = initial.values,\n                             monitors = parameters.to.save,\n                             niter = n.iter,\n                             nburnin = n.burnin, \n                             nchains = n.chains)\nMCMCplot(mcmc.multisite)\nMCMCsummary(mcmc.multisite, round = 2)\n##       mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p1    0.53 0.09 0.37 0.53  0.71    1  1107\n## p2    0.40 0.04 0.32 0.39  0.48    1  1080\n## phi1  0.60 0.05 0.50 0.60  0.71    1  1675\n## phi2  0.70 0.04 0.63 0.70  0.77    1  1145\n## psi12 0.27 0.06 0.17 0.27  0.39    1  2001\n## psi21 0.07 0.02 0.04 0.07  0.11    1  2192\n# read in data\ngeese <- read_csv(\"geese.csv\", col_names = TRUE)\ny <- as.matrix(geese)\n# drop Carolinas\ny[y==3] <- 0 # act as if there was no detection in site 3 Carolinas\nmask <- apply(y, 1, sum)\ny <- y[mask!=0,] # remove rows w/ 0s only\n# get occasions of first encounter\nget.first <- function(x) min(which(x != 0))\nfirst <- apply(y, 1, get.first)\n# filter out individuals that are first captured at last occasion. \n# These individuals do not contribute to parameter estimation, \n# and also they cause problems with nimbleEcology\nmask <- which(first!=ncol(y)) \ny <- y[mask, ]                # keep only these\nfirst <- first[mask]\n\n# NIMBLE code \nmultisite.marginalized <- nimbleCode({\n  \n  # -------------------------------------------------\n  # Parameters:\n  # phi1: survival probability site 1\n  # phi2: survival probability site 2\n  # psi12: movement probability from site 1 to site 2\n  # psi21: movement probability from site 2 to site 1\n  # p1: recapture probability site 1\n  # p2: recapture probability site 2\n  # pi1: prop of being in site 1 at initial capture\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive at 1\n  # 2 alive at 2\n  # 3 dead\n  # Observations (y):  \n  # 1 not seen\n  # 2 seen at site 1 \n  # 3 seen at site 2\n  # -------------------------------------------------\n  \n  # priors\n  phi1 ~ dunif(0, 1)\n  phi2 ~ dunif(0, 1)\n  psi12 ~ dunif(0, 1)\n  psi21 ~ dunif(0, 1)\n  p1 ~ dunif(0, 1)\n  p2 ~ dunif(0, 1)\n  pi1 ~ dunif(0, 1)\n  \n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phi1 * (1 - psi12)\n  gamma[1,2] <- phi1 * psi12\n  gamma[1,3] <- 1 - phi1\n  gamma[2,1] <- phi2 * psi21\n  gamma[2,2] <- phi2 * (1 - psi21)\n  gamma[2,3] <- 1 - phi2\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n  \n  # probabilities of y(t) given z(t)\n  omega[1,1] <- 1 - p1     # Pr(alive 1 t -> non-detected t)\n  omega[1,2] <- p1         # Pr(alive 1 t -> detected 1 t)\n  omega[1,3] <- 0          # Pr(alive 1 t -> detected 2 t)\n  omega[2,1] <- 1 - p2     # Pr(alive 2 t -> non-detected t)\n  omega[2,2] <- 0          # Pr(alive 2 t -> detected 1 t)\n  omega[2,3] <- p2         # Pr(alive 2 t -> detected 2 t)\n  omega[3,1] <- 1          # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0          # Pr(dead t -> detected 1 t)\n  omega[3,3] <- 0          # Pr(dead t -> detected 2 t)\n  \n  # likelihood \n  # initial state probs\n  for(i in 1:N) {\n    # first state propagation\n    init[i, 1:3] <- gamma[ y[i, first[i] ] - 1, 1:3 ]        \n  }\n  for (i in 1:N){\n    y[i,(first[i]+1):K] ~ dHMM(init = init[i,1:3],# data first[i]+1\n                               probObs = omega[1:3,1:3], # obs\n                               probTrans = gamma[1:3,1:3], # trans\n                               len = K - first[i], # nb of occasions\n                               checkRowSums = 0) # do not check \n                                                 # whether elements \n                                                 # in a row sum up \n                                                 # to 1\n  }\n})\n# constants\nmy.constants <- list(first = first, \n                     K = ncol(y), \n                     N = nrow(y))\n# data\nmy.data <- list(y = y + 1)\n# initial values \ninitial.values <- function(){list(phi1 = runif(1, 0, 1), \n                                  phi2 = runif(1, 0, 1), \n                                  psi12 = runif(1, 0, 1), \n                                  psi21 = runif(1, 0, 1), \n                                  p1 = runif(1, 0, 1), \n                                  p2 = runif(1, 0, 1))}\n# parameters to monitor\nparameters.to.save <- c(\"phi1\", \"phi2\",\"psi12\", \"psi21\", \"p1\", \"p2\")\n# MCMC details\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\n# run NIMBLE\nmcmc.multisite.marginalized <- nimbleMCMC(\n  code = multisite.marginalized, \n  constants = my.constants,\n  data = my.data,              \n  inits = initial.values,\n  monitors = parameters.to.save,\n  niter = n.iter,\n  nburnin = n.burnin, \n  nchains = n.chains)\nMCMCsummary(mcmc.multisite.marginalized, round = 2)\n##       mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p1    0.53 0.09 0.36 0.53  0.71    1   651\n## p2    0.40 0.04 0.32 0.39  0.49    1   618\n## phi1  0.60 0.05 0.51 0.60  0.71    1   935\n## phi2  0.70 0.04 0.63 0.70  0.76    1   804\n## psi12 0.27 0.06 0.17 0.26  0.39    1   973\n## psi21 0.07 0.02 0.04 0.07  0.11    1   965"},{"path":"dispersal.html","id":"gofas","chapter":"5 Sites and states","heading":"5.3.3 Goodness of fit","text":"Like CJS model, need ensure model provides good fit data. regard classical tests, goodness--fit testing procedures covered Section 4.7 CJS model extended model. procedure also available package R2ucare. transience trap-dependence tests can used site, worth mentionning test specific model several sites. ‚Äú‚Äù (WBWA) tests memory, words ‚Äôs test Markovian property HMM particular context capture-recapture. WBWA quantifies whether relationship animal last seen next seen . relationship exists, positive negative, suggests memory movements, probability animal moving site \\(t\\), given present site \\(t-1\\) made dependent \\(t-2\\). called second-order Markov process.Going back geese data, WBWA test implemented follows whole dataset:clearly strong (say significant) positive relationship judging value statistic. demonstrate account memory issue extension model case study Section 7.3.","code":"\n# To install the R2ucare package:\n# if(!require(devtools)) install.packages(\"devtools\")\n# devtools::install_github(\"oliviergimenez/R2ucare\")\nlibrary(R2ucare)\ngeese <- read_csv2(\"allgeese.csv\") %>% as.matrix()\ny <- geese[,1:6]\nsize <- geese[,7]\nwbwa <- test3Gwbwa(y, size)\nwbwa$test3Gwbwa##  stat    df p_val \n## 472.9  20.0   0.0"},{"path":"dispersal.html","id":"what-if-more-than-2-sites","chapter":"5 Sites and states","heading":"5.4 What if more than 2 sites?","text":"far considered two sites , sake simplicity. Indeed going three sites (), difficulty arises. movement probabilities still need 0 1, sum probabilities moving site also sum one. individual alive site 1 example, stay 1, move 2 move 3, choice. problem two sites probability moving 1 2 always estimated 0 1, complementary, probability moving 2 1 . three sites, might happen sum estimates \\(\\psi^{12}\\) \\(\\psi^{13}\\) larger one, even though ‚Äôre 0 1, make \\(\\psi^{11} = 1 - \\psi^{12} - \\psi^{13}\\) negative.basically two methods fulfill constraints, either assign Dirichlet (pronounced deer-eesh-lay) prior movement probabilities, use multinomial logit link function.","code":""},{"path":"dispersal.html","id":"dirichletprior","chapter":"5 Sites and states","heading":"5.4.1 Dirichlet prior","text":"Dirichlet distribution extends Beta distribution multivariate seen previously (Figure 1.2) values 0 1 add 1. Going back example 3 sites, like come prior parameters moving 1, \\(\\psi^{11}\\), \\(\\psi^{12}\\) \\(\\psi^{13}\\). Dirichlet distribution dimension 3 vector parameters \\((\\alpha_1, \\alpha_2, \\alpha_3)\\) controls shape. sum \\(\\alpha\\)‚Äôs can interpreted measure precision: higher sum, peaked distribution mean value, mean value along dimension ratio corresponding sum \\(\\alpha\\)‚Äôs. \\(\\alpha\\)‚Äôs equal, distribution symmetric (Figure 5.2). mean \\((1/3, 1/3, 1/3)\\) example 3 parameters, whatever value \\(\\alpha\\). \\(\\alpha_1 = \\alpha_2 = \\alpha_3 = 1\\), obtain uniform marginal distribution \\(\\psi\\)‚Äôs, values 1 (\\(\\alpha_1 = \\alpha_2 = \\alpha_3 = 0.1\\)) result distribution concentrating corners (skewed U-shaped forms) values 1 (\\(\\alpha_1 = \\alpha_2 = \\alpha_3 = 10\\)) result unimodal marginal distributions.\nFigure 5.2: Dirichlet distribution prior \\((\\psi^{11}, \\psi^{12}, \\psi^{13})\\) vector parameters \\(\\alpha\\). components \\(\\alpha\\) equal makes distribution symmetric, mean \\((1/3, 1/3, 1/3)\\). \\(\\alpha = 1\\), prior \\(\\psi\\)‚Äôs uniform (middle panel), unimodal \\(\\alpha = 10\\) (right panel) concentrated corners (0 1) \\(\\alpha = 0.1\\) (left panel).\nGoing back example, NIMBLE, consider Dirichlet prior triplet movement parameters, site 1 (\\(\\psi^{11}\\), \\(\\psi^{12}\\) \\(\\psi^{13}\\)), site 2 (\\(\\psi^{21}\\), \\(\\psi^{22}\\) \\(\\psi^{23}\\)) site 3 (\\(\\psi^{31}\\), \\(\\psi^{32}\\) \\(\\psi^{33}\\)).start setting scene comments:use parameters (now respect constraints) define transition matrix:fit model geese dataset detections Carolinas wintering site back , alpha <- c(1, 1, 1) passed constants, obtain following results:Survival probabilities similar among sites, although lower mid-Atlantic (phi[1]). detection probability Carolinas (p3) seems much lower two wintering sites. estimated probability moving Chesapeake Carolinas (psi3[2]) 2 times high probability moving opposite direction (psi2[3]).theory, include covariates Section 4.8 \\(\\alpha\\) parameters use log link function (ensure \\(\\alpha > 0\\)), e.g.¬†\\(\\log(\\alpha) = \\beta_1 + \\beta_2 x\\). However, NIMBLE allow . Fortunately, another way specify Dirichlet distribution ratio gamma distributions allows incorporate covariates.gamma distribution continuous. two parameters \\(\\alpha\\) \\(\\theta\\) control shape scale (Figure 5.3). Another parameterization considers shape rate inverse scale.\nFigure 5.3: distribution gamma(\\(\\alpha\\),\\(\\theta\\)) different values \\(\\alpha\\) \\(\\theta\\). shape argument \\(\\alpha\\) determines overall shape scale parameter \\(\\theta\\) affects scale values (compare values X- Y-axes bottom upper panels). exponential chi-square distributions particular cases gamma distribution. parameter shape close zero, gamma similar exponential (bottom upper left panels). parameter shape large, gamma similar chi-squared distribution (bottom upper right panels).\nthree independent random variables \\(Y_1, Y_2\\) \\(Y_3\\) distributed gamma distributions shape parameters \\(\\alpha\\)‚Äôs scale parameter \\(\\theta\\), \\(Y_j \\sim \\text{Gamma}(\\alpha_j, \\theta)\\), can shown vector \\((Y_1/V, Y_2/V, Y_3/V)\\) Dirichlet vector parameters \\(\\alpha\\)‚Äôs, \\(V\\) sum \\(Y\\)‚Äôs (also gamma distributed). NIMBLE, suggests using \\(\\theta = 1\\) get uniform prior:, can express shape parameter gamma distribution (precisely \\(\\alpha\\)‚Äôs ) function covariates \\(\\log(\\alpha) = \\beta_1 + \\beta_2 x\\) spirit generalized linear model gamma response.","code":"\n...\n  # -------------------------------------------------\n  # Parameters:\n  # phi1: survival prob site 1\n  # phi2: survival prob site 2\n  # phi3: survival prob site 3\n  # psi11 = psi1[1]: mov prob site 1 -> site 1 (reference)\n  # psi12 = psi1[2]: mov prob site 1 -> site 2\n  # psi13 = psi1[3]: mov prob site 1 -> site 3 \n  # psi21 = psi2[1]: mov prob site 2 -> site 1\n  # psi22 = psi2[2]: mov prob site 2 -> site 2 (reference)\n  # psi23 = psi2[3]: mov prob site 2 -> site 3\n  # psi31 = psi3[1]: mov prob site 3 -> site 1\n  # psi32 = psi3[2]: mov prob site 3 -> site 2\n  # psi33 = psi3[3]: mov prob site 3 -> site 3 (reference)\n  # p1: recapture prob site 1\n  # p2: recapture prob site 2\n  # p3: recapture prob site 3\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive at 1\n  # 2 alive at 2\n  # 2 alive at 3\n  # 3 dead\n  # Observations (y):  \n  # 1 not seen\n  # 2 seen at 1 \n  # 3 seen at 2\n  # 3 seen at 3\n...multisite <- nimbleCode({\n...\n  # transitions: Dirichlet priors\n  psi1[1:3] ~ ddirch(alpha[1:3]) # psi11, psi12, psi13\n  psi2[1:3] ~ ddirch(alpha[1:3]) # psi21, psi22, psi23\n  psi3[1:3] ~ ddirch(alpha[1:3]) # psi31, psi32, psi33\n...multisite <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phi1 * psi1[1]\n  gamma[1,2] <- phi1 * psi1[2]\n  gamma[1,3] <- phi1 * psi1[3]\n  gamma[1,4] <- 1 - phi1\n  gamma[2,1] <- phi2 * psi2[1]\n  gamma[2,2] <- phi2 * psi2[2]\n  gamma[2,3] <- phi2 * psi2[3]\n  gamma[2,4] <- 1 - phi2\n  gamma[3,1] <- phi3 * psi3[1]\n  gamma[3,2] <- phi3 * psi3[2]\n  gamma[3,3] <- phi3 * psi3[3]\n  gamma[3,4] <- 1 - phi3\n  gamma[4,1] <- 0\n  gamma[4,2] <- 0\n  gamma[4,3] <- 0\n  gamma[4,4] <- 1\n...\nMCMCsummary(mcmc.multisite, round = 2)\n##         mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p1      0.53 0.09 0.36 0.52  0.70 1.01   412\n## p2      0.46 0.05 0.37 0.45  0.57 1.00   399\n## p3      0.24 0.06 0.13 0.23  0.38 1.01   248\n## phi1    0.60 0.05 0.50 0.60  0.70 1.01   564\n## phi2    0.70 0.04 0.63 0.70  0.77 1.00   547\n## phi3    0.78 0.07 0.64 0.78  0.91 1.00   258\n## psi1[1] 0.74 0.06 0.62 0.74  0.84 1.00   798\n## psi1[2] 0.24 0.05 0.14 0.23  0.36 1.00   853\n## psi1[3] 0.02 0.03 0.00 0.02  0.10 1.01   401\n## psi2[1] 0.07 0.02 0.04 0.07  0.12 1.01   687\n## psi2[2] 0.83 0.04 0.73 0.84  0.90 1.00   363\n## psi2[3] 0.09 0.04 0.04 0.09  0.18 1.01   361\n## psi3[1] 0.02 0.02 0.00 0.02  0.06 1.00  1631\n## psi3[2] 0.21 0.05 0.12 0.20  0.32 1.00   721\n## psi3[3] 0.77 0.06 0.65 0.78  0.87 1.00   672\n...\n# transitions: Dirichlet priors with Gamma formulation\nfor (s in 1:3){\n  # Y1, Y2, Y3 for psi11, psi12, psi13\n  lpsi1[s] ~ dgamma(alpha[s], 1) \n  psi1[s] <- lpsi1[s]/V1 # psi11, psi12, psi13\n  # Y'1, Y'2, Y'3 for psi21, psi22, psi23\n  lpsi2[s] ~ dgamma(alpha[s], 1) \n  psi2[s] <- lpsi2[s]/V2 # psi21, psi22, psi23\n  # Y''1, Y''2, Y''3 for psi31, psi32, psi33\n  lpsi3[s] ~ dgamma(alpha[s], 1) \n  psi3[s] <- lpsi3[s]/V3 # psi31, psi32, psi33\n}\nV1 <- sum(lpsi1[1:3])\nV2 <- sum(lpsi2[1:3])\nV3 <- sum(lpsi3[1:3])\n..."},{"path":"dispersal.html","id":"multinomiallogit","chapter":"5 Sites and states","heading":"5.4.2 Multinomial logit","text":"Another possibility build prior ensures movement probabilities 0 1 sum 1 extend logit link used CJS model Section 4.8. Remember \\(\\text{logit}(\\phi) = \\beta\\), specified prior \\(\\beta\\) say \\(\\beta \\sim N(0,1.5)\\) got prior \\(\\phi\\) back-transforming \\(\\beta\\) \\(\\phi = \\text{logit}^{-1}(\\beta)\\).Going back example \\(3\\) sites, focusing movement probabilities say, site 1, first choose reference (pivot) site, say 1, \\(\\log\\left(\\displaystyle{\\frac{\\psi^{12}}{\\psi^{11}}}\\right) = \\beta_2\\) \\(\\log\\left(\\displaystyle{\\frac{\\psi^{13}}{\\psi^{11}}}\\right) = \\beta_3\\). Interestingly, exponentiated, \\(\\beta\\)‚Äôs can interpreted increase odds moving versus staying site resulting one-unit increase covariate. sites can chosen reference, change likelihood get results. Now specify normal prior distribution \\(\\beta\\)‚Äôs. Eventually, back-transform, use \\(\\psi^{12} = \\displaystyle{\\frac{\\exp(\\beta_2)}{1+\\displaystyle{\\exp(\\beta_2)+\\displaystyle{\\exp(\\beta_3)}}}}\\) \\(\\psi^{13} = \\displaystyle{\\frac{\\exp(\\beta_3)}{1+\\displaystyle{\\exp(\\beta_2)+\\displaystyle{\\exp(\\beta_3)}}}}\\). reference parameter, \\(\\psi^{11}\\), calculated \\(\\psi^{11} = \\displaystyle{\\frac{1}{1 + \\displaystyle{\\exp(\\beta_2)+\\displaystyle{\\exp(\\beta_3)}}}}\\), simply complementary probability \\(\\psi^{11} = 1 - \\psi^{12} - \\psi^{13}\\).Note 2 sites instead 3 , multinomial logit reduces logit link.NIMBLE, write:use parameters (now respect constraints) define transition matrix:may check results similar obtained Dirichlet prior:Dirichlet prior multinomial logit link give similar results, much difference terms runtime quality convergence, use option feel comfortable .","code":"multisite <- nimbleCode({\n...\n  # transitions: multinomial logit\n  for (i in 1:2){\n    # normal priors on logit of all but one movement prob\n    beta1[i] ~ dnorm(0, sd = 1.5)\n    beta2[i] ~ dnorm(0, sd = 1.5)\n    beta3[i] ~ dnorm(0, sd = 1.5)\n    # constrain the transitions such that their sum is < 1\n    psi1[i] <- exp(beta1[i]) / (1 + exp(beta1[1]) + exp(beta1[2]))\n    psi2[i] <- exp(beta2[i]) / (1 + exp(beta2[1]) + exp(beta2[2]))\n    psi3[i] <- exp(beta3[i]) / (1 + exp(beta3[1]) + exp(beta3[2]))\n  }\n  # reference movement probability\n  psi1[3] <- 1 - psi1[1] - psi1[2]\n  psi2[3] <- 1 - psi2[1] - psi2[2]\n  psi3[3] <- 1 - psi3[1] - psi3[2]\n...multisite <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phi1 * psi1[1]\n  gamma[1,2] <- phi1 * psi1[2]\n  gamma[1,3] <- phi1 * psi1[3]\n  gamma[1,4] <- 1 - phi1\n  gamma[2,1] <- phi2 * psi2[1]\n  gamma[2,2] <- phi2 * psi2[2]\n  gamma[2,3] <- phi2 * psi2[3]\n  gamma[2,4] <- 1 - phi2\n  gamma[3,1] <- phi3 * psi3[1]\n  gamma[3,2] <- phi3 * psi3[2]\n  gamma[3,3] <- phi3 * psi3[3]\n  gamma[3,4] <- 1 - phi3\n  gamma[4,1] <- 0\n  gamma[4,2] <- 0\n  gamma[4,3] <- 0\n  gamma[4,4] <- 1\n...\nMCMCsummary(mcmc.multisite, round = 2)\n##         mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p1      0.52 0.09 0.36 0.52  0.69 1.02   702\n## p2      0.46 0.05 0.37 0.46  0.57 1.00   538\n## p3      0.23 0.06 0.13 0.23  0.36 1.00   404\n## phi1    0.61 0.05 0.51 0.61  0.71 1.00   893\n## phi2    0.70 0.04 0.63 0.70  0.77 1.00   879\n## phi3    0.77 0.07 0.64 0.77  0.91 1.01   462\n## psi1[1] 0.73 0.06 0.62 0.74  0.83 1.02  1435\n## psi1[2] 0.22 0.05 0.13 0.22  0.33 1.00  1687\n## psi1[3] 0.05 0.03 0.01 0.04  0.12 1.03   313\n## psi2[1] 0.07 0.02 0.04 0.07  0.12 1.00  1318\n## psi2[2] 0.83 0.04 0.73 0.84  0.90 1.01   466\n## psi2[3] 0.10 0.04 0.04 0.09  0.18 1.00   325\n## psi3[1] 0.03 0.02 0.01 0.02  0.07 1.01  2526\n## psi3[2] 0.21 0.05 0.12 0.21  0.33 1.00  1197\n## psi3[3] 0.76 0.06 0.64 0.76  0.86 1.00   994"},{"path":"dispersal.html","id":"states","chapter":"5 Sites and states","heading":"5.5 Sites may be states","text":"far, considered geographical locations (sites) refine alive information animal detected. However, quickly realized sites actually states defined physiology behavior, hence opening avenue applications capture-recapture models many fields ecology.Examples states include:Epidemiological disease states: sick/healthy, uninfected/infected/recovered;Morphological states: small/medium/big, light/medium/heavy;Life-history states: e.g.¬†breeder/non-breeder, failed breeder, first-time breeder;Developmental states: e.g.¬†juvenile/subadult/adult;Social states: e.g.¬†solitary/group-living, subordinate/dominant;Death states: e.g.¬†alive, dead harvest, dead natural causes.brief, states individual, time-specific discrete covariates.","code":""},{"path":"dispersal.html","id":"titis-data","chapter":"5 Sites and states","heading":"5.5.1 Titis data","text":"illustrate section, consider data collected 1942 1956 Lance Richdale Sooty shearwaters (Ardenna grisea), also known titis (Figure 5.4).\nFigure 5.4: Sooty shearwater (Ardenna grisea). Credit: John Harrison.\nmay see data :total, 1013 titis captured, marked recaptured small colony Whero Island southern New Zealand. data previously analyzed Richard Scofield kindly provided us data.Following way data collected, four states originally considered: Alive breeder; Accompanied another bird burrow; Alone burrow; surface; Dead. simplicity, pooled alive states (except breeder) together non-breeder state (NB) includes failed breeders (birds bred previously ‚Äì skip reproduction divorce) pre-breeders (birds yet breed). burrows checked hatching, birds category NB might already failed. Therefore birds breeder state (B) seen successful breeders, NB state nonbreeders plus prebreeders failed breeders.summary, code states 1 alive breeding, 2 alive non-breeding 3 dead. make modelling process self-explanatory, use letters B, NB D keep mind actually numbers. Observations non-detected coded 1, detected breeder non-breeder coded 2 3 respectively.aim study life-history trade‚Äìoffs. Specifically, ask questions: breeding affect survival? breeding current year affect breeding next year?","code":"\ntitis <- read_csv2(\"titis.csv\", \n                   col_names = FALSE)\ntitis %>%\n  rename(year_1942 = X1,\n         year_1943 = X2,\n         year_1944 = X3,\n         year_1949 = X4,\n         year_1952 = X5,\n         year_1953 = X6,\n         year_1956 = X7)## # A tibble: 1,013 √ó 7\n##    year_1942 year_1943 year_1944 year_1949 year_1952\n##        <dbl>     <dbl>     <dbl>     <dbl>     <dbl>\n##  1         0         0         0         0         0\n##  2         0         0         0         0         0\n##  3         0         0         0         0         0\n##  4         0         0         0         0         0\n##  5         0         0         0         0         0\n##  6         0         0         0         0         0\n##  7         0         0         0         0         0\n##  8         0         0         0         0         0\n##  9         0         0         0         0         0\n## 10         0         0         0         0         0\n## # ‚Ñπ 1,003 more rows\n## # ‚Ñπ 2 more variables: year_1953 <dbl>, year_1956 <dbl>"},{"path":"dispersal.html","id":"the-as-model-for-states","chapter":"5 Sites and states","heading":"5.5.2 The AS model for states","text":"Basically, model states model geese example two sites, see Sections 5.2 5.3.let \\(\\phi^B\\) \\(\\phi^{NB}\\) survival probabilities breeders non-breeders, \\(\\psi^{NBB}\\) probability becoming breeder non-breeder, \\(\\psi^{BNB}\\) probability skipping reproduction, transition matrix :\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=B & z_t=NB & z_t=D \\\\[0.3em] \\hdashline\n\\phi^B (1-\\psi^{BNB}) & \\phi^B \\psi^{BNB} & 1 - \\phi^B\\\\\n\\phi^{NB} \\psi^{NBB} & \\phi^{NB} (1-\\psi^{NBB}) & 1 - \\phi^{NB}\\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=B \\\\ z_{t-1}=NB \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\\]costs reproduction reflect future reproduction breeders lower probability breed next year non-breeders \\(\\psi^{BB} = 1 - \\psi^{BNB} < \\psi^{NBB}\\) survival survival breeders lower non-breeders \\(\\phi^B < \\phi^{NB}\\).observation matrix :\\[\\begin{matrix}\n& \\\\\n\\Omega =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=1 & y_t=2 & y_t=3 \\\\[0.3em] \\hdashline\n1 - p^B & p^B & 0\\\\\n1 - p^{NB} & 0 & p^{NB}\\\\\n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=B \\\\ z_{t}=NB \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\\]\\(p^B\\) \\(p^{NB}\\) detection proabilities non-breeders breeders respectively.","code":""},{"path":"dispersal.html","id":"nimble-implementation-2","chapter":"5 Sites and states","heading":"5.5.3 NIMBLE implementation","text":"first write NIMBLE code, exactly geese example two sites, see Section 5.3.First definitions comments code:priors:transition matrix:observation matrix:likelihood:run NIMBLE get following results:Non-breeder individuals seem survival higher breeder individuals, suggesting trade-reproduction survival. Let‚Äôs compare graphically survival breeder non-breeder individuals. First gather values generated \\(\\phi^B\\) \\(\\phi^{NB}\\) two chains:, plot two posterior distributions:little overlap two distributions, suggesting actual trade‚Äì. formal test trade-consist fitting model survival irrespective state, compare WAIC value model just fitted.potential trade-reproduction?overlap whatsoever, two transition probabilities clearly different. Interestingly, breeder individuals much better non-breeder individuals. failure detecting trade-probably due individual heterogeneity accounted . add individual random effect Section 4.8.4 consider 2 classes individuals case study Section 7.4.","code":"multistate <- nimbleCode({\n  # -------------------------------------------------\n  # Parameters:\n  # B is for breeder, NB for non-breeder\n  # phiB: survival probability state B\n  # phiNB: survival probability state NB\n  # psiBNB: transition probability from B to NB\n  # psiNBB: transition probability from NB to B\n  # pB: detection probability B\n  # pNB: detection probability NB\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive B\n  # 2 alive NB\n  # 3 dead\n  # Observations (y):\n  # 1 not seen\n  # 2 seen as B\n  # 3 seen as NB\n  # -------------------------------------------------\n...multistate <- nimbleCode({\n...\n  # Priors\n  phiB ~ dunif(0, 1)\n  phiNB ~ dunif(0, 1)\n  psiBNB ~ dunif(0, 1)\n  psiNBB ~ dunif(0, 1)\n  pB ~ dunif(0, 1)\n  pNB ~ dunif(0, 1)\n...multistate <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiB * (1 - psiBNB)\n  gamma[1,2] <- phiB * psiBNB\n  gamma[1,3] <- 1 - phiB\n  gamma[2,1] <- phiNB * psiNBB\n  gamma[2,2] <- phiNB * (1 - psiNBB)\n  gamma[2,3] <- 1 - phiNB\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n...multistate <- nimbleCode({\n...\n  # probabilities of y(t) given z(t)\n  omega[1,1] <- 1 - pB    # Pr(alive B t -> non-detected t)\n  omega[1,2] <- pB        # Pr(alive B t -> detected B t)\n  omega[1,3] <- 0         # Pr(alive B t -> detected NB t)\n  omega[2,1] <- 1 - pNB   # Pr(alive NB t -> non-detected t)\n  omega[2,2] <- 0         # Pr(alive NB t -> detected B t)\n  omega[2,3] <- pNB       # Pr(alive NB t -> detected NB t)\n  omega[3,1] <- 1         # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0         # Pr(dead t -> detected N t)\n  omega[3,3] <- 0         # Pr(dead t -> detected NB t)\n...\nmultistate <- nimbleCode({\n...\n  # likelihood\n  for (i in 1:N){\n    # latent state at first capture\n    z[i,first[i]] <- y[i,first[i]] - 1\n    for (t in (first[i]+1):K){\n      # z(t) given z(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # y(t) given z(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:3])\n    }\n  }\n})\nMCMCsummary(mcmc.multistate, round = 2)\n##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pB     0.60 0.03 0.54 0.60  0.65 1.00   756\n## pNB    0.56 0.03 0.51 0.56  0.62 1.01   725\n## phiB   0.80 0.02 0.77 0.80  0.83 1.00  1485\n## phiNB  0.85 0.02 0.81 0.85  0.88 1.01  1231\n## psiBNB 0.25 0.02 0.21 0.25  0.30 1.01  1227\n## psiNBB 0.24 0.02 0.20 0.24  0.28 1.00  1123\nphiB <- c(mcmc.multistate$chain1[,\"phiB\"], \n          mcmc.multistate$chain2[,\"phiB\"])\nphiNB <- c(mcmc.multistate$chain1[,\"phiNB\"], \n           mcmc.multistate$chain2[,\"phiNB\"])\ndf <- data.frame(param = c(rep(\"phiB\", length(phiB)), \n                           rep(\"phiNB\", length(phiB))), \n                 value = c(phiB, phiNB))\ndf %>%\n  ggplot(aes(x = value, fill = param)) +\n  geom_density(color = \"white\", alpha = 0.6, position = 'identity') +\n  scale_fill_manual(values = c(\"#69b3a2\", \"#404080\")) +\n  labs(fill = \"\", x = \"survival\")\npsiBNB <- c(mcmc.multistate$chain1[,\"psiBNB\"], \n            mcmc.multistate$chain2[,\"psiBNB\"])\npsiBB <- 1 - psiBNB\npsiNBB <- c(mcmc.multistate$chain1[,\"psiNBB\"], \n            mcmc.multistate$chain2[,\"psiNBB\"])\ndf <- data.frame(param = c(rep(\"psiBB\", length(phiB)), \n                           rep(\"psiNBB\", length(phiB))), \n                 value = c(psiBB, psiNBB))\ndf %>%\n  ggplot(aes(x = value, fill = param)) +\n  geom_density(color = \"white\", alpha = 0.6, position = 'identity') +\n  scale_fill_manual(values = c(\"#69b3a2\", \"#404080\")) +\n  labs(fill = \"\", x = \"breeding probabilities\")"},{"path":"dispersal.html","id":"localminima","chapter":"5 Sites and states","heading":"5.6 Issue of local minima","text":"frequentist approach, use maximum likelihood theory estimate parameters. maximum likelihood estimates values get maximum model likelihood. find maximum likelihood, use iterative optimization algorithms (e.g.¬†default method Nelder Mead R optim() function). However, sometimes, model likelihood contains several maxima guarantee algorithms find global maximum corresponding maximum likelihood estimates, may get stuck local maximum. Let‚Äôs illustrate issue simulated data kindly provided J√©r√¥me Dupuis. consider 2 sites (alive states), say 1 2, 7 sampling occasions. survival probability constant \\(\\phi = 1\\) well detection probability \\(p = 0.6\\). probability moving 1 2 \\(\\psi^{12} = 0.6\\) \\(\\psi^{21} = 0.85\\) opposite direction. encounter histories 27 individuals simulated J√©r√¥me:Figure 5.5, provide illustration influence choice initial values trying maximize likelihood, rather minimize deviance (minus two times log likelihood). black curve called profile deviance \\(\\psi^{21}\\). Profiling deviance consists taking slice direction parameter interest treating parameters nuisance parameters. example, set \\(\\psi^{21}\\) value (x-axis) minimize deviance (y-axis) respect parameters. two minima, global minimum (corresponding lowest value deviance) corresponding \\(\\psi^{21}\\) around 0.8 interest us. thing start optimization algorithm picking value red area, get stuck local minimum tell maximum likelihood estimate \\(\\psi^{21}\\) around 0.35, obviously far value used simulate data. contrast, pick initial values green area, algorithm converge global minimum.\nFigure 5.5: Influence choice initial values convergence global minimum deviance illustrated simulated data. black curve profile deviance probability move site 2 1. initial value picked red area, end local minimum picked green area, get global minimum corresponds maximum lilkelihood estimate.\nmight argue problem optimization algorithm therefore inherent frequentist approach. Well, turns MCMC algorithms immune issue. fit model constant parameters simulated data, trace probability moving 2 1:Clearly, two regimes. chain spends time around high values \\(\\psi^{21}\\) close true value represented blue dashed line. sometimes, chain jumps values around 0.3-0.4. behavior translates two modes posterior distribution \\(\\psi^{21}\\) mode right closer truth represented dashed blue vertical line:issue local minima difficult problem. get problematic situation? frequentist approach, trick fit model several times different initial values time, hoping ‚Äôll get fall green area somehow Figure 5.5. Bayesian approach, key handle distributions multiple modes sample posteriors efficiently. Assuming chains run NIMBLE spend time region parameter space corresponding global minimum, recommend using median mode summarize posterior distribution. simulated example, get median 0.79 \\(\\psi^{21}\\), bad given data simulated value 0.85 parameter:general advice, recommend always inspect trace plots find whether posterior distributions multiple modes suggest local minima.","code":"\ndat <- matrix(c(2, 0, 2, 1, 2, 0, 2,\n                2, 0, 2, 1, 2, 0, 2,\n                2, 0, 2, 1, 2, 0, 2,\n                2, 0, 2, 1, 2, 0, 2,\n                1, 1, 1, 0, 1, 0, 1,\n                1, 1, 1, 0, 1, 0, 1,\n                1, 1, 1, 0, 1, 0, 1,\n                1, 1, 1, 0, 1, 0, 1,\n                2, 0, 2, 0, 2, 0, 1,\n                2, 0, 2, 0, 2, 0, 1,\n                2, 0, 2, 0, 2, 0, 1,\n                2, 0, 2, 0, 2, 0, 1,\n                1, 0, 1, 0, 1, 0, 1,\n                1, 0, 1, 0, 1, 0, 1,\n                1, 0, 1, 0, 1, 0, 1,\n                1, 0, 1, 0, 1, 0, 1,\n                2, 0, 2, 0, 2, 0, 2,\n                2, 0, 2, 0, 2, 0, 2,\n                2, 0, 2, 0, 2, 0, 2,\n                2, 0, 2, 0, 2, 0, 2,\n                1, 0, 1, 0, 1, 0, 2,\n                1, 0, 1, 0, 1, 0, 2,\n                1, 0, 1, 0, 1, 0, 2,\n                1, 0, 1, 0, 1, 0, 2,\n                2, 2, 0, 1, 0, 2, 1,\n                2, 2, 0, 1, 0, 2, 1,\n                2, 2, 0, 1, 0, 2, 1,\n                2, 2, 0, 1, 0, 2, 1,\n                2, 1, 0, 2, 0, 1, 1,\n                2, 1, 0, 2, 0, 1, 1,\n                2, 1, 0, 2, 0, 1, 1,\n                2, 1, 0, 2, 0, 1, 1),\n              byrow = T,\n              ncol = 7)\nMCMCsummary(mcmc.multisite, round = 2)\n##       mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p     0.58 0.04 0.51 0.58  0.65 1.00  3194\n## phi   0.99 0.01 0.98 1.00  1.00 1.02  1173\n## psi12 0.51 0.15 0.19 0.56  0.72 1.10    76\n## psi21 0.70 0.20 0.27 0.78  0.93 1.12    56"},{"path":"dispersal.html","id":"multievent","chapter":"5 Sites and states","heading":"5.7 Uncertainty","text":"model, assume can without doubt assign site state animal whenever detected. always case. example, breeding status mammals birds ascertained based presence offspring eggs, uncertain whether female breeding offspring eggs seen. Another example epidemiological status mammals birds ascertained based tests run animals captured, uncertain whether animals healthy sick detected distance without possibility manipulate testing. section cover extension model uncertain states ‚Äì known multievent models Pradel (2005) ‚Äì two examples, one breeding states disease states. cover examples part Case studies.","code":""},{"path":"dispersal.html","id":"breedingmultievent","chapter":"5 Sites and states","heading":"5.7.1 Breeding states","text":"revisit titis example 5.5 try assess life-history trade-offs accounting uncertainty breeding status. still 3 states, alive breeding, alive non-breeding dead. regard observations, bird may encountered. may also encountered, contrast previous analysis titis data, don‚Äôt know state sure. may found ascertained (classified) breeder. may found ascertained non-breeder. may found unable determine whether ‚Äôs breeding non-breeding.states generate observations?alive state can generate 3 observations. deterministic link dead state observation non-encountered, bird dead, detected sure.Let‚Äôs specify model. First thing need, ‚Äôs big difference model, need initial state probabilities assign states individuals certainty. write probability state first encounter, vector initial state probabilities:\\[\\begin{matrix}\n& \\\\\n\\delta =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=B & z_t=NB & z_t=D \\\\[0.3em] \\hdashline\n\\pi^B & 1 - \\pi^{B} & 0\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\end{matrix}\n\\end{matrix}\\]\\(\\pi^B\\) probability newly encountered individual breeder, \\(\\pi^{NB} = 1 - \\pi^B\\) probability newly encountered individual non-breeder (complementary probability \\(\\pi^B\\)). probability dead first encounter 0 (bird alive first encountered).Now transition matrix, easy part doesn‚Äôt change. :\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=B & z_t=NB & z_t=D \\\\[0.3em] \\hdashline\n\\phi^B (1-\\psi^{BNB}) & \\phi^B \\psi^{BNB} & 1 - \\phi^B\\\\\n\\phi^{NB} \\psi^{NBB} & \\phi^{NB} (1-\\psi^{NBB}) & 1 - \\phi^{NB}\\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=B \\\\ z_{t-1}=NB \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\\]\\(\\phi^B\\) breeder survival, \\(\\phi_ {NB}\\) non-breeders, \\(\\psi^{BNB}\\) probability individual breeding year non-breeder next year, \\(\\psi^{NBB}\\) probability non-breeder individual breeder next year.Last, observation matrix. main difference multisite/multistate multievent models , observation parameters. Besides \\(p^B\\) detection probability breeders \\(p^{NB}\\) non-breeders, introduce two new parameters: \\(\\beta^B\\) probability correctly assign individual state B state B, \\(\\beta^{NB}\\) probability correctly assign individual state NB state NB. complementary \\(\\beta\\) parameters often called false positive probabilities. put everything matrix, usual. rows states: breeding, non-breeding dead. columns, occasion, observations: non-detected, detected ascertained B, detected ascertained NB, detected state unknown:\\[\\begin{matrix}\n& \\\\\n\\Omega =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=1 & y_t=2 & y_t=3 & y_t=4 \\\\[0.3em] \\hdashline\n1 - p^B & p^B \\beta^B & 0 & p^B (1-\\beta_ B) \\\\\n1-p^{NB} & 0 & p^{NB} \\beta^{NB} & p^{NB} (1-\\beta^{NB})\\\\\n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=B \\\\ z_{t}=NB \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\\]example, probability detected assigned state B, given ‚Äôre state B product \\(p^B\\) detection probability B \\(\\beta^B\\) probability correctly assigning breeding individual state B.first encounter, individuals captured, still need assign state. means set \\(p^B = p^{NB} = 1\\) use:\\[\\begin{matrix}\n& \\\\\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_{t = \\text{first}}=1 & y_{t = \\text{first}}=2 & y_{t = \\text{first}}=3 & y_{t = \\text{first}}=4 \\\\[0.3em] \\hdashline\n0 & \\beta^B & 0 & (1-\\beta^B)\\\\\n0 & 0 & \\beta^{NB} & (1-\\beta^{NB})\\\\\n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t = \\text{first}}=B \\\\ z_{t = \\text{first}}=NB \\\\ z_{t = \\text{first}}=D\n    \\end{matrix}\n\\end{matrix}\\]implement model NIMBLE, start using comments define parameters, states observations header code:assign prior parameters estimated. deal probabilities, uniform distribution 0 1 job:Now write vector initial state probabilities:transition matrix:observation matrix:observation matrix first encounter:Eventually, get likelihood:change line y[,first[]] ~ dcat(omega.init[z[,first[]],1:4]) use observation matrix first encounter.run NIMBLE get following numerical summaries model parameters:Breeders difficult assign correct state \\(\\beta^B\\), non-breeders relatively well classified non-breeders \\(\\beta^{NB}\\).cost current reproduction future reproduction. longer detect cost breeding survival.","code":"multievent <- nimbleCode({\n  # -------------------------------------------------\n  # Parameters:\n  # phiB: survival probability state B\n  # phiNB: survival probability state NB\n  # psiBNB: transition probability from B to NB\n  # psiNBB: transition probability from NB to B\n  # pB: recapture probability B\n  # pNB: recapture probability NB\n  # piB prob. of being in initial state breeder\n  # betaNB prob ascertain breeding status of ind encountered as NB\n  # betaB prob ascertain breeding status of ind encountered as B\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive B\n  # 2 alive NB\n  # 3 dead\n  # Observations (y):\n  # 1 = non-detected\n  # 2 = seen and ascertained as breeder\n  # 3 = seen and ascertained as non-breeder\n  # 4 = not ascertained\n  # -------------------------------------------------\n...multievent <- nimbleCode({\n...\n  # Priors\n  phiB ~ dunif(0, 1)\n  phiNB ~ dunif(0, 1)\n  psiBNB ~ dunif(0, 1)\n  psiNBB ~ dunif(0, 1)\n  pB ~ dunif(0, 1)\n  pNB ~ dunif(0, 1)\n  piB ~ dunif(0, 1)\n  betaNB ~ dunif(0, 1)\n  betaB ~ dunif(0, 1)\n...multievent <- nimbleCode({\n...\n  # vector of initial stats probs\n  delta[1] <- piB # prob. of being in initial state B\n  delta[2] <- 1 - piB # prob. of being in initial state NB\n  delta[3] <- 0 # prob. of being in initial state dead\n...multievent <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiB * (1 - psiBNB)\n  gamma[1,2] <- phiB * psiBNB\n  gamma[1,3] <- 1 - phiB\n  gamma[2,1] <- phiNB * psiNBB\n  gamma[2,2] <- phiNB * (1 - psiNBB)\n  gamma[2,3] <- 1 - phiNB\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n...multievent <- nimbleCode({\n...\n  # probabilities of y(t) given z(t)\n  omega[1,1] <- 1 - pB             # Pr(alive B t -> non-detected t)\n  omega[1,2] <- pB * betaB         # Pr(alive B t -> detected B t)\n  omega[1,3] <- 0                  # Pr(alive B t -> detected NB t)\n  omega[1,4] <- pB * (1 - betaB)   # Pr(alive B t -> detected U t)\n  omega[2,1] <- 1 - pNB            # Pr(alive NB t -> non-detected t)\n  omega[2,2] <- 0                  # Pr(alive NB t -> detected B t)\n  omega[2,3] <- pNB * betaNB       # Pr(alive NB t -> detected NB t)\n  omega[2,4] <- pNB * (1 - betaNB) # Pr(alive NB t -> detected U t)\n  omega[3,1] <- 1                  # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0                  # Pr(dead t -> detected N t)\n  omega[3,3] <- 0                  # Pr(dead t -> detected NB t)\n  omega[3,4] <- 0                  # Pr(dead t -> detected U t)\n...multievent <- nimbleCode({\n...\n  # probabilities of y(first) given z(first)\n  # Pr(alive B t = first -> non-detected t = first)\n  omega.init[1,1] <- 0          \n  # Pr(alive B t = first -> detected B t = first)\n  omega.init[1,2] <- betaB      \n  # Pr(alive B t = first -> detected NB t = first)\n  omega.init[1,3] <- 0          \n  # Pr(alive B t = first -> detected U t = first)\n  omega.init[1,4] <- 1 - betaB  \n  # Pr(alive NB t = first -> non-detected t = first)\n  omega.init[2,1] <- 0          \n  # Pr(alive NB t = first -> detected B t = first)\n  omega.init[2,2] <- 0          \n  # Pr(alive NB t = first -> detected NB t = first)\n  omega.init[2,3] <- betaNB     \n  # Pr(alive NB t = first -> detected U t = first)\n  omega.init[2,4] <- 1 - betaNB \n  # Pr(dead t = first -> non-detected t = first)\n  omega.init[3,1] <- 1          \n  # Pr(dead t = first -> detected N t = first)\n  omega.init[3,2] <- 0          \n  # Pr(dead t = first -> detected NB t = first)\n  omega.init[3,3] <- 0          \n  # Pr(dead t = first -> detected U t = first)\n  omega.init[3,4] <- 0          \n...\nmultievent <- nimbleCode({\n...\n  # likelihood\n  for (i in 1:N){\n    # latent state at first capture\n    z[i,first[i]] ~ dcat(delta[1:3])\n    # obs at first encounter\n    y[i,first[i]] ~ dcat(omega.init[z[i,first[i]],1:4]) \n    for (t in (first[i]+1):K){\n      # z(t) given z(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # y(t) given z(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:4])\n    }\n  }\n})\nMCMCsummary(mcmc.multievent, round = 2)\n##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## betaB  0.19 0.01 0.16 0.19  0.22 1.00   583\n## betaNB 0.74 0.06 0.64 0.73  0.88 1.00   198\n## pB     0.56 0.03 0.51 0.56  0.62 1.01   801\n## pNB    0.60 0.04 0.53 0.60  0.67 1.02   757\n## phiB   0.81 0.02 0.78 0.81  0.85 1.00  1551\n## phiNB  0.84 0.02 0.80 0.84  0.87 1.00  1610\n## piB    0.70 0.03 0.64 0.70  0.76 1.00   296\n## psiBNB 0.22 0.03 0.17 0.22  0.28 1.01   925\n## psiNBB 0.23 0.05 0.15 0.23  0.35 1.00   250"},{"path":"dispersal.html","id":"diseasemultievent","chapter":"5 Sites and states","heading":"5.7.2 Disease states","text":"Let‚Äôs look another example. consider system emerging pathogen Mycoplasma gallisepticum Edward Kanarek host house finch, Carpodacus mexicanus M√ºller. pathogen causes moderate severe eye swelling (Figure 5.6).\nFigure 5.6: house finch heavy infection caused conjunctivitis. Credit: Jim Mondok.\n‚Äôre asking whether presence clinical signs pathogen influences survival. objective study also quantify infection (moving state healthy state ill) recovery (moving state ill state healthy) probabilities. birds captured via mist nets marked individually identifiable color bands three years. data kindly provided Paul Conn Evan Cooch. difficulty ascertaining disease status birds seen distance difficult since determining presence pathogen possible bird‚Äôs eyes clearly visible. context, study dynamics disease?First, think states observations. :3 states\nhealthy (H)\nill ()\ndead (D)\nhealthy (H)ill ()dead (D)4 observations\nseen (1)\ncaptured healthy (2)\ncaptured ill (3)\nhealth status unknown, .e.¬†seen distance (4)\nseen (1)captured healthy (2)captured ill (3)health status unknown, .e.¬†seen distance (4)states generate observations?Clearly, model previous section titis, Section 5.7.1, loosely speaking replace breeder healthy non-breeder ill.vector initial state probabilities :\\[\\begin{matrix}\n& \\\\\n\\delta =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=H & z_t=& z_t=D \\\\[0.3em] \\hdashline\n\\pi^H & 1 - \\pi^{H} & 0\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\end{matrix}\n\\end{matrix}\\]\\(\\pi^H\\) probability newly encountered individual healthy, \\(\\pi^{} = 1 - \\pi^H\\) probability newly encountered individual ill.transition matrix :\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=H & z_t=& z_t=D \\\\[0.3em] \\hdashline\n\\phi^H (1-\\psi^{HI}) & \\phi^H \\psi^{HI} & 1 - \\phi^H\\\\\n\\phi^{} \\psi^{IH} & \\phi^{} (1-\\psi^{IH}) & 1 - \\phi^{}\\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=H \\\\ z_{t-1}=\\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\\]\\(\\phi^H\\) survival probability healthy individuals, \\(\\phi^\\) survival probability ill individuals, \\(\\psi^{HI}\\) probability getting ill (infection rate) \\(\\psi^{IH}\\) probability recovering disease (recovery rate).Image ‚Äôd like model dynamic incurable disease, transition matrix modified \\(\\psi^{IH} = 0\\), bird gets ill, remains ill \\(\\psi^{II} = 1 - \\psi^{IH} = 1\\). Therefore :\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=H & z_t=& z_t=D \\\\[0.3em] \\hdashline\n\\phi^H (1-\\psi^{HI}) & \\phi^H \\psi^{HI} & 1 - \\phi^H\\\\\n0 & \\phi^{}  & 1 - \\phi^{}\\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=H \\\\ z_{t-1}=\\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\\]analysing house finch data, allow recovering disease. observation matrix :\\[\\begin{matrix}\n& \\\\\n\\Omega =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 & y_t=3 \\\\[0.3em] \\hdashline\n1-p^H & p^H \\beta^H & 0 & p^H (1-\\beta^H)\\\\\n1-p^& 0 & p^{} \\beta^{} & p^{} (1-\\beta^{})\\\\\n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=H \\\\ z_{t}=\\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\\]\\(\\beta^H\\) probability assign healthy individual state H, \\(\\beta^{}\\) probability assign sick individual state . \\(p^H\\) detection probability healthy individuals, \\(p^\\) sick individuals.Using code developped titis example, get following results finches running NIMBLE:Healthy individuals correctly assigned (\\(\\beta^H\\) almost 1), infected individuals difficult ascertain (\\(\\beta^\\) around 0.05). Unexpectedly, ill birds better survival healthy individuals (compare \\(\\phi^\\) \\(\\phi^H\\)). Infection rate (\\(\\psi^{HI}\\)) 75%, recovery rate 20% (\\(\\psi^{IH}\\)).","code":"##       mean   sd 2.5%  50% 97.5% Rhat n.eff\n## betaH 0.99 0.01 0.97 0.99  1.00 1.01  2118\n## betaI 0.05 0.01 0.02 0.05  0.08 1.01  1810\n## pH    0.71 0.21 0.15 0.75  0.98 1.04   142\n## pI    0.28 0.10 0.21 0.25  0.63 1.00   317\n## phiH  0.70 0.07 0.62 0.69  0.89 1.08   192\n## phiI  0.99 0.01 0.96 0.99  1.00 1.00   832\n## pi    0.96 0.01 0.93 0.96  0.98 1.00  6332\n## psiHI 0.75 0.17 0.19 0.80  0.88 1.02   160\n## psiIH 0.20 0.09 0.12 0.17  0.50 1.05   146"},{"path":"dispersal.html","id":"summary-4","chapter":"5 Sites and states","heading":"5.8 Summary","text":"model HMM extends CJS model allowing estimation movements sites (e.g.¬†geographical locations) transitions states (e.g.¬†breeding status). flexibility allows addressing sorts questions ecology evolution.model HMM extends CJS model allowing estimation movements sites (e.g.¬†geographical locations) transitions states (e.g.¬†breeding status). flexibility allows addressing sorts questions ecology evolution.Covariates can considered, appropriate priors link functions need used 2 sites 2 alive states.Covariates can considered, appropriate priors link functions need used 2 sites 2 alive states.Model comparison can achieved WAIC goodness fit model capture-recapture data can assessed classical procedures.Model comparison can achieved WAIC goodness fit model capture-recapture data can assessed classical procedures.Importantly, HMM framework allows account uncertainty assigning states individuals.Importantly, HMM framework allows account uncertainty assigning states individuals.models covered chapter haven called multistratum/strata models, multisite models (section 5.2), multistate models (section 5.5) multievent models (section 5.7). models HMMs.models covered chapter haven called multistratum/strata models, multisite models (section 5.2), multistate models (section 5.5) multievent models (section 5.7). models HMMs.","code":""},{"path":"dispersal.html","id":"suggested-reading-4","chapter":"5 Sites and states","heading":"5.9 Suggested reading","text":"model introduced Arnason (1972), Arnason (1973) Schwarz, Schweigert, Arnason (1993). soon clever folks realized sites replaced states Nichols et al. (1992) Nichols et al. (1994). review models sites states, see Lebreton et al. (2009).model introduced Arnason (1972), Arnason (1973) Schwarz, Schweigert, Arnason (1993). soon clever folks realized sites replaced states Nichols et al. (1992) Nichols et al. (1994). review models sites states, see Lebreton et al. (2009).geese data analyzed Hestbeck, Nichols, Malecki (1991) Brownie et al. (1993), titis data Scofield, Fletcher, Robertson (2001). house finches data analyzed Faustino et al. (2004) Conn Cooch (2009; see also Cooch et al. 2012). Check Santoro et al. (2014), Marescot et al. (2018) Ollivier et al. (2023) examples disease ecology.geese data analyzed Hestbeck, Nichols, Malecki (1991) Brownie et al. (1993), titis data Scofield, Fletcher, Robertson (2001). house finches data analyzed Faustino et al. (2004) Conn Cooch (2009; see also Cooch et al. 2012). Check Santoro et al. (2014), Marescot et al. (2018) Ollivier et al. (2023) examples disease ecology.Section 5.6 local minima inspired chapter 10 Cooch White (2017).Section 5.6 local minima inspired chapter 10 Cooch White (2017).Classical goodness fit tests reviewed Pradel, Gimenez, Lebreton (2005). See also Pradel, Wintrebert, Gimenez (2003) tests specifically designed multisite/multistate models.Classical goodness fit tests reviewed Pradel, Gimenez, Lebreton (2005). See also Pradel, Wintrebert, Gimenez (2003) tests specifically designed multisite/multistate models.Models uncertainty introduced Pradel (2005). Dupuis (1995) similar idea model. review, see Gimenez et al. (2012).Models uncertainty introduced Pradel (2005). Dupuis (1995) similar idea model. review, see Gimenez et al. (2012).","code":""},{"path":"introduction-7.html","id":"introduction-7","chapter":"Introduction","heading":"Introduction","text":"third part Case studies provides real-world case studies scientific literature can reproduce using material covered previous chapters. problems can either ) used cement deepen understanding methods models, ii) adapted purpose, iii) serve teaching projects. case study, recall ecological question, build model step step conclude discussion results. provide code snippets needed illustrate specific points; complete code data available https://github.com/oliviergimenez/banana-book/tree/master/appendix.","code":""},{"path":"covariateschapter.html","id":"covariateschapter","chapter":"6 Dealing with covariates","heading":"6 Dealing with covariates","text":"","code":""},{"path":"covariateschapter.html","id":"introduction-8","chapter":"6 Dealing with covariates","heading":"6.1 Introduction","text":"Capture-recapture models often aim just estimate demographic parameters, also understand drives variation seen Chapter 4. , cover selection covariates potentially large set, using extension standard MCMC algorithms known reversible jump MCMC (RJMCMC), handle uncertainty key covariates, namely age sex, perfectly known individuals.","code":""},{"path":"covariateschapter.html","id":"covariate-selection-with-reversible-jump-mcmc","chapter":"6 Dealing with covariates","heading":"6.2 Covariate selection with Reversible Jump MCMC","text":"","code":""},{"path":"covariateschapter.html","id":"motivation","chapter":"6 Dealing with covariates","heading":"6.2.1 Motivation","text":"Section 4.6, used WAIC figure model, among several candidates, best supported data. model represented different ecological hypothesis. Now situation several individual temporal covariates might explain variation demographic parameters, say survival Section 4.8, things can quickly become bit tedious.\nLet‚Äôs look real-world example white stork (Ciconia ciconia) population Baden-W√ºrttemberg, Germany. 1960s 1990s, Western European stork populations decline. One leading hypothesis declines driven reduced food availability, caused severe droughts storks‚Äô wintering grounds Sahel region Grosbois et al. (2008).explore idea, ‚Äôll use rainfall measurements 10 meteorological stations chosen represent storks‚Äô wintering area: Diourbel, Gao, Kayes, Kita, Maradi, Mopti, Ouahigouya, S√©gou, Tahoua, Tombouctou. data cumulative rainfall amounts (mm) June, July, August, September ‚Äì roughly rainy season Sahel:question : combination stations best explains variation survival? tried answer testing every possible model, consider every subset 10 stations compare 1024 models (2^10 combinations). ‚Äôs far many WAIC-based approach practical.Instead comparing possible models one one, can use Reversible Jump MCMC (RJMCMC). RJMCMC extension standard Bayesian inference model treated additional, discrete parameter. framework, posterior distribution spans parameter space (e.g.¬†regression coefficients) model space (e.g.¬†covariates included). simple terms, allow algorithm jump models, switching covariates goes. can think hiker exploring different trails (models), stopping along trail take measurements (parameters) deciding whether move onto another path.Using RJMCMC, can estimate posterior probability covariate influences survival, obtain model-averaged regression coefficients survival estimates incorporate parameter model uncertainty.won‚Äôt dive mathematical details don‚Äôt worry, can still follow analysis without . Check Chapter 7 King et al. (2009; see also Gimenez et al. 2009) ‚Äôre interested .","code":"##      Diourbel  Gao Kayes  Kita Maradi Mopti Ouahigouya\n## [1,]     6770 1900  7130 11350   6970  6580       6220\n## [2,]     6420 2690  6180 13690   5880  6470       6260\n## [3,]     6890 3530  6480 11820   6100  5230       6730\n## [4,]     5700 2710  8440  9590   5210  5670       5670\n## [5,]     6760 2090  6910  9850   6020  4200       5630\n## [6,]     5432 2100  6300  8960   6890  3900       7180\n##      S√©gou Tahoua Tombouctou\n## [1,]  8380   3920       1390\n## [2,]  7530   3200       2210\n## [3,]  6340   5170       1760\n## [4,]  7490   4370       2580\n## [5,]  5920   3120       2340\n## [6,]  6461   3891       2020"},{"path":"covariateschapter.html","id":"model-and-nimble-implementation","chapter":"6 Dealing with covariates","heading":"6.2.2 Model and NIMBLE implementation","text":"example, ‚Äôll work data 321 encounter histories white storks ringed chicks 1956 1970. data kindly provided Jean-Dominique Lebreton. ‚Äôll fit Cormack‚ÄìJolly‚ÄìSeber (CJS) model time-dependent survival constant detection probability, described Section 4.5. model survival probability phi linear function covariates stored x. handle model selection inside RJMCMC, use trick: covariate, introduce indicator variable ksi can take value 1 (covariate included model) 0 (covariate excluded). combine regression coefficients beta indicators single vector betaksi. means ksi[j] = 0, effect covariate j zero, effectively removing model. ‚Äôs works NIMBLE code:indicators regression coefficients:prior psi controls overall tendency include covariates model. Setting dbeta(1, 1) makes inclusion probabilities equally likely, data drive selection. priors beta intercept (consider selection) weakly informative.saw Section 2.6.1, NIMBLE allows change default sampler. , ‚Äôre going something slightly different use NIMBLE‚Äôs configureRJ() function set RJMCMC variable selection. function configureRJ() modifies existing MCMC configuration RJMCMC used sample certain parameters, allowing covariates turned run. uses univariate normal proposal distribution, can adjust proposal mean scale. main arguments :\n- targetNodes: parameters want apply variable selection (e.g.¬†beta);\n- indicatorNodes: indicator variables paired target nodes (e.g.¬†ksi);\n- control: list fine-tuning proposal mean mean proposal distribution (default 0), scale standard deviation proposal (default 1) fixedValue value variable takes excluded (default 0).‚Äôs apply white stork example:build, compile, run RJMCMC:run MCMC, configureRJ() takes care proposing moves either keep covariate model drop setting ksi value 0. covariate included (ksi = 1), sampler updates regression coefficient beta using specified normal proposal distribution. ‚Äôs excluded (ksi = 0), coefficient fixed zero (fixedValue). many iterations, chain ‚Äòjumps‚Äô different combinations covariates, building posterior probabilities one‚Äôs inclusion. means can later summarise covariates likely affect survival (via inclusion probabilities), model-averaged estimates survival incorporate uncertainty covariates belong model. R next section.","code":"\nfor (t in 1:(T-1)){\n  logit(phi[t]) <- intercept + inprod(betaksi[1:10], x[t, 1:10])\n  gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n  gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n  gamma[2,1,t] <- 0           # Pr(dead t -> alive t+1)\n  gamma[2,2,t] <- 1           # Pr(dead t -> dead t+1)\n}\nfor (j in 1:10){\n  betaksi[j] <- beta[j] * ksi[j]\n  ksi[j] ~ dbern(psi) # indicator variable associated with betaj\n}\npsi ~ dbeta(1, 1) # prior on inclusion probability\nfor (j in 1:10){\n  beta[j] ~ dnorm(0, sd = 1.5) # prior slopes\n}\nintercept ~ dnorm(0, sd = 1.5) # prior intercept\n## Build the model and configure default MCMC\nRJsurvival <- nimbleModel(code = hmm.phirjmcmcp, \n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values())\n\nCsurvival <- compileNimble(RJsurvival)\n\nRJsurvivalConf <- configureMCMC(RJsurvival)\nRJsurvivalConf$addMonitors('ksi')\n\n# Switch to reversible jump sampling for the betas\nconfigureRJ(conf = RJsurvivalConf,\n            targetNodes = 'beta',\n            indicatorNodes = 'ksi',\n            control = list(mean = 0, scale = 2))\nsurvivalMCMC <- buildMCMC(RJsurvivalConf)\nCsurvivalMCMC <- compileNimble(survivalMCMC, project = RJsurvival)\nsamples <- runMCMC(mcmc = CsurvivalMCMC, \n                   niter = n.iter,\n                   nburnin = n.burnin,\n                   nchains = n.chains)"},{"path":"covariateschapter.html","id":"results-and-interpretation","chapter":"6 Dealing with covariates","heading":"6.2.3 Results and interpretation","text":"RJMCMC run gives us posterior probabilities different models model corresponds specific combination covariates. get probabilities, first combine MCMC samples two chains:Next, look inclusion indicators ksi, take value 1 covariate model 0 . posterior mean ksi[j] simply estimated probability covariate j included:posterior inclusion probabilities tell us likely covariate appear ‚Äòtrue‚Äô model given data priors. , ksi[4] stands , inclusion probability around 0.96. corresponds Kita station.can also identify probable models visited RJMCMC. MCMC draw corresponds model, encode binary string (e.g., ‚Äú0101001001‚Äù):posterior model probabilities rank different combinations covariates, case, model containing rainfall Kita clearly dominant.conclusion, high inclusion probability Kita (covariate #4) dominant model containing Kita indicate station‚Äôs rainfall strongly linked survival, others .Now turning inference, ‚Äôd like get model-averaged parameters. covariate‚Äôs effect ‚Äò‚Äô indicator (ksi) 1. Multiplying beta ksi zeros effect covariate excluded. Summarising betaksi across draws gives model-averaged effect logit scale:large P_gt0 (e.g., > 0.95) suggests strong evidence covariate increases survival (logit scale).Now let‚Äôs get model-averaged survival estimates time. MCMC draw, build linear predictor covariates using beta * ksi, add intercept, inverse-logit get survival phi:Shaded ribbons show 95% credible intervals; solid line posterior mean survival, decreases time, model-averaged covariate inclusion.","code":"\n# Gather two chains\nout <- rbind(samples[[1]], samples[[2]])\n# Number of covariates\nK <- 10\n\n# Extract only ksi columns, in order ksi[1], ..., ksi[10]\nksi <- out[, paste0(\"ksi[\", 1:K, \"]\")]\n\n# Posterior inclusion probabilities for each covariate\ninclusion_prob <- colMeans(ksi)\ninclusion_prob\n##  ksi[1]  ksi[2]  ksi[3]  ksi[4]  ksi[5]  ksi[6]  ksi[7] \n## 0.02575 0.01720 0.01560 0.96120 0.04430 0.05350 0.02025 \n##  ksi[8]  ksi[9] ksi[10] \n## 0.03360 0.02630 0.02965\n# Encode each model draw as a string of 0s and 1s\nmodel_id <- apply(ksi, 1, paste0, collapse = \"\")\n\n# Empirical posterior model probabilities\npost_model_prob <- sort(prop.table(table(model_id)), \n                        decreasing = TRUE)\n\n# Show the top models\nhead(data.frame(model = names(post_model_prob), \n                prob = as.numeric(post_model_prob)), 10)\n##         model    prob\n## 1  0001000000 0.75470\n## 2  0001010000 0.03965\n## 3  0001100000 0.02910\n## 4  0000000000 0.02310\n## 5  0001000001 0.02055\n## 6  0001000100 0.01710\n## 7  0001000010 0.01660\n## 8  1001000000 0.01575\n## 9  0001001000 0.01320\n## 10 0101000000 0.01045\n# Pull posterior draws\nbeta  <- out[, paste0(\"beta[\", 1:K, \"]\")]\n\n# Model-averaged coefficients on the logit scale\nbetaksi <- beta * ksi\n\n# Summaries: mean, 95% credible intervals, and Pr(effect > 0)\ndf_betaksi <- data.frame(\n  mean  = apply(betaksi, 2, mean),\n  low  = apply(betaksi, 2, quantile, probs = 2.5/100),\n  high  = apply(betaksi, 2, quantile, probs = 97.5/100),\n  P_gt0 = apply(betaksi > 0, 2, mean))\n\nround(df_betaksi, 3)\n##            mean    low  high P_gt0\n## beta[1]   0.003  0.000 0.000 0.023\n## beta[2]   0.000  0.000 0.000 0.009\n## beta[3]   0.000  0.000 0.000 0.010\n## beta[4]   0.348  0.000 0.545 0.961\n## beta[5]  -0.006 -0.123 0.000 0.003\n## beta[6]   0.007  0.000 0.144 0.051\n## beta[7]  -0.002  0.000 0.000 0.004\n## beta[8]   0.005  0.000 0.048 0.028\n## beta[9]   0.002  0.000 0.000 0.021\n## beta[10] -0.003 -0.020 0.000 0.003\ninvlogit <- function(x) 1 / (1 + exp(-x))\n\n# Table of covariate values\nX <- rainfall[1:(16 - 1), 1:K]\n\n# Intercept MCMC draws\nintercept <- out[, \"intercept\"]\n\n# Linear predictor for every time t (rows) \n# and every MCMC draw (columns)\neta <- X %*% t(betaksi) \neta <- sweep(eta, 2, intercept, \"+\")  # add intercept per draw\n\n# Back-transform to survival probabilities\nphi_draws <- invlogit(eta)\n\n# Summaries by time\ndf_phi <- data.frame(\n  mean  = apply(phi_draws, 1, mean),\n  low  = apply(phi_draws, 1, quantile, probs = 2.5/100),\n  high  = apply(phi_draws, 1, quantile, probs = 97.5/100))\n\n# Visualize\nggplot(df_phi, aes(x = 1956:1970, y = mean)) +\n  geom_ribbon(aes(ymin = low, ymax = high), alpha = 0.2) +\n  geom_line(linewidth = 0.9) +\n  geom_point() +\n  labs(\n    x = \"Years (interval start)\",\n    y = \"Estimated survival probability\",\n    title = \"Model-averaged survival with 95% credible intervals\"\n  )"},{"path":"covariateschapter.html","id":"ageuncertainty","chapter":"6 Dealing with covariates","heading":"6.3 Uncertainty in age","text":"","code":""},{"path":"covariateschapter.html","id":"motivation-1","chapter":"6 Dealing with covariates","heading":"6.3.1 Motivation","text":"Survival demographic parameters often differ young older animals, blur age classes can end telling wrong story population dynamics. Section 4.8.5, incorporated age covariate capture-recapture models, assuming perfectly known. non-invasive genetics (Figure 4.1), though, age observed: DNA profile can identify , old . ignore uncertainty, survival estimates can biased. Inspired saw Section 5.7, see HMM capture-recapture models can handle kind problem treating age hidden state separating actually observe field.neat example comes Apennine brown bears Gervasi et al. (2017; see also Gowan et al. 2021). age bear DNA, authors paired genetics field information classify detections two broad age classes, cubs (<1 year) adults (‚â•1 year). , used two criteria. First, classify newly detected bear cub year sampled least date site known adult female shared ‚â•1 allele every locus (mother-offspring consistent). ‚Äôs lenient criterion (P1). Second, apply stricter criterion (P2): make mother‚Äìoffspring call, require two co-sampling occasions female, date site time.two criteria? ‚Äôs trade-. P1 better catching real cubs (sensitive) risks misclassifying adults cubs; P2 conservative calling ‚Äòcub‚Äô, reduces false cubs misses true ones.Instead pretending criteria perfect, authors model misclassification explicitly: age hidden, ‚Äòcub/adult P1/P2‚Äô observe, model estimates classification accuracy age-specific survival time. way, uncertainty propagated demographic estimates rather swept rug., show encode logic HMM NIMBLE: define hidden age states, write transition (survival) detection components, add classification step links hidden age observed P1/P2 outcomes. ‚Äôll also see small subset known-age individuals (e.g., live-trapped aged beforehand) anchors classification step. payoff set age-specific survival estimates robust imperfect age assignment, exactly need sound ecological inference management.","code":""},{"path":"covariateschapter.html","id":"model-and-nimble-implementation-1","chapter":"6 Dealing with covariates","heading":"6.3.2 Model and NIMBLE implementation","text":"estimate bear survival, disposal 12-year time series non-invasive genetic sampling data, collected 2003 2014. data kindly provided Vincenzo Gervasi. build model, first define states observations:States\nalive cub (C)\nalive adult ()\ndead (D)\nalive cub (C)alive adult ()dead (D)Observations\ndetected (1)\ndetected classified cub criteria (2)\ndetected classified cub P1 (3)\ndetected classified adult criteria (4)\ndetected (1)detected classified cub criteria (2)detected classified cub P1 (3)detected classified adult criteria (4)Now turn writing model.start vector initial states. Unknown-age individuals enter mixture cubs adults:\\[\\begin{matrix}\n& \\\\\n\\delta =\n  \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n          \\end{matrix}\n          \\hspace{-1.2em}\n          \\begin{matrix}\n          z_t=C & z_t=& z_t=D \\\\[0.3em] \\hdashline\n          \\pi & 1 - \\pi & 0\\\\\n          \\end{matrix}\n          \\hspace{-0.2em}\n          \\begin{matrix}\n          & \\\\\n          \\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n\\begin{matrix}\n\\end{matrix}\n\\end{matrix}\\]\\(\\pi\\) probability alive cub, \\(1 - \\pi\\) probability alive adult. bears known age first detection, fix initial state accordingly. NIMBLE implement individual-specific \\(\\delta_i\\) using equals() pin known ages:proceed transition matrix contains survival probabilities. cub either survives becomes adult next year (\\(\\phi_C\\)), dies; adults either survive class (\\(\\phi_A\\)) die:\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n  \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n          \\end{matrix}\n          \\hspace{-1.2em}\n          \\begin{matrix}\n          z_t=C & z_t=& z_t=D \\\\[0.3em] \\hdashline\n          0  & \\phi_C & 1 - \\phi_C\\\\\n          0 & \\phi_A & 1 - \\phi_A\\\\\n          0 & 0 & 1\n          \\end{matrix}\n          \\hspace{-0.2em}\n          \\begin{matrix}\n          & \\\\\n          \\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t-1}=C \\\\ z_{t-1}=\\\\ z_{t-1}=D\n\\end{matrix}\n\\end{matrix}\\]Following paper, adult survival sex-specific; cub survival common sexes:Last step observations, arise two steps: detection classification. detection matrix, need introduce intermediate observations, say \\(y'\\) detected (1), detected cub (2) detected adult (2):\\[\\begin{matrix}\n& \\\\\n\\Omega_1 =\n  \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n          \\end{matrix}\n          \\hspace{-1.2em}\n          \\begin{matrix}\n          y'_t=1 & y'_t=2 & y'_t=3 \\\\[0.3em] \\hdashline\n          1-p_C  & p_C & 0\\\\\n          1-p_A & 0 & 1 - p_A\\\\\n          1 & 0 & 0\n          \\end{matrix}\n          \\hspace{-0.2em}\n          \\begin{matrix}\n          & \\\\\n          \\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t}=C \\\\ z_{t}=\\\\ z_{t}=D\n\\end{matrix}\n\\end{matrix}\\]\\(p_C\\) detection cubs, \\(p_A\\) adults. classification matrix :\\[\\begin{matrix}\n& \\\\\n\\Omega_2 =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=1 & y_t=2 & y_t=3 & y_t=4 \\\\[0.3em] \\hdashline\n1 & 0 & 0 & 0\\\\\n0 & \\beta_{C,CC} & \\beta_{C,CA} & 1 - \\beta_{C,CC} - \\beta_{C,CA}\\\\\n0 & \\beta_{,CC} & \\beta_{,CA} & 1 - \\beta_{,CC} - \\beta_{,CA}\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    y'_{t}=1 \\\\ y'_{t}=2 \\\\ y'_{t}=3\n    \\end{matrix}\n\\end{matrix}\\]\\(\\beta_{C,CC}\\) probability , cub, individual classified cub criteria, \\(\\beta_{C,CA}\\) probability , cub, individual classified cub P1 adult P2, \\(\\beta_{,CC}\\) probability , adult, individual classified cub criteria, \\(\\beta_{,CA}\\) probability , adult, individual classified cub P1 adult P2.observation matrix product two detection classification matrices \\(\\Omega_1 \\Omega_2\\):\\[\\begin{matrix}\n& \\\\\n\\Omega =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=1 & y_t=2 & y_t=3 & y_t=4 \\\\[0.3em] \\hdashline\n1-p_C & p_C \\beta_{C,CC} & p_C \\beta_{C,CA} & p_C (1 - \\beta_{C,CC} - \\beta_{C,CA})\\\\\n1-p_A & p_A \\beta_{,CC} & p_A \\beta_{,CA} & p_A (1 - \\beta_{,CC} - \\beta_{,CA})\\\\\n1 & 0 & 0 & 0\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=1 \\\\ z_{t}=2 \\\\ z_{t}=3\n    \\end{matrix}\n\\end{matrix}\\]code, write \\(\\Omega_1 \\Omega_2\\) directly, faster matrix multiplication MCMC iteration. simplicity use single detection probability \\(p\\) ages, can let \\(p\\) vary age, sex, year sampling method, paper:first detection, event ‚Äòdetected‚Äô impossible construction (condition first detection). therefore use initial observation matrix \\(\\Omega_{\\text{init}}\\) \\(p\\) set 1 (shown).likelihood priors handled usual.","code":"\n# Initial state\n# age[i] == 0: unknown -> use delta: pi, 1 - pi\n# age[i] == 1: known cub -> force delta to [1, 0, 0]\n# age[i] == 2: known adult -> force delta to [0, 1, 0]\nfor (i in 1:N){\n  # Pr(C)\n  delta[1, i] <- equals(age[i], 0) * pi + equals(age[i], 1)  \n  # Pr(A)\n  delta[2, i] <- equals(age[i], 0) * (1 - pi) + equals(age[i], 2)  \n  delta[3, i] <- 0\n}\n# Transition matrix\nfor (i in 1:N){\n  gamma[1,1,i] <- 0\n  gamma[1,2,i] <- phiC\n  gamma[1,3,i] <- 1 - phiC\n  gamma[2,1,i] <- 0\n  gamma[2,2,i] <- phiA[sex[i]] # sex-spec adult surv (1=f, 2=m)\n  gamma[2,3,i] <- 1 - phiA[sex[i]]\n  gamma[3,1,i] <- 0\n  gamma[3,2,i] <- 0\n  gamma[3,3,i] <- 1\n}\n# Observation matrix\nomega[1,1] <- 1 - p\nomega[1,2] <- p * betaCCC\nomega[1,3] <- p * betaCCA\nomega[1,4] <- p * (1 - betaCCC - betaCCA)\n\nomega[2,1] <- 1 - p\nomega[2,2] <- p * betaACC\nomega[2,3] <- p * betaACA\nomega[2,4] <- p * (1 - betaACC - betaACA)\n\nomega[3,1] <- 1\nomega[3,2] <- 0\nomega[3,3] <- 0\nomega[3,4] <- 0"},{"path":"covariateschapter.html","id":"results-and-interpretation-1","chapter":"6 Dealing with covariates","heading":"6.3.3 Results and interpretation","text":"raw results:can arrange Table 6.1 compare results obtained Gervasi et al. (2017):\nTable 6.1: Table 6.2: Comparison parameter estimates HMM account age uncertainty: NIMBLE fit vs.¬†Gervasi et al.¬†(2017, Table 3).\nIntervals Table 6.1 95% credible intervals NIMBLE confidence intervals Gervasi et al. (2017). Detection Gervasi et al. (2017) varies design year; report overall average.NIMBLE fit reproduces main biological signals reported Apennine brown bear. Survival shows expected ordering, cubs << adults, adult females > adult males ‚Äì estimates closely match published analysis. credible/confidence intervals overlap broadly, indicating good agreement.detection estimate aligns study‚Äôs average detection, even though analysis lets detection vary design year rather assuming single constant value.age classification (linking hidden age P1/P2 outcomes), mapping parameters , found lower adult--cub misclassification paper (thus higher probability detected adults correctly called ‚Äòadult ‚Äô), still matches qualitative take: stricter criterion (P2) performs well adults.main divergence initial state mix. Intervals overlap, means differ. likely explanation model structure: used single, constant detection probability, published analysis allows detection vary sampling design year ‚Äì detectability vary meaningfully across methods years. Collapsing heterogeneity one \\(p\\) can nudge mixture first detection toward higher cub fraction explain patterns richer detection model attributes design year effects.conclusion, managed recover core findings published study (age- sex-specific survival average detection). Small discrepancies appear mainly adult misclassification rates \\(\\pi\\). mirror Gervasi et al. (2017) even closely, natural next step let \\(p\\) vary sampling design/year (information ), best supported model.","code":"##         mean   sd 2.5%  50% 97.5% Rhat n.eff\n## betaACA 0.05 0.02 0.02 0.04  0.08 1.00  4114\n## betaACC 0.02 0.01 0.00 0.02  0.05 1.00  4211\n## betaCCA 0.57 0.12 0.33 0.58  0.79 1.00   966\n## betaCCC 0.30 0.10 0.13 0.29  0.50 1.00   998\n## p       0.71 0.04 0.63 0.71  0.79 1.00  3329\n## phiA[1] 0.88 0.03 0.80 0.88  0.94 1.00  4195\n## phiA[2] 0.82 0.06 0.69 0.82  0.92 1.00  3643\n## phiC    0.53 0.13 0.28 0.53  0.78 1.00  3563\n## pi      0.27 0.09 0.12 0.26  0.49 1.02  1416"},{"path":"covariateschapter.html","id":"uncertainty-in-sex","chapter":"6 Dealing with covariates","heading":"6.4 Uncertainty in sex","text":"","code":""},{"path":"covariateschapter.html","id":"motivation-2","chapter":"6 Dealing with covariates","heading":"6.4.1 Motivation","text":"Many species show sex differences demographic parameters, mislabeling sex discarding uncertain cases can bias patterns want estimate. monomorphic birds example, field sexing relies behaviour (e.g., copulation posture, courtship displays, relative body size), clues vary reliability; Audouin‚Äôs gull (Larus audouinii) study motivates section, almost 80% individuals never sexed field, making ‚Äòknown-sex ‚Äô analyses wasteful biased toward higher survival.Pradel et al. (2008; see also Genovart, Pradel, Oro 2012) turned problem HMM inference task: treat sex hidden state (male/female/dead) model sex-assignment process . model developed Pradel, Genovart colleagues separates () probability attempting sex judgment (time trend, sexing effort increased) (ii) criterion-specific accuracy four behavioural clues (copulation, courtship feeding, begging food, body size).brief, message : field classifications uncertain, exploit rather filter , use HMM couple biological states imperfect observations propagate classification uncertainty survival.philosophy mirrors age-uncertainty Section 6.3 just completed: , age hidden P1/P2 provided noisy age labels; , sex hidden multiple behavioural criteria provide noisy sex labels.","code":""},{"path":"covariateschapter.html","id":"model-and-nimble-implementation-2","chapter":"6 Dealing with covariates","heading":"6.4.2 Model and NIMBLE implementation","text":"estimate Audouin‚Äôs gull survival, disposal dataset 4093 marked birds colony Ebro Delta (Spain), collected 10 years. data kindly provided Meritxell Genovart Roger Pradel. build model, first define states observations:States\nalive male (M)\nalive female (F)\ndead (D)\nalive male (M)alive female (F)dead (D)Observations\nseen (1)\njudged copulation male (2)\njudged begging food male (3)\njudged coutship feeding male (4)\njudged body size male (5)\njudged copulation female (6)\njudged begging food female (7)\njudged coutship feeding female (8)\njudged body size female (9)\njudged (10)\nseen (1)judged copulation male (2)judged begging food male (3)judged coutship feeding male (4)judged body size male (5)judged copulation female (6)judged begging food female (7)judged coutship feeding female (8)judged body size female (9)judged (10)Now turn writing model.start vector initial states. Unknown-sex individuals enter mixture males females probabilities \\(\\pi\\) \\(1-\\pi\\):\\[\\begin{matrix}\n& \\\\\n\\delta =\n  \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n          \\end{matrix}\n          \\hspace{-1.2em}\n          \\begin{matrix}\n          z_t=M & z_t=F & z_t=D \\\\[0.3em] \\hdashline\n          \\pi & 1 - \\pi & 0\\\\\n          \\end{matrix}\n          \\hspace{-0.2em}\n          \\begin{matrix}\n          & \\\\\n          \\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n\\begin{matrix}\n\\end{matrix}\n\\end{matrix}\\]proceed transition matrix contains survival probabilities. male either survives next year male (\\(\\phi_M\\)), dies; happens females (probability \\(\\phi_F\\)):\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n  \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n          \\end{matrix}\n          \\hspace{-1.2em}\n          \\begin{matrix}\n          z_t=M & z_t=F & z_t=D \\\\[0.3em] \\hdashline\n          \\phi_M  & 0 & 1 - \\phi_M\\\\\n          0 & \\phi_F & 1 - \\phi_F\\\\\n          0 & 0 & 1\n          \\end{matrix}\n          \\hspace{-0.2em}\n          \\begin{matrix}\n          & \\\\\n          \\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t-1}=M \\\\ z_{t-1}=F \\\\ z_{t-1}=D\n\\end{matrix}\n\\end{matrix}\\]vector initial states matrix transition probabilities written usual NIMBLE:Last step observation matrix, write follows (transposed convenience):\\[\\begin{matrix}\n& \\\\\n\\Omega' =\n  \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n          \\end{matrix}\n          \\hspace{-1.2em}\n          \\begin{matrix}\n          z_t=M & z_t=F & z_t=D \\\\[0.3em] \\hdashline\n          1 - p  & 1 - p & 1\\\\\n          p e (1-m_4) m_1 x_1 & p e (1-m_4) m_1 (1-x_1) & 0\\\\\n          p e (1-m_4) m_2 x_2 & p e (1-m_4) m_2 (1-x_2) & 0\\\\\n          p e (1-m_4) m_3 x_3 & p e (1-m_4) m_3 (1-x_3) & 0\\\\\n          p e m_4 x_4 & p e m_4 (1-x_4) & 0\\\\\n          p e (1-m_4) m_1 (1-x_1) & p e (1-m_4) m_1 x_1 & 0\\\\\n          p e (1-m_4) m_2 (1-x_2) & p e (1-m_4) m_2 x_2 & 0\\\\\n          p e (1-m_4) m_3 (1-x_3) & p e (1-m_4) m_3 x_3 & 0\\\\\n          p e m_4 (1-x_4) & p e m_4 x_4 & 0\\\\\n          p (1-e) & p (1-e) & 0\\\\\n          \\end{matrix}\n          \\hspace{-0.2em}\n          \\begin{matrix}\n          & \\\\\n          \\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n\\begin{matrix}\ny_{t}=1 \\\\ y_{t}=2 \\\\ y_{t}=3 \\\\ y_{t}=4 \\\\ y_{t}=5 \\\\ y_{t}=6 \\\\ y_{t}=7 \\\\ y_{t}=8 \\\\ y_{t}=9 \\\\ y_{t}=10\n\\end{matrix}\n\\end{matrix}\\]matrix bit complex encountered , needs explanations. individual encountered (probability \\(p\\)), chance sexed (\\(e\\)) based general appearance (body size: probability \\(m_4\\)) behaviour (probability \\(1 - m_4\\)). behaviour used, three different criteria (copulation, begging food courtship feeding), occur probabilities \\(m_1\\), \\(m_2\\), \\(m_3\\), respectively. Finally, criterion reliability (probabilities \\(x_1\\), \\(x_2\\), \\(x_3\\), \\(x_4\\), \\(x_4\\) reliability body-size criterion).admit matrix representation can difficult grasp . can easier split observation matrix several steps, like encountering, sexing, body size sexing, sex determination correctness, sketch decision tree Figure 2 Genovart, Pradel, Oro (2012) (see also appendix S1 paper).code, gives:first detection, observation ‚Äòdetected‚Äô impossible construction (condition first detection). therefore use initial observation matrix \\(\\Omega_{\\text{init}}\\) \\(p\\) set 1 (shown).likelihood priors handled usual.","code":"\n  delta[1] <- pi\n  delta[2] <- 1 - pi\n  delta[3] <- 0\n  \n  gamma[1,1] <- phiM            \n  gamma[1,2] <- 0               \n  gamma[1,3] <- 1 - phiM        \n  gamma[2,1] <- 0               \n  gamma[2,2] <- phiF            \n  gamma[2,3] <- 1 - phiF        \n  gamma[3,1] <- 0               \n  gamma[3,2] <- 0               \n  gamma[3,3] <- 1               \nomega[1,1] <- 1 - p                                  \nomega[1,2] <- p * e * (1 - m[4]) * m[1] * x[1]      \nomega[1,3] <- p * e * (1 - m[4]) * m[2] * x[2]      \nomega[1,4] <- p * e * (1 - m[4]) * m[3] * x[3]      \nomega[1,5] <- p * e * m[4] * x[4]      \nomega[1,6] <- p * e * (1 - m[4]) * m[1] * (1 - x[1])      \nomega[1,7] <- p * e * (1 - m[4]) * m[2] * (1 - x[2])      \nomega[1,8] <- p * e * (1 - m[4]) * m[3] * (1 - x[3])      \nomega[1,9] <- p * e * m[4] * (1 - x[4])      \nomega[1,10] <- p * (1 - e)      \n\nomega[2,1] <- 1 - p                                  \nomega[2,2] <- p * e * (1 - m[4]) * m[1] * (1 - x[1])      \nomega[2,3] <- p * e * (1 - m[4]) * m[2] * (1 - x[2])      \nomega[2,4] <- p * e * (1 - m[4]) * m[3] * (1 - x[3])      \nomega[2,5] <- p * e * m[4] * (1 - x[4])      \nomega[2,6] <- p * e * (1 - m[4]) * m[1] * x[1]      \nomega[2,7] <- p * e * (1 - m[4]) * m[2] * x[2]     \nomega[2,8] <- p * e * (1 - m[4]) * m[3] * x[3]   \nomega[2,9] <- p * e * m[4] * x[4]   \nomega[2,10] <- p * (1 - e)      \n\nomega[3,1] <- 1                                  \nomega[3,2] <- 0     \nomega[3,3] <- 0     \nomega[3,4] <- 0     \nomega[3,5] <- 0     \nomega[3,6] <- 0     \nomega[3,7] <- 0     \nomega[3,8] <- 0     \nomega[3,9] <- 0     \nomega[3,10] <- 0     "},{"path":"covariateschapter.html","id":"results-and-interpretation-2","chapter":"6 Dealing with covariates","heading":"6.4.3 Results and interpretation","text":"raw results:\nTable 6.3: Table 6.4: Comparison parameter estimates HMM account sex uncertainty: NIMBLE fit vs.¬†Pradel et al.¬†(2008, Table 5, model B genetically sexed anchors).\nIntervals Table 6.3 95% credible intervals NIMBLE confidence intervals Pradel et al. (2008). error rates 1 ‚àí x[]. Pradel‚Äôs \\(m\\)‚Äôs provided main author paper . Note m4 time-varying; estimates \\(t=1,\\ldots,10\\): 0.001, 0.002, 0.004, 0.007, 0.014, 0.026, 0.047, 0.084, 0.146, 0.242.NIMBLE fit recovers main biological signals reported Audouin‚Äôs gulls analysis. Survival shows expected ordering ‚Äì adult females ‚â• adult males ‚Äì broadly overlapping intervals means close published model. run, female‚Äìmale gap bit smaller (0.90 vs 0.89), direction matches paper‚Äôs message (higher female survival).used single, constant detection probability obtained \\(p \\approx 0.65\\), sits near middle year‚Äêspecific values obtained authors (shown paper).estimated probabilities clue used align closely published analysis three ‚Äòbehavioural‚Äô criteria: \\(m_1 \\approx 0.29\\) (copulation), \\(m_2 \\approx 0.60\\) (begging), \\(m_3 \\approx 0.11\\) (courtship feeding). paper lets body size use vary time; constant estimate (\\(m_4 \\approx 0.17\\)) read pooled average across years‚Äîconsistent finding low increasing use criterion.main discrepancy lies error rates criterion. published analysis finds low misclassification (roughly 5‚Äì10% criteria, imprecise estimate courtship feeding). fit suggests substantially higher error across criteria. discrepancy expect sensitivity known‚Äêsex anchors (components simplified). Without anchors, model can admit dual solutions (swapping sex labels flipping error probabilities) fit nearly equally well; small modelling choices initial values can tip chain toward one mode, see Pradel et al. (2008).estimate proportion males first encounter (\\(\\mu \\approx 0.52\\)) agrees closely published result, reinforcing state mix well constrained data even sex uncertain.conclude, sex‚Äêuncertainty HMM retrieves core demographic pattern (female ‚â• male survival) matches paper overall detectability use criteria. mirror published results closely, one add small anchor set genetically sexed individuals (information used Pradel et al. 2008 ).","code":"##      mean   sd 2.5%  50% 97.5% Rhat n.eff\n## e    0.07 0.00 0.07 0.07  0.07 1.01   589\n## m[1] 0.29 0.02 0.26 0.29  0.32 1.00   913\n## m[2] 0.60 0.02 0.56 0.60  0.63 1.00   892\n## m[3] 0.11 0.01 0.09 0.11  0.14 1.00   817\n## m[4] 0.17 0.01 0.14 0.17  0.19 1.01   949\n## p    0.65 0.00 0.64 0.65  0.66 1.00   394\n## phiF 0.90 0.01 0.89 0.90  0.91 1.01   205\n## phiM 0.89 0.01 0.88 0.89  0.90 1.01   279\n## pi   0.52 0.01 0.50 0.52  0.55 1.00   291\n## x[1] 0.52 0.03 0.45 0.52  0.58 1.01   915\n## x[2] 0.55 0.02 0.50 0.55  0.60 1.01   725\n## x[3] 0.54 0.05 0.44 0.55  0.65 1.00   927\n## x[4] 0.58 0.04 0.50 0.58  0.67 1.00   753"},{"path":"lackoffit.html","id":"lackoffit","chapter":"7 Addressing model lack of fit","heading":"7 Addressing model lack of fit","text":"","code":""},{"path":"lackoffit.html","id":"introduction-9","chapter":"7 Addressing model lack of fit","heading":"7.1 Introduction","text":"Capture-recapture models rely assumptions must hold inference reliable. Section 4.7, saw go wrong diagnose issues. chapter, turn remedies show fix building models explicitly accommodate lack fit. focus three topics: trap-dependence (detection today affects detection tomorrow), memory state process (Markov assumption short ‚Äì transitions depend current state), individual heterogeneity (persistent differences among animals).","code":""},{"path":"lackoffit.html","id":"trapdep","chapter":"7 Addressing model lack of fit","heading":"7.2 Accounting for trap-dependence","text":"","code":""},{"path":"lackoffit.html","id":"motivation-3","chapter":"7 Addressing model lack of fit","heading":"7.2.1 Motivation","text":"Capture-recapture inference can go sideways detection depends past capture. animals become trap‚Äêshy (avoid traps) trap‚Äêhappy (seek ) caught, independence assumption breaks, survival detection can biased ignore . Tests trap‚Äêdependence exist, see Section 4.7, surveys show ‚Äôs common across taxa ‚Äì roughly 70% reviewed studies reported evidence (Pradel Sanz-Aguilar 2012).fix encode behavioural response. Following Pradel Sanz-Aguilar (2012), treat trap‚Äêawareness (possibly temporary) state: right capture, individuals move ‚Äòtrap‚Äêaware‚Äô state detection probability, detection time \\(t+1\\) can differ animals caught vs.¬†caught \\(t\\). HMM formulation avoids awkward data splitting, plays nicely age covariates. Importantly, authors‚Äô example, ignoring trap‚Äêdependence underestimated survival, illustrating modelling trap-dependence matters., adopt logic NIMBLE: define trap‚Äêaware state, let detection depend , keep rest HMM machinery unchanged.","code":""},{"path":"lackoffit.html","id":"model-and-nimble-implementation-3","chapter":"7 Addressing model lack of fit","heading":"7.2.2 Model and NIMBLE implementation","text":"example, ‚Äôll work data 519 encounter histories Cory‚Äôs shearwaters (Calonectris diomedea) marked adults 2001 2008 Pantaleu Islet (Balearic Archipelago, Spain). data kindly provided Ana Sanz-Aguilar. perform goodness--fit tests dataset, Section 4.7, end significant trap-dependence effect (well transience effect). build model explicitly account lack fit, first define states observations:States\n- ‚Äòtrap-aware‚Äô, original state individual first released\n- U ‚Äòtrap-unaware‚Äô, follows occasion captured\n- D deadStates\n- ‚Äòtrap-aware‚Äô, original state individual first released\n- U ‚Äòtrap-unaware‚Äô, follows occasion captured\n- D deadObservations\n- detected (1)\n- detected (2)Observations\n- detected (1)\n- detected (2)Now turn writing model. start vector initial states. Individuals enter trap-aware probability 1:\\[\\begin{matrix}\n& \\\\\n\\delta =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\nz_t=& z_t=U & z_t=D \\\\[0.3em] \\hdashline\n1 & 0 & 0\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n\\begin{matrix}\n\\end{matrix}\n\\end{matrix}\\]proceed transition matrix:\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\nz_t=& z_t=U & z_t=D \\\\[0.3em] \\hdashline\n\\phi p' & \\phi (1-p') & 1 - \\phi\\\\\n\\phi p & \\phi (1-p) & 1 - \\phi\\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t-1}=\\\\ z_{t-1}=U \\\\ z_{t-1}=D\n\\end{matrix}\n\\end{matrix}\\]might noticed something ususual \\(\\Gamma\\) contains survival detection probabilities. ? track three hidden states end session \\(t\\) \\(t+1\\): \\(=\\) trap-aware (bird just caught \\(t\\)), \\(U =\\) trap-unaware (caught \\(t\\)), \\(D =\\) dead. sessions, everyone either survives probability \\(\\phi\\) dies \\(1 - \\phi\\) (moves \\(D\\), absorbing state). alive \\(t+1\\), awareness flag next session set whether bird gets caught \\(t+1\\): caught \\(\\) next time, caught \\(U\\). capture probabilities can differ current awareness, allow \\(p'\\) birds \\(\\) \\(t\\) \\(p\\) birds \\(U\\) \\(t\\). \\(p'>p\\) trap-happy behaviour (recently caught birds easier catch next time); \\(p'<p\\), ‚Äôs trap-shy. ‚Äòsurvive -> update awareness via capture‚Äô factorization transition matrix formalizes.Following paper, adult survival age-specific account transient effect, see Section 4.7:code , age passed data created follows:Last step observation matrix:\\[\\begin{matrix}\n& \\\\\n\\Omega =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\ny_t=1 & y_t=2 \\\\[0.3em] \\hdashline\n0 & 1 \\\\\n1 & 0 \\\\\n1 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t}=\\\\ z_{t}=U \\\\ z_{t}=D\n\\end{matrix}\n\\end{matrix}\\]animal trap-aware \\(t\\), means just captured. trap unaware dead, captured session. code, write:likelihood priors handled usual.","code":"\n# Transition matrix\n  for (i in 1:N){\n    for (t in first[i]:(K-1)){\n      phi[i,t] <- beta[age[i,t]] # beta1 = phi1, beta2 = phi2+\n      gamma[1,1,i,t] <- phi[i,t] * pprime\n      gamma[1,2,i,t] <- phi[i,t] * (1 - pprime)\n      gamma[1,3,i,t] <- 1 - phi[i,t]\n      gamma[2,1,i,t] <- phi[i,t] * p\n      gamma[2,2,i,t] <- phi[i,t] * (1 - p)\n      gamma[2,3,i,t] <- 1 - phi[i,t] \n      gamma[3,1,i,t] <- 0\n      gamma[3,2,i,t] <- 0 \n      gamma[3,3,i,t] <- 1\n    }\n  }\n# Age effect via individual x time cov and nested indexing \n# to distinguish survival over interval after first detection \n# from survival afterwards: \nage <- matrix(NA, nrow = nrow(y), ncol = ncol(y) - 1)\nfor (i in 1:nrow(age)){\n  for (j in 1:ncol(age)){\n    if (j == first[i]) age[i,j] <- 1 # age = 1\n    if (j > first[i]) age[i,j] <- 2  # age > 1\n  }\n}\n# Observation matrix\n  omega[1,1] <- 0\n  omega[1,2] <- 1\n  omega[2,1] <- 1\n  omega[2,2] <- 0\n  omega[3,1] <- 1\n  omega[3,2] <- 0"},{"path":"lackoffit.html","id":"results-and-interpretation-3","chapter":"7 Addressing model lack of fit","heading":"7.2.3 Results and interpretation","text":"raw results trap-dependence:two detection probabilities, depending whether bird previously caught pprime p, differ clearly, providing evidence trap-happiness. survival estimates similar obtained Pradel Sanz-Aguilar (2012) found \\(\\phi_1 = 0.77\\; (0.70, 0.82)\\) \\(\\phi_2 = 0.87\\; (0.82,0.90)\\) (check Table 1). Interestingly, fit model ignoring trap-dependence, get following results:compared previous estimates, see ignoring trap-dependence leads underestimation survival, either \\(\\phi_1\\) transient survival \\(\\phi_{2}\\) resident survival.approach described can conveniently extended several sites states, see Pradel Sanz-Aguilar (2012).","code":"##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p      0.46 0.06 0.34 0.46  0.56 1.10   580\n## phi1   0.76 0.02 0.71 0.76  0.80 1.03  1892\n## phi2   0.87 0.02 0.84 0.87  0.90 1.08   940\n## pprime 0.79 0.02 0.75 0.79  0.82 1.06  1154##      mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p    0.78 0.02 0.75 0.78  0.81 1.00   489\n## phi1 0.74 0.02 0.70 0.74  0.79 1.00   615\n## phi2 0.84 0.01 0.82 0.84  0.87 1.01   569"},{"path":"lackoffit.html","id":"memorymodel","chapter":"7 Addressing model lack of fit","heading":"7.3 Allowing your Markov models to remember","text":"","code":""},{"path":"lackoffit.html","id":"motivation-4","chapter":"7 Addressing model lack of fit","heading":"7.3.1 Motivation","text":"make models remember? far, dynamics states first-order Markov: state animal moves next depends state occupies now. think states sites, transitions dispersal migration, many species show site fidelity directional return reflects several steps back.relax first-order assumption, move second-order Markov description, happens \\(t+1\\) depends site \\(t\\) \\(t‚àí1\\). idea, often called memory model, introduced multisite capture-recapture Hestbeck, Nichols, Malecki (1991) Brownie et al. (1993), formulated cleanly within HMM framework Pradel (2005) Rouan, Choquet, Pradel (2009).illustrate memory model, use geese data introduced Chapter 5. saw Section 5.3.3, strong positive association site animal last seen site next seen. suggests first-order model simple transitions \\(t+1\\) depend \\(t\\) also \\(t-1\\).","code":""},{"path":"lackoffit.html","id":"model-and-nimble-implementation-4","chapter":"7 Addressing model lack of fit","heading":"7.3.2 Model and NIMBLE implementation","text":"reminder, two main ingredients HMM capturing dispersal 2 sites transition matrix:\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\nz_t=& z_t=B & z_t=D \\\\[0.3em] \\hdashline\n\\phi^(1-\\psi^{AB}) & \\phi^\\psi^{AB} & 1 - \\phi^\\\\\n\\phi^B \\psi^{BA} & \\phi^B (1-\\psi^{BA}) & 1 - \\phi^B\\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t-1}=\\\\ z_{t-1}=B \\\\ z_{t-1}=D\n\\end{matrix}\n\\end{matrix}\\]observation matrix:\\[\\begin{matrix}\n& \\\\\n\\Omega =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\ny_t=1 & y_t=2 & y_t=3 \\\\[0.3em] \\hdashline\n1 - p^& p^& 0\\\\\n1 - p^B & 0 & p^B\\\\\n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t}=\\\\ z_{t}=B \\\\ z_{t}=D\n\\end{matrix}\n\\end{matrix}\\], come HMM formulation memory model? need keep track sites previously visited, , trick consider states pairs sites occupied:States\nAA alive site \\(t\\) alive site \\(t-1\\)\nAB alive site \\(t\\) alive site B \\(t-1\\)\nBA alive site B \\(t\\) alive site \\(t-1\\)\nBB alive site B \\(t\\) alive site B \\(t-1\\)\nD dead\nAA alive site \\(t\\) alive site \\(t-1\\)AB alive site \\(t\\) alive site B \\(t-1\\)BA alive site B \\(t\\) alive site \\(t-1\\)BB alive site B \\(t\\) alive site B \\(t-1\\)D deadObservations\n1 captured\n2 captured site \n3 captured site B\n1 captured2 captured site A3 captured site BNow turn writing model. start vector initial states. Individuals enter study probabilities:\\[\\begin{matrix}\n& \\\\\n\\delta =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\nz_t=AA & z_t=AB & z_t=BA & z_t=BB &z_t=D \\\\[0.3em] \\hdashline\n\\pi^{AA} & \\pi^{AB} & \\pi^{BA} & \\pi^{BB} & 0\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n\\begin{matrix}\n\\end{matrix}\n\\end{matrix}\\]\\(\\pi^{ij}\\) probability alive site \\(j\\) first captured site \\(\\) , \\(\\pi^{BB} = 1 - (\\pi^{AA} + \\pi^{AB} + \\pi^{BA})\\).proceed transition matrix contains survival movement probabilities:\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\nz_t=AA & z_t=AB & z_t=BA & z_t=BB & z_t=D \\\\[0.3em] \\hdashline\n\\phi^{AAA} & \\phi^{AAB} & 0 & 0 & 1 - \\phi^{AAA} - \\phi^{AAB}\\\\\n0 & 0 & \\phi^{ABA} & \\phi^{ABB} & 1 - \\phi^{ABA} - \\phi^{ABB}\\\\\n\\phi^{BAA} & \\phi^{BAB} & 0 & 0 & 1 - \\phi^{BAA} - \\phi^{BAB}\\\\\n0 & 0 & \\phi^{BBA} & \\phi^{BBB} & 1 - \\phi^{BBA} - \\phi^{BBB}\\\\\n0 & 0 & 0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n\\begin{matrix}\nz_{t-1}=AA \\\\ z_{t-1}=AB \\\\ z_{t-1}=BA \\\\ z_{t-1}=BB \\\\ z_{t-1}=D\n\\end{matrix}\n\\end{matrix}\\]\\(\\phi^{ijk}\\) probability site \\(k\\) time \\(t + 1\\) individual\npresent site \\(j\\) \\(t\\) site \\(\\) \\(t - 1\\).alternate parameterization \\(\\Gamma\\) :\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\nz_t=AA & z_t=AB & z_t=BA & z_t=BB & z_t=D \\\\[0.3em] \\hdashline\n\\phi \\psi^{AAA} & \\phi (1 - \\psi^{AAA}) & 0 & 0 & 1 - \\phi\\\\\n0 & 0 & \\phi (1 - \\psi^{ABB}) & \\phi \\psi^{ABB} & 1 - \\phi\\\\\n\\phi \\psi^{BAA} & \\phi (1 - \\psi^{BAA}) & 0 & 0 & 1 - \\phi\\\\\n0 & 0 & \\phi (1-\\psi^{BBB}) & \\phi \\psi^{BBB} & 1 - \\phi\\\\\n0 & 0 & 0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n\\begin{matrix}\nz_{t-1}=AA \\\\ z_{t-1}=AB \\\\ z_{t-1}=BA \\\\ z_{t-1}=BB \\\\ z_{t-1}=D\n\\end{matrix}\n\\end{matrix}\\]\\(\\phi\\) probability surviving one occasion next, \\(\\psi_{ijj}\\) probability animal stays site \\(j\\) given site \\(\\) previous occasion.Last step observation matrix, write follows:\\[\\begin{matrix}\n& \\\\\n\\Omega =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\ny_t=1 & y_t=2 & y_t=3 \\\\[0.3em] \\hdashline\n1 - p^& p^& 0\\\\\n1 - p^B & 0 & p^B\\\\\n1 - p^& p^& 0\\\\\n1 - p^B & 0 & p^B\\\\\n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n\\begin{matrix}\nz_t=AA \\\\ z_t=AB \\\\ z_t=BA \\\\ z_t=BB \\\\ z_t=D\n\\end{matrix}\n\\end{matrix}\\]implement model NIMBLE, ‚Äôre going use nimbleEcology, makes life much easier initialize latent states \\(z\\) ‚Äì remember likelihood marginalized, see Sections 3.8 3.8.3.2. Specifically, use function dHMM() implements distribution HMM constant parameters. also use Dirichlet prior ensure initial state probabilities survival-movement probabilities sum 1 lie 0 1, see Section 5.4.1. code follows:","code":"\nmultisite.marginalized <- nimbleCode({\n  \n  # -------------------------------------------------\n  # Parameters:\n  # phi111: survival-mov probability from state 11 to state 11\n  # phi112: survival-mov probability from state 11 to state 12\n  # phi121: survival-mov probability from state 12 to state 21\n  # phi122: survival-mov probability from state 12 to state 22\n  # phi211: survival-mov probability from state 21 to state 11\n  # phi212: survival-mov probability from state 21 to state 12\n  # phi221: survival-mov probability from state 22 to state 21\n  # phi222: survival-mov probability from state 22 to state 22\n  # det1: detection probability site 1\n  # det2: detection probability site 2\n  # pi11: init stat prob 11\n  # pi12: init stat prob 12\n  # pi21: init stat prob 21\n  # pi22: init stat prob 22\n  # -------------------------------------------------\n  # States (S):\n  # 1 alive 11\n  # 2 alive 12\n  # 3 alive 21\n  # 4 alive 22\n  # 5 dead\n  # Observations (O):  \n  # 1 not seen\n  # 2 seen at site 1 \n  # 3 seen at site 2\n  # -------------------------------------------------\n  \n  # priors\n  det1 ~ dunif(0, 1)\n  det2 ~ dunif(0, 1)\n  phi11[1:3] ~ ddirch(alpha[1:3]) # phi111, phi112, 1-sum\n  phi12[1:3] ~ ddirch(alpha[1:3]) # phi121, phi122, 1-sum\n  phi21[1:3] ~ ddirch(alpha[1:3]) # phi211, phi212, 1-sum\n  phi22[1:3] ~ ddirch(alpha[1:3]) # phi221, phi222, 1-sum\n  \n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phi11[1]\n  gamma[1,2] <- phi11[2]\n  gamma[1,3] <- 0\n  gamma[1,4] <- 0\n  gamma[1,5] <- phi11[3]\n  gamma[2,1] <- 0\n  gamma[2,2] <- 0\n  gamma[2,3] <- phi12[1]\n  gamma[2,4] <- phi12[2]\n  gamma[2,5] <- phi12[3]\n  gamma[3,1] <- phi21[1]\n  gamma[3,2] <- phi21[2]\n  gamma[3,3] <- 0\n  gamma[3,4] <- 0\n  gamma[3,5] <- phi21[3]\n  gamma[4,1] <- 0\n  gamma[4,2] <- 0\n  gamma[4,3] <- phi22[1]\n  gamma[4,4] <- phi22[2]\n  gamma[4,5] <- phi22[3]\n  gamma[5,1] <- 0\n  gamma[5,2] <- 0\n  gamma[5,3] <- 0\n  gamma[5,4] <- 0\n  gamma[5,5] <- 1\n  \n  # probabilities of y(t) given z(t)\n  omega[1,1] <- 1 - det1\n  omega[1,2] <- det1\n  omega[1,3] <- 0\n  omega[2,1] <- 1 - det2\n  omega[2,2] <- 0\n  omega[2,3] <- det2\n  omega[3,1] <- 1 - det1\n  omega[3,2] <- det1\n  omega[3,3] <- 0\n  omega[4,1] <- 1 - det2\n  omega[4,2] <- 0\n  omega[4,3] <- det2\n  omega[5,1] <- 1\n  omega[5,2] <- 0\n  omega[5,3] <- 0\n  \n  # initial state probs\n  for(i in 1:N) {\n    # first state propagation\n    init[i, 1:5] <- gamma[ y[i, first[i] ] - 1, 1:5 ] \n  }\n  \n  # likelihood \n  for (i in 1:N){\n    y[i,(first[i]+1):K] ~ dHMM(init = init[i,1:5],# data first[i]+1\n                               probObs = omega[1:5,1:3], # obs\n                               probTrans = gamma[1:5,1:5], # trans\n                               len = K - first[i], # nb of occasions\n                               checkRowSums = 0) # do not check \n                                                 # whether elements \n                                                 # in a row sum \n                                                 # to 1\n  }\n})"},{"path":"lackoffit.html","id":"results-and-interpretation-4","chapter":"7 Addressing model lack of fit","heading":"7.3.3 Results and interpretation","text":"raw results :\nTable 7.1: Table 7.2: Second-order (memory) estimates transition probabilities.\nTable 7.1, first column gives Transition made \\(t\\) \\(t+1\\) M mid‚ÄìAtlantic C Chesapeake. second column gives Condition whether location \\(t+1\\) Equal equal location \\(t-1\\). Pradel (2005) time-averaged estimates given third column. NIMBLE estimates (mean 95% credible interval) given fourth column.analyses, memory real: transition, probability higher destination \\(t+1\\) matches bird \\(t‚àí1\\) (‚ÄòEqual \\(t-1\\)‚Äô rows) doesn‚Äôt (‚Äòequal \\(t-1\\)‚Äô rows). ‚Äôs site fidelity directional return. fit mirrors Pradel‚Äôs fit especially well staying Chesapeake (CC, equal: 0.63 ) still shows clear memory signal staying mid-Atlantic (MM, 0.50 vs 0.57 equal). Moves also carry memory: MC likely bird C two steps back (0.33 vs 0.16), CM shows weaker similar pattern (0.10 vs 0.06).differ directional balance. Relative Pradel‚Äôs averages, model leans toward Chesapeake: estimate higher MC probabilities (equal equal; e.g., 0.33 vs 0.27 0.16 vs 0.09) lower CM (equal) (0.10 vs 0.21). also find higher chance staying C (CC, equal: 0.57 vs 0.48). Several differences well outside 95% credible intervals (e.g., CM equal 0.09-0.11 vs 0.21, MC equal 0.15-0.17 vs 0.09). discrepancies likely explained difference model structures: assumes constant parameters, whereas Pradel‚Äôs allows vary time. big picture remains , though: movements second‚Äìorder memory asymmetric, strongest persistence Chesapeake moves toward .","code":"##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## det1     0.45 0.01 0.43 0.45  0.47 1.01   597\n## det2     0.41 0.01 0.39 0.41  0.42 1.02   613\n## phi11[1] 0.50 0.01 0.49 0.50  0.52 1.01   889\n## phi11[2] 0.16 0.01 0.15 0.16  0.17 1.01  1103\n## phi11[3] 0.34 0.01 0.32 0.34  0.35 1.00  1206\n## phi12[1] 0.10 0.00 0.09 0.10  0.11 1.01   931\n## phi12[2] 0.57 0.01 0.55 0.57  0.59 1.02   838\n## phi12[3] 0.34 0.01 0.32 0.34  0.35 1.01  1007\n## phi21[1] 0.37 0.03 0.31 0.36  0.42 1.00  1784\n## phi21[2] 0.32 0.03 0.27 0.32  0.38 1.00  2196\n## phi21[3] 0.31 0.03 0.25 0.31  0.38 1.00  1634\n## phi22[1] 0.06 0.00 0.05 0.06  0.07 1.00  1424\n## phi22[2] 0.63 0.01 0.61 0.63  0.64 1.00  2356\n## phi22[3] 0.31 0.01 0.30 0.31  0.33 1.00  2067"},{"path":"lackoffit.html","id":"indhet","chapter":"7 Addressing model lack of fit","heading":"7.4 Accomodating individual heterogeneity","text":"","code":""},{"path":"lackoffit.html","id":"motivation-5","chapter":"7 Addressing model lack of fit","heading":"7.4.1 Motivation","text":"‚Äôve worked large carnivores almost two decades, ‚Äôre pulled HMMs ‚Äì especially gray wolves. Wolves social, live hierarchical packs, structure shows demography. also shows detect : dominant individuals use trails roads often, ‚Äôs pretty much search scats DNA-based identification. result individual heterogeneity detection, wolves detectable (via DNA) others.Shirley Pledger series papers developed ‚Äìcalled mixture models individuals assigned two classes class-specific survival/detection probabilities. ignore variation, estimates can biased lack--fit tests light . Cubaynes et al. (2010), used HMM formulation capture heterogeneity detection (see also Pradel 2009).follows, ‚Äôll show build fit finite‚Äìmixture HMMs using simulated data control truth. gives practical template dealing heterogeneity whenever behavior status makes individuals easier (difficult) find others.","code":""},{"path":"lackoffit.html","id":"model-and-nimble-implementation-5","chapter":"7 Addressing model lack of fit","heading":"7.4.2 Model and NIMBLE implementation","text":"build model, first define states observations:States\nalive class 1 (A1)\nalive class 2 (A2)\ndead (D)\nalive class 1 (A1)alive class 2 (A2)dead (D)Observations\ndetected (1)\ndetected (2)\ndetected (1)detected (2)Now turn writing model. start vector initial states. Individuals enter mixture A1 A2:\\[\\begin{matrix}\n& \\\\\n\\delta =\n  \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n          \\end{matrix}\n          \\hspace{-1.2em}\n          \\begin{matrix}\n          z_t=A1 & z_t=A2 & z_t=D \\\\[0.3em] \\hdashline\n          \\pi & 1 - \\pi & 0\\\\\n          \\end{matrix}\n          \\hspace{-0.2em}\n          \\begin{matrix}\n          & \\\\\n          \\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n\\begin{matrix}\n\\end{matrix}\n\\end{matrix}\\]\\(\\pi\\) probability alive A1, \\(1 - \\pi\\) probability A2.proceed transition matrix contains survival probabilities:\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n  \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n          \\end{matrix}\n          \\hspace{-1.2em}\n          \\begin{matrix}\n          z_t=A1 & z_t=A2 & z_t=D \\\\[0.3em] \\hdashline\n          \\phi  & 0 & 1 - \\phi\\\\\n          0 & \\phi & 1 - \\phi\\\\\n          0 & 0 & 1\n          \\end{matrix}\n          \\hspace{-0.2em}\n          \\begin{matrix}\n          & \\\\\n          \\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t-1}=A1 \\\\ z_{t-1}=A2 \\\\ z_{t-1}=D\n\\end{matrix}\n\\end{matrix}\\]\\(\\phi\\) survival probability. NIMBLE, write:Survival made heterogeneous; , ‚Äôd need amend transition matrix follows:\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n  \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n          \\end{matrix}\n          \\hspace{-1.2em}\n          \\begin{matrix}\n          z_t=A1 & z_t=A2 & z_t=D \\\\[0.3em] \\hdashline\n          \\phi (1-\\psi^{12}) & \\phi \\psi^{12} & 1 - \\phi\\\\\n          \\phi \\psi^{21} & \\phi (1-\\psi^{21}) & 1 - \\phi\\\\\n          0 & 0 & 1\n          \\end{matrix}\n          \\hspace{-0.2em}\n          \\begin{matrix}\n          & \\\\\n          \\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t-1}=A1 \\\\ z_{t-1}=A2 \\\\ z_{t-1}=D\n\\end{matrix}\n\\end{matrix}\\]\\(\\psi\\)‚Äôs probabilities individual change class heterogeneity, \\(\\psi^{12}\\) A1 A2, \\(\\psi^{21}\\) A2 A1.Last step observation matrix, write follows:\\[\\begin{matrix}\n& \\\\\n\\Omega =\n  \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n          \\end{matrix}\n          \\hspace{-1.2em}\n          \\begin{matrix}\n          y_t=1 & y_t=2 \\\\[0.3em] \\hdashline\n          1 - p^1 & p^1\\\\\n          1 - p^2 & p^2\\\\\n          1 & 0\n          \\end{matrix}\n          \\hspace{-0.2em}\n          \\begin{matrix}\n          & \\\\\n          \\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n\\begin{matrix}\nz_{t}=A1 \\\\ z_{t}=A2 \\\\ z_{t}=D\n\\end{matrix}\n\\end{matrix}\\]\\(p^1\\) detection individuals A1, \\(p^2\\) individuals A2. NIMBLE, translates :first detection, observation ‚Äòdetected‚Äô impossible construction (condition first detection). therefore use initial observation matrix \\(\\Omega_{\\text{init}}\\) \\(p_1 = p_2\\) set 1 (shown).Instead real data, use simulated data, useful identify problems analysis illustrate . simulate finite‚Äìmixture scenario individuals differ detection share survival. animal assigned one two latent classes: small, highly detectable group (class A1; proportion \\(\\pi = 0.2\\), \\(p_1=0.8\\)) larger, less detectable group (class A2; proportion \\(1-\\pi = 0.8\\), \\(p_2=0.3\\)). Everyone starts captured first occasion (mimics CJS conditioning first capture), latent alive state \\(z_{,t}\\) evolves constant survival \\(\\phi = 0.7\\). individual \\(\\) alive time \\(t\\), ‚Äôs observed detection probability \\(p_i\\) (either \\(p_1\\) \\(p_2\\) depending class). result matrix 0/1 encounter histories \\(y\\) built-individual heterogeneity detection, plus bookkeeping objects: which_mixture (true class), detection (animal‚Äôs \\(p_i\\)), z (true alive states). simulate fate 400 animals 10 years.simulated data look like:Now fit model data, get following results:\nTable 7.3: Table 7.4: Comparison posterior estimates NIMBLE data-generating values finite‚Äìmixture HMM.\n? first issue classes permuted. model, nothing tells NIMBLE highly detectable individuals must belong class A1 less detectable ones class A2. labeling classes arbitrary. interpretation comes afterwards, inspecting parameter estimates. Now re-calculate \\(\\pi\\) proportion individuals A1 follows:can get sorted new Table 7.5:\nTable 7.5: Table 7.6: Comparison posterior estimates NIMBLE data-generating values finite‚Äìmixture HMM.\nStill, detection estimates . ‚Äôs deeper issue . HMM formulation used capturing heterogeneity creates limitation: individuals allowed switch classes time (e.g., A1 A2), transition matrix permit . words, individual seen > 1 time (‚Äôs detected first observation occasion) can never change class assignments away initial value class assignment. formulation fails? problem subtle fundamental: HMM, transitions states governed Markov process. transition matrix says individual A1 must stay A1 (die), individual permanently locked class. result, individual assigned class initial latent state (e.g., A1), can never change class sampling. Even worse, individual seen multiple occasions (say, years 1 4) must stay alive years, latent state ‚Äòjump‚Äô classes without violating transition constraints, therefore, initial class assignment fixed forever, MCMC sampler explore alternative class, matter much data supports .must confess, got stuck trap, used simulations identify problem. asked NIMBLE team help, Daniel Turek came explanation ‚Äì thanks, Daniel!Fortunately, several solutions problem:Marginalize latent states: Instead sampling latent states \\(z\\), can marginalize , avoids class-switching problem entirely. principle behind nimbleEcology package, see Section 3.8.3.2.Marginalize latent states: Instead sampling latent states \\(z\\), can marginalize , avoids class-switching problem entirely. principle behind nimbleEcology package, see Section 3.8.3.2.Use class-level latent variable: Rather coding classes HMM states, define latent class assignment (e.g., g[] ~ dcat(pi[1:2])) individual. HMM conditions fixed class, allowing proper inference switching MCMC.Use class-level latent variable: Rather coding classes HMM states, define latent class assignment (e.g., g[] ~ dcat(pi[1:2])) individual. HMM conditions fixed class, allowing proper inference switching MCMC.Custom block sampler: Design custom MCMC sampler updates entire latent history individual (z[, 1:K]) . allows class-switching consistent way, though ‚Äôs advanced computationally heavier.Custom block sampler: Design custom MCMC sampler updates entire latent history individual (z[, 1:K]) . allows class-switching consistent way, though ‚Äôs advanced computationally heavier.adopt first solution use material saw Section 3.8. NIMBLE, start writing functions HMM likelihood, using backward algorithm:Now NIMBLE code model, last:","code":"\n# Transition matrix\ngamma[1,1] <- phi      # A1(t)->A1(t+1)\ngamma[1,2] <- 0        # A1(t)->A2(t+1)\ngamma[1,3] <- 1 - phi  # A1(t)->D(t+1)\ngamma[2,1] <- 0        # A2(t)->A1(t+1)\ngamma[2,2] <- phi      # A2(t)->A2(t+1)\ngamma[2,3] <- 1 - phi  # A2(t)->D(t+1)\ngamma[3,1] <- 0        # D(t)->A1(t+1)\ngamma[3,2] <- 0        # D(t)->A2(t+1)\ngamma[3,3] <- 1        # D(t)->D(t+1)\n# Observation matrix\nomega[1,1] <- 1 - p1 # A1(t)->1(t) (non-detected)\nomega[1,2] <- p1 # A1(t)->2(t) (detected)\nomega[2,1] <- 1 - p2 # A2(t)->1(t)\nomega[2,2] <- p2 # A2(t)->2(t)\nomega[3,1] <- 1 # D(t)->1(t)\nomega[3,2] <- 0 # D(t)->2(t)\n# Simulate encounter histories w ind het (finite mixture)\n\nset.seed(1234)           # for reproducibility\n\n# Parameters\nphi <- 0.7               # apparent survival (same for all)\nprop_class1 <- 0.2       # mixture proportion pi: Pr(class 1)\np_class1 <- 0.8          # detection if in class 1 (high)\np_class2 <- 0.3          # detection if in class 2 (low)\n\nnind <- 400              # number of individuals\nnyear <- 10              # number of occasions\n\n# Storage\nz <- matrix(NA, nind, nyear)    # latent alive state\nx <- matrix(NA, nind, nyear)    # observed detections\ny <- matrix(NA, nind, nyear)    # final encounter histories (0/1)\nfirst <- rep(1, nind)           # first-capture occasion\ndetection <- rep(NA, nind)      # each individual's p_i\nwhich_mixture <- rep(NA, nind)  # latent class: 1 or 0 (class 2)\n\n# Assign ind to classes, then give them class-specific detection\nfor (i in 1:nind) {\n  which_mixture[i] <- rbinom(1, 1, prop_class1) # 1 w prob pi else 0\n  detection[i] <- if (which_mixture[i] == 1) p_class1 else p_class2\n}\n\n# Generate latent states and observations\n# Everyone is alive and detected at first capture (CJS conditioning)\nfor (i in 1:nind) {\n  z[i, first[i]] <- 1\n  x[i, first[i]] <- 1\n\n  # From the second occasion on:\n  for (j in (first[i] + 1):nyear) {\n    # Alive state: survive from previous if alive; else remain 0\n    z[i, j] <- rbinom(1, 1, phi * z[i, j - 1])\n\n    # Observation: if alive, detect with p_i; if dead, 0\n    x[i, j] <- rbinom(1, 1, z[i, j] * detection[i])\n  }\n}\n\n# Final encounter histories: replace NAs (before first) with 0\ny <- x\ny[is.na(y)] <- 0\nhead(y)\n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n## [1,]    1    0    0    0    0    0    0    0    0     0\n## [2,]    1    0    0    0    0    0    0    0    0     0\n## [3,]    1    0    0    0    0    0    0    0    0     0\n## [4,]    1    0    1    0    0    0    0    0    0     0\n## [5,]    1    0    0    0    0    0    0    0    0     0\n## [6,]    1    1    0    0    0    0    0    0    0     0##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi 0.70 0.01 0.67 0.70  0.72 1.01  1003\n## pi  0.70 0.03 0.63 0.70  0.76 1.01   631\n## pp1 0.45 0.02 0.40 0.45  0.50 1.02   431\n## pp2 0.48 0.03 0.43 0.48  0.55 1.01   638\nsamples <- rbind(mcmc.phipmix[[1]], mcmc.phipmix[[2]])\npi <- 1 - samples[,'pi']\nmean(pi)\n## [1] 0.3041\nquantile(pi, probs = c(2.5, 97.5)/100)\n##   2.5%  97.5% \n## 0.2417 0.3727\n# Integrate out latent states using custom density (forward algo)\n# speed things up by pooling identical histories w pooled lik\n\n# Get rid of individuals for which first==K\n# individuals that are not first encountered at last occasion\nmask <- which(first!=ncol(y)) \ny <- y[mask, ] # keep only these\nfirst <- first[mask]\n# if first == K (first seen at last occasion), \n# no post-capture interval to inform phi/p; \n# removing them simplifies forward recursion and \n# avoids degenerate len=1 cases\n\n# Pool encounter histories\ny_weighted <- y %>% \n  as_tibble() %>% \n  group_by_all() %>% # group by entire history (all columns)\n  summarise(size = n()) %>% # count how many inds share that history\n  relocate(size) %>% # move \"size\" column to front\n  as.matrix()\nhead(y_weighted)\nsize <- y_weighted[,1] # nb of inds w/ a particular history\ny <- y_weighted[,-1] # pooled data: one row per unique history\n\n# Assemble data and constants\n# +1 because custom distribution expects categories 1/2 (not 0/1)\nmy.data <- list(y = y + 1)\nmy.constants <- list(N = nrow(y), \n                     K = ncol(y), \n                     first = first,\n                     size = size,\n                     one = 1)\n# \"one\" is a dummy constant used in a dconstraint\n\n# NIMBLE functions\n# Custom HMM *density* for pooled histories via forward algorithm\ndwolfHMM <- nimbleFunction(\n  run = function(x = double(1), \n                 probInit = double(1), # initial states (delta)\n                 probObs = double(2),  # obs (omega)\n                 probObse = double(2), # obs used at first occasion\n                 probTrans = double(2),# trans (gamma)\n                 size = double(0),     # cardinal\n                 len = double(0, default = 0), # nb sampling occ\n                 log = integer(0, default = 0)) {\n    # Initial forward probs:\n    # multiply initial state probs by obs prob at first date x[1]\n    # (probObs at t=first is 1 due to CJS conditioning; \n    # and handled via 'probObse').\n    alpha <- probInit[1:3] * probObse[1:3,x[1]] \n    # * probObs[1:3,x[1]] == 1 due to conditioning on first detection\n    for (t in 2:len) {\n      # standard forward step: \n      # alpha_t = (alpha_{t-1} * Gamma) .* Omega(:, y_t)\n      alpha[1:3] <- (alpha[1:3] %*% probTrans[1:3,1:3]) * \n        probObs[1:3,x[t]]\n    }\n    # Pooling: multiply the log-likelihood by 'size'\n    logL <- size * log(sum(alpha[1:3]))\n    returnType(double(0))\n    if (log) return(logL)\n    return(exp(logL))\n  }\n)\n\n# Matching *random generator* \n# (required by NIMBLE for custom distributions)\n# Generates one synthetic history consistent with the HMM; \n# not used in MCMC, but needed to register the dist.\nrwolfHMM <- nimbleFunction(\n  run = function(n = integer(),\n                 probInit = double(1),\n                 probObs = double(2),\n                 probObse = double(2),\n                 probTrans = double(2),\n                 size = double(0),\n                 len = double(0, default = 0)) {\n    returnType(double(1))\n    z <- numeric(len) # latent states\n    # all individuals alive at t = 0 (by construction)\n    z[1] <- rcat(n = 1, prob = probInit[1:3]) \n    y <- z\n    y[1] <- 2 # all inds detected at t = 0 (CJS conditioning)\n    for (t in 2:len){\n      # state at t given state at t-1\n      z[t] <- rcat(n = 1, prob = probTrans[z[t-1],1:3]) \n      # observation at t given state at t\n      y[t] <- rcat(n = 1, prob = probObs[z[t],1:2]) \n    }\n    return(y)\n  })\n\n# Register the custom density/generator in the global environment\nassign('dwolfHMM', dwolfHMM, .GlobalEnv)\nassign('rwolfHMM', rwolfHMM, .GlobalEnv)\n# Model code\nhmm.phipmix <- nimbleCode({\n  \n  # -------------------------------------------------\n  # Parameters:\n  # pi: initial state probability A1   (mixture weight for class 1)\n  # phi: survival probability          (shared across classes)\n  # pp1: recapture probability A1      (detection for class 1)\n  # pp2: recapture probability A2      (detection for class 2)\n  # -------------------------------------------------\n  # States (S):\n  # 1 alive (A1)  -> class 1\n  # 2 alive (A2)  -> class 2\n  # 3 dead (D)\n  # Observations (O):\n  # 1 neither seen nor recovered (0)\n  # 2 seen alive (1)\n  # -------------------------------------------------\n  \n  # priors\n  phi ~ dunif(0, 1) # prior survival\n  # to avoid label switching (enforces an ordering)\n  one ~ dconstraint(pp1 < pp2) \n  pp1 ~ dunif(0, 1) # prior detection (class 1)\n  pp2 ~ dunif(0, 1) # prior detection (class 2)\n  pi ~ dunif(0, 1)  # prob init state 1 (mixture prop class 1)\n  \n  # transition matrix (classes are persistent; \n  # no switching between A1 and A2)\n  gamma[1,1] <- phi      # A1(t)->A1(t+1)\n  gamma[1,2] <- 0        # A1(t)->A2(t+1)\n  gamma[1,3] <- 1 - phi  # A1(t)->D(t+1)\n  gamma[2,1] <- 0        # A2(t)->A1(t+1)\n  gamma[2,2] <- phi      # A2(t)->A2(t+1)\n  gamma[2,3] <- 1 - phi  # A2(t)->D(t+1)\n  gamma[3,1] <- 0        # D(t)->A1(t+1)\n  gamma[3,2] <- 0        # D(t)->A2(t+1)\n  gamma[3,3] <- 1        # D(t)->D(t+1)\n  \n  # vector of initial state probs (mixture at first capture)\n  delta[1] <- pi         # A1(first)\n  delta[2] <- 1 - pi     # A2(first)\n  delta[3] <- 0          # D(first)\n  \n  # observation matrix (det differs by class; dead never seen)\n  omega[1,1] <- 1 - pp1   # A1(t)->0(t)\n  omega[1,2] <- pp1       # A1(t)->1(t)\n  omega[2,1] <- 1 - pp2   # A2(t)->0(t)\n  omega[2,2] <- pp2       # A2(t)->1(t)\n  omega[3,1] <- 1         # D(t)->0(t)\n  omega[3,2] <- 0         # D(t)->1(t)\n  \n  # 'omegae' is used only at first date inside custom density\n  # to implement CJS cond (everyone detected at first capture)\n  omegae[1,1] <- 0        # A1(t)->0(t)\n  omegae[1,2] <- 1        # A1(t)->1(t)\n  omegae[2,1] <- 0        # A2(t)->0(t)\n  omegae[2,2] <- 1        # A2(t)->1(t)\n  omegae[3,1] <- 1        # D(t)->0(t)\n  omegae[3,2] <- 0        # D(t)->1(t)\n  \n  # likelihood\n  for(i in 1:N) {\n    # One weighted lik contrib per *unique* history,\n    # using the forward algorithm implemented in dwolfHMM.\n    y[i,first[i]:K] ~ dwolfHMM(probInit = delta[1:3],# initial states\n                               probObs = omega[1:3,1:2], # obs\n                               probObse=omegae[1:3,1:2],# obs first\n                               probTrans = gamma[1:3,1:3], # trans\n                               size = size[i], # weight\n                               len = K - first[i] + 1) # nb occ\n  }\n})\n\n# Initial values \n# (cool thing, we do not need inits for latent states anymore!!)\ninitial.values <- function() list(phi = runif(1,0,1),\n                                  pp1 = 0.3,\n                                  pp2 = 0.8,\n                                  pi = runif(1,0,1))\n# 'one' is provided in constants; no init needed\n# The pp1<pp2 constraint prevents label switching \n# by fixing the class ordering\n\n# Parameters to be monitored\nparameters.to.save <- c(\"phi\", \"pp1\", \"pp2\", \"pi\")\n\n# Run NIMBLE\nout <- nimbleMCMC(code = hmm.phipmix, \n                  constants = my.constants,\n                  data = my.data,              \n                  inits = initial.values,\n                  monitors = parameters.to.save,\n                  niter = n.iter,\n                  nburnin = n.burnin, \n                  nchains = n.chains)"},{"path":"lackoffit.html","id":"results-and-interpretation-5","chapter":"7 Addressing model lack of fit","heading":"7.4.3 Results and interpretation","text":"\nTable 7.7: Table 7.8: Posterior estimates vs.¬†data-generating values finite‚Äìmixture HMM, marginalized likelihood used.\nsummary, modeling unobservable individual heterogeneity (e.g., detection classes) HMM, avoid encoding class identity dynamic state. Instead, treat fixed latent variable, marginalize . Otherwise, model unable explore full posterior yield biased unreliable estimates.question remains number classes use. words, 2 classes 3 4? One option fit models classes select among (e.g., Cubaynes et al. 2012). Alternatively, can take non-parametric route let data decide many classes needed; relatively easy NIMBLE (see Turek, Wehrhahn, Gimenez 2021).broader context individual heterogeneity, see Gimenez, Cam, Gaillard (2018). Finally, remember hidden classes introduced Pledger colleagues primarily correct bias survival abundance heterogeneity ignored; interpreting classes biologically fitting done caution.","code":""},{"path":"tradeoffs.html","id":"tradeoffs","chapter":"8 Quantifying life history traits","heading":"8 Quantifying life history traits","text":"","code":""},{"path":"tradeoffs.html","id":"introduction-10","chapter":"8 Quantifying life history traits","heading":"8.1 Introduction","text":"Capture-recapture models allow estimation key demographic parameters survival, recruitment, dispersal. parameters central life history theory, seeks explain organisms allocate limited resources across survival, growth, reproduction lifetime. Life-history traits, age first breeding, breeding frequency, lifespan, reflect trade-offs shaped natural selection environmental constraints.Capture-recapture data particularly suited quantifying traits wild, providing direct estimates can compared theoretical predictions. introduced Section 5.5, states transitions ‚Äì whether disease, developmental, breeding states ‚Äì can incorporated naturally HMM framework.chapter, focus three examples: cause- age-specific mortalities, age-specific breeding probabilities, stopover duration. Together, illustrate capture-recapture HMMs can shed light life-history strategies.","code":""},{"path":"tradeoffs.html","id":"assessing-age--and-cause-specific-mortality","chapter":"8 Quantifying life history traits","heading":"8.2 Assessing age- and cause-specific mortality","text":"","code":""},{"path":"tradeoffs.html","id":"motivation-6","chapter":"8 Quantifying life history traits","heading":"8.2.1 Motivation","text":"Cause‚Äê age-specific mortalities key life-history traits, shaping population dynamics informing management conservation strategies. Yet wild, direct assignment causes death challenging field observations often incomplete, carcass recovery biased towards certain causes death habitats. ignore uncertainty, estimates mortality rates cause age class can biased, understanding population processes compromised.fix treat cause death latent state. Following Koons et al. (2014), model survival transitions cause-specific death states jointly within HMM capture-recapture framework. , combine data recaptures live recoveries dead animals. Individuals can either survive next occasion die one several competing causes, probabilities may depend age., use case study roe deer (Capreolus capreolus) Koons et al. (2014). authors show failing account uncertain cause assignment underestimated mortality hunting overestimated natural mortality, particularly younger age classes., define cause‚Äêspecific death states, let survival cause‚Äêspecific mortality depend age, keep rest HMM machinery unchanged NIMBLE.","code":""},{"path":"tradeoffs.html","id":"model-and-nimble-implementation-6","chapter":"8 Quantifying life history traits","heading":"8.2.2 Model and NIMBLE implementation","text":"example, use data roe deer population enclosed forest Territoire d‚ÄôEtude et d‚ÄôExp√©rimentation Trois Fontaines, eastern France. , focus 556 known-age females (marked fawns), 217 recaptured least 41 deadly injured handling, victim car collisions, recovered reported hunters (human-related mortalities). data kindly provided Marl√®ne Gamelon.build model, first define states observations:States\n- alive\n- H individual just died human causes\n- NH individual just died natural (non-human) cause\n- D individual already deadStates\n- alive\n- H individual just died human causes\n- NH individual just died natural (non-human) cause\n- D individual already deadObservations\n- 1 seen\n- 2 captured first time recaptured\n- 3 killed human activities reportedObservations\n- 1 seen\n- 2 captured first time recaptured\n- 3 killed human activities reportedNow turn writing model. start vector initial states. Individuals enter alive study probability 1:\\[\\begin{matrix}\n& \\\\\n\\delta =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\nz_t=& z_t=H & z_t=NH & z_t=D \\\\[0.3em] \\hdashline\n1 & 0 & 0 & 0\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n\\begin{matrix}\n\\end{matrix}\n\\end{matrix}\\]proceed transition matrix:\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\nz_t=& z_t=H & z_t=NH & z_t=D \\\\[0.3em] \\hdashline\n1 - \\mu_H - \\mu_{NH}  & \\mu_H & \\mu_{NH} & 0\\\\\n0 & 0 & 0 &  1\\\\\n0 & 0 & 0 &  1\\\\\n0 & 0 & 0 &  1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t-1}=\\\\ z_{t-1}=H \\\\ z_{t-1}=NH \\\\ z_{t-1}=D\n\\end{matrix}\n\\end{matrix}\\]transition probability \\(\\) \\(t\\) \\(H\\) \\(t + 1\\) human-related mortality probability \\(\\mu_H\\) transition probability \\(\\) \\(t\\) \\(NH\\) \\(t + 1\\) natural mortality probability \\(\\mu_{NH}\\). individual return state \\(\\) dead, fix transitions 0.Following paper, adult survival age-specific: \\(\\mu_H\\) different individuals first year life birth ([0,1[) vs.¬†age 1 onwards, \\(\\mu_{NH}\\) two different parameters ages [0,1[ [1,2[ linear trend age age 2 onward. use multinomial logit link function ensure mortality probabilities estimated 0 1 sum 1, see Section 5.4.2. NIMBLE, code:code , age passed data created follows:Last step observation matrix:\\[\\begin{matrix}\n& \\\\\n\\Omega =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\ny_t=1 & y_t=2 & y_t=3 \\\\[0.3em] \\hdashline\n1 - p & p & 0 \\\\\n1 - \\lambda & 0 & \\lambda\\\\\n1 & 0 & 0\\\\\n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t}=\\\\ z_{t}=H \\\\ z_{t}=NH \\\\ z_{t}=D\n\\end{matrix}\n\\end{matrix}\\]live individual can detected probability \\(p\\), probability \\(1‚àíp\\). include time-dependence age \\(p\\), different parameter 1 year-old individuals vs.¬†individuals older 1 year age. NIMBLE, write:individual just died human causes can recovered reported probability \\(\\lambda\\), probability \\(1-\\lambda\\). tag recovery protocols constant course study, authors considered parameter constant time across age classes.","code":"\n# Transition matrix\n# Age effects\netaH[i,t] <- (alpha_H_01 * age_lt1[i,t] + alpha_H_ge1 * age_ge1[i,t])\n\netaNH[i,t] <- (alpha_NH_01 * age_lt1[i,t] + # if age is [0,1[\n              alpha_NH_12 * age_1to2[i,t] + # if age is [1,2[\n              # linear trend if age >= 2\n              (beta0_NH+beta1_NH*age_std_mu2[i,t])*age_ge2[i,t]) \n\n# Transitions from A\nden[i,t] <- 1 + exp(etaH[i,t]) + exp(etaNH[i,t])  # denominator\ngamma[i,t,1,1] <- 1 / den[i,t]                    # stay alive\ngamma[i,t,1,2] <- exp(etaH[i,t]) / den[i,t]       # muH\ngamma[i,t,1,3] <- exp(etaNH[i,t]) / den[i,t]      # muNH\ngamma[i,t,1,4] <- 0                               # always 0\n\n# From H, NH, D (always go to D)\ngamma[i,t,2,1] <- 0\ngamma[i,t,2,2] <- 0\ngamma[i,t,2,3] <- 0\ngamma[i,t,2,4] <- 1\ngamma[i,t,3,1] <- 0\ngamma[i,t,3,2] <- 0\ngamma[i,t,3,3] <- 0\ngamma[i,t,3,4] <- 1\ngamma[i,t,4,1] <- 0\ngamma[i,t,4,2] <- 0\ngamma[i,t,4,3] <- 0\ngamma[i,t,4,4] <- 1\n# Build an N x K age matrix\nage <- matrix(0, nrow = nrow(obs_matrix), ncol = K)\nfor (i in 1:nrow(obs_matrix)) {\n  for (t in first[i]:K) {\n    age[i, t] <- t - first[i]   # age 0 at first capture\n  }\n}\n# Define age [0,1[ and age >=1\nfor (i in 1:nrow(obs_matrix)) {\n  for (t in first[i]:K) {\n    age_val <- age[i, t]\n    if (age_val == 0) { # age < 1\n      age_lt1[i, t] <- 1\n      age_ge1[i, t] <- 0\n    } else {            # age >= 1\n      age_lt1[i, t] <- 0  \n      age_ge1[i, t] <- 1\n    }\n  }\n}\n# Define age >1 and age [1,2[\nfor (i in 1:nrow(obs_matrix)) {\n  for (t in first[i]:K) {\n    age_val <- age[i, t]\n    age_ge2[i, t] <- as.integer(age_val > 1) # age > 1 or 2 onwards\n    age_1to2[i, t] <- as.integer(age_val == 1) # age in [1,2[\n  }\n}\npA[i,t] <- p_ageLE1[t] * age_lt1[i,t] + p_ageGT1[t] * age_ge1[i,t]"},{"path":"tradeoffs.html","id":"results-and-interpretation-6","chapter":"8 Quantifying life history traits","heading":"8.2.3 Results and interpretation","text":"results given Figure 8.1. see senescence natural mortality age 2 onwards, well well slightly higher human-related mortality first year life birth. patterns similar obtained Koons et al. (2014), check Figure 4.\nFigure 8.1: Age‚Äêspecific mortality probabilities human‚Äêrelated (solid line) natural (dashed line) causes female roe deer Trois‚ÄêFontaines, France, 1985 2013. Shaded polygons represent 95% credible intervals.\n","code":""},{"path":"tradeoffs.html","id":"quantifying-age-specific-breeding","chapter":"8 Quantifying life history traits","heading":"8.3 Quantifying age-specific breeding","text":"","code":""},{"path":"tradeoffs.html","id":"motivation-7","chapter":"8 Quantifying life history traits","heading":"8.3.1 Motivation","text":"Breeding simple yes/coin flip. breeds year depends happened last year. long-lived mammals, adult survival high fairly stable, breeding probability can differ according recent reproductive history reliably detect mothers offspring. blur pieces treat breeding status perfectly known risk biasing survival breeding estimates.Couet et al. (2019) give clear template female bottlenose dolphins. show calf detectability differs age female‚Äôs breeding probability depends outcome previous calf. Rather assuming states observed without error, use HMM keep true breeding state hidden, model misclassification/detection explicitly, tie breeding year last year‚Äôs outcome. way, uncertainty calf presence age feeds correctly demographic estimates., follow logic: define hidden female states (nonbreeder vs.¬†breeder calf age classes), let detection vary calf age, make breeding probability state-dependent previous year‚Äôs result.","code":""},{"path":"tradeoffs.html","id":"model-and-nimble-implementation-7","chapter":"8 Quantifying life history traits","heading":"8.3.2 Model and NIMBLE implementation","text":"example, ‚Äôll work data population bottlenose dolphins (Tursiops truncatus) inhabiting French waters Normano-Breton Gulf English Channel. 106 encounter histories 2004 2016, made photographs taken boat July November, corresponds birth peak best weather conditions monitoring. data shared Pauline Couet.build model, first define states observations:States\n- NB non-breeding adult female\n- Byoy breeding adult female young year\n- Bc1 breeding adult female 1‚Äêyear‚Äêold calf\n- Bc3 breeding adult female 3‚Äêyear‚Äêold calf\n- Bc2 breeding adult female 2‚Äêyear‚Äêold calf\n- D dead femaleStates\n- NB non-breeding adult female\n- Byoy breeding adult female young year\n- Bc1 breeding adult female 1‚Äêyear‚Äêold calf\n- Bc3 breeding adult female 3‚Äêyear‚Äêold calf\n- Bc2 breeding adult female 2‚Äêyear‚Äêold calf\n- D dead femaleObservations\n- 1 seen\n- 2 seen alone\n- 3 seen young year\n- 4 seen calf (1 3 years old)Observations\n- 1 seen\n- 2 seen alone\n- 3 seen young year\n- 4 seen calf (1 3 years old)Now turn writing model. start vector initial states:\\[\n\\begin{matrix}\n& \\\\\n\\boldsymbol{\\delta} =\n\\left ( \\vphantom{ \\begin{matrix} 1 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n\\text{NB} & \\text{Byoy} & \\text{Bc1} & \\text{Bc2} & \\text{Bc3} & \\text{D} \\\\[0.3em] \\hdashline\n\\pi_1 & \\pi_2 & \\pi_3 & \\pi_4 & \\pi_5 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 1 \\end{matrix} } \\right )\n\\end{matrix}\n\\]\n\\(\\displaystyle \\pi_5 = 1 - \\sum_{j=1}^4\\pi_j\\).proceed transition matrix given Couet et al. (2019):\\[\n\\begin{matrix}\n& \\\\\n\\Gamma =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\nz_t=NB & z_t = Byoy & z_t = Bc1 & z_t = Bc2 & z_t = Bc3 & z_t = D \\\\[0.3em] \\hdashline\n\\phi_A (1 - \\beta_1) & \\phi_A \\beta_1 & 0 & 0 & 0 & 1 - \\phi_A \\\\\n0 & 0 & \\phi_A \\phi_Y & \\phi_A (1-\\phi_Y) & 0 & 1-\\phi_A \\\\\n\\phi_A (1 - \\beta_1) & \\phi_A \\beta_1 & 0 & 0 & 0 & 1-\\phi_A \\\\\n\\phi_A (1 - \\beta_2) & \\phi_A \\beta_2 & 0 & 0 & 0 & 1-\\phi_A \\\\\n\\phi_A (1 - \\beta_2) & \\phi_A \\beta_2 & 0 & 0 & 0 & 1-\\phi_A \\\\\n0 & 0 & 0 & 0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t-1} = NB \\\\\nz_{t-1} = Byoy \\\\\nz_{t-1} = Bc1 \\\\\nz_{t-1} = Bc2 \\\\\nz_{t-1} = Bc3 \\\\\nz_{t-1} = D\n\\end{matrix}\n\\end{matrix}\n\\]Rather attempting explain full complexity matrix , follow authors‚Äô suggestion break four steps, corresponding biological event life cycle female bottlenose dolphins: (1) female survival \\(\\Phi_A\\), (2) young survival \\(\\Phi_Y\\), (3) young aging \\(AGING\\), (4) breeding \\(BREED\\), step conditional previous ones. , introduce intermediate states:Intermediate states\n- Byoy‚ÄêD breeding adult female lost young year\n- Bc1‚ÄêD breeding adult female lost 1‚Äêyear‚Äêold calf\n- Bc2‚ÄêD breeding adult female lost 2‚Äêyear‚Äêold calf\n- Bc3‚Äêleave Breeding adult female raised calf age 3The four corresponding matrices given , starting female survival matrix:\\[\n\\begin{matrix}\n& \\\\\n\\Phi_A =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n\\text{NB} & \\text{Byoy} & \\text{Bc1} & \\text{Bc2} & \\text{Bc3} & \\text{D} \\\\[0.3em] \\hdashline\n\\phi_A & 0      & 0      & 0      & 0      & 1 - \\phi_A \\\\\n0      & \\phi_A & 0      & 0      & 0      & 1 - \\phi_A \\\\\n0      & 0      & \\phi_A & 0      & 0      & 1 - \\phi_A \\\\\n0      & 0      & 0      & \\phi_A & 0      & 1 - \\phi_A \\\\\n0      & 0      & 0      & 0      & \\phi_A & 1 - \\phi_A \\\\\n0      & 0      & 0      & 0      & 0      & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\n\\text{NB} \\\\\n\\text{Byoy} \\\\\n\\text{Bc1} \\\\\n\\text{Bc2} \\\\\n\\text{Bc3} \\\\\n\\text{D}\n\\end{matrix}\n\\end{matrix}\n\\]adult female survives \\(t\\) \\(t+1\\) probability \\(\\phi_A\\) dies \\(1‚àí\\phi_A\\). go young survival matrix:\\[\n\\begin{matrix}\n& \\\\\n\\Phi_Y =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n\\text{NB} & \\text{Byoy} & \\text{Byoy-D} & \\text{Bc1} & \\text{Bc1-D} & \\text{Bc2} & \\text{Bc2-D} & \\text{Bc3-leave} & \\text{D} \\\\[0.3em] \\hdashline\n1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & \\phi_{Y} & 1 - \\phi_{Y} & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & \\phi_{Y} & 1 - \\phi_{Y} & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & \\phi_{Y} & 1 - \\phi_{Y} & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\n\\text{NB} \\\\\n\\text{Byoy} \\\\\n\\text{Bc1} \\\\\n\\text{Bc2} \\\\\n\\text{Bc3} \\\\\n\\text{D}\n\\end{matrix}\n\\end{matrix}\n\\]Offspring survive probability \\(\\phi_Y\\) die \\(1-\\phi_Y\\). calf survives, female remains breeding state. dies, moves intermediate ‚Äòdead-offspring‚Äô state (BYOY-D, Bc1-D, Bc2-D) later steps can condition loss. 3-year-old calves, mortality distinguished emancipation (leaving mother), add intermediate Bc3-leave state fix survival 1 (parameter otherwise unidentifiable). paper, distinguish young‚Äê‚Äê‚Äêyear 1‚Äêyear‚Äêold calf survival 2‚Äêyear‚Äêold calf survival. go young aging matrix:\\[\n\\begin{matrix}\n& \\\\\nAGING =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n\\text{NB} & \\text{Byoy} & \\text{Byoy-D} & \\text{Bc1} & \\text{Bc1-D} & \\text{Bc2} & \\text{Bc2-D} & \\text{Bc3-leave} & \\text{D} \\\\[0.3em] \\hdashline\n1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\n\\text{NB} \\\\\n\\text{Byoy} \\\\\n\\text{Byoy-D} \\\\\n\\text{Bc1} \\\\\n\\text{Bc1-D} \\\\\n\\text{Bc2} \\\\\n\\text{Bc2-D} \\\\\n\\text{Bc3-leave} \\\\\n\\text{D}\n\\end{matrix}\n\\end{matrix}\n\\]\nprogression calf age classes \\(t\\) \\(t+1\\) deterministic, relevant age-advancing transitions set 1, parameters estimated matrix. Last, breeding matrix:\\[\n\\begin{matrix}\n& \\\\\nBREED =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n\\text{NB} & \\text{Byoy} & \\text{Bc1} & \\text{Bc2} & \\text{Bc3} & \\text{D} \\\\[0.3em] \\hdashline\n1 - \\beta_1 & \\beta_1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 \\\\\n1 - \\beta_1 & \\beta_1 & 0 & 0 & 0 & 0 \\\\\n1 - \\beta_1 & \\beta_1 & 0 & 0 & 0 & 0 \\\\\n1 - \\beta_2 & \\beta_2 & 0 & 0 & 0 & 0 \\\\\n1 - \\beta_2 & \\beta_2 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\n\\text{NB} \\\\\n\\text{Byoy} \\\\\n\\text{Bc1} \\\\\n\\text{Bc2} \\\\\n\\text{Byoy-D} \\\\\n\\text{Bc1-D} \\\\\n\\text{Bc2-D} \\\\\n\\text{Bc3-leave} \\\\\n\\text{D}\n\\end{matrix}\n\\end{matrix}\n\\]Breeding \\(t+1\\) occurs probability \\(\\beta\\) (otherwise \\(1‚àí\\beta\\)). Breeding can depend female‚Äôs state, namely non-breeding females females just lost young year 1‚Äêyear‚Äêold calf (\\(\\beta_1\\)) vs.¬†females lost 2‚Äêyear‚Äêold calf raised age 3 (\\(\\beta_2\\)).Overall, transition matrix product four matrices. NIMBLE, code directly full matrix, take opportunity illustrate code splitting several ecological processes:Last step observation matrix can also split two steps, given intermediate observations:\n- ND: detected\n- DNB: non-breeding female detected time \\(t\\)\n- DByoy: breeding female young year detected time \\(t\\)\n- DBc: breeding female 1-year-old calf detected time \\(t\\)\n- DBc2: breeding female 2-year-old calf detected time \\(t\\)\n- DBc3: breeding female 3-year-old calf detected time \\(t\\)First, detection step:\\[\n\\begin{matrix}\n& \\\\\nDETECTION =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n\\text{ND} & \\text{DNB} & \\text{DByoy} & \\text{DBc} & \\text{DBc2} & \\text{DBc3} \\\\[0.3em] \\hdashline\n1 - p_1 & p_1 & 0 & 0 & 0 & 0 \\\\\n1 - p_2 & 0 & p_2 & 0 & 0 & 0 \\\\\n1 - p_2 & 0 & 0 & p_2 & 0 & 0 \\\\\n1 - p_1 & 0 & 0 & 0 & p_1 & 0 \\\\\n1 - p_1 & 0 & 0 & 0 & p_1 & 0 \\\\\n1 & 0 & 0 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\n\\text{NB} \\\\\n\\text{Byoy} \\\\\n\\text{Bc1} \\\\\n\\text{Bc2} \\\\\n\\text{Bc3} \\\\\n\\text{D}\n\\end{matrix}\n\\end{matrix}\n\\]contains probability \\(p\\) detecting female given latent state \\(t\\): \\(p_2\\) females young year 1‚Äêyear‚Äêold calf \\(p_1\\) non-breeding females older calf. observation matrix:\\[\n\\begin{matrix}\n& \\\\\nOBS =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n1 & 2 & 3 & 4 \\\\[0.3em] \\hdashline\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 1 - q_1 & q_1 & 0 \\\\\n0 & 1 - q_2 & 0 & q_2 \\\\\n0 & 1 - q_2 & 0 & q_2 \\\\\n0 & 1 - q_2 & 0 & q_2\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\n\\text{ND} \\\\\n\\text{DNB} \\\\\n\\text{DByoy} \\\\\n\\text{DBc} \\\\\n\\text{DBc2} \\\\\n\\text{DBc3}\n\\end{matrix}\n\\end{matrix}\n\\], conditional breeding state, probability \\(q\\) calf seen vs.¬†seen. Calf age identifiable photographs, observations seen seen, \\(q\\) may still vary calf age (young year vs.¬†older). coded NIMBLE follows:","code":"\n# Transition matrix\n\n# PHIA is 6x6\nfor (i in 1:5) {\n  PHIA[i, i] <- adultsurvival\n  PHIA[i, 6] <- 1 - adultsurvival\n}\nPHIA[6, 6] <- 1\n\n# PHIY is 6x9\n# Row 1: NB stays NB\nPHIY[1, 1] <- 1\n# Row 2: Byoy\nPHIY[2, 2] <- youngsurvival[1] # YOY survives ‚Üí becomes Bc1\nPHIY[2, 3] <- 1 - youngsurvival[1] # YOY dies ‚Üí becomes Byoy-D\n# Row 3: Bc1\nPHIY[3, 4] <- youngsurvival[1] # 1-year-old survives ‚Üí Bc2\nPHIY[3, 5] <- 1 - youngsurvival[1] # dies ‚Üí Bc1-D\n# Row 4: Bc2\nPHIY[4, 6] <- youngsurvival[2] # 2-year-old survives ‚Üí Bc3-L\nPHIY[4, 7] <- 1 - youngsurvival[2] # dies ‚Üí Bc2-D\n# Row 5: Bc3 always emancipates\nPHIY[5, 8] <- 1\n# Row 6: dead female stays dead\nPHIY[6, 9] <- 1\n\n# AGING is 9x9\nAGING[1, 1] <- 1   # NB ‚Üí NB\nAGING[2, 2] <- 1   # Byoy ‚Üí Bc1\nAGING[3, 5] <- 1   # Byoy-D ‚Üí Byoy-D\nAGING[4, 3] <- 1   # Bc1 ‚Üí Bc2\nAGING[5, 6] <- 1   # Bc1-D ‚Üí Bc1-D\nAGING[6, 4] <- 1   # Bc2 ‚Üí Bc3\nAGING[7, 7] <- 1   # Bc2-D ‚Üí Bc2-D\nAGING[8, 8] <- 1   # Bc3-L ‚Üí Bc3-L\nAGING[9, 9] <- 1   # D ‚Üí D\n\n# BREED is 9x6\n# Row 1: NB ‚Üí Byoy or NB\nBREED[1, 2] <- beta[1]\nBREED[1, 1] <- 1 - beta[1]\n# Row 2: Bc1 ‚Üí Bc1\nBREED[2, 3] <- 1\n# Row 3: Bc2 ‚Üí Bc2\nBREED[3, 4] <- 1\n# Row 4: Bc3 ‚Üí Bc3\nBREED[4, 5] <- 1\n# Row 5: Byoy-D ‚Üí Byoy or NB\nBREED[5, 2] <- beta[1]\nBREED[5, 1] <- 1 - beta[1]\n# Row 6: Bc1-D ‚Üí Byoy or NB\nBREED[6, 2] <- beta[1]\nBREED[6, 1] <- 1 - beta[1]\n# Row 7: Bc2-D ‚Üí Byoy or NB\nBREED[7, 2] <- beta[2]\nBREED[7, 1] <- 1 - beta[2]\n# Row 8: Bc3-L ‚Üí Byoy or NB\nBREED[8, 2] <- beta[2]\nBREED[8, 1] <- 1 - beta[2]\n# Row 9: D ‚Üí D\nBREED[9, 6] <- 1\n\ngamma[1:6,1:6] <- PHIA[1:6,1:6] %*% PHIY[1:6,1:9] %*% \n  AGING[1:9,1:9] %*% BREED[1:9,1:6]\n# Observation matrix\n\n# Detection probabilities\nDETECTION[1, 1] <- 1 - p[1]     # NB not detected\nDETECTION[1, 2] <- p[1]         # NB detected\nDETECTION[2, 1] <- 1 - p[2]\nDETECTION[2, 3] <- p[2]        # Byoy detected\nDETECTION[3, 1] <- 1 - p[2]\nDETECTION[3, 4] <- p[2]         # Bc1 detected\nDETECTION[4, 1] <- 1 - p[1]\nDETECTION[4, 5] <- p[1]         # Bc2 detected\nDETECTION[5, 1] <- 1 - p[1]\nDETECTION[5, 6] <- p[1]         # Bc3 detected\nDETECTION[6, 1] <- 1           # Dead never detected\n\n# OBS is 6x4\n# Not detected ‚Üí not sighted\nOBS[1, 1] <- 1\n# Detected NB ‚Üí alone\nOBS[2, 2] <- 1\n# Detected Byoy ‚Üí YOY visible or not\nOBS[3, 2] <- 1 - q[1]    # alone\nOBS[3, 3] <- q[1]        # with YOY\n# Detected Bc1 ‚Üí calf visible or not\nOBS[4, 2] <- 1 - q[2]\nOBS[4, 4] <- q[2]\n# Detected Bc2\nOBS[5, 2] <- 1 - q[2]\nOBS[5, 4] <- q[2]\n# Detected Bc3\nOBS[6, 2] <- 1 - q[2]\nOBS[6, 4] <- q[2]\n\nomega[1:6,1:4] <- DETECTION[1:6,1:6] %*% OBS[1:6,1:4]"},{"path":"tradeoffs.html","id":"results-and-interpretation-7","chapter":"8 Quantifying life history traits","heading":"8.3.3 Results and interpretation","text":"raw results :\nTable 8.1: Table 8.2: Age-specific estimates breeding probabilities. Comparison NIMBLE estimates Couet et al.¬†(2019). ‚ÄòNR‚Äô denotes quantities reported paper. ‚ÄòNB‚Äô non-breeding ‚Äòyoy‚Äô young---year. Adult female detection paper side rough time-average read eye authors‚Äô Figure 3 (2005‚Äì2016).\nNIMBLE estimates track published values closely. Calf survival shows discrepancies, credible confidence intervals overlap, worry much. Note also model differs slightly: held adult female detection constant time, whereas paper models time‚Äêdependent.Offspring often missed even female breeding, especially young year, harder see older calves. Offspring detection well 1. Adult detection also depends female‚Äôs state: females young year 1-year calf detectable non-breeders older calves.Adult female survival high. Calf survival ranks young---year ‚â• 1-year. Breeding probability depends recent history: ‚Äôs lower non-breeding losing young---year/1-year calf, higher losing 2-year calf successfully raising calf age 3.","code":"##                  mean   sd 2.5%  50% 97.5% Rhat n.eff\n## adultsurvival    0.96 0.01 0.94 0.96  0.98 1.00  2069\n## beta[1]          0.35 0.04 0.28 0.35  0.45 1.03   656\n## beta[2]          0.57 0.10 0.39 0.57  0.78 1.00  1009\n## p[1]             0.63 0.03 0.58 0.63  0.69 1.00  1764\n## p[2]             0.79 0.03 0.72 0.79  0.86 1.00  1123\n## pi[1]            0.49 0.06 0.37 0.49  0.60 1.01  2743\n## pi[2]            0.26 0.05 0.17 0.26  0.37 1.00  3412\n## pi[3]            0.08 0.03 0.03 0.08  0.16 1.00  2225\n## pi[4]            0.14 0.04 0.07 0.14  0.23 1.00  1931\n## pi[5]            0.03 0.03 0.00 0.02  0.10 1.02  1315\n## q[1]             0.59 0.05 0.49 0.59  0.69 1.01  1091\n## q[2]             0.80 0.05 0.70 0.80  0.89 1.01   818\n## youngsurvival[1] 0.63 0.05 0.55 0.63  0.73 1.00   808\n## youngsurvival[2] 0.69 0.08 0.53 0.69  0.83 1.00  1702"},{"path":"tradeoffs.html","id":"estimating-stopover-duration","chapter":"8 Quantifying life history traits","heading":"8.4 Estimating stopover duration","text":"","code":""},{"path":"tradeoffs.html","id":"motivation-8","chapter":"8 Quantifying life history traits","heading":"8.4.1 Motivation","text":"Stopover just logistical pause; ‚Äôs stage-specific timing trait migratory life cycle. Like age first reproduction length breeding attempt, duration stopover shapes exposure predators, energy balance, downstream reproductive timing. Two core questions migration ecology : (1) long individuals stop , (2) whether groups differ stopover behaviour. Treating stopover life-history trait puts questions center stage.catch arrivals departures hidden detection imperfect. look individuals seen, bias entry curve distribution stay lengths. reviewed Gu√©rin et al. (2017), HMM fixes keeping states hidden observations separate: example, may use three latent states: yet arrived, arrived (present), departed; let two transition probabilities drive dynamics: recruitment (yet arrived arrived) staying (arrived arrived). Detection operates state arrived. -called time-effect parameterization assumes staying depends calendar date, time since arrival, often right first step.setup can estimate daily entry staying probabilities, derive expected stopover duration arrival date, test group differences behaviour.","code":""},{"path":"tradeoffs.html","id":"model-and-nimble-implementation-8","chapter":"8 Quantifying life history traits","heading":"8.4.2 Model and NIMBLE implementation","text":"illustrate model marbled newts (Triturus marmoratus) monitored 2013 permanent pond near Vigneux-de-Bretagne (Loire-Atlantique, western France). Intensive capture-recapture yielded 713 PIT-tagged newts (412 males, 301 females). Captures within week pooled create 12 equally spaced occasions (11 weekly samples plus leading ‚Äòempty‚Äô occasion), individuals start ‚Äòyet arrived‚Äô state. data shared Sandra Gu√©rin.build model, first define states observations:States\n- NYA yet arrived pond\n- ARR arrived pond\n- DEP departed pondStates\n- NYA yet arrived pond\n- ARR arrived pond\n- DEP departed pondObservations\n- 1 captured\n- 2 capturedObservations\n- 1 captured\n- 2 capturedNow turn writing model. start vector initial states. start study, everyone \\(NYA\\), initial state vector :\\[\n\\begin{matrix}\n& \\\\\n\\boldsymbol{\\delta} =\n\\left ( \\vphantom{ \\begin{matrix} 1 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n\\text{NYA} & \\text{ARR} & \\text{DEP} \\\\[0.3em] \\hdashline\n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 1 \\end{matrix} } \\right )\n\\end{matrix}\n\\]proceed transition matrix, governed two processes: recruitment \\(r\\) probability individual \\(NYA\\) enters pond staying \\(s\\) probability individual \\(ARR\\) remains pond. State \\(DEP\\) absorbing. :\\[\\begin{matrix}\n& \\\\\n\\Gamma =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\nz_t=NYA & z_t=ARR & z_t=DEP \\\\[0.3em] \\hdashline\n1 - r & r & 0 \\\\\n0 & s & 1 - s \\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t-1}=NYA \\\\ z_{t-1}=ARR \\\\ z_{t-1}=DEP\n\\end{matrix}\n\\end{matrix}\\]make parameters \\(r\\) \\(s\\) sex time-dependent, code NIMBLE:Graphically, corresponds :Last step observation matrix:\\[\\begin{matrix}\n& \\\\\n\\Omega =\n\\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\ny_t=1 & y_t=2 \\\\[0.3em] \\hdashline\n1 & 0 \\\\\n1-p & p \\\\\n1 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n\\begin{matrix}\nz_{t}=NYA \\\\ z_{t}=ARR \\\\ z_{t}=DEP\n\\end{matrix}\n\\end{matrix}\\]individuals state \\(ARR\\) observable probability \\(p\\).likelihood priors handled usual.Using MCMC draws posterior distribution staying probability \\(s\\), can calculate expected stopover duration \\(\\mathbb{E}[D]\\) number occasions present arrival. constant \\(s\\), given :\n\\[\n\\mathbb{E}[D] \\;=\\; \\frac{1}{\\,1 - s\\,}.\n\\]? length stay (counting arrival occasion) geometric. arriving, present week probability 1 (‚Äôs 1 week). still present next week probability \\(s\\). still present week probability \\(s^2\\). . expected number occasions present sum probabilities:\\[\n\\mathbb{E}[D] \\;=\\; 1+s+s^2+\\cdots \\;=\\; \\frac{1}{\\,1 - s\\,}.\n\\]\\(s\\) varies date, ‚Äòlength stay‚Äô arrival longer geometric single parameter, ‚Äôs non-homogeneous geometric process week-specific stay probabilities \\(s_t\\). individual arrives date \\(\\tau\\), chance still present \\(k\\) occasions later product stay probabilities along run:\\[\nPr(D > k \\mid \\text{arrive } \\tau) \\;=\\; \\prod_{j=0}^{k-1} s_{\\tau + j}.\n\\]Therefore, expected number occasions present (counting arrival occasion) sum tail probabilities:\\[\n\\mathbb{E}[D \\mid \\text{arrive } \\tau]\n\\;=\\;\n\\sum_{k=0}^{\\infty} \\prod_{j=0}^{k-1} s_{\\tau + j}.\n\\]empty product \\(k=0\\) equal 1, words sum probabilities ‚Äòsurviving‚Äô additional week \\(ARR\\) calendar-date effects.","code":"\nfor (j in 1:(K-1)){\n  # prior probability of arriving in the pond / 1 = female\n  logit(r[1,j]) <- beta[1,1] + beta[1,2] * (j-4.5)/2.45 \n  # prior probability of arriving in the pond / 2 = male\n  logit(r[2,j]) <- beta[2,1] + beta[2,2] * (j-4.5)/2.45 \n  # prior retention probability (staying) / 1 = female\n  s[1,j] ~ dunif(0, 1) \n  # prior retention probability (staying) / 2 = male\n  s[2,j] ~ dunif(0, 1) \n}\nfor (i in 1:N){\n  for (j in 1:(K-1)){\n    gamma[1,1,i,j] <- 1 - r[sex[i],j] \n    gamma[1,2,i,j] <- r[sex[i],j] \n    gamma[1,3,i,j] <- 0 \n    gamma[2,1,i,j] <- 0\n    gamma[2,2,i,j] <- s[sex[i],j]\n    gamma[2,3,i,j] <- 1 - s[sex[i],j]\n    gamma[3,1,i,j] <- 0 \n    gamma[3,2,i,j] <- 0 \n    gamma[3,3,i,j] <- 1\n  }\n}"},{"path":"tradeoffs.html","id":"results-and-interpretation-8","chapter":"8 Quantifying life history traits","heading":"8.4.3 Results and interpretation","text":"NIMBLE estimates match pretty closely obtained Gu√©rin et al. (2017), compare Figure 8.2 authors‚Äô Figure 2.Early season, females arrive first: first three capture occasions arrival probability exceeds males (Figure 8.2). occasion 7, essentially individuals entered pond.\nFigure 8.2: Arrival probability sex week. Means 95% credible intervals (shaded areas) provided.\nFemales show longer stopovers males season; near end, pattern reverses (Figure 8.3). Individuals arriving early breeding season stay longer arriving later.\nFigure 8.3: Stopover duration sex arrival week. Means 95% credible intervals (shaded areas) provided.\n","code":""},{"path":"conclusion.html","id":"conclusion","chapter":"Conclusion","heading":"Conclusion","text":"wrap book, let share pieces advice. rocket science, just lessons ‚Äôve picked along way building hidden Markov models analysing data Bayesian statistics.Make ecological question explicit. First things first. Make sure ‚Äôve spent time make ecological question explicit. step help stay course, make right choices. example, ‚Äôs fine use subsets data address different questions.Make ecological question explicit. First things first. Make sure ‚Äôve spent time make ecological question explicit. step help stay course, make right choices. example, ‚Äôs fine use subsets data address different questions.Now terms modeling. Think observations states first. Don‚Äôt jump keyboard right away. Spend time thinking model pen paper. particular make sure observations states HMM. write observation transition matrices paper. Write transition matrix first. may act imperfect detection. really ‚Äôre , ecological process (survival, dispersal, etc). proceed observation matrix.Now terms modeling. Think observations states first. Don‚Äôt jump keyboard right away. Spend time thinking model pen paper. particular make sure observations states HMM. write observation transition matrices paper. Write transition matrix first. may act imperfect detection. really ‚Äôre , ecological process (survival, dispersal, etc). proceed observation matrix.comes model fitting NIMBLE, start simple, parameters constant example. Make sure convergence reached. add complexity one step time. Time effect example, random effects, uncertainty assignment states.comes model fitting NIMBLE, start simple, parameters constant example. Make sure convergence reached. add complexity one step time. Time effect example, random effects, uncertainty assignment states.Consider simulations better understand model. comes model building, consider simulating data better understand model. always learn something model seeing engine generate data, instead estimating parameters. nice thing NIMBLE can use model simulate data.Consider simulations better understand model. comes model building, consider simulating data better understand model. always learn something model seeing engine generate data, instead estimating parameters. nice thing NIMBLE can use model simulate data.Another advice, quite general programming, try optimize code try make elegant right away. Make model work first, think optimization.Another advice, quite general programming, try optimize code try make elegant right away. Make model work first, think optimization.hope convinced hidden Markov models combined Bayesian framework flexible analyse capture-recapture data. data, may ask myriad questions. limit imagination (CPU time).stimulate imagination, assembled searchable list https://oliviergimenez.github.io/curated-list--HMM-CR-papers/ HMM analyses capture-recapture data get inspiration. list exhaustive, please get touch ‚Äôd like add reference.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]

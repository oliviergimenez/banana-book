[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"Welcome online version book Bayesian Analysis Capture-Recapture Data Hidden Markov Models – Theory Case Studies R. HMM framework gained much attention ecological literature last decade, suggested general modelling framework demography plant animal populations. particular, HMMs increasingly used analyse capture-recapture data estimate key population parameters (e.g., survival, dispersal, recruitment abundance) applications fields ecology.parallel, Bayesian statistics well established fast growing ecology related disciplines, resonates scientific reasoning allows accommodating uncertainty smoothly. popularity Bayesian statistics also comes availability free pieces software (WinBUGS, OpenBUGS, JAGS, Stan, NIMBLE) allow practitioners code analyses.book offers Bayesian treatment HMMs applied capture-recapture data. learn use R package NIMBLE seen many future Bayesian statistical ecology deal complex models /big data. important part book consists case studies presented tutorial style abide “learning ” philosophy.’m currently writing book, welcome feedback. may raise issue , amend directly R Markdown file generated page ’re reading clicking ‘Edit page’ icon right panel, email . Many thanks!Olivier Gimenez. Written Montpellier, France Athens, Greece.\nLast updated: August 12, 2023","code":""},{"path":"index.html","id":"license","chapter":"Welcome","heading":"License","text":"online version book licensed Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.code public domain, licensed Creative Commons CC0 1.0 Universal (CC0 1.0).","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"preface.html","id":"why-this-book","chapter":"Preface","heading":"Why this book?","text":"completed. capture-recapture data models, fields application.1 Brief history capture-recapture, switch state-space/hidden Markov model (HMM) formulation. Flexibility HMM decompose complex problems smaller pieces easier understand, model analyse. satellite guidance conservation endangered species. Bayes? Also three fav research topics – capture-recapture, HMM Bayes statistics – let’s enjoy great cocktail together.","code":""},{"path":"preface.html","id":"who-should-read-this-book","chapter":"Preface","heading":"Who should read this book?","text":"book aimed beginners ’re comfortable using R write basic code (including loops), well connoisseurs capture-recapture ’d like tap power Bayesian side statistics. audiences, thinking HMM framework help confidently building models make capture-recapture data.","code":""},{"path":"preface.html","id":"what-will-you-learn","chapter":"Preface","heading":"What will you learn?","text":"book divided five parts. first part aimed getting --speed Bayesian statistics, NIMBLE, hidden Markov models. second part teach capture-recapture models open populations, reproducible R code ease learning process. third part, focus issues inferring states (dealing uncertainty assignment, modelling waiting time distribution). fourth part provides real-world case studies scientific literature can reproduce using material covered previous chapters. problems can either ) used cement deepen understanding methods models, ii) adapted purpose, iii) serve teaching projects. fifth last chapter closes book take-home messages recommendations, list frequently asked questions references cited book. Likely amended feedbacks.","code":""},{"path":"preface.html","id":"what-wont-you-learn","chapter":"Preface","heading":"What won’t you learn?","text":"hardly maths book. equations use either simple enough understood without background maths, can skipped without prejudice. cover Bayesian statistics even hidden Markov models fully, provide just need work capture-recapture data. interested knowing topics, hopefully section Suggested reading end chapter put right direction. also number important topics specific capture-recapture cover, including closed-population capture-recapture models (Williams, Nichols, Conroy 2002), spatial capture-recapture models (Royle et al. 2013). models can treated HMMs, now usual formulation just fine. spatial considerations Covariates chapter w/ splines CAR. ’m sure yet SCR models (R. Glennie’s Biometrics paper HMMs open pop SCR easy Bayes transform implement NIMBLE).","code":""},{"path":"preface.html","id":"prerequisites","chapter":"Preface","heading":"Prerequisites","text":"book uses primarily R package NIMBLE, need install least R NIMBLE. bunch R packages used. can install running:","code":"\ninstall.packages(c(\n  \"magick\", \"MCMCvis\", \"nimble\", \"pdftools\", \n  \"tidyverse\", \"wesanderson\" \n))"},{"path":"preface.html","id":"acknowledgements","chapter":"Preface","heading":"Acknowledgements","text":"completed.","code":""},{"path":"preface.html","id":"how-this-book-was-written","chapter":"Preface","heading":"How this book was written","text":"writing book RStudio using bookdown. book website hosted GitHub Pages, automatically updated every push Github Actions. source available GitHub.version book ’re reading built R version 4.2.3 (2023-03-15) following packages:","code":""},{"path":"about-the-author.html","id":"about-the-author","chapter":"About the author","heading":"About the author","text":"name Olivier Gimenez (https://oliviergimenez.github.io/). senior (euphemism young anymore) scientist National Centre Scientific Research (CNRS) beautiful city Montpellier, France.struggled studying maths, obtained PhD applied statistics long time ago galaxy wine cheese. awarded habilitation (https://en.wikipedia.org/wiki/Habilitation) ecology evolution stop pretending understand colleagues talking . recently embarked sociology studies hey, .Lost somewhere interface animal ecology, statistical modeling social sciences, -called expertise lies population dynamics species distribution modeling address questions ecology conservation biology impact human activities management large carnivores. nothing without students colleagues kind enough bear .may find Twitter (https://twitter.com/oaggimenez), GitHub (https://github.com/oliviergimenez), get touch email.","code":""},{"path":"introduction.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"introduction-1.html","id":"introduction-1","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"survival.html","id":"survival","chapter":"1 Survival","heading":"1 Survival","text":"","code":""},{"path":"survival.html","id":"introduction-2","chapter":"1 Survival","heading":"1.1 Introduction","text":"fourth chapter, learn Cormack-Jolly-Seber model allows estimating survival based capture-recapture data. also see deal covariates try explain temporal /individual variation survival. chapter also opportunity illustrate incorporate prior information improve model inference.","code":""},{"path":"survival.html","id":"the-cormack-jolly-seber-cjs-model","chapter":"1 Survival","heading":"1.2 The Cormack-Jolly-Seber (CJS) model","text":"chapter ??, introduced capture-recapture model constant survival detection probabilities formulated HMM fitted data NIMBLE. Historically, however, slightly complicated model first proposed – -called Cormack-Jolly-Seber (CJS) model – survival recapture probabilities time-varying. feature CJS model useful account variation due environmental conditions survival sampling effort detection. Schematically CJS model can represented way:Note states (gray) observations (white) change. still \\(z = 1\\) alive, \\(z = 2\\) dead, \\(y = 1\\) non-detected, \\(y = 2\\) detected.Parameters now indexed time. survival probability defined probability staying alive (“ah, ha, ha, ha, stayin’ alive” like Bee Gees say) interval \\(t\\) \\(t+1\\), \\(\\phi_t = \\Pr(z_{t+1} = 1 | z_t = 1)\\). detection probability defined probability observed \\(t\\) given ’re alive \\(t\\), \\(p_t = \\Pr(y_{t} = 1 | z_t = 1)\\). important bear mind survival operates interval detection occurs specific time (see Section 1.8).CJS model named three statisticians published independently paper introducing less approach, year apart ! fact, Richard Cormack George Jolly working corridor Scotland back 1960’s. meet every day coffee play game together, never mention work aware ’s work.","code":""},{"path":"survival.html","id":"capture-recapture-data","chapter":"1 Survival","heading":"1.3 Capture-recapture data","text":"turn fitting CJS model actual data, let’s talk capture-recapture minute. said Section ?? animals individually marked. can accomplished two ways, either artificial marks like rings birds ear tags mammals, (non-invasive) natural marks like coat patterns feces DNA sequencing (Figure 1.1).\nFigure 1.1: Animal individual marking. Top-left: rings; Top-right: ear-tags; Bottom left: coat patterns; Bottom right: ADN feces\nThroughout chapter, use data White-throated Dipper (Cinclus cinclus; dipper hereafter) kindly provided Gilbert Marzolin (Figure 1.2). total, 294 dippers known sex wing length captured recaptured 1981 1987 March-June period. Birds least 1 year old initially banded.\nFigure 1.2: White-throated Dipper (Cinclus cinclus)\nmay scroll data :first seven columns years Gilbert went field captured birds. 0 stands non-detection, 1 detection. eighth column informs sex bird, F female M male. last column gives measure wing length first time bird captured.","code":""},{"path":"survival.html","id":"fitting-the-cjs-model-to-the-dipper-data-with-nimble","chapter":"1 Survival","heading":"1.4 Fitting the CJS model to the dipper data with NIMBLE","text":"write NIMBLE code corresponding CJS model, need make adjustments NIMBLE code model constant parameters Section ??. main modification concerns observation transition matrices need make time-varying. matrices therefore become arrays inherit third dimension besides rows columns. Also need priors time-varying survival detection probabilities. write:likelihood change, except time-varying observation transition matrices need used appropriately. Also, now deal several cohorts animals first captured, marked released year (contrast single cohort Chapter ??), need start loop time first capture individual. Therefore, write:Overall, code looks like:read data:get occasion first capture individuals, finding position detections encounter history ((x !=0)), keeping first one:Now specify constants:Now put data list. add 1 data code non-detections 1’s detections 2’s (see Section @ref{fittinghmmnimble}).Now let’s write function initial values. latent states, go easy way, say individuals alive study period:specify parameters like monitor:provide MCMC details:Now ready run NIMBLE:may look numerical summaries:much time variation detection probability estimated high around 0.90. Note p[1] corresponds detection probability 1982 \\(p_2\\), p[2] detection 1983 therefore \\(p_3\\), . contrast, dippers seem experienced decrease survival years 1982-1983 (phi[2]) 1983-1984 (phi[4]). get back Section 1.8.may noticed small effective sample size last survival (phi[6]) detection (p[6]) probabilities. Let’s look mixing parameter phi[6] example:Clearly mixing (left panel plot ) bad big overlap prior posterior parameter (right panel) suggesting prior well updated data. going ? inspect likelihood CJS model, realise two parameters \\(\\phi_6\\) \\(p_7\\) appear product \\(\\phi_6 p_7\\) estimated separately. words, one parameters redundant, ’d need extra sampling occasion able disentangle . big issue long ’re aware attempt ecologically interpret parameters.","code":"\n...\n# parameters\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n...\n...\n# likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n...\nhmm.phitpt <- nimbleCode({\n  # parameters\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})\ndipper <- read_csv(here::here(\"dat\", \"dipper.csv\"), show_col_types = FALSE)\ny <- dipper %>%\n  select(year_1981:year_1987) %>%\n  as.matrix()\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nmy.constants <- list(N = nrow(y),   # number of animals\n                     T = ncol(y),   # number of sampling occasions\n                     first = first) # first capture for all animales\nmy.constants\n## $N\n## [1] 294\n## \n## $T\n## [1] 7\n## \n## $first\n##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n##  [28] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n##  [55] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n##  [82] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n## [109] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4\n## [136] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n## [163] 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n## [190] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6\n## [217] 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n## [244] 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n## [271] 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\nmy.data <- list(y = y + 1)\nzinits <- y + 1 # non-detection -> alive\nzinits[zinits == 2] <- 1 # dead -> alive\ninitial.values <- function() list(phi = runif(my.constants$T-1,0,1),\n                                  p = runif(my.constants$T-1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"phi\", \"p\")\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nmcmc.phitpt <- nimbleMCMC(code = hmm.phitpt,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\nMCMCsummary(mcmc.phitpt, params = c(\"phi\",\"p\"), round = 2)\n##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi[1] 0.73 0.14 0.46 0.72  0.99 1.02   199\n## phi[2] 0.45 0.07 0.32 0.44  0.59 1.02   410\n## phi[3] 0.48 0.06 0.35 0.48  0.59 1.01   506\n## phi[4] 0.63 0.06 0.52 0.63  0.75 1.03   415\n## phi[5] 0.60 0.06 0.49 0.60  0.72 1.01   365\n## phi[6] 0.74 0.13 0.51 0.74  0.97 1.10    38\n## p[1]   0.66 0.14 0.38 0.67  0.89 1.01   344\n## p[2]   0.87 0.08 0.68 0.89  0.98 1.02   249\n## p[3]   0.88 0.07 0.73 0.89  0.97 1.02   307\n## p[4]   0.87 0.06 0.74 0.88  0.96 1.05   333\n## p[5]   0.90 0.05 0.77 0.91  0.98 1.01   224\n## p[6]   0.72 0.13 0.50 0.72  0.97 1.08    37\npriors <- runif(3000, 0, 1)\nMCMCtrace(object = mcmc.phitpt,\n          ISB = FALSE,\n          exact = TRUE, \n          params = c(\"phi[6]\"),\n          pdf = FALSE, \n          priors = priors)"},{"path":"survival.html","id":"cjs-model-derivatives","chapter":"1 Survival","heading":"1.5 CJS model derivatives","text":"Besides model considered constant parameters (see Chapter ??) CJS model time-varying parameters, might want fit -models time variation either detection survival.Let’s start model time-varying survival constant detection. modify CJS model NIMBLE code longer observation matrix time-specific:obtain following numerical summaries parameters, confirming high detection temporal variation survival:Now model time-varying detection constant survival, NIMBLE code constant time transition matrix:Numerical summaries parameters :note two models longer parameter redundancy issues. left four models, saying different story data, temporal variation either survival detection probabilty. quantify plausible four ecological hypotheses? Rendez-vous next section.","code":"\nhmm.phitp <- nimbleCode({\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi[1] 0.63 0.10 0.42 0.63  0.82 1.04   564\n## phi[2] 0.46 0.06 0.35 0.46  0.59 1.01   629\n## phi[3] 0.48 0.05 0.37 0.48  0.59 1.00   610\n## phi[4] 0.62 0.06 0.51 0.62  0.73 1.00   553\n## phi[5] 0.61 0.05 0.50 0.61  0.72 1.00   568\n## phi[6] 0.59 0.05 0.48 0.59  0.69 1.03   463\n## p      0.89 0.03 0.82 0.89  0.95 1.04   211\nhmm.phipt <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})##      mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi  0.56 0.03 0.52 0.56  0.61 1.02   381\n## p[1] 0.75 0.12 0.48 0.77  0.93 1.03   452\n## p[2] 0.85 0.08 0.68 0.86  0.97 1.02   359\n## p[3] 0.85 0.07 0.69 0.85  0.96 1.00   316\n## p[4] 0.89 0.05 0.77 0.89  0.97 1.00   412\n## p[5] 0.91 0.04 0.82 0.92  0.98 1.00   376\n## p[6] 0.90 0.07 0.73 0.91  1.00 1.07   111"},{"path":"survival.html","id":"waic","chapter":"1 Survival","heading":"1.6 Model comparison with WAIC","text":"four models best supported data? answer question, need bear mind used observed data fit models, close truth models perform predicting future data – predictive accuracy – assessed. natural candidate measure predictive accuracy likelihood often referred context model comparison predictive density. However, know neither true process, future data, can estimate predictive density bias.may heard Akaike Information Criterion (AIC) Frequentist framework, Deviance Information Criterion (DIC) Bayesian framework. consider Widely Applicable Information Criterion Watanabe Information Criterion (WAIC). AIC, DIC WAIC aim provide approximation predictive accuracy.AIC predictive measure choice Frequentist framework ecologists, DIC around time Bayesian applications due availability population BUGS pieces software. However, methods utilize point estimate unknown parameters. Also, various difficulties noted DIC may give nonsensical results posterior distribution well summarized mean. fully Bayesian approach like use entire posterior distribution evaluate predictive performance, exactly WAIC .Conveniently, NIMBLE calculates WAIC . modifications need make ) monitor nodes, including latent states ii) add WAIC = TRUE call nimbleMCMC() function. example, CJS model, write:re-ran four models calculate WAIC value themLower values WAIC imply higher predictive accuracy, thefore favor model constant parameters.","code":"\nparameters.to.save <- c(\"phi\", \"p\", \"z\") \nmcmc.phitpt <- nimbleMCMC(code = hmm.phitpt,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains,\n                          WAIC = TRUE) ##                                         model  WAIC\n## 1          both survival & detection constant 265.9\n## 2 time-dependent survival, constant detection 277.6\n## 3 constant survival, time-dependent detection 270.2\n## 4    both survival & detection time-dependent 308.8"},{"path":"survival.html","id":"gof","chapter":"1 Survival","heading":"1.7 Goodness of fit","text":"previous section, Section 1.6, compared models based predictive accuracy – assessed relative fit. However, even though able rank models according predictive accuracy, happen models actually poor predictive performance – absolute fit.assess goodness fit CJS model capture-recapture data? particular assess homogeneity survival detection probabilities fundamental assumption model?","code":""},{"path":"survival.html","id":"posterior-predictive-checks","chapter":"1 Survival","heading":"1.7.1 Posterior predictive checks","text":"Bayesian framework, rely posterior predictive checks assess absolute fit. Briefly speaking, idea compare observed data replicated data generated model. model good fit data, replicated data predicted model look similar observed data. simplify comparison, summary statistics generally used. CJS model, use -called m-array gathers elements \\(m_{ij}\\) number marked individuals initially released time \\(\\) first detected time \\(j\\). include example? yes, refer paper Paganin & de Valpine use code https://github.com/salleuska/fastCPPP","code":""},{"path":"survival.html","id":"classical-tests","chapter":"1 Survival","heading":"1.7.2 Classical tests","text":"Frequentist literature, well established procedures assessing absolute fit departures specific CJS model assumptions shame just ignore.focus two assumptions ecological interpretation, transience trap-dependence. transience procedure assesses whether newly encountered individuals (‘new’ individuals) chance later re-observed recaptured (previously encountered) individuals (‘old’ individuals). trap-dependence procedure assesses whether missed individuals chance recaptured next occasion currently captured individuals. Although procedures called test transience test trap-dependence, comes interpretation, keep mind transience – excess individuals never seen – trap-dependence – effect trapping detection – just two specific reasons tests might detect lack fit.tests implemented package R2ucare, illustrate use dipper data.get capture-recapture data:sake illustration, consider females :overall test shows reject hypothesis CJS models fits data well:may perform test specifically assess transient effect:trap-dependence:tests significant? Transience may occur animals transit belong study population (true transients), reproduce die permanently disperse (cost first reproduction), die permanently disperse due effect marking (marking effect). transient individuals never detected initial capture, means zero probability local survival initial capture. suggests way account transience issue cover case study (see transience case study).Trap-dependence may occur animals affected (positively negatively) trapping (true trap-dependence), observers tend visit parts study area often individuals detected (preferential sampling), patches heterogeneous habitat accessible individuals stationed higher detection probabilities (access bias), age, sex social status unknown, determine individual movements activity patterns susceptibility detected varies (individual heterogeneity), non random temporary emigration occurs (skipped reproduction). Trap-dependence therefore designates correlation detection events. account trap-dependence issue, correlation needs accounted , show case study (see trap dep case study).","code":"\nlibrary(R2ucare)\n# capture-recapture data\ndipper <- read_csv(here::here(\"dat\", \"dipper.csv\"))\ndip.hist <- dipper %>%\n  select(year_1981:year_1987) %>%\n  as.matrix()\n# number of birds with that particular capture-recapture history\ndip.freq <- rep(1, nrow(dip.hist))\n# sex of each bird\ndip.group <- dipper$sex\nmask <- (dip.group == 'F')\ndip.fem.hist <- dip.hist[mask,]\ndip.fem.freq <- dip.freq[mask]\noverall_CJS(dip.fem.hist, dip.fem.freq)\n##                          chi2 degree_of_freedom p_value\n## Gof test for CJS model: 10.28                12   0.592\ntest3sr(dip.fem.hist, dip.fem.freq)\n## $test3sr\n##      stat        df     p_val sign_test \n##     4.985     5.000     0.418     1.428 \n## \n## $details\n##   component  stat p_val signed_test  test_perf\n## 1         2 0.858 0.354       0.926 Chi-square\n## 2         3 3.586 0.058       1.894 Chi-square\n## 3         4 0.437 0.509       0.661 Chi-square\n## 4         5 0.103 0.748      -0.321 Chi-square\n## 5         6 0.001 0.982       0.032 Chi-square\ntest2ct(dip.fem.hist, dip.fem.freq)\n## $test2ct\n##      stat        df     p_val sign_test \n##     3.250     4.000     0.517    -0.901 \n## \n## $details\n##   component dof stat p_val signed_test test_perf\n## 1         2   1    0     1           0    Fisher\n## 2         3   1    0     1           0    Fisher\n## 3         4   1    0     1           0    Fisher\n## 4         5   1 3.25 0.071      -1.803    Fisher"},{"path":"survival.html","id":"design-considerations","chapter":"1 Survival","heading":"1.7.3 Design considerations","text":"far, addressed assumptions relative model. also assumptions relative design. particular, survival refers study area, need think carefully survival actually mean. actually estimate usually call apparent survival, exactly true survival. Apparent survival probability product true survival study area fidelity. Consequently, apparent survival always lower true survival unless study area fidelity exactly 1.\nassumptions relative design, simply list . mark loss, identity individuals recorded without error (false positives), captured animals random sample population.","code":""},{"path":"survival.html","id":"covariates","chapter":"1 Survival","heading":"1.8 Covariates","text":"models considered far, survival detection probabilities may vary time, include ecological drivers might explain variation. Luckily, spirit generalized linear models, can make parameters dependent external covariates time, environmental conditions survival sampling effort detection.Besides variation time, also cover individual variation parameters, example survival vary according sex phenotypic characteristics (e.g. size body mass).Let’s illustrate use covariates dipper example.","code":""},{"path":"survival.html","id":"temporal-covariates","chapter":"1 Survival","heading":"1.8.1 Temporal covariates","text":"","code":""},{"path":"survival.html","id":"discrete","chapter":"1 Survival","heading":"1.8.1.1 Discrete","text":"major flood occurred 1983 breeding season (October 1982 May 1983). captures breding season occurred flood, survival two years 1982-1983 1983-1984 likely affected. Indeed survival species living along feeding river two flood years likely lower nonflood years.Let’s use covariate \\(\\text{flood}\\) contains 1s 2s, indicating whether flood nonflood year year: 1 nonflood year, 2 flood year.write model code:use nested indexing specifying survival transition matrix. E.g. year \\(t = 2\\), phi[flood[t]] gives phi[flood[2]] phi[2] flood[2] 2 flood year.Let’s provide constants list:function generate initial values:parameters monitored:’re set, ready run NIMBLE:look numerical summaries, see expected, survival flood years (phi[2]) much lower survival non-flood years (phi[1]):important point formulated ecological hypothesis translated model. next step consist calculating WAIC model compare four model fitted far (see Section 1.6).Another method include discrete covariate consists considering effect difference levels. example, consider survival nonflood years reference test difference survival flood years., write survival linear function covariate scale, e.g. \\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 \\;\\text{flood}_t\\) \\(\\beta\\)’s regression coefficient need estimate (intercept \\(\\beta_1\\) slope \\(\\beta_2\\)), \\(\\displaystyle{\\text{logit}(x) = \\log \\left(\\frac{x}{1-x}\\right)}\\) logit function. logit function lives \\(-\\infty\\) \\(+\\infty\\), sends values 0 1 onto real line. example \\(\\log(0.2/(1-0.2))=-1.39\\), \\(\\log(0.5/(1-0.5))=0\\) \\(\\log(0.8/(1-0.8))=1.39\\). use logit function? survival probability bounded 0 1, used directly \\(\\phi_t = \\beta_1 + \\beta_2 \\;\\text{flood}_t\\) might end estimates regression coefficients make survival bound. Therefore, consider survival linear function covariates scale logit function, working real line, back-transform using inverse-logit (reciprocal function) obtain survival natural scale. inverse-logit function \\(\\displaystyle{\\text{logit}^{-1}(x) = \\frac{\\exp(x)}{1+\\exp(x)} = \\frac{1}{1+\\exp(-x)}}\\). logit function often called link function like generalized linear models.Another point attention prior assign regression coefficients. longer assign prior survival directly like previously, need assign prior \\(\\beta\\)’s induce prior survival. sometimes, priors regression coefficients non-informative, prior survival . Consider example case single intercept covariate. assign prior regression coefficient normal distribution mean 0 large standard deviation, first reflex, end informative prior survival bathtub shape, putting much importance low high values:Now go lower standard deviation intercept prior, prior survival non-informative, looking like uniform distribution 0 1:Now let’s go back model. first define flood covariate 0 nonflood year, 1 flood year.write NIMBLE code:wrote \\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 \\; \\text{flood}_t\\), meaning survival nonflood years (\\(\\text{flood}_t = 0\\)) \\(\\text{logit}(\\phi_t) = \\beta_1\\) survival flood years (\\(\\text{flood}_t = 1\\)) \\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2\\). see \\(\\beta_1\\) survival nonflood years (logit scale) \\(\\beta_2\\) difference survival flood years survival nonflood years (, logit scale).Let’s put constants list:function generating initial values:parameters monitored.Finaly, may run NIMBLE:may check get numerical summaries survival nonflood years (phi[1], phi[4], phi[5] phi[6]) flood years (phi[2] phi[3]):may also check go \\(\\beta\\)’s survival probabilities \\(\\phi\\). Let’s get draws posterior distribution \\(\\beta\\)’s first:apply inverse-logit function get survival nonflood years, e.g. posterior mean credible interval:thing survival flood years:","code":"\nflood <- c(1, # 1981-1982 (nonflood)\n           2, # 1982-1983 (flood)\n           2, # 1983-1984 (flood)\n           1, # 1984-1985 (nonflood)\n           1, # 1985-1986 (nonflood)\n           1) # 1986-1987 (nonflood)\nhmm.phifloodp <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    gamma[1,1,t] <- phi[flood[t]]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[flood[t]]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  phi[1] ~ dunif(0, 1) # prior for survival in nonflood years\n  phi[2] ~ dunif(0, 1) # prior for survival in flood years\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y),\n                     T = ncol(y),\n                     first = first,\n                     flood = flood)\ninitial.values <- function() list(phi = runif(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"p\", \"phi\")\nmcmc.phifloodp <- nimbleMCMC(code = hmm.phifloodp, \n                             constants = my.constants,\n                             data = my.data,              \n                             inits = initial.values,\n                             monitors = parameters.to.save,\n                             niter = n.iter,\n                             nburnin = n.burnin, \n                             nchains = n.chains)##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p      0.89 0.03 0.83 0.90  0.95    1   609\n## phi[1] 0.61 0.03 0.55 0.61  0.67    1  1474\n## phi[2] 0.47 0.04 0.38 0.47  0.56    1  1700\nMCMCsummary(mcmc.phifloodp, round = 2)\n# 1000 random values from a N(0,10)\nintercept <- rnorm(1000, mean = 0, sd = 10) \n# plogis() is the inverse-logit function in R\nsurvival <- plogis(intercept) \ndf <- data.frame(intercept = intercept, survival = survival)\nplot1 <- df %>%\n  ggplot(aes(x = intercept)) +\n  geom_density() +\n  labs(x = \"prior on intercept\")\nplot2 <- df %>%\n  ggplot(aes(x = survival)) +\n  geom_density() +\n  labs(x = \"prior on survival\")\nplot1 + plot2\nset.seed(123)\n# 1000 random values from a N(0,1.5)\nintercept <- rnorm(1000, mean = 0, sd = 1.5) \n# plogis() is the inverse-logit function in R\nsurvival <- plogis(intercept) \ndf <- data.frame(intercept = intercept, survival = survival)\nplot1 <- df %>%\n  ggplot(aes(x = intercept)) +\n  geom_density() +\n  labs(x = \"prior on intercept\")\nplot2 <- df %>%\n  ggplot(aes(x = survival)) +\n  geom_density() +\n  labs(x = \"prior on survival\")\nplot1 + plot2\nflood <- c(0, # 1981-1982 (nonflood)\n           1, # 1982-1983 (flood)\n           1, # 1983-1984 (flood)\n           0, # 1984-1985 (nonflood)\n           0, # 1985-1986 (nonflood)\n           0) # 1986-1987 (nonflood)\nhmm.phifloodp <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    logit(phi[t]) <- beta[1] + beta[2] * flood[t]\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  beta[1] ~ dnorm(0, sd = 1.5) # prior intercept\n  beta[2] ~ dnorm(0, sd = 1.5) # prior slope\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y),\n                     T = ncol(y),\n                     first = first,\n                     flood = flood)\ninitial.values <- function() list(beta = rnorm(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"beta\", \"p\", \"phi\")\nmcmc.phifloodp <- nimbleMCMC(code = hmm.phifloodp, \n                             constants = my.constants,\n                             data = my.data,              \n                             inits = initial.values,\n                             monitors = parameters.to.save,\n                             niter = n.iter,\n                             nburnin = n.burnin, \n                             nchains = n.chains)\nMCMCsummary(mcmc.phifloodp, round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.44 0.13  0.17  0.44  0.69 1.01   725\n## beta[2] -0.54 0.22 -0.96 -0.54 -0.11 1.00   770\n## p        0.89 0.03  0.83  0.89  0.94 1.00   631\n## phi[1]   0.61 0.03  0.54  0.61  0.67 1.01   724\n## phi[2]   0.47 0.04  0.39  0.47  0.56 1.00  1597\n## phi[3]   0.47 0.04  0.39  0.47  0.56 1.00  1597\n## phi[4]   0.61 0.03  0.54  0.61  0.67 1.01   724\n## phi[5]   0.61 0.03  0.54  0.61  0.67 1.01   724\n## phi[6]   0.61 0.03  0.54  0.61  0.67 1.01   724\nbeta1 <- c(mcmc.phifloodp$chain1[,'beta[1]'], # beta1 chain 1\n           mcmc.phifloodp$chain2[,'beta[1]']) # beta1 chain 2\nbeta2 <- c(mcmc.phifloodp$chain1[,'beta[2]'], # beta2 chain 1\n           mcmc.phifloodp$chain2[,'beta[2]']) # beta2 chain 2\nmean(plogis(beta1))\n## [1] 0.6066\nquantile(plogis(beta1), probs = c(2.5, 97.5)/100)\n##   2.5%  97.5% \n## 0.5435 0.6651\nmean(plogis(beta1 + beta2))\n## [1] 0.4744\nquantile(plogis(beta1 + beta2), probs = c(2.5, 97.5)/100)\n##   2.5%  97.5% \n## 0.3895 0.5606"},{"path":"survival.html","id":"continuous","chapter":"1 Survival","heading":"1.8.1.2 Continuous","text":"Instead discrete covariate varying time, may want consider continuous covariate, say \\(x_t\\), \\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\). example, let’s investigate effect water flow dipper survival, reflect flood occurred 1983 breeding season.build covariate water flow liters per second measured March May period year, starting year 1982:need water flow 1981 write probability \\(\\phi_t\\) alive year \\(t + 1\\) given bird alive year \\(t\\) linear function water flow year \\(t + 1\\).may noticed high value water flow 1983, twice much years, corresponding flood. Importantly, standardize covariate improve convergence:Now write model code:put constants list:Initial values usual:parameters monitored:Eventually, run NIMBLE:can look results caterpillar plot regression parameters:posterior distribution slope (beta[2]) centered negative values, suggesting water flow increases, survival decreases.Let’s inspect time-dependent survival probability:Survival 1982 1983 (phi[2]) greatly affected much lower average. decrease corresponds high water flow 1983 flood. results line previous findings obtained considering covariate nonflood vs. flood years.","code":"\n# water flow in L/s\nwater_flow <- c(443,  # March-May 1982\n                1114, # March-May 1983\n                529,  # March-May 1984\n                434,  # March-May 1985\n                627,  # March-May 1986\n                466)  # March-May 1987\nwater_flow_st <- (water_flow - mean(water_flow))/sd(water_flow)\nhmm.phiflowp <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    logit(phi[t]) <- beta[1] + beta[2] * flow[t] \n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  beta[1] ~ dnorm(0, 1.5) # prior intercept\n  beta[2] ~ dnorm(0, 1.5) # prior slope\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y),\n                     T = ncol(y),\n                     first = first,\n                     flow = water_flow_st)\ninitial.values <- function() list(beta = rnorm(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"beta\", \"p\", \"phi\")\nmcmc.phiflowp <- nimbleMCMC(code = hmm.phiflowp, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin, \n                          nchains = n.chains)\nMCMCplot(object = mcmc.phiflowp, params = \"beta\")\nMCMCplot(object = mcmc.phiflowp, params = \"phi\", ISB = TRUE)"},{"path":"survival.html","id":"individual-covariates","chapter":"1 Survival","heading":"1.8.2 Individual covariates","text":"previous section, learnt explain temporal heterogeneity survival detection. Heterogeneity also originate individual differences animals. may think diffence survival males females discrete covariate example, size body mass examples continuous covariate. Let’s illustrate discrete continuous covariates dipper.","code":""},{"path":"survival.html","id":"discrete-1","chapter":"1 Survival","heading":"1.8.2.1 Discrete","text":"first consider covariate \\(\\text{sex}\\) contains 1’s 2’s indicating sex bird: 1 male, 2 female. implement model sex effect using nested indexing, similarly model flood vs. nonflood years. section NIMBLE code needs amended :running NIMBLE, get:Male survival (phi[1]) looks similar female survival (phi[2]). Give entire NIMBLE code? Alternatively, chapter others, provide fragments code emphasize specific point adjustments, file whole code elsewhere convenience, R script. avoid repeating data/constants/initial values/MCMC details/nimble run steps, save space well.","code":"\n...\nfor (i in 1:N){\n  gamma[1,1,i] <- phi[sex[i]]      # Pr(alive t -> alive t+1)\n  gamma[1,2,i] <- 1 - phi[sex[i]]  # Pr(alive t -> dead t+1)\n  gamma[2,1,i] <- 0                # Pr(dead t -> alive t+1)\n  gamma[2,2,i] <- 1                # Pr(dead t -> dead t+1)\n}\nphi[1] ~ dunif(0,1) # male survival\nphi[2] ~ dunif(0,1) # female survival\n...\nMCMCsummary(object = mcmc.phisexp.ni, round = 2)##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p      0.90 0.03 0.84 0.90  0.95    1   643\n## phi[1] 0.57 0.03 0.50 0.57  0.64    1  1668\n## phi[2] 0.55 0.03 0.48 0.55  0.62    1  1482"},{"path":"survival.html","id":"continuous-1","chapter":"1 Survival","heading":"1.8.2.2 Continuous","text":"Besides discrete individual covariates, might want continuous individual covariates, e.g. wing length dipper example. Note ’re considering individual trait takes value whatever occasion. consider wing length , precisely measurement first detection. first standardize covariate:Now write model:put constants list:write function generating initial values:run NIMBLE:Let’s inspect numerical summaries regression parameters:Wing length seem explain much individual--individual variation survival – posterior distribution slope (beta[2]) centered 0 can see credible interval.Let’s plot relationship survival wing length. First, gather values generated posterior distribution regression parameters two chains:define grid values wing length, predict survival MCMC iteration:Now calculate posterior mean credible interval (note ordering):Now time visualize:flat relationship survival wing length confirmed.","code":"\nwing.length.st <- as.vector(scale(dipper$wing_length))\nhead(wing.length.st)\n## [1]  0.7581 -0.8671  0.5260 -1.5637 -1.3315  1.2225\nhmm.phiwlp <- nimbleCode({\n    p ~ dunif(0, 1) # prior detection\n    omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n    omega[1,2] <- p        # Pr(alive t -> detected t)\n    omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i]\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5)\n  beta[2] ~ dnorm(mean = 0, sd = 1.5)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first,\n                     winglength = wing.length.st)\ninitial.values <- function() list(beta = rnorm(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nmcmc.phiwlp <- nimbleMCMC(code = hmm.phiwlp, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin, \n                          nchains = n.chains)\nMCMCsummary(mcmc.phiwlp, params = \"beta\", round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.25 0.10  0.04  0.25  0.45    1  1472\n## beta[2] -0.02 0.09 -0.20 -0.02  0.17    1  1555\nbeta1 <- c(mcmc.phiwlp$chain1[,'beta[1]'], # intercept, chain 1\n           mcmc.phiwlp$chain2[,'beta[1]']) # intercept, chain 2\nbeta2 <- c(mcmc.phiwlp$chain1[,'beta[2]'], # slope, chain 1\n           mcmc.phiwlp$chain2[,'beta[2]']) # slope, chain 2\npredicted_survival <- matrix(NA, \n                             nrow = length(beta1), \n                             ncol = length(my.constants$winglength))\nfor (i in 1:length(beta1)){\n  for (j in 1:length(my.constants$winglength)){\n    predicted_survival[i,j] <- plogis(beta1[i] + \n                               beta2[i] * my.constants$winglength[j])\n  }\n}\nmean_survival <- apply(predicted_survival, 2, mean)\nlci <- apply(predicted_survival, 2, quantile, prob = 2.5/100)\nuci <- apply(predicted_survival, 2, quantile, prob = 97.5/100)\nord <- order(my.constants$winglength)\ndf <- data.frame(wing_length = my.constants$winglength[ord],\n                 survival = mean_survival[ord],\n                 lci = lci[ord],\n                 uci = uci[ord])\ndf %>%\n  ggplot() + \n  aes(x = wing_length, y = survival) + \n  geom_line() + \n  geom_ribbon(aes(ymin = lci, ymax = uci), \n              fill = \"grey70\", \n              alpha = 0.5) + \n  ylim(0,1) + \n  labs(x = \"wing length\", y = \"estimated survival\")"},{"path":"survival.html","id":"several-covariates","chapter":"1 Survival","heading":"1.8.3 Several covariates","text":"may test effect sex wing length. Let’s consider additive effect covariates. use covariate \\(\\text{sex}\\) takes value 0 male, 1 female. \\(\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2 \\text{sex}_i + \\beta_3 \\text{winglength}_i\\) bird \\(\\), male survival \\(\\beta_1 + \\beta_3 \\text{winglength}_i\\) female survival \\(\\beta_1 + \\beta_2 + \\beta_3 \\text{winglength}_i\\) (logit scale). relationship survival wing length parallel males females, logit scale, gap two measured \\(\\beta_2\\) (hence term additive effect).NIMBLE code :put constants data lists:write fuction generate initial values:specify parameters monitored:now run NIMBLE:Let’s display numerical summaries parameters:slope males females. Although posterior mean negative, crebible interval suggest posterior distribution largely encompasses 0, therefore weak signal, .Let’s visualize survival function wing length sexes. First put together values two chains generated posterior distributions regression parameters:get survival estimates MCMC iteration:, may calculate posterior mean credible intervals:Now plot:Note two curves exactly parallel back-transformed linear part relationship survival wing length. may check parallelism occurs logit scale:Show use values covariate de-standardized.Mention interaction bw sex wing length w/ logit(phi[]) <- beta[1] + beta[2] * sex[] + beta[3] * winglength[] + beta[4] * sex[] * winglength[] explain.","code":"\nhmm.phisexwlp <- nimbleCode({\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    logit(phi[i]) <- beta[1] + beta[2] * sex[i] + beta[3] * winglength[i]\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5) # intercept male\n  beta[2] ~ dnorm(mean = 0, sd = 1.5) # difference bw male and female\n  beta[3] ~ dnorm(mean = 0, sd = 1.5) # slope wing length\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nwing.length.st <- as.vector(scale(dipper$wing_length))\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first,\n                     winglength = wing.length.st,\n                     sex = if_else(dipper$sex == \"M\", 0, 1))\nmy.data <- list(y = y + 1)\nzinits <- y\nzinits[zinits == 0] <- 1\ninitial.values <- function() list(beta = rnorm(3,0,2),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"beta\", \"p\")\nmcmc.phisexwlp <- nimbleMCMC(code = hmm.phisexwlp, \n                             constants = my.constants,\n                             data = my.data,              \n                             inits = initial.values,\n                             monitors = parameters.to.save,\n                             niter = n.iter,\n                             nburnin = n.burnin, \n                             nchains = n.chains)\nMCMCsummary(mcmc.phisexwlp, round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.47 0.24 -0.02  0.48  0.94 1.01   102\n## beta[2] -0.43 0.43 -1.28 -0.44  0.46 1.01    85\n## beta[3] -0.19 0.20 -0.60 -0.19  0.22 1.00   106\n## p        0.89 0.03  0.83  0.90  0.94 1.01   643\nbeta1 <- c(mcmc.phisexwlp$chain1[,'beta[1]'], # beta1 chain 1\n           mcmc.phisexwlp$chain2[,'beta[1]']) # beta1 chain 2\nbeta2 <- c(mcmc.phisexwlp$chain1[,'beta[2]'], # beta2 chain 1\n           mcmc.phisexwlp$chain2[,'beta[2]']) # beta2 chain 2\nbeta3 <- c(mcmc.phisexwlp$chain1[,'beta[3]'], # beta3 chain 1\n           mcmc.phisexwlp$chain2[,'beta[3]']) # beta3 chain 2\npredicted_survivalM <- matrix(NA, nrow = length(beta1), \n                              ncol = length(my.constants$winglength))\npredicted_survivalF <- matrix(NA, nrow = length(beta1), \n                              ncol = length(my.constants$winglength))\nfor (i in 1:length(beta1)){\n  for (j in 1:length(my.constants$winglength)){\n    predicted_survivalM[i,j] <- plogis(beta1[i] + \n                                beta3[i] * my.constants$winglength[j]) \n    predicted_survivalF[i,j] <- plogis(beta1[i] + \n                                beta2[i] + \n                                beta3[i] * my.constants$winglength[j])\n  }\n}\nmean_survivalM <- apply(predicted_survivalM, 2, mean)\nlciM <- apply(predicted_survivalM, 2, quantile, prob = 2.5/100)\nuciM <- apply(predicted_survivalM, 2, quantile, prob = 97.5/100)\nmean_survivalF <- apply(predicted_survivalF, 2, mean)\nlciF <- apply(predicted_survivalF, 2, quantile, prob = 2.5/100)\nuciF <- apply(predicted_survivalF, 2, quantile, prob = 97.5/100)\nord <- order(my.constants$winglength)\ndf <- data.frame(wing_length = c(my.constants$winglength[ord], \n                                 my.constants$winglength[ord]),\n                 survival = c(mean_survivalM[ord], \n                              mean_survivalF[ord]),\n                 lci = c(lciM[ord],lciF[ord]),\n                 uci = c(uciM[ord],uciF[ord]),\n                 sex = c(rep(\"male\", length(mean_survivalM)), \n                         rep(\"female\", length(mean_survivalF))))\ndf %>%\n  ggplot() + \n  aes(x = wing_length, y = survival, color = sex) + \n  geom_line() + \n  geom_ribbon(aes(ymin = lci, ymax = uci, fill = sex), alpha = 0.5) + \n  ylim(0,1) + \n  labs(x = \"wing length\", y = \"estimated survival\", color = \"\", fill = \"\")\npredicted_lsurvivalM <- matrix(NA, nrow = length(beta1), \n                              ncol = length(my.constants$winglength))\npredicted_lsurvivalF <- matrix(NA, nrow = length(beta1), \n                              ncol = length(my.constants$winglength))\nfor (i in 1:length(beta1)){\n  for (j in 1:length(my.constants$winglength)){\n    predicted_lsurvivalM[i,j] <- beta1[i] + beta3[i] * my.constants$winglength[j] \n    predicted_lsurvivalF[i,j] <- beta1[i] + beta2[i] + beta3[i] * my.constants$winglength[j]\n  }\n}\nmean_lsurvivalM <- apply(predicted_lsurvivalM, 2, mean)\nmean_lsurvivalF <- apply(predicted_lsurvivalF, 2, mean)\nord <- order(my.constants$winglength)\ndf <- data.frame(wing_length = c(my.constants$winglength[ord], \n                                 my.constants$winglength[ord]),\n                 survival = c(mean_lsurvivalM[ord], \n                              mean_lsurvivalF[ord]),\n                 sex = c(rep(\"male\", length(mean_lsurvivalM)), \n                         rep(\"female\", length(mean_lsurvivalF))))\ndf %>%\n  ggplot() + \n  aes(x = wing_length, y = survival, color = sex) + \n  geom_line() + \n  ylim(-2,2) + \n  labs(x = \"wing length\", \n       y = \"estimated survival (on the lgit scale)\", \n       color = \"\")"},{"path":"survival.html","id":"random-effects","chapter":"1 Survival","heading":"1.8.4 Random effects","text":"individual variation survival fully explained covariates, may add random effects \\(\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2 x_i + \\varepsilon_i\\) \\(\\varepsilon_i \\sim N(0,\\sigma^2)\\). consider individual variation section, reasoning holds temporal variation. essence, treating individual survival probabilities \\(\\phi_i\\) sample population survival probabilities, assume normal distribution mean linear component (without covariate) standard deviation \\(\\sigma\\). variation unexplained covariate \\(x_i\\) measured variation \\(\\sigma\\) residuals \\(\\varepsilon_i\\). Ignoring individual heterogeneity generated individuals contrasted performances life may mask senescence hamper understanding life history trade-offs.Overall, failing incorporate unexplained residual variance may induce bias parameter estimates lead detecting effect covariate often .Let’s go back dipper example wing length covariate, write NIMBLE code:prior standard deviation random effect uniform 0 10. Explain pick prior SD.now write function generating initial values:specify parameters monitored:increase number iterations length burn-period reach better convergence:finally, run NIMBLE:inspect numerical summaries:effective sample size standard deviation random effect low. Let’s try something else. use non-centering reparameterize model. Explain.running NIMBLE, inspect numerical summaries, see effective sample sizes much better:","code":"\nhmm.phiwlrep <- nimbleCode({\n    p ~ dunif(0, 1) # prior detection\n    omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n    omega[1,2] <- p        # Pr(alive t -> detected t)\n    omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i] + eps[i]\n    eps[i] ~ dnorm(mean = 0, sd = sdeps)\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5)\n  beta[2] ~ dnorm(mean = 0, sd = 1.5)\n  sdeps ~ dunif(0, 10)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\ninitial.values <- function() list(beta = rnorm(2,0,1.5),\n                                  sdeps = runif(1,0,3),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"beta\", \"sdeps\", \"p\")\nn.iter <- 10000\nn.burnin <- 5000\nn.chains <- 2\nmcmc.phiwlrep <- nimbleMCMC(code = hmm.phiwlrep, \n                            constants = my.constants,\n                            data = my.data,              \n                            inits = initial.values,\n                            monitors = parameters.to.save,\n                            niter = n.iter,\n                            nburnin = n.burnin, \n                            nchains = n.chains)\nMCMCsummary(mcmc.phiwlrep, round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.22 0.12 -0.02  0.22  0.44 1.24  1335\n## beta[2] -0.01 0.10 -0.20 -0.01  0.19 1.02  1894\n## p        0.90 0.03  0.84  0.90  0.95 1.03   752\n## sdeps    0.27 0.25  0.01  0.16  0.83 4.68    12...\n  for (i in 1:N){\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i] + sdeps * eps[i]\n    eps[i] ~ dnorm(mean = 0, sd = 1)\n...\nMCMCsummary(mcmc.phiwlrep, round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.21 0.12 -0.04  0.21  0.43 1.00  1202\n## beta[2] -0.01 0.10 -0.20 -0.01  0.19 1.00  1789\n## p        0.90 0.03  0.83  0.90  0.95 1.01   790\n## sdeps    0.40 0.26  0.02  0.37  0.95 1.01   170"},{"path":"survival.html","id":"individual-time-varying-covariates","chapter":"1 Survival","heading":"1.8.5 Individual time-varying covariates","text":"far, allowed covariates vary along single dimension, either time individual. need consider covariate varies one animal , time. Think age example, value specific individual, (sadly) changes time.Age particular meaning capture-recapture framework. time elapsed since first encounter, proxy true age, true age. age known first encounter, true age. example, dippers marked young, true biological age bird.convenient thing age missing value age \\(t+1\\) just age \\(t\\) add 1. suggests way code age effect NIMBLE follows:used equals(t, first[]) renders 1 \\(t\\) first encounter 0 otherwise. Therefore distinguish survival first interval first encounter \\(\\phi_1\\) (logit(phi[,t]) <- beta[1] + beta[2]) survival afterwards \\(\\phi_{1+}\\) (logit(phi[,t]) <- beta[1]).put constants list:data list:write function generate initial values:specify parameters monitored:now run NIMBLE:display results:Age time elapsed since first encounter seem effect survival .Another method include age effect create individual time covariate use nested indexing (flood/nonflood example) distinguish survival interval first detection survival afterwards:Now may write NIMBLE code model. just need remember survival longer defined logit scale previous model, use uniform priors:put constants list, including age covariate:re-write function generate initial values:run NIMBLE:display numerical summaries model parameters, acknowledge obtain similar results parameterization:Like mentioned earlier, age easy deal contain missing values. Now think size body mass minute. problem record size body mass animal non-detected. easiest way cope individual time-varying covariates discretize e.g. small, medium large Chapter ??. Another option come model covariate fill missing values simulating model (see case study).","code":"\nhmm.phiage.in <- nimbleCode({\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    for (t in first[i]:(T-1)){\n    # phi1 = beta1 + beta2; phi1+ = beta1\n    logit(phi[i,t]) <- beta[1] + beta[2] * equals(t, first[i]) \n    gamma[1,1,i,t] <- phi[i,t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i,t] <- 1 - phi[i,t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i,t] <- 0             # Pr(dead t -> alive t+1)\n    gamma[2,2,i,t] <- 1             # Pr(dead t -> dead t+1)\n    }\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5) # phi1+\n  beta[2] ~ dnorm(mean = 0, sd = 1.5) # phi1 - phi1+\n  phi1plus <- plogis(beta[1])         # phi1+\n  phi1 <- plogis(beta[1] + beta[2])   # phi1\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first)\nmy.data <- list(y = y + 1)\nzinits <- y\nzinits[zinits == 0] <- 1\ninitial.values <- function() list(beta = rnorm(2,0,5),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"phi1\", \"phi1plus\", \"p\")\nmcmc.phi.age.in <- nimbleMCMC(code = hmm.phiage.in, \n                              constants = my.constants,\n                              data = my.data,              \n                              inits = initial.values,\n                              monitors = parameters.to.save,\n                              niter = n.iter,\n                              nburnin = n.burnin, \n                              nchains = n.chains)\nMCMCsummary(mcmc.phi.age.in, round = 2)##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p        0.89 0.03 0.83 0.90  0.94 1.00   402\n## phi1     0.56 0.03 0.49 0.55  0.63 1.01   689\n## phi1plus 0.57 0.04 0.50 0.57  0.64 1.00   309\nage <- matrix(NA, nrow = nrow(y), ncol = ncol(y) - 1)\nfor (i in 1:nrow(age)){\n  for (j in 1:ncol(age)){\n    if (j == first[i]) age[i,j] <- 1 # age = 1\n    if (j > first[i]) age[i,j] <- 2  # age > 1\n  }\n}\nhmm.phiage.out <- nimbleCode({\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    for (t in first[i]:(T-1)){\n    phi[i,t] <- beta[age[i,t]] # beta1 = phi1, beta2 = phi1+\n    gamma[1,1,i,t] <- phi[i,t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i,t] <- 1 - phi[i,t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i,t] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i,t] <- 1           # Pr(dead t -> dead t+1)\n    }\n  }\n  beta[1] ~ dunif(0, 1) # phi1\n  beta[2] ~ dunif(0, 1) # phi1+\n  phi1 <- beta[1]\n  phi1plus <- beta[2]\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first,\n                     age = age)\nzinits <- y\nzinits[zinits == 0] <- 1\ninitial.values <- function() list(beta = runif(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nmcmc.phi.age.out <- nimbleMCMC(code = hmm.phiage.out, \n                               constants = my.constants,\n                               data = my.data,              \n                               inits = initial.values,\n                               monitors = parameters.to.save,\n                               niter = n.iter,\n                               nburnin = n.burnin, \n                               nchains = n.chains)\nMCMCsummary(mcmc.phi.age.out, round = 2)##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p        0.90 0.03 0.84 0.90  0.95 1.02   438\n## phi1     0.55 0.03 0.48 0.55  0.62 1.00   878\n## phi1plus 0.57 0.04 0.50 0.57  0.64 1.02  1048"},{"path":"survival.html","id":"summary","chapter":"1 Survival","heading":"1.9 Summary","text":"CJS model HMM time-varying parameters account variation due environmental conditions survival sampling effort detection.CJS model HMM time-varying parameters account variation due environmental conditions survival sampling effort detection.Covariates can considered try explain temporal /individual variation survival detection probabilities. needed, random effects can added cope unexplained variation.Covariates can considered try explain temporal /individual variation survival detection probabilities. needed, random effects can added cope unexplained variation.model comparison, WAIC can used evaluate relative predictive performance capture-recapture models.model comparison, WAIC can used evaluate relative predictive performance capture-recapture models.Statistical models rely assumptions, CJS model makes exception. procedures assess goodness fit CJS model capture-recapture data.Statistical models rely assumptions, CJS model makes exception. procedures assess goodness fit CJS model capture-recapture data.","code":""},{"path":"survival.html","id":"suggested-reading","chapter":"1 Survival","heading":"1.10 Suggested reading","text":"Buckland (2016) provides historical perspective CJS model anecdotes. monography Lebreton et al. (1992) must-read better understand CJS model applications. HMM formulation CJS model proposed Gimenez et al. (2007) Royle (2008).Buckland (2016) provides historical perspective CJS model anecdotes. monography Lebreton et al. (1992) must-read better understand CJS model applications. HMM formulation CJS model proposed Gimenez et al. (2007) Royle (2008).Gimenez et al. (2009) deals parameter redundandy capture-recapture models Bayesian framework. exhaustive treatment, see Cole’s excellent book.Gimenez et al. (2009) deals parameter redundandy capture-recapture models Bayesian framework. exhaustive treatment, see Cole’s excellent book.Relative model comparison, warmly recommend McElreath’s book better understand WAIC (video well, see https://www.youtube.com/watch?v=vSjL2Zc-gEQ). paper Gelman et al. 2014 also much helpful.Relative model comparison, warmly recommend McElreath’s book better understand WAIC (video well, see https://www.youtube.com/watch?v=vSjL2Zc-gEQ). paper Gelman et al. 2014 also much helpful.posterior predictive checks, may check Conn et al. 2018. R2ucare package introduced Gimenez et al. 2018.posterior predictive checks, may check Conn et al. 2018. R2ucare package introduced Gimenez et al. 2018.Temporal heterogeneity addressed papers Grosbois et al. 2008 Frederiksen et al. 2014, individual heterogeneity reviewed Gimenez et al. 2018.Temporal heterogeneity addressed papers Grosbois et al. 2008 Frederiksen et al. 2014, individual heterogeneity reviewed Gimenez et al. 2018.","code":""},{"path":"introduction-3.html","id":"introduction-3","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"introduction-4.html","id":"introduction-4","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"take-home-messages.html","id":"take-home-messages","chapter":"Take-home messages","heading":"Take-home messages","text":"–>\n –>–>–>–>","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]

[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"Welcome online version book Bayesian Analysis Capture-Recapture Data Hidden Markov Models – Theory Case Studies R. HMM framework gained much attention ecological literature last decade, suggested general modelling framework demography plant animal populations. particular, HMMs increasingly used analyse capture-recapture data estimate key population parameters (e.g., survival, dispersal, recruitment abundance) applications fields ecology.parallel, Bayesian statistics well established fast growing ecology related disciplines, resonates scientific reasoning allows accommodating uncertainty smoothly. popularity Bayesian statistics also comes availability free pieces software (WinBUGS, OpenBUGS, JAGS, Stan, NIMBLE) allow practitioners code analyses.book offers Bayesian treatment HMMs applied capture-recapture data. learn use R package NIMBLE seen many future Bayesian statistical ecology deal complex models /big data. important part book consists case studies presented tutorial style abide “learning ” philosophy.’m currently writing book, welcome feedback. may raise issue , amend directly R Markdown file generated page ’re reading clicking ‘Edit page’ icon right panel, email . Many thanks!Olivier Gimenez, Montpellier, France\nLast updated: August 09, 2023","code":""},{"path":"index.html","id":"license","chapter":"Welcome","heading":"License","text":"online version book licensed Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.code public domain, licensed Creative Commons CC0 1.0 Universal (CC0 1.0).","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"preface.html","id":"why-this-book","chapter":"Preface","heading":"Why this book?","text":"completed. capture-recapture data models, fields application.1 Brief history capture-recapture, switch state-space/hidden Markov model (HMM) formulation. Flexibility HMM decompose complex problems smaller pieces easier understand, model analyse. satellite guidance conservation endangered species. Bayes? Also three fav research topics – capture-recapture, HMM Bayes statistics – let’s enjoy great cocktail together.","code":""},{"path":"preface.html","id":"who-should-read-this-book","chapter":"Preface","heading":"Who should read this book?","text":"book aimed beginners ’re comfortable using R write basic code (including loops), well connoisseurs capture-recapture ’d like tap power Bayesian side statistics. audiences, thinking HMM framework help confidently building models make capture-recapture data.","code":""},{"path":"preface.html","id":"what-will-you-learn","chapter":"Preface","heading":"What will you learn?","text":"book divided five parts. first part aimed getting --speed Bayesian statistics, NIMBLE, hidden Markov models. second part teach capture-recapture models open populations, reproducible R code ease learning process. third part, focus issues inferring states (dealing uncertainty assignment, modelling waiting time distribution). fourth part provides real-world case studies scientific literature can reproduce using material covered previous chapters. problems can either ) used cement deepen understanding methods models, ii) adapted purpose, iii) serve teaching projects. fifth last chapter closes book take-home messages recommendations, list frequently asked questions references cited book. Likely amended feedbacks.","code":""},{"path":"preface.html","id":"what-wont-you-learn","chapter":"Preface","heading":"What won’t you learn?","text":"hardly maths book. equations use either simple enough understood without background maths, can skipped without prejudice. cover Bayesian statistics even hidden Markov models fully, provide just need work capture-recapture data. interested knowing topics, hopefully section Suggested reading end chapter put right direction. also number important topics specific capture-recapture cover, including closed-population capture-recapture models (Williams, Nichols, Conroy 2002), spatial capture-recapture models (Royle et al. 2013). models can treated HMMs, now usual formulation just fine. spatial considerations Covariates chapter w/ splines CAR. ’m sure yet SCR models (R. Glennie’s Biometrics paper HMMs open pop SCR easy Bayes transform implement NIMBLE).","code":""},{"path":"preface.html","id":"prerequisites","chapter":"Preface","heading":"Prerequisites","text":"book uses primarily R package NIMBLE, need install least R NIMBLE. bunch R packages used. can install running:","code":"\ninstall.packages(c(\n  \"magick\", \"MCMCvis\", \"nimble\", \"pdftools\", \n  \"tidyverse\", \"wesanderson\" \n))"},{"path":"preface.html","id":"acknowledgements","chapter":"Preface","heading":"Acknowledgements","text":"completed.","code":""},{"path":"preface.html","id":"how-this-book-was-written","chapter":"Preface","heading":"How this book was written","text":"writing book RStudio using bookdown. book website hosted GitHub Pages, automatically updated every push Github Actions. source available GitHub.version book ’re reading built R version 4.2.3 (2023-03-15) following packages:","code":""},{"path":"about-the-author.html","id":"about-the-author","chapter":"About the author","heading":"About the author","text":"name Olivier Gimenez (https://oliviergimenez.github.io/). senior (euphemism young anymore) scientist National Centre Scientific Research (CNRS) beautiful city Montpellier, France.struggled studying maths, obtained PhD applied statistics long time ago galaxy wine cheese. awarded habilitation (https://en.wikipedia.org/wiki/Habilitation) ecology evolution stop pretending understand colleagues talking . recently embarked sociology studies hey, .Lost somewhere interface animal ecology, statistical modeling social sciences, -called expertise lies population dynamics species distribution modeling address questions ecology conservation biology impact human activities management large carnivores. nothing without students colleagues kind enough bear .may find Twitter (https://twitter.com/oaggimenez), GitHub (https://github.com/oliviergimenez), get touch email.","code":""},{"path":"introduction.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"introduction-1.html","id":"introduction-1","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"survival.html","id":"survival","chapter":"1 Survival","heading":"1 Survival","text":"WORK PROGRESS.","code":""},{"path":"survival.html","id":"introduction-2","chapter":"1 Survival","heading":"1.1 Introduction","text":"fourth chapter, learn blabla. also see blabla. Blabla.","code":""},{"path":"survival.html","id":"the-cormack-jolly-seber-cjs-model","chapter":"1 Survival","heading":"1.2 The Cormack-Jolly-Seber (CJS) model","text":"S.T. Buckland (2016). Conversation Richard M. Cormack. Statistical Science 31: 142-150.Bayesian uptake.","code":""},{"path":"survival.html","id":"what-weve-seen-so-far","chapter":"1 Survival","heading":"1.2.1 What we’ve seen so far","text":"states (gray), \\(z = 1\\) alive, \\(z = 2\\) dead.observations (white), \\(y = 1\\) non-detected, \\(y = 2\\) detected","code":""},{"path":"survival.html","id":"model","chapter":"1 Survival","heading":"1.2.2 Model","text":"CJS model, survival recapture time-varyingSurvival probability \\(\\phi_t = \\Pr(z_{t+1} = 1 | z_t = 1)\\).Recapture (detection) probability \\(p_t = \\Pr(y_{t} = 1 | z_t = 1)\\).Accounts variation e.g. environmental conditions (survival) sampling effort (detection).","code":""},{"path":"survival.html","id":"capture-mark-and-recapture","chapter":"1 Survival","heading":"1.2.3 Capture, mark and recapture","text":"Artificial marksNatural marks","code":""},{"path":"survival.html","id":"the-famous-dipper-example","chapter":"1 Survival","heading":"1.2.4 The famous Dipper example","text":"\nFigure 1.1: White-throated Dipper (Cinclus cinclus)\n\nFigure 1.2: Gilbert Marzolin\n294 dippers captured recaptured 1981 1987 known sex wing length","code":""},{"path":"survival.html","id":"back-to-nimble.","chapter":"1 Survival","heading":"1.2.5 Back to Nimble.","text":"model far \\((\\phi, p)\\)model far \\((\\phi, p)\\)CJS model \\((\\phi_t, p_t)\\)","code":"\nhmm.phip <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n  # likelihood\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi 0.56 0.03 0.52 0.56  0.62 1.00   500\n## p   0.89 0.03 0.83 0.89  0.94 1.13   273\nhmm.phitpt <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival #\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n    p[t] ~ dunif(0, 1) # prior detection #\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi[1] 0.73 0.14 0.46 0.72  0.99 1.02   199\n## phi[2] 0.45 0.07 0.32 0.44  0.59 1.02   410\n## phi[3] 0.48 0.06 0.35 0.48  0.59 1.01   506\n## phi[4] 0.63 0.06 0.52 0.63  0.75 1.03   415\n## phi[5] 0.60 0.06 0.49 0.60  0.72 1.01   365\n## phi[6] 0.74 0.13 0.51 0.74  0.97 1.10    38\n## p[1]   0.66 0.14 0.38 0.67  0.89 1.01   344\n## p[2]   0.87 0.08 0.68 0.89  0.98 1.02   249\n## p[3]   0.88 0.07 0.73 0.89  0.97 1.02   307\n## p[4]   0.87 0.06 0.74 0.88  0.96 1.05   333\n## p[5]   0.90 0.05 0.77 0.91  0.98 1.01   224\n## p[6]   0.72 0.13 0.50 0.72  0.97 1.08    37"},{"path":"survival.html","id":"derivatives-w-time-variation-on-detection-andor-survival","chapter":"1 Survival","heading":"1.3 Derivatives w/ time variation on detection and/or survival","text":"","code":""},{"path":"survival.html","id":"time-varying-survival-phi_t-p","chapter":"1 Survival","heading":"1.3.1 Time-varying survival \\((\\phi_t, p)\\)","text":"]","code":"\nhmm.phitp <- nimbleCode({\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi[1] 0.63 0.10 0.42 0.63  0.82 1.04   564\n## phi[2] 0.46 0.06 0.35 0.46  0.59 1.01   629\n## phi[3] 0.48 0.05 0.37 0.48  0.59 1.00   610\n## phi[4] 0.62 0.06 0.51 0.62  0.73 1.00   553\n## phi[5] 0.61 0.05 0.50 0.61  0.72 1.00   568\n## phi[6] 0.59 0.05 0.48 0.59  0.69 1.03   463\n## p      0.89 0.03 0.82 0.89  0.95 1.04   211"},{"path":"survival.html","id":"time-varying-detection-phi-p_t","chapter":"1 Survival","heading":"1.3.2 Time-varying detection \\((\\phi, p_t)\\)","text":"","code":"\nhmm.phipt <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})##      mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi  0.56 0.03 0.52 0.56  0.61 1.02   381\n## p[1] 0.75 0.12 0.48 0.77  0.93 1.03   452\n## p[2] 0.85 0.08 0.68 0.86  0.97 1.02   359\n## p[3] 0.85 0.07 0.69 0.85  0.96 1.00   316\n## p[4] 0.89 0.05 0.77 0.89  0.97 1.00   412\n## p[5] 0.91 0.04 0.82 0.92  0.98 1.00   376\n## p[6] 0.90 0.07 0.73 0.91  1.00 1.07   111"},{"path":"survival.html","id":"model-selection-via-waic","chapter":"1 Survival","heading":"1.4 Model selection via WAIC","text":"select best model? Model selectionWhich four models best supported data?four models best supported data?proportion explained variance \\(R^2\\) problematic, variables , bigger \\(R^2\\) .proportion explained variance \\(R^2\\) problematic, variables , bigger \\(R^2\\) .idea penalize models many parameters.idea penalize models many parameters.Akaike information criterion (AIC)\\[AIC = - 2 \\log(L(\\hat{\\theta}_1,\\ldots,\\hat{\\theta}_K)) + 2 K\\]\\(L\\) likelihood \\(K\\) number parameters \\(\\theta_i\\).\\[\\text{AIC} = {\\color{purple}{- 2 \\log(L(\\hat{\\theta}_1,\\ldots,\\hat{\\theta}_K))}} + 2 K\\]measure goodness--fit model data: parameters , smaller deviance (bigger likelihood ).\\[\\text{AIC} = - 2 \\log(L(\\hat{\\theta}_1,\\ldots,\\hat{\\theta}_K)) + {\\color{purple}{2 K}}\\]penalty: twice number parameters \\(K\\)AIC makes balance quality fit complexity model.AIC makes balance quality fit complexity model.Best model one lowest AIC value.Best model one lowest AIC value.Two models difficult distinguish \\(\\Delta \\text{AIC} < 2\\).Two models difficult distinguish \\(\\Delta \\text{AIC} < 2\\).Bayesian versionWatanabe-Akaike (Widely-Applicable) Information Criteria WAIC:\\[\\textrm{WAIC} = -2 \\sum_{= 1}^n \\log E[\\Pr(y_i \\mid \\theta)] +\n                  2 p_\\text{WAIC}\\]\\(E[p(y_i \\mid \\theta)]\\) posterior mean likelihood evaluated pointwise \\(\\)th observation.\\(E[p(y_i \\mid \\theta)]\\) posterior mean likelihood evaluated pointwise \\(\\)th observation.\\(p_\\text{WAIC}\\) penalty computed using posterior variance likelihood.\\(p_\\text{WAIC}\\) penalty computed using posterior variance likelihood.video https://www.youtube.com/watch?v=vSjL2Zc-gEQ R. McElreath.video https://www.youtube.com/watch?v=vSjL2Zc-gEQ R. McElreath.Nimble provides conditional WAIC, parameters directly involved likelihood considered. want calculate marginal WAIC, integrating latent variables, monitor relevant nodes carry calculations based MCMC output.Nimble provides conditional WAIC, parameters directly involved likelihood considered. want calculate marginal WAIC, integrating latent variables, monitor relevant nodes carry calculations based MCMC output.compute WAIC Nimble?Dipper example - continued","code":"\nparameters.to.save <- c(\"phi\", \"p\")\nmcmc.phitpt <- nimbleMCMC(code = hmm.phitpt,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\nparameters.to.save <- c(\"phi\", \"p\", \"z\") #<<\nmcmc.phitpt <- nimbleMCMC(code = hmm.phitpt,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains,\n                          WAIC = TRUE) #<<##       model  WAIC\n## 1   (phi,p) 265.9\n## 2  (phit,p) 277.6\n## 3  (phi,pt) 270.2\n## 4 (phit,pt) 308.8"},{"path":"survival.html","id":"why-bayes-incorporate-prior-information.","chapter":"1 Survival","heading":"1.5 Why Bayes? Incorporate prior information.","text":"","code":""},{"path":"survival.html","id":"vague-prior","chapter":"1 Survival","heading":"1.5.1 Vague prior","text":"far, assumed vague prior:\\[\\phi_{prior} \\sim \\text{Beta}(1,1) = \\text{Uniform}(0,1)\\]vague prior, mean posterior survival \\(\\phi_{posterior} = 0.56\\)credible interval \\([0.52,0.62]\\)Posterior distribution survival color (two chains), prior gray dashed line.","code":""},{"path":"survival.html","id":"how-to-incorporate-prior-information","chapter":"1 Survival","heading":"1.5.2 How to incorporate prior information?","text":"Using information body mass annual survival 27 European passerines, can predict survival European dippers using body mass.dippers, body mass 59.8g, therefore \\(\\phi = 0.57\\) \\(\\text{sd} = 0.073\\).Assuming informative prior \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\).Mean posterior \\(\\phi_{posterior} = 0.56\\) credible interval \\([0.52, 0.61]\\).increase precision posterior inference.","code":""},{"path":"survival.html","id":"how-to-incorporate-prior-information-1","chapter":"1 Survival","heading":"1.5.3 How to incorporate prior information?","text":"Now three first years data, happened?Width credible interval 0.53 (vague prior) vs. 0.24 (informative prior).Huge increase precision posterior inference, \\(120\\%\\) gain!","code":""},{"path":"survival.html","id":"compare-survival-posterior-with-and-without-informative-prior","chapter":"1 Survival","heading":"1.5.3.1 Compare survival posterior with and without informative prior","text":"","code":""},{"path":"survival.html","id":"prior-elicitation-via-moment-matching","chapter":"1 Survival","heading":"1.5.4 Prior elicitation via moment matching","text":"prior \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\) entirely satisfyingRemember Beta distributionRecall Beta distribution continuous distribution values 0 1. Useful modelling survival detection probabilities.\\(X \\sim Beta(\\alpha,\\beta)\\), first second moments \\(X\\) :\\[\\mu = \\text{E}(X) = \\frac{\\alpha}{\\alpha + \\beta}\\]\\[\\sigma^2 = \\text{Var}(X) = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\]","code":""},{"path":"survival.html","id":"moment-matching","chapter":"1 Survival","heading":"1.5.5 Moment matching","text":"capture-recapture example, know priori mean probability ’re interested \\(\\mu = 0.57\\) variance \\(\\sigma^2 = 0.073^2\\). Parameters \\(\\mu\\) \\(\\sigma^2\\) seen moments \\(Beta(\\alpha,\\beta)\\) distribution. Now look values \\(\\alpha\\) \\(\\beta\\) match observed moments Beta distribution \\(\\mu\\) \\(\\sigma^2\\). need another set equations:\\[\\alpha = \\bigg(\\frac{1-\\mu}{\\sigma^2}- \\frac{1}{\\mu} \\bigg)\\mu^2\\]\\[\\beta = \\alpha \\bigg(\\frac{1}{\\mu}-1\\bigg)\\]\nmodel, means:Now use \\(\\phi_{prior} \\sim \\text{Beta}(\\alpha = 25.6,\\beta = 19.3)\\) instead \\(\\phi_{prior} \\sim \\text{Normal}(0.57,0.073^2)\\)","code":"\n(alpha <- ( (1 - 0.57)/(0.073*0.073) - (1/0.57) )*0.57^2)\n## [1] 25.65\n(beta <- alpha * ( (1/0.57) - 1))\n## [1] 19.35"},{"path":"survival.html","id":"capture-recapture-model-assumptions","chapter":"1 Survival","heading":"1.6 Capture-recapture model assumptions","text":"Models rely assumptions.Design: mark lost, Identity individuals recorded without error (false positives), Captured individuals random sampleModel: Homogeneity survival recapture probabilities, Independence individuals (overdispersion)Test validity assumptions: assumptions valid, whatever inferential framework, Use goodness--fit tests — Pradel et al. (2005), R implementation package R2ucare, Posterior predictive checks can also used (covered; Gelman et al. 2020). Forward reference chapter gof model selection.survival actually mean capture-recapture ?Survival refers study area.Mortality permanent emigration confounded.Therefore estimate apparent survival, true survival.Apparent survival probability = true survival × study area fidelity.Consequently, apparent survival < true survival unless study area fidelity = 1.Use caution interpretation. possible, combine ring-recovery data, go spatial get closer true survival.","code":""},{"path":"survival.html","id":"parameter-redundancy-issue","chapter":"1 Survival","heading":"1.7 Parameter-redundancy issue","text":"Last survival recapture probabilities estimated separately.Poor mixing chains.Two issuesIntrinsic redundancy: Likelihood can expressed smaller number parameters; Feature modelExtrinsic redundancy: Model structure fine, lack data makes parameter non-estimable, Feature data.","code":""},{"path":"survival.html","id":"prior-posterior-overlap-for-phi_4-and-phi_6","chapter":"1 Survival","heading":"1.7.1 Prior-posterior overlap for \\(\\phi_4\\) and \\(\\phi_6\\)","text":"","code":""},{"path":"survival.html","id":"prior-posterior-overlap-for-p_3-and-p_7","chapter":"1 Survival","heading":"1.7.2 Prior-posterior overlap for \\(p_3\\) and \\(p_7\\)","text":"","code":""},{"path":"survival.html","id":"covariates","chapter":"1 Survival","heading":"1.8 Covariates","text":"Proportion variance explained. Path analyses, structural equation models. Splines (spatial stats? CAR model?). Imputation multistate models account missing data. Explain basics parametric statistical modeling (linear models, GLMs random effects).Talk ANODEV?","code":""},{"path":"survival.html","id":"can-we-explain-time-variation-embrace-heterogeneity","chapter":"1 Survival","heading":"1.8.1 Can we explain time variation? Embrace heterogeneity","text":"Include temporal covariates, say \\(x_t\\).Include temporal covariates, say \\(x_t\\).\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\).\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\).Let’s investigate effect water flow dipper survival (Marzolin 2002).Let’s investigate effect water flow dipper survival (Marzolin 2002).]Regression intercept slopeTime-dependent (covariate constrained) survival probability estimates","code":"\nhmm.phiflowp <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    logit(phi[t]) <- beta[1] + beta[2] * flow[t] #<<\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  beta[1] ~ dnorm(0, 1.5) # prior intercept #<<\n  beta[2] ~ dnorm(0, 1.5) # prior slope #<<\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\n# water flow in L/s\nwater_flow <- c(443, 1114, 529, 434, 627, 466) # 1981, 1982, ..., 1987\nwater_flow_st <- (water_flow - mean(water_flow))/sd(water_flow) #<<\nmy.constants <- list(N = nrow(y),\n                     T = ncol(y),\n                     first = first,\n                     flow = water_flow_st) #<<\n\ninitial.values <- function() list(beta = rnorm(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\n\nparameters.to.save <- c(\"beta\", \"p\", \"phi\")"},{"path":"survival.html","id":"embrace-heterogeneity","chapter":"1 Survival","heading":"1.8.2 Embrace heterogeneity","text":"Include temporal covariates, say \\(x_t\\)Include temporal covariates, say \\(x_t\\)\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\)\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\)temporal variation fully explained covariates, add random effectsIf temporal variation fully explained covariates, add random effects\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t + \\varepsilon_t, \\; \\varepsilon_t \\sim N(0,\\sigma^2)\\)\\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t + \\varepsilon_t, \\; \\varepsilon_t \\sim N(0,\\sigma^2)\\)","code":"hmm.phiflowREp <- nimbleCode({\n  for (t in 1:(T-1)){\n    logit(phi[t]) <- beta[1] + beta[2] * flow[t] + eps[t]\n    eps[t] ~ dnorm(0, sd = sdeps)\n    ...\n  }\n  sdeps ~ dunif(0,10)\n  ..."},{"path":"survival.html","id":"what-about-individual-heterogeneity","chapter":"1 Survival","heading":"1.8.3 What about individual heterogeneity?","text":"Discrete covariate like, e.g., sexDiscrete covariate like, e.g., sexContinuous covariate like, e.g., mass sizeContinuous covariate like, e.g., mass sizeSex wing length DipperSex effectLet’s use covariate \\(\\text{sex}\\) takes value 0 male, 1 femaleLet’s use covariate \\(\\text{sex}\\) takes value 0 male, 1 femaleAnd write \\(\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2 \\; \\text{sex}_i\\) bird \\(\\)write \\(\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2 \\; \\text{sex}_i\\) bird \\(\\)male survival isThen male survival \\[\\text{logit}(\\phi_i) = \\beta_1\\]female survival \\[\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2\\]Nimble implementation sex covariateNimble implementation nested indexingLet’s use covariate \\(\\text{sex}\\) contains 1s 2s, indicating sex individual: 1 male, 2 femaleE.g. individual \\(= 2\\), beta[sex[]] gives beta[sex[2]] beta[1] beta[2] depending whether sex[2] 1 2.wing length?Wing lengthYou may test effect sex wing length, see exercise Worksheets.","code":"\nhmm.phisexp <- nimbleCode({\n...\n  for (i in 1:N){ #<<\n    logit(phi[i]) <- beta[1] + beta[2] * sex[i] #<<\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1        # Pr(dead t -> dead t+1)\n  } #<<\n  beta[1] ~ dnorm(mean = 0, sd = 1.5) #<<\n  beta[2] ~ dnorm(mean = 0, sd = 1.5) #<<\n  phi_male <- 1/(1+exp(-beta[1])) #<<\n  phi_female <- 1/(1+exp(-(beta[1]+beta[2]))) #<<\n...\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i]) #<<\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})##             mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]     0.29 0.14  0.01  0.29  0.57 1.01   237\n## beta[2]    -0.09 0.19 -0.47 -0.10  0.29 1.01   241\n## p           0.90 0.03  0.83  0.90  0.95 1.02   253\n## phi_female  0.55 0.04  0.48  0.55  0.62 1.02   698\n## phi_male    0.57 0.03  0.50  0.57  0.64 1.01   237\n...\nfor (i in 1:N){\n  phi[i] <- beta[sex[i]] #<<\n  gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n  gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n  gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n  gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n}\nbeta[1] ~ dunif(0,1) # male survival #<<\nbeta[2] ~ dunif(0,1) # female survival #<<\n...##         mean   sd 2.5%  50% 97.5% Rhat n.eff\n## beta[1] 0.57 0.03 0.50 0.57  0.63 1.00   616\n## beta[2] 0.55 0.03 0.48 0.55  0.62 1.02   657\n## p       0.90 0.03 0.83 0.90  0.95 1.10   229\n...\n  for (i in 1:N){ #<<\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i] #<<\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1        # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5) # intercept #<<\n  beta[2] ~ dnorm(mean = 0, sd = 1.5) # slope #<<\n..."},{"path":"survival.html","id":"what-if-covariates-vary-with-individual-and-time","chapter":"1 Survival","heading":"1.8.4 What if covariates vary with individual and time?","text":"Think age example (see exercises Worksheets); covariate nested indexing works fine.Think age example (see exercises Worksheets); covariate nested indexing works fine.Now, think body size across life.Now, think body size across life.Problem record size animal non-detected.Problem record size animal non-detected.Discretize small, medium large treat state — later.Discretize small, medium large treat state — later.Assume model covariate fill missing values (imputation).Assume model covariate fill missing values (imputation).","code":""},{"path":"survival.html","id":"summary","chapter":"1 Survival","heading":"1.9 Summary","text":"Blabla.Blabla.Blabla.Blabla.","code":""},{"path":"survival.html","id":"suggested-reading","chapter":"1 Survival","heading":"1.10 Suggested reading","text":"CJS state-space formulation Gimenez et al. (2007) Royle (2008).CJS state-space formulation Gimenez et al. (2007) Royle (2008).Work missing values Bonner et al. (2006) Langrock King (2013) Worthington et al. (2015).Work missing values Bonner et al. (2006) Langrock King (2013) Worthington et al. (2015).example incorporate prior information McCarthy Masters (2005).example incorporate prior information McCarthy Masters (2005).Combine live recapture w/ dead recoveries Lebreton et al. (1999) go spatial account emigration Gilroy et al. (2012) Schaub & Royle (2014).Combine live recapture w/ dead recoveries Lebreton et al. (1999) go spatial account emigration Gilroy et al. (2012) Schaub & Royle (2014).Non-identifiability Bayesian framework, see Gimenez et al. (2009) book Cole (2020).Non-identifiability Bayesian framework, see Gimenez et al. (2009) book Cole (2020).","code":""},{"path":"dispersal.html","id":"dispersal","chapter":"2 Dispersal","heading":"2 Dispersal","text":"WORK PROGRESS.","code":""},{"path":"uncertainty.html","id":"uncertainty","chapter":"3 State uncertainty","heading":"3 State uncertainty","text":"WORK PROGRESS.","code":""},{"path":"introduction-3.html","id":"introduction-3","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"introduction-4.html","id":"introduction-4","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"take-home-messages.html","id":"take-home-messages","chapter":"Take-home messages","heading":"Take-home messages","text":"–>\n –>–>–>–>","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]

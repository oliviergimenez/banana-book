[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"Welcome online version book Bayesian Analysis Capture-Recapture Data Hidden Markov Models – Theory Case Studies R. HMM framework gained much attention ecological literature last decade, suggested general modelling framework demography plant animal populations. particular, HMMs increasingly used analyse capture-recapture data estimate key population parameters (e.g., survival, dispersal, recruitment abundance) applications fields ecology.parallel, Bayesian statistics well established fast growing ecology related disciplines, resonates scientific reasoning allows accommodating uncertainty smoothly. popularity Bayesian statistics also comes availability free pieces software (WinBUGS, OpenBUGS, JAGS, Stan, NIMBLE) allow practitioners code analyses.book offers Bayesian treatment HMMs applied capture-recapture data. learn use R package NIMBLE seen many future Bayesian statistical ecology deal complex models /big data. important part book consists case studies presented tutorial style abide “learning ” philosophy.’m currently writing book, welcome feedback. may raise issue , amend directly R Markdown file generated page ’re reading clicking ‘Edit page’ icon right panel, email . Many thanks!Olivier Gimenez. Written Montpellier, France Athens, Greece.\nLast updated: August 12, 2023","code":""},{"path":"index.html","id":"license","chapter":"Welcome","heading":"License","text":"online version book licensed Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.code public domain, licensed Creative Commons CC0 1.0 Universal (CC0 1.0).","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"preface.html","id":"why-this-book","chapter":"Preface","heading":"Why this book?","text":"completed. capture-recapture data models, fields application.1 Brief history capture-recapture, switch state-space/hidden Markov model (HMM) formulation. Flexibility HMM decompose complex problems smaller pieces easier understand, model analyse. satellite guidance conservation endangered species. Bayes? Also three fav research topics – capture-recapture, HMM Bayes statistics – let’s enjoy great cocktail together.","code":""},{"path":"preface.html","id":"who-should-read-this-book","chapter":"Preface","heading":"Who should read this book?","text":"book aimed beginners ’re comfortable using R write basic code (including loops), well connoisseurs capture-recapture ’d like tap power Bayesian side statistics. audiences, thinking HMM framework help confidently building models make capture-recapture data.","code":""},{"path":"preface.html","id":"what-will-you-learn","chapter":"Preface","heading":"What will you learn?","text":"book divided five parts. first part aimed getting --speed Bayesian statistics, NIMBLE, hidden Markov models. second part teach capture-recapture models open populations, reproducible R code ease learning process. third part, focus issues inferring states (dealing uncertainty assignment, modelling waiting time distribution). fourth part provides real-world case studies scientific literature can reproduce using material covered previous chapters. problems can either ) used cement deepen understanding methods models, ii) adapted purpose, iii) serve teaching projects. fifth last chapter closes book take-home messages recommendations, list frequently asked questions references cited book. Likely amended feedbacks.","code":""},{"path":"preface.html","id":"what-wont-you-learn","chapter":"Preface","heading":"What won’t you learn?","text":"hardly maths book. equations use either simple enough understood without background maths, can skipped without prejudice. cover Bayesian statistics even hidden Markov models fully, provide just need work capture-recapture data. interested knowing topics, hopefully section Suggested reading end chapter put right direction. also number important topics specific capture-recapture cover, including closed-population capture-recapture models (Williams, Nichols, Conroy 2002), spatial capture-recapture models (Royle et al. 2013). models can treated HMMs, now usual formulation just fine. spatial considerations Covariates chapter w/ splines CAR. ’m sure yet SCR models (R. Glennie’s Biometrics paper HMMs open pop SCR easy Bayes transform implement NIMBLE).","code":""},{"path":"preface.html","id":"prerequisites","chapter":"Preface","heading":"Prerequisites","text":"book uses primarily R package NIMBLE, need install least R NIMBLE. bunch R packages used. can install running:","code":"\ninstall.packages(c(\n  \"magick\", \"MCMCvis\", \"nimble\", \"pdftools\", \n  \"tidyverse\", \"wesanderson\" \n))"},{"path":"preface.html","id":"acknowledgements","chapter":"Preface","heading":"Acknowledgements","text":"completed.","code":""},{"path":"preface.html","id":"how-this-book-was-written","chapter":"Preface","heading":"How this book was written","text":"writing book RStudio using bookdown. book website hosted GitHub Pages, automatically updated every push Github Actions. source available GitHub.version book ’re reading built R version 4.2.3 (2023-03-15) following packages:","code":""},{"path":"about-the-author.html","id":"about-the-author","chapter":"About the author","heading":"About the author","text":"name Olivier Gimenez (https://oliviergimenez.github.io/). senior (euphemism young anymore) scientist National Centre Scientific Research (CNRS) beautiful city Montpellier, France.struggled studying maths, obtained PhD applied statistics long time ago galaxy wine cheese. awarded habilitation (https://en.wikipedia.org/wiki/Habilitation) ecology evolution stop pretending understand colleagues talking . recently embarked sociology studies hey, .Lost somewhere interface animal ecology, statistical modeling social sciences, -called expertise lies population dynamics species distribution modeling address questions ecology conservation biology impact human activities management large carnivores. nothing without students colleagues kind enough bear .may find Twitter (https://twitter.com/oaggimenez), GitHub (https://github.com/oliviergimenez), get touch email.","code":""},{"path":"introduction.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"crashcourse.html","id":"crashcourse","chapter":"1 Bayesian statistics & MCMC","heading":"1 Bayesian statistics & MCMC","text":"","code":""},{"path":"crashcourse.html","id":"introduction-1","chapter":"1 Bayesian statistics & MCMC","heading":"1.1 Introduction","text":"first chapter, learn Bayesian theory , may use simple example. also see implement simulation algorithms implement Bayesian method complex analyses. exhaustive treatment Bayesian statistics, get need navigate rest book.","code":""},{"path":"crashcourse.html","id":"bayes-theorem","chapter":"1 Bayesian statistics & MCMC","heading":"1.2 Bayes’ theorem","text":"Let’s wait longer jump . Bayesian statistics relies Bayes’ theorem (law, rule, whatever prefer) named Reverend Thomas Bayes (Figure 1.1). theorem published 1763 two years Bayes’ death thanks friend’s efforts Richard Price, independently discovered Pierre-Simon Laplace (McGrayne 2011).\nFigure 1.1: Cartoon Thomas Bayes Bayes’ theorem background. Source: James Kulich\nsee minute, Bayes’ theorem conditional probabilities, somehow tricky understand. Conditional probability outcome event given event B, denote \\(\\Pr(\\mid B)\\), probability occurs, revised considering additional information event B occurred.2 order B appear important, make sure confuse \\(\\Pr(\\mid B)\\) \\(\\Pr(B \\mid )\\).Bayes’ theorem (Figure 1.2) gives \\(\\Pr(\\mid B)\\) using marginal probabilities \\(\\Pr()\\) \\(\\Pr(B)\\) \\(\\Pr(B \\mid )\\):\n\\[\\Pr(\\mid B) = \\displaystyle{\\frac{ \\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}}.\\]\nOriginally, Bayes’ theorem seen way infer unkown cause particular effect B, knowing probability effect B given cause . Think example situation medical diagnosis needed, unkown disease B symptoms, doctor knows P(symptoms|disease) wants derive P(disease|symptoms). way reversing \\(\\Pr(B \\mid )\\) \\(\\Pr(\\mid B)\\) explains Bayesian thinking used referred ‘inverse probability’.\nFigure 1.2: Bayes’ theorem spelt blue neon. Source: Wikipedia\ndon’t know , need think twice messing letters around. find easier remember Bayes’ theorem written like this3:great think , exactly scientific method ! ’d like know plausible hypothesis based data collected, possibly compare several hypotheses among . respect, Bayesian reasoning matches scientific reasoning, probably explains Bayesian framework natural understanding statistics.might ask , Bayesian statistics default statistics? Clearly, futile wars male statisticians (including Ronald Fisher, Jerzy Neyman Egon Sharpe Pearson among others), little progress made two centuries. Also, recently, practical problems implement Bayes’ theorem. Recent advances computational power coupled development new algorithms led great increase application Bayesian methods within last three decades.","code":""},{"path":"crashcourse.html","id":"what-is-the-bayesian-approach","chapter":"1 Bayesian statistics & MCMC","heading":"1.3 What is the Bayesian approach?","text":"Typical statistical problems involve estimating parameter (several parameters) \\(\\theta\\) available data. , might used frequentist rather Bayesian method. frequentist approach, particular maximum likelihood estimation (MLE), assumes parameters fixed, unknown values estimated. Therefore classical estimates generally point estimates parameters interest. contrast, Bayesian approach assumes parameters fixed, unknown distribution4.Bayesian approach based upon idea , experimenter, begin prior beliefs system. collect data update prior beliefs basis observations. observations might arise field work, lab work expertise esteemed colleagues. updating process based upon Bayes’ theorem. Loosely, let’s say \\(= \\theta\\) \\(B = \\text{data}\\), Bayes’ theorem gives way estimate parameter \\(\\theta\\) given data :\\[{\\color{red}{\\Pr(\\theta \\mid \\text{data})}} = \\frac{\\color{blue}{\\Pr(\\text{data} \\mid \\theta)} \\times \\color{green}{\\Pr(\\theta)}}{\\color{orange}{\\Pr(\\text{data})}}.\\]\nLet’s spend time going quantity formula.left-hand side \\(\\color{red}{\\text{posterior distribution}}\\). represents know seen data. basis inference clearly ’re , distribution, possibly multivariate one parameter.right-hand side, \\(\\color{blue}{\\text{likelihood}}\\). quantity MLE approach. Yes, Bayesian frequentist approaches likelihood core, mostly explains results often differ much. likelihood captures information data, given model parameterized \\(\\theta\\).\\(\\color{green}{\\text{prior distribution}}\\). quantity represents know seeing data. source much discussion Bayesian approach. may vague don’t know anything \\(\\theta\\). Usually however, never start scratch, ’d like prior reflect information have5.Last, \\(\\color{orange}{\\Pr(\\text{data})}\\) sometimes called average likelihood obtained integrating likelihood respect prior \\(\\color{orange}{\\Pr(\\text{data}) = \\int{L(\\text{data} \\mid \\theta)\\Pr(\\theta) d\\theta}}\\) posterior standardized, integrates one posterior distribution. average likelihood integral dimension number parameters \\(\\theta\\) need estimate. quantity difficult, impossible, calculate general. one reasons Bayesian method wasn’t used recently, need algorithms estimate posterior distributions illustrate next section.","code":""},{"path":"crashcourse.html","id":"numerical-approx","chapter":"1 Bayesian statistics & MCMC","heading":"1.4 Approximating posteriors via numerical integration","text":"Let’s take example illustrate Bayes’ theorem. Say capture, mark release \\(n = 57\\) animals beginning winter, recapture \\(y = 19\\) animals alive6. ’d like estimate winter survival \\(\\theta\\).build model first. Assuming animals independent survival probability, \\(y\\) number alive animals end winter binomial distribution7 \\(n\\) trials \\(\\theta\\) probability success:\\[\\begin{align*}\ny &\\sim \\text{Binomial}(n, \\theta) &\\text{[likelihood]}\n\\end{align*}\\]likelihood can visualised R:\nFigure 1.3: Binomial likelihood \\(n = 57\\) released animals \\(y = 19\\) survivors winter. value survival (x-axis) corresponds maximum likelihood function (y-axis) MLE, proportion success example, close 0.33.\nBesides likelihood, priors another component model Bayesian approach. parameter probability, one thing know prior continuous random variable lies 0 1. reflect , often go uniform distribution \\(U(0,1)\\) imply vague priors. vague means survival , see data, probability falling 0.1 0.2 0.8 0.9, example.\\[\\begin{align*}\n\\theta &\\sim \\text{Uniform}(0, 1) &\\text{[prior }\\theta \\text{]}\n\\end{align*}\\]Now apply Bayes’ theorem. write R function computes product likelihood times prior, numerator Bayes’ theorem: \\(\\Pr(\\text{data} \\mid \\theta) \\times \\Pr(\\theta)\\)write another function calculates denominator, average likelihood: \\(\\Pr(\\text{data}) = \\int{L(\\theta \\mid \\text{data}) \\Pr(\\theta) d\\theta}\\)use R function integrate calculate integral denominator, implements quadrature techniques divide little squares area underneath curve delimited function integrate (numerator), count .get numerical approximation posterior Figure 1.4 applying Bayes’ theorem.\nFigure 1.4: Winter survival posterior distribution obtained numerical integration.\ngood numerical approximation survival posterior distribution? Ideally, want compare approximation true posterior distribution. Although closed-form expression posterior distribution general intractable, combine binomial likelihood together beta distribution prior, posterior distribution also beta distribution, makes amenable sorts exact calculations8. beta distribution continuous 0 1, extends uniform distribution situations outcomes equally likely. two parameters \\(\\) \\(b\\) control shape (Figure 1.5).\nFigure 1.5: distribution beta(\\(\\),\\(b\\)) different values \\(\\) \\(b\\). Note \\(= b = 1\\), get uniform distribution 0 1 top left panel. \\(\\) \\(b\\) equal, distribution symmetric, bigger \\(\\) \\(b\\), peaked distribution smaller variance.\n\nFigure 1.6: Comparison exact (dashed line) vs. numerical approximation (continuous line) winter survival posterior distribution.\nexample, single parameter estimate, winter survival. means dealing one-dimensional integral denominator pretty easy quadrature techniques R function integrate(). Now multiple parameters? example, imagine ’d like fit capture-recapture model detection probability \\(p\\) regression parameters \\(\\alpha\\) \\(\\beta\\) intercept slope relationship survival probability covariate, Bayes’ theorem gives posterior distribution three parameters together:\\[ \\Pr(\\alpha, \\beta, p \\mid \\text{data}) = \\frac{ \\Pr(\\text{data} \\mid \\alpha, \\beta, p) \\times \\Pr(\\alpha, \\beta, p)}{\\iiint \\, \\Pr(\\text{data} \\mid \\alpha, \\beta, p) \\Pr(\\alpha, \\beta, p) d\\alpha d\\beta dp} \\]\ntwo computational challenges formula. First, really wish calculate three-dimensional integral? answer , one-dimensional two-dimensional integrals much can go standard methods. Second, ’re interested posterior distribution parameter separately joint posterior distribution. -called marginal distribution \\(p\\) example obtained integrating parameters – two-dimensional integral example. Now imagine tens hundreds parameters estimate, integrals become highly multi-dimensional simply intractable. next section, introduce powerful simulation methods circumvent issue.","code":"\ny <- 19 # nb of success\nn <- 57 # nb of attempts\ngrid <- seq(0, 1, 0.01) # grid of values for survival\nlikelihood <- dbinom(y, n, grid) # compute binomial likelihood\ndf <- data.frame(survival = grid, likelihood = likelihood) \ndf %>%\n  ggplot() + \n  aes(x = survival, y = likelihood) + \n  geom_line(size = 1.5)\nnumerator <- function(theta) dbinom(y, n, theta) * dunif(theta, 0, 1)\ndenominator <- integrate(numerator,0,1)$value\ngrid <- seq(0, 1, 0.01) # grid of values for theta\nnumerical_posterior <- data.frame(survival = grid, \n                                  posterior = numerator(grid)/denominator) # Bayes' theorem\nnumerical_posterior %>%\n  ggplot() +\n  aes(x = survival, y = posterior) + \n  geom_line(size = 1.5)"},{"path":"crashcourse.html","id":"markov-chain-monte-carlo-mcmc","chapter":"1 Bayesian statistics & MCMC","heading":"1.5 Markov chain Monte Carlo (MCMC)","text":"early 1990s, statisticians rediscovered work 1950’s physics. famous paper lay fundations modern Bayesian statistics (Figure 1.7), authors use simulations approximate posterior distributions precision drawing large samples. neat trick avoid explicit calculation multi-dimensional integrals struggle using Bayes’ theorem.\nFigure 1.7: MCMC article cover. Source: Journal Chemical Physics\nsimulation algorithms called Markov chain Monte Carlo (MCMC), definitely gave boost Bayesian statistics. two parts MCMC, Markov chain Monte Carlo, let’s try make sense terms.","code":""},{"path":"crashcourse.html","id":"monte-carlo-integration","chapter":"1 Bayesian statistics & MCMC","heading":"1.5.1 Monte Carlo integration","text":"Monte Carlo stand ? Monte Carlo integration simulation technique calculate integrals function \\(f\\) random variable \\(X\\) distribution \\(\\Pr(X)\\) say \\(\\int f(X) \\Pr(X)dX\\). draw values \\(X_1,\\ldots,X_k\\) \\(\\Pr(X)\\) distribution \\(X\\), apply function \\(f\\) values, calculate mean new values \\(\\displaystyle{\\frac{1}{k}}\\sum_{=1}^k{f(X_i)}\\) approximate integral. Monte Carlo integration used Bayesian context? posterior distribution contains information need parameter estimated. dealing many parameters however, may want summarise posterior results calculating numerical summaries. simplest numerical summary mean posterior distribution, \\(E(\\theta) = \\int \\theta \\Pr(\\theta|\\text{data})\\), \\(X\\) \\(\\theta\\) now \\(f\\) identity function. Posterior mean can calculated Monte Carlo integration:may check mean just calculated matches closely expectation beta distribution10:Another useful numerical summary credible interval within parameter falls probability, usually 0.95 hence 95\\(\\%\\) credible interval. Finding bounds credible interval requires calculating quantiles, turn involves integrals use Monte Carlo integration. 95\\(\\%\\) credible interval winter survival can obtained R :","code":"\nsample_from_posterior <- rbeta(1000, 20, 39) # draw 1000 values from posterior survival beta(20,39)\nmean(sample_from_posterior) # compute mean with Monte Carlo integration\n## [1] 0.3382\n20/(20+39) # expectation of beta(20,39)\n## [1] 0.339\nquantile(sample_from_posterior, probs = c(2.5/100, 97.5/100))\n##   2.5%  97.5% \n## 0.2308 0.4673"},{"path":"crashcourse.html","id":"markovmodelmcmc","chapter":"1 Bayesian statistics & MCMC","heading":"1.5.2 Markov chains","text":"Markov chain? Markov chain random sequence numbers, number depends previous number. example weather home town Southern France, Montpellier, sunny day likely followed another sunny day, say probability 0.8, rainy day rarely followed another rainy day, say probability 0.1. dynamic Markov chain captured transition matrix \\(\\mathbf{\\Gamma}\\):\n\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    \\text{sunny tomorrow} & \\text{rainy tomorrow} \\\\\n0.8 & 0.2 \\\\\n0.9 & 0.1 \\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\text{sunny today} \\\\ \\text{rainy today}\n    \\end{matrix}\n\\end{matrix}\n\\]\nrows weather today, columns weather tomorrow. cells give probability sunny rainy day tomorrow, given day sunny rainy today. certain conditions11, Markov chain converge unique stationary distribution. weather example, let’s run Markov chain 20 steps:row transition matrix converges distribution \\((0.82, 0.18)\\) number steps increases. Convergence happens matter state start , always probability 0.82 day sunny 0.18 day rainy.Back MCMC, core idea can build Markov chain given stationary distribution set desired posterior distribution.","code":"\nweather <- matrix(c(0.8, 0.2, 0.9, 0.1), nrow = 2, byrow = T) # transition matrix\nsteps <- 20\nfor (i in 1:steps){\n  weather <- weather %*% weather # matrix multiplication\n}\nround(weather, 2) # matrix product after 20 steps\n##      [,1] [,2]\n## [1,] 0.82 0.18\n## [2,] 0.82 0.18"},{"path":"crashcourse.html","id":"metropolis-algorithm","chapter":"1 Bayesian statistics & MCMC","heading":"1.5.3 Metropolis algorithm","text":"several ways constructing Markov chains Bayesian inference12. illustrate Metropolis algorithm implement practice13.Let’s go back example animal survival estimation. illustrate sampling survival posterior distribution. write functions likelihood, prior posterior.Metropolis algorithm works follows:pick value parameter estimated. start Markov chain – starting value.pick value parameter estimated. start Markov chain – starting value.decide go next, propose move away current value parameter – candidate value. , add current value random value e.g. normal distribution variance – proposal distribution. Metropolis algorithm particular case Metropolis-Hastings algorithm symmetric proposals.decide go next, propose move away current value parameter – candidate value. , add current value random value e.g. normal distribution variance – proposal distribution. Metropolis algorithm particular case Metropolis-Hastings algorithm symmetric proposals.compute ratio probabilities candidate current locations \\(R=\\displaystyle{\\frac{{\\Pr(\\text{candidate}|\\text{data})}}{{\\Pr(\\text{current}|\\text{data})}}}\\). magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes’ theorem, appears numerator denominator \\(R\\) therefore cancels need calculated.compute ratio probabilities candidate current locations \\(R=\\displaystyle{\\frac{{\\Pr(\\text{candidate}|\\text{data})}}{{\\Pr(\\text{current}|\\text{data})}}}\\). magic MCMC happens, \\(\\Pr(\\text{data})\\), denominator Bayes’ theorem, appears numerator denominator \\(R\\) therefore cancels need calculated.posterior candidate location \\(\\Pr(\\text{candidate}|\\text{data})\\) higher current location \\(\\Pr(\\text{current}|\\text{data})\\), words candidate value plausible current value, definitely accept candidate value. , accept candidate value probability \\(R\\) reject probability \\(1-R\\). example, candidate value ten times less plausible current value, accept probability 0.1 reject probability 0.9. work practice? use continuous spinner lands somewhere 0 1 – call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location. want accept reject often. practice, Metropolis algorithm acceptance probability 0.2 0.4, can achieved tuning variance normal proposal distribution.posterior candidate location \\(\\Pr(\\text{candidate}|\\text{data})\\) higher current location \\(\\Pr(\\text{current}|\\text{data})\\), words candidate value plausible current value, definitely accept candidate value. , accept candidate value probability \\(R\\) reject probability \\(1-R\\). example, candidate value ten times less plausible current value, accept probability 0.1 reject probability 0.9. work practice? use continuous spinner lands somewhere 0 1 – call random spin \\(X\\). \\(X\\) smaller \\(R\\), move candidate location, otherwise remain current location. want accept reject often. practice, Metropolis algorithm acceptance probability 0.2 0.4, can achieved tuning variance normal proposal distribution.repeat 2-4 number times – steps.repeat 2-4 number times – steps.Enough theory, let’s implement Metropolis algorithm R. Let’s start setting scene.Now follow 5 steps ’ve just described. First, pick starting value, store (step 1)., need function propose candidate value. add value taken normal distribution mean zero standard deviation call away. work logit scale make sure candidate value survival lies 0 1.Now ’re ready steps 2, 3 4. write loop take care step 5. start initial value 0.5 run algorithm 100 steps iterations.get following values.\nFigure 1.8: Visualisation Markov chain starting value 0.5, steps iterations x-axis, samples y-axis. graphical representation called trace plot.\nacceptance probability average number times accepted candidated value, 0.44 almost satisfying.\nFigure 1.9: Trace plot survival two chains starting 0.2 (yellow) 0.5 (blue) run 100 steps.\n\nFigure 1.10: Trace plot survival chain starting 0.5 1000 steps.\n’re , trace plot looks like beautiful lawn, see Section 1.6. find informative look animated version Figure 1.10, helps understanding stochastic behavior algorithm, also realise chains converge stationary distribution, see Figure 1.11.\nFigure 1.11: Animated trace plot survival three chains starting 0.2, 0.5 0.7 run 1000 steps.\nstationary distribution reached, may regard realisations Markov chain sample posterior distribution, obtain numerical summaries. next section, consider several important implementation issues.","code":"\n# 19 animals recaptured alive out of 57 captured, marked and released\nsurvived <- 19\nreleased <- 57\n\n# binomial log-likelihood function\nloglikelihood <- function(x, p){\n  dbinom(x = x, size = released, prob = p, log = TRUE)\n}\n\n# uniform prior density\nlogprior <- function(p){\n  dunif(x = p, min = 0, max = 1, log = TRUE)\n}\n\n# posterior density function (log scale)\nposterior <- function(x, p){\n  loglikelihood(x, p) + logprior(p) # - log(Pr(data))\n}\nsteps <- 100 # number of steps\ntheta.post <- rep(NA, steps) # vector to store samples\naccept <- rep(NA, steps) # keep track of accept/reject\nset.seed(1234) # for reproducibility\ninits <- 0.5\ntheta.post[1] <- inits\naccept[1] <- 1\nmove <- function(x, away = 1){ # by default, standard deviation of the proposal distribution is 1\n  logitx <- log(x / (1 - x)) # apply logit transform (-infinity,+infinity)\n  logit_candidate <- logitx + rnorm(1, 0, away) # add a value taken from N(0,sd=away) to current value\n  candidate <- plogis(logit_candidate) # back-transform (0,1)\n  return(candidate)\n}\nfor (t in 2:steps){ # repeat steps 2-4 (step 5)\n  \n  # propose candidate value for survival (step 2)\n  theta_star <- move(theta.post[t-1])\n  \n  # calculate ratio R (step 3)\n  pstar <- posterior(survived, p = theta_star)  \n  pprev <- posterior(survived, p = theta.post[t-1])\n  logR <- pstar - pprev # likelihood and prior are on the log scale\n  R <- exp(logR)\n  \n  # accept candidate value or keep current value (step 4)\n  X <- runif(1, 0, 1) # spin continuous spinner\n  if (X < R){\n    theta.post[t] <- theta_star # accept candidate value\n    accept[t] <- 1 # accept\n  }\n  else{\n    theta.post[t] <- theta.post[t-1] # keep current value\n    accept[t] <- 0 # reject\n  }\n}\nhead(theta.post) # first values\n## [1] 0.5000 0.2302 0.2906 0.2906 0.2980 0.2980\ntail(theta.post) # last values\n## [1] 0.2622 0.2622 0.2622 0.3727 0.3232 0.3862"},{"path":"crashcourse.html","id":"convergence-diag","chapter":"1 Bayesian statistics & MCMC","heading":"1.6 Assessing convergence","text":"","code":""},{"path":"crashcourse.html","id":"burn-in","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.1 Burn-in","text":"practice, discard observations start Markov chain just use observations chain converged. initial observations discard usually referred burn-.simplest method determine length burn-period look trace plots. Going back example, see trace plot Figure 1.12 need least 100 iterations achieve convergence toward average survival around 0.3. always better conservative specifying length burn-period, example, use 250 even 500 iterations burn-. length burn-period can determined performing preliminary MCMC short runs.\nFigure 1.12: Determining length burn-period. chain starts value 0.99 rapidly stabilises, values bouncing back forth around 0.3 100th iteration onwards. may choose shaded area burn-, discard corresponding values.\nInspecting trace plot single run Markov chain useful. However, usually run Markov chain several times, starting different -dispersed points, check runs achieve stationary distribution. approach formalised using Brooks-Gelman-Rubin (BGR) statistic \\(\\hat{R}\\) measures ratio total variability combining multiple chains (-chain plus within-chain) within-chain variability. BGR statistic asks whether chain effect, much alike \\(F\\) test analysis variance. Values 1.1 indicate likely convergence.Back example, run two Markov chains starting values 0.2 0.8 using 100 5000 iterations, calculate BGR statistic using half number iterations length burn-. Figure 1.13, get value BGR statistic near 1 2000 iterations, suggests 2000 iterations burn-, evidence lack convergence.\nFigure 1.13: Brooks-Gelman-Rubin statistic function number iterations.\nimportant bear mind value near 1 BGR statistic necessary sufficient condition convergence. words, diagnostic tell sure Markov chain achieved convergence, .14","code":""},{"path":"crashcourse.html","id":"chain-length","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.2 Chain length","text":"long chain needed produce reliable parameter estimates? answer question, need keep mind successive steps Markov chain independent – usually referred autocorrelation. Ideally, like keep autocorrelation low possible. , trace plots useful diagnose issues autocorrelation. Let’s get back survival example. Figure 1.14 shows trace plots different values standard deviation (parameter away) (normal) proposal distribution use propose candidate value (Section 1.5.3). Small big moves provide high correlations successive observations Markov chain, whereas standard deviation 1 allows efficient exploration parameter space. movement around parameter space referred mixing. Mixing bad chain makes small big moves, good otherwise.\nFigure 1.14: Trace plots different values standard deviation (SD) proposal distribution. Left: chain exhibits small moves mixing bad. Right: chain exhibits big moves mixing bad. Middle: chain exhibits adequate moves mixing good. thousand last iterations shown.\naddition trace plots, autocorrelation function (ACF) plots convenient way displaying strength autocorrelation given sample values. ACF plots provide autocorrelation successively sampled values separated increasing number iterations, lag (Figure 1.15).\nFigure 1.15: Autocorrelation function plots different values standard deviation (SD) proposal distribution. Left right: Autocorrelation strong, decreases slowly increasing lag mixing bad. Middle: Autocorrelation weak, decreases rapidly increasing lag mixing good.\nAutocorrelation necessarily big issue. Strongly correlated observations just require large sample sizes therefore longer simulations. many iterations exactly? effective sample size (n.eff) measures chain length taking account chain autocorrelation. check n.eff every parameter interest, interesting parameter combinations. general, need \\(\\text{n.eff} \\geq 1000\\) independent steps get reasonable Monte Carlo estimates model parameters. animal survival example, n.eff can calculated R coda::effectiveSize() function.expected, n.eff less number MCMC iterations autocorrelation. standard deviation proposal distribution 1 mixing good (Figures 1.14 1.15) get satisfying effective sample size.","code":""},{"path":"crashcourse.html","id":"what-if-you-have-issues-of-convergence","chapter":"1 Bayesian statistics & MCMC","heading":"1.6.3 What if you have issues of convergence?","text":"diagnosing MCMC convergence, () often run troubles. section find helpful tips hope.mixing bad effective sample size small, may just need increase burn-/sample . Using informative priors might also make Markov chains converge faster helping MCMC sampler (e.g. Metropolis algorithm) navigating efficiently parameter space. spirit, picking better initial values starting chain harm. , strategy consists using estimates simpler model MCMC chains converge.convergence issues persist, often problem model15. bug code? typo somewhere? mistake maths? often coding involved, issue can identified removing complexities, start simpler model find problem .general advice see model data generating tool first place, simulate data using realistic values parameters, try recover parameter values fitting model simulated data. Simulating model help understanding works, , data need get reasonable parameter estimates.see strategies improve convergence next chapters.16","code":""},{"path":"crashcourse.html","id":"summary","chapter":"1 Bayesian statistics & MCMC","heading":"1.7 Summary","text":"Bayes’ theorem, update beliefs (prior) new data (likelihood) get posterior beliefs (posterior): posterior \\(\\propto\\) likelihood \\(\\times\\) prior.Bayes’ theorem, update beliefs (prior) new data (likelihood) get posterior beliefs (posterior): posterior \\(\\propto\\) likelihood \\(\\times\\) prior.idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ’re .idea Markov chain Monte Carlo (MCMC) simulate values Markov chain stationary distribution equal posterior distribution ’re .practice, run Markov chain multiple times starting -dispersed initial values.practice, run Markov chain multiple times starting -dispersed initial values.discard iterations initial burn-phase achieve convergence chains reach regime.discard iterations initial burn-phase achieve convergence chains reach regime., run chains long enough proceed calculating Monte Carlo estimates numerical summaries (e.g. posterior means credible intervals) parameters., run chains long enough proceed calculating Monte Carlo estimates numerical summaries (e.g. posterior means credible intervals) parameters.","code":""},{"path":"crashcourse.html","id":"suggested-reading","chapter":"1 Bayesian statistics & MCMC","heading":"1.8 Suggested reading","text":"Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.Gelman, . Hill, J. (2006). Data Analysis Using Regression Multilevel/Hierarchical Models (Analytical Methods Social Research). Cambridge: Cambridge University Press.Gelman, . colleagues (2020). Bayesian workflow. arXiv preprint.Gelman, . colleagues (2020). Bayesian workflow. arXiv preprint.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McCarthy, M. (2007). Bayesian Methods Ecology. Cambridge: Cambridge University Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press.","code":""},{"path":"intronimble.html","id":"intronimble","chapter":"2 NIMBLE tutorial","heading":"2 NIMBLE tutorial","text":"","code":""},{"path":"intronimble.html","id":"introduction-2","chapter":"2 NIMBLE tutorial","heading":"2.1 Introduction","text":"second chapter, get familiar NIMBLE, R package implements --date MCMC algorithms fitting complex models. NIMBLE spares coding MCMC algorithms hand, requires specification likelihood priors model parameters. illustrate NIMBLE main features simple example, ideas hold problems.","code":""},{"path":"intronimble.html","id":"what-is-nimble","chapter":"2 NIMBLE tutorial","heading":"2.2 What is NIMBLE?","text":"NIMBLE stands Numerical Inference statistical Models using Bayesian Likelihood Estimation. Briefly speaking, NIMBLE R package implements MCMC algorithms generate samples posterior distribution model parameters. Freed burden coding MCMC algorithms, specify likelihood priors apply Bayes theorem. , NIMBLE uses syntax similar R syntax, make life easier. -called BUGS language also used programs like WinBUGS, OpenBUGS, JAGS.use NIMBLE may ask? short answer NIMBLE capable much just running MCMC algorithms! First, work within R, background NIMBLE translate code C++ (general) faster computation. Second, NIMBLE extends BUGS language writing new functions distributions , borrow written others. Third, NIMBLE gives full control MCMC samplers, may pick algorithms defaults. Fourth, NIMBLE comes library numerical methods MCMC algorithms, including sequential Monte Carlo (particle filtering) Monte Carlo Expectation Maximization (maximum likelihood). Last least, development team friendly helpful, based users’ feedbacks, NIMBLE folks work constantly improving package capabilities.\nFigure 2.1: Logo NIMBLE R package designed Luke Larson. Ask Perry context meaning.\n","code":""},{"path":"intronimble.html","id":"start-nimble","chapter":"2 NIMBLE tutorial","heading":"2.3 Getting started","text":"First things first, let’s forget load nimble package:Note can install nimble like R package, Windows users need install Rtools, Mac users need install Xcode. https://r-nimble.org/download.Now let’s go back example animal survival previous chapter. First step build model specifying binomial likelihood uniform prior survival probability theta. use nimbleCode() function wrap code within curly brackets:can check model R object contains code:code , survived released known, theta needs estimated. line survived ~ dbinom(theta, released) states number successes animals survived winter survived distributed (’s ~) binomial released trials probability success survival theta. line theta ~ dunif(0, 1) assigns uniform 0 1 prior distribution survival probability. need, likelihood priors model parameters, NIMBLE knows Bayes theorem. last line lifespan <- - 1/log(theta) calculates quantity derived theta, expected lifespan assuming constant survival17.comments:common distributions available NIMBLE. Among others, use later book dbeta, dmultinom dnorm. find need NIMBLE, can write distribution illustrated Section 2.4.common distributions available NIMBLE. Among others, use later book dbeta, dmultinom dnorm. find need NIMBLE, can write distribution illustrated Section 2.4.matter order write line code, NIMBLE uses called declarative language building models. brief, write code tells NIMBLE want achieve, get . contrast, imperative language requires write want program step step.matter order write line code, NIMBLE uses called declarative language building models. brief, write code tells NIMBLE want achieve, get . contrast, imperative language requires write want program step step.can think models NIMBLE graphs Figure 2.2. graph made relations (edges) can two types. stochastic relation signaled ~ sign defines random variable model, survived theta. deterministic relation signaled <- sign, like lifespan. Relations define nodes left - children - terms nodes right - parents, relations directed edges parents children. graphs called directed acyclic graph DAG.\n\n\nFigure 2.2: Graph animal survival model. Survived stochastic node defined parents released theta, lifespan deterministic node value defined exactly value parent theta.\n\ncan think models NIMBLE graphs Figure 2.2. graph made relations (edges) can two types. stochastic relation signaled ~ sign defines random variable model, survived theta. deterministic relation signaled <- sign, like lifespan. Relations define nodes left - children - terms nodes right - parents, relations directed edges parents children. graphs called directed acyclic graph DAG.\nFigure 2.2: Graph animal survival model. Survived stochastic node defined parents released theta, lifespan deterministic node value defined exactly value parent theta.\nSecond step workflow read data. use list component corresponds known quantity model:can proceed data passed way, know little NIMBLE sees data. NIMBLE distinguishes data constants. Constants values change, e.g. vectors known index values indices used define loops. Data values might want change, basically anything appears left ~. Declaring relevant values constants better computational efficiency, easy forget, fortunately NIMBLE distinguish data constants. use distinction data constants chapter, next chapters become important.Third step tell NIMBLE nodes model like keep track , words quantities ’d like inference . model want survival theta lifespan:general many quantities model, including little interest worth monitoring, full control verbosity prove handy.Fourth step specify initial values model parameters. make sure MCMC algorithm explores posterior distribution, start different chains different parameter values. can specify initial values chain list put yet another list:Alternatively, can write simple R function generates random initial values:Firth last step, need tell NIMBLE number chains run, say n.chain, long burn-period , say n.burnin, number iterations following burn-period used posterior inference. NIMBLE, specify total number iterations, say n.iter, number posterior samples per chain n.iter - n.burnin. NIMBLE also allows discarding samples burn-, procedure known thinning, use book18.now ingredients run model, sample posterior distribution model parameters using MCMC simulations. accomplished using function nimbleMCMC():NIMBLE goes several steps explain Section 2.5. Function nimbleMCMC() takes arguments might find useful. example, can suppress progress bar find depressing running long simulations progressBar = FALSE. can also get summary outputs specifying summary = TRUE. Check ?nimbleMCMC details.Now let’s inspect mcmc.output:R object mcmc.output list three components, one MCMC chain. Let’s look chain1 example:component list matrix. rows, 4000 samples posterior distribution theta, corresponds n.iter - n.burnin iterations. columns, quantities monitor, theta lifespan. , can compute posterior mean theta:can also obtain 95% credible interval theta:Let’s visualise posterior distribution theta histogram:less painful ways posterior inference. book, use R package MCMCvis19 summarise visualize MCMC outputs, perfectly valid options like ggmcmc20 basicMCMCplots21. Shall demonstrate options?Let’s load package MCMCvis:get common numerical summaries, function MCMCsummary() job:can use caterpillar plot visualise posterior distributions theta MCMCplot():point represents posterior median, thick line 50% credible interval thin line 95% credible interval.trace posterior density theta can obtained MCMCtrace():can also add diagnostics convergence discussed previous chapter:calculated lifespan directly model lifespan <- -1/log(theta). can also calculate quantity outside NIMBLE. nice -product using MCMC simulations: can obtain posterior distribution quantity function model parameters applying function samples posterior distribution parameters. example, need samples posterior distribution theta, pool three chains :get samples posterior distribution lifespan, apply function calculate lifespan samples posterior distribution survival:usual , can calculate posterior mean 95% credible interval:can also visualise posterior distribution lifespan:Now ’re good go. convenience summarized steps box . NIMBLE workflow provided nimbleMCMC() allows build models make inference. can achieve software like WinBUGS JAGS.NIMBLE workflow:NIMBLE just another MCMC engine. provides programming environment full control building models estimating parameters. NIMBLE allows write functions distributions build models, choose alternative MCMC samplers code new ones. flexibility often comes faster convergence.honest, learning improvements software takes reading experimentation, might well need use features. ’s fine. next sections, cover advanced material. may skip sections go back material later need .","code":"\nlibrary(nimble)\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n  # derived quantity\n  lifespan <- -1/log(theta)\n})\nmodel\n## {\n##     survived ~ dbinom(theta, released)\n##     theta ~ dunif(0, 1)\n##     lifespan <- -1/log(theta)\n## }\nmy.data <- list(released = 57, survived = 19)\nparameters.to.save <- c(\"theta\", \"lifespan\")\ninit1 <- list(theta = 0.1)\ninit2 <- list(theta = 0.5)\ninit3 <- list(theta = 0.9)\ninitial.values <- list(init1, init2, init3)\ninitial.values\n## [[1]]\n## [[1]]$theta\n## [1] 0.1\n## \n## \n## [[2]]\n## [[2]]$theta\n## [1] 0.5\n## \n## \n## [[3]]\n## [[3]]$theta\n## [1] 0.9\ninitial.values <- function() list(theta = runif(1,0,1))\ninitial.values()\n## $theta\n## [1] 0.8356\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 3\nmcmc.output <- nimbleMCMC(code = model,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nstr(mcmc.output)\n## List of 3\n##  $ chain1: num [1:4000, 1:2] 0.907 0.907 0.907 0.907 0.853 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr [1:2] \"lifespan\" \"theta\"\n##  $ chain2: num [1:4000, 1:2] 0.787 0.894 1.291 1.388 1.388 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr [1:2] \"lifespan\" \"theta\"\n##  $ chain3: num [1:4000, 1:2] 0.745 0.745 0.745 0.886 1.136 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr [1:2] \"lifespan\" \"theta\"\ndim(mcmc.output$chain1)\n## [1] 4000    2\nhead(mcmc.output$chain1)\n##      lifespan  theta\n## [1,]   0.9069 0.3320\n## [2,]   0.9069 0.3320\n## [3,]   0.9069 0.3320\n## [4,]   0.9069 0.3320\n## [5,]   0.8526 0.3095\n## [6,]   0.7987 0.2859\nmean(mcmc.output$chain1[,'theta'])\n## [1] 0.3407\nquantile(mcmc.output$chain1[,'theta'], probs = c(2.5, 97.5)/100)\n##   2.5%  97.5% \n## 0.2219 0.4620\nmcmc.output %>%\n  as_tibble() %>%\n  ggplot() +\n  geom_histogram(aes(x = chain1[,\"theta\"]), color = \"white\") +\n  labs(x = \"survival probability\")\nlibrary(MCMCvis)\nMCMCsummary(object = mcmc.output, round = 2)\n##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## lifespan 0.94 0.17 0.66 0.92  1.32    1  2513\n## theta    0.34 0.06 0.22 0.34  0.47    1  2533\nMCMCplot(object = mcmc.output, \n         params = 'theta')\nMCMCtrace(object = mcmc.output,\n          pdf = FALSE, # no export to PDF\n          ind = TRUE, # separate density lines per chain\n          params = \"theta\")\nMCMCtrace(object = mcmc.output,\n          pdf = FALSE,\n          ind = TRUE,\n          Rhat = TRUE, # add Rhat\n          n.eff = TRUE, # add eff sample size\n          params = \"theta\")\ntheta_samples <- c(mcmc.output$chain1[,'theta'], \n                   mcmc.output$chain2[,'theta'],\n                   mcmc.output$chain3[,'theta'])\nlifespan <- -1/log(theta_samples)\nmean(lifespan)\n## [1] 0.9398\nquantile(lifespan, probs = c(2.5, 97.5)/100)\n##   2.5%  97.5% \n## 0.6629 1.3194\nlifespan %>%\n  as_tibble() %>%\n  ggplot() +\n  geom_histogram(aes(x = value), color = \"white\") +\n  labs(x = \"lifespan\")\n# model building\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n  # derived quantity\n  lifespan <- -1/log(theta)\n})\n# read in data\nmy.data <- list(released = 57, survived = 19)\n# specify parameters to monitor\nparameters.to.save <- c(\"theta\", \"lifespan\")\n# pick initial values\ninitial.values <- function() list(theta = runif(1,0,1))\n# specify MCMC details\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 3\n# run NIMBLE\nmcmc.output <- nimbleMCMC(code = model,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n# calculate numerical summaries\nMCMCsummary(object = mcmc.output, round = 2)\n# visualize parameter posterior distribution\nMCMCplot(object = mcmc.output, \n         params = 'theta')\n# check convergence\nMCMCtrace(object = mcmc.output,\n          pdf = FALSE, # no export to PDF\n          ind = TRUE, # separate density lines per chain\n          params = \"theta\")"},{"path":"intronimble.html","id":"functions-in-nimble","chapter":"2 NIMBLE tutorial","heading":"2.4 Programming","text":"NIMBLE can write use functions, use existing R C/C++ functions. allows customize models way want.","code":""},{"path":"intronimble.html","id":"nimble-functions","chapter":"2 NIMBLE tutorial","heading":"2.4.1 NIMBLE functions","text":"NIMBLE provides nimbleFunctions programming. nimbleFunction like R function, plus can compiled faster computation. Going back animal survival example, can write nimbleFunction compute lifespan:Within nimbleFunction, run section gives function executed. written NIMBLE language. theta = double(0) returnType(double(0)) arguments tell NIMBLE input output single numeric values (scalars). Alternatively, double(1) double(2) vectors matrices, logical(), integer() character() logical, integer character values.can use nimbleFunction R:can compile use C++ code faster computation:can also use nimbleFunction model:rest workflow remains :nimbleFunctions, can mimic basic R syntax, linear algebra (e.g. compute eigenvalues), operate vectors matrices (e.g. inverse matrix), use logical operators (e.g. /) flow control (e.g. -else). also long list common less common distributions can used nimbleFunctions.learn everything need know writing nimbleFunctions, make sure read chapter 11 NIMBLE manual https://r-nimble.org/html_manual/cha-RCfunctions.html#cha-RCfunctions.","code":"\ncomputeLifespan <- nimbleFunction(\n    run = function(theta = double(0)) { # type declarations\n        ans <- -1/log(theta)\n        return(ans)\n        returnType(double(0))  # return type declaration\n    } )\ncomputeLifespan(0.8)\n## [1] 4.481\nCcomputeLifespan <- compileNimble(computeLifespan)\nCcomputeLifespan(0.8)\n## [1] 4.481\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n  # derived quantity\n  lifespan <- computeLifespan(theta)\n})\nmy.data <- list(survived = 19, released = 57)\nparameters.to.save <- c(\"theta\", \"lifespan\")\ninitial.values <- function() list(theta = runif(1,0,1))\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 3\nmcmc.output <- nimbleMCMC(code = model,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nMCMCsummary(object = mcmc.output, round = 2)\n##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## lifespan 0.94 0.16 0.66 0.92  1.31    1  2593\n## theta    0.34 0.06 0.22 0.34  0.47    1  2652"},{"path":"intronimble.html","id":"callrfninnimble","chapter":"2 NIMBLE tutorial","heading":"2.4.2 Calling R/C++ functions","text":"’re like , lazy write functions, can rely scientific community use existing C, C++ R code. trick write nimbleFunction wraps access code can used NIMBLE. example, imagine ’d like use R function myfunction(), either function wrote , function available favorite R package:Now wrap function using nimbleRcall() nimbleExternalCall() C C++ function:call nimbleRcall() , argument prototype specifies inputs (single numeric value double(0)) R function Rfun generates outputs returnType (single numeric value double(0)).Now can call R function model (nimbleFunctions):rest workflow remains :Evaluating R function within NIMBLE slows MCMC sampling , can live , cost easily offset convenience able use existing R functions.Another advantage using nimbleRcall() (nimbleExternalCall()) can keep large objects model, NIMBLE handle MCMC sampling. objects constants change run NIMBLE. Letting R manipulating objects save time, usually time lose calling R within NIMBLE.","code":"\nmyfunction <- function(x) {\n  -1/log(x)\n}\nRmyfunction <- nimbleRcall(prototype = function(x = double(0)){}, \n                           Rfun = 'myfunction',\n                           returnType = double(0))\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n  lifespan <- Rmyfunction(theta)\n})\nmy.data <- list(survived = 19, released = 57)\nparameters.to.save <- c(\"theta\", \"lifespan\")\ninitial.values <- function() list(theta = runif(1,0,1))\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 3\nmcmc.output <- nimbleMCMC(code = model,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nMCMCsummary(object = mcmc.output, round = 2)\n##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## lifespan 0.94 0.16 0.68 0.92  1.29    1  2597\n## theta    0.34 0.06 0.23 0.34  0.46    1  2643"},{"path":"intronimble.html","id":"user-defined-distributions","chapter":"2 NIMBLE tutorial","heading":"2.4.3 User-defined distributions","text":"nimbleFunctions can provide user-defined distributions NIMBLE. need write functions density (d) simulation (r) distribution. example, write binomial distribution:need define nimbleFunctions R’s global environment accessed:can try function simulate random value binomial distribution size 5 probability 0.1:set. can run workflow:nimbleFunctions offers infinite possibilities customize models algorithms. Besides covered already, can write samplers. see example minute, first need tell NIMBLE workflow.","code":"\n# density\ndmybinom <- nimbleFunction(\n  run = function(x = double(0), \n                 size = double(0), \n                 prob = double(0), \n                 log = integer(0, default = 1)) {\n    returnType(double(0))\n    # compute binomial coefficient \n    lchoose <- lfactorial(size) - lfactorial(x) - lfactorial(size - x)\n    # binomial density function\n    logProb <- lchoose + x * log(prob) + (size - x) * log(1 - prob)\n    if(log) return(logProb)\n    else return(exp(logProb)) \n  })\n# simulation using the coin flip method (p. 524 in Devroye 1986)\nrmybinom <- nimbleFunction(\n  run = function(n = integer(0, default = 1),\n                 size = double(0),\n                 prob = double(0)) {\n    returnType(double(0))\n    x <- 0\n    y <- runif(n = size, min = 0, max = 1)\n    for (j in 1:size){\n      if (y[j] < prob){\n        x <- x + 1\n      }else{\n        x <- x\n      }\n    }\n    return(x)    \n  })\nassign('dmybinom', dmybinom, .GlobalEnv)\nassign('rmybinom', rmybinom, .GlobalEnv)\nrmybinom(n = 1, size = 5, prob = 0.1)\n## [1] 0\nmodel <- nimbleCode({\n # likelihood\n survived ~ dmybinom(prob = theta, size = released)\n # prior\n theta ~ dunif(0, 1)\n})\nmy.data <- list(released = 57, survived = 19)\ninitial.values <- function() list(theta = runif(1,0,1))\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 3\nmcmc.output <- nimbleMCMC(code = model,\n data = my.data,\n inits = initial.values,\n niter = n.iter,\n nburnin = n.burnin,\n nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nMCMCsummary(mcmc.output)\n##       mean      sd   2.5%    50%  97.5% Rhat n.eff\n## theta 0.34 0.05976 0.2286 0.3378 0.4598    1  2970"},{"path":"intronimble.html","id":"under-the-hood","chapter":"2 NIMBLE tutorial","heading":"2.5 Under the hood","text":"far, used nimbleMCMC() runs default MCMC workflow. perfecly fine applications. However, situations need customize MCMC samplers improve fasten convergence. NIMBLE allows look hood using detailed workflow several steps: nimbleModel(), configureMCMC(), buildMCMC(), compileNimble() runMCMC(). Note nimbleMCMC() .write model code, read data pick initial values :First step create model R object (uncompiled model) nimbleModel():can look nodes:can look values stored node:can also calculate log-likelihood initial value theta:ability NIMBLE access nodes model evaluate model likelihood can help identifying bugs code. Give example? Provide negative initial value theta, released data < survived.can obtain graph model Figure 2.2 :Second compile model compileNimble():compileNimble(), C++ code generated, compiled loaded back R can used R (compiled model):Now two versions model, survival R Csurvival C++. able separate steps model building parameter estimation strength NIMBLE. gives lot flexibility steps. example, imagine like fit model maximum likelihood, can wrapping model R function gets likelihood maximise function. Using C version model, can write:maximising likelihood (minimising negative log-likelihood), obtain maximum likelihood estimate animal survival, exactly 19 surviving animals 57 released animals 0.33.Third create MCMC configuration model configureMCMC():steps tells nodes monitored default, MCMC samplers assigned . theta monitored, samples posterior distribution simulated random walk sampler similar Metropolis sampler coded previous chapter Section 1.5.3.monitor lifespan addition theta, write:Third, create MCMC function buildMCMC() compile compileNimble():Note models nimbleFunctions need compiled can used specify project.Fourth, run NIMBLE runMCMC():run single chain runMCMC() allows use multiple chains nimbleMCMC().can look samples contains values simulated posterior distribution parameters monitor:, can obtain numerical summaries samplesSummary():summarized steps box .Detailed NIMBLE workflow:first glance, using several steps instead nimbleMCMC() seems odds. useful? Mastering whole sequence steps allows play around samplers, changing samplers NIMBLE picks default, even writing samplers.","code":"\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n  # derived quantity\n  lifespan <- -1/log(theta)\n})\nmy.data <- list(survived = 19, released = 57)\ninitial.values <- list(theta = 0.5)\nsurvival <- nimbleModel(code = model,\n                        data = my.data,\n                        inits = initial.values)\nsurvival$getNodeNames()\n## [1] \"theta\"    \"lifespan\" \"survived\"\nsurvival$theta\n## [1] 0.5\nsurvival$survived\n## [1] 19\nsurvival$lifespan \n## [1] 1.443\n# this is -1/log(0.5)\nsurvival$calculate()\n## [1] -5.422\n# this is dbinom(x = 19, size = 57, prob = 0.5, log = TRUE)\nsurvival$plotGraph()\nCsurvival <- compileNimble(survival)\nCsurvival$theta\n## [1] 0.5\n# function for negative log-likelihood to minimize\nf <- function(par) {\n    Csurvival[['theta']] <- par # assign par to theta \n    ll <- Csurvival$calculate() # update log-likelihood with par value\n    return(-ll) # return negative log-likelihood\n}\n# evaluate function at 0.5 and 0.9\nf(0.5)\n## [1] 5.422\nf(0.9)\n## [1] 55.41\n# minimize function\nout <- optimize(f, interval = c(0,1))\nround(out$minimum, 2)\n## [1] 0.33\nsurvivalConf <- configureMCMC(survival)\n## ===== Monitors =====\n## thin = 1: theta\n## ===== Samplers =====\n## RW sampler (1)\n##   - theta\nsurvivalConf$addMonitors(c(\"lifespan\"))\n## thin = 1: lifespan, theta\nsurvivalConf\n## ===== Monitors =====\n## thin = 1: lifespan, theta\n## ===== Samplers =====\n## RW sampler (1)\n##   - theta\nsurvivalMCMC <- buildMCMC(survivalConf)\nCsurvivalMCMC <- compileNimble(survivalMCMC, project = survival)\nn.iter <- 5000\nn.burnin <- 1000\nsamples <- runMCMC(mcmc = CsurvivalMCMC, \n                   niter = n.iter,\n                   nburnin = n.burnin)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nhead(samples)\n##      lifespan  theta\n## [1,]   0.9093 0.3330\n## [2,]   0.9093 0.3330\n## [3,]   0.9093 0.3330\n## [4,]   1.2095 0.4374\n## [5,]   1.2095 0.4374\n## [6,]   1.1835 0.4296\nsamplesSummary(samples)\n##            Mean Median St.Dev. 95%CI_low 95%CI_upp\n## lifespan 0.9357 0.9194 0.16117    0.6831    1.2969\n## theta    0.3386 0.3370 0.06128    0.2313    0.4625\n# model building\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n  # derived quantity\n  lifespan <- -1/log(theta)\n})\n# read in data\nmy.data <- list(released = 57, survived = 19)\n# pick initial values\ninitial.values <- function() list(theta = runif(1,0,1))\n# create model as an R object (uncompiled model)\nsurvival <- nimbleModel(code = model,\n                        data = my.data,\n                        inits = initial.values())\n# compile model\nCsurvival <- compileNimble(survival)\n# create a MCMC configuration\nsurvivalConf <- configureMCMC(survival)\n# add lifespan to list of parameters to monitor\nsurvivalConf$addMonitors(c(\"lifespan\"))\n# create a MCMC function and compile it\nsurvivalMCMC <- buildMCMC(survivalConf)\nCsurvivalMCMC <- compileNimble(survivalMCMC, project = survival)\n# specify MCMC details\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\n# run NIMBLE\nsamples <- runMCMC(mcmc = CsurvivalMCMC, \n                   niter = n.iter,\n                   nburnin = n.burnin,\n                   nchain = n.chains)\n# calculate numerical summaries\nMCMCsummary(object = samples, round = 2)\n# visualize parameter posterior distribution\nMCMCplot(object = samples, \n         params = 'theta')\n# check convergence\nMCMCtrace(object = samples,\n          pdf = FALSE, # no export to PDF\n          ind = TRUE, # separate density lines per chain\n          params = \"theta\")"},{"path":"intronimble.html","id":"mcmc-samplers","chapter":"2 NIMBLE tutorial","heading":"2.6 MCMC samplers","text":"","code":""},{"path":"intronimble.html","id":"change-sampler","chapter":"2 NIMBLE tutorial","heading":"2.6.1 Default samplers","text":"default sampler used NIMBLE example? can answer question inspecting MCMC configuration obtained configureMCMC():Now control MCMC configuration, let’s mess . start removing default sampler:change slice sampler:Now can resume workflow:NIMBLE implements many samplers, list available ?samplers. example, high correlation (regression) parameters can make independent samplers inefficient. situation, block sampling might help consists proposing candidate values multivariate distribution acknowledges correlation parameters. Say something default samplers chosen NIMBLE?","code":"\n#survivalConf <- configureMCMC(survival)\nsurvivalConf$printSamplers()\n## [1] RW sampler: theta\nsurvivalConf$removeSamplers(c('theta'))\nsurvivalConf$printSamplers()\nsurvivalConf$addSampler(target = c('theta'),\n                        type = 'slice')\nsurvivalConf$printSamplers()\n## [1] slice sampler: theta\n# create a new MCMC function and compile it:\nsurvivalMCMC2 <- buildMCMC(survivalConf)\nCsurvivalMCMC2 <- compileNimble(survivalMCMC2, \n                                project = survival,\n                                resetFunctions = TRUE) # to compile new functions \n                                                       # into existing project, \n                                                       # need to reset nimbleFunctions\n# run NIMBLE:\nsamples2 <- runMCMC(mcmc = CsurvivalMCMC2, \n                    niter = n.iter,\n                    nburnin = n.burnin)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n# obtain numerical summaries:\nsamplesSummary(samples2)\n##            Mean Median St.Dev. 95%CI_low 95%CI_upp\n## lifespan 0.9357 0.9231 0.16002    0.6645    1.2826\n## theta    0.3387 0.3385 0.06098    0.2221    0.4586"},{"path":"intronimble.html","id":"user-defined-samplers","chapter":"2 NIMBLE tutorial","heading":"2.6.2 User-defined samplers","text":"Allowing code sampler another topic NIMBLE thrives. example, focus Metropolis algorithm Section 1.5.3 coded R. section, make nimbleFunction can use within model:Compared nimbleFunctions wrote earlier, my_metropolis() contains setup function ) gets dependencies parameter update run function Metropolis, target node, theta example ii) extracts control parameters, scale standard deviation proposal distribution example. run function implements steps Metropolis algorithm: (1) get log-likelihood function evaluated current value, (2) get current value, (3) apply logit transform , (4) propose candidate value perturbing current value normal noise controled standard deviation scale, (5) back-transform candidate value (6) plug model, (7) calculate log-likelihood function candidate value, (8) compute Metropolis ratio log scale, (9) compare output spinner Metropolis ratio decide whether (10) accept candidate value copy model mvSaved (11) reject keep current value copying mvSaved model. nimbleFunction used MCMC sampler, several constraints need respected like contains = sampler_BASE statement using four arguments model, mvSaved, target control setup function. course, NIMBLE implements advanced efficient version Metropolis algorithm, can look https://github.com/cran/nimble/blob/master/R/MCMC_samplers.R#L184.Now user-defined MCMC algorithm, can change default sampler new sampler Section 2.6.1. start scratch:print samplers used default, remove default sampler theta, replace my_metropolis() sampler standard deviation proposal distribution set 0.1, print make sure NIMBLE now uses new sampler:rest workflow unchanged:\nFigure 2.3: Trace plots different values standard deviation (scale) proposal distribution.\n","code":"\nmy_metropolis <- nimbleFunction(\n  name = 'my_metropolis', # fancy name for our MCMC sampler\n  contains = sampler_BASE,\n  setup = function(model, mvSaved, target, control) {\n    # i) get dependencies for 'target' in 'model'\n    calcNodes <- model$getDependencies(target) \n    # ii) get sd of proposal distribution\n    scale <- control$scale \n  },\n  run = function() {\n    # (1) log-lik at current value\n    initialLP <- model$getLogProb(calcNodes) \n    # (2) current parameter value\n    current <- model[[target]] \n    # (3) logit transform\n    lcurrent <- log(current / (1 - current))\n    # (4) propose candidate value\n    lproposal <- lcurrent  + rnorm(1, mean = 0, scale) \n    # (5) back-transform\n    proposal <- plogis(lproposal)\n    # (6) plug candidate value in model \n    model[[target]] <<- proposal \n    # (7) log-lik at candidate value\n    proposalLP <- model$calculate(calcNodes)\n    # (8) compute lik ratio on log scale\n    lMHR <- proposalLP - initialLP \n    # (9) spin continuous spinner and compare to ratio\n    if(runif(1,0,1) < exp(lMHR)) { \n      # (10) if candidate value is accepted, update current value\n      copy(from = model, to = mvSaved, nodes = calcNodes, logProb = TRUE, row = 1)\n    } else {\n      ## (11) if candidate value is accepted, keep current value\n      copy(from = mvSaved, to = model, nodes = calcNodes, logProb = TRUE, row = 1)\n    }\n  },\n  methods = list(\n    reset = function() {}\n  )\n)\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n})\nmy.data <- list(survived = 19, released = 57)\ninitial.values <- function() list(theta = runif(1,0,1))\nsurvival <- nimbleModel(code = model, \n                        data = my.data, \n                        inits = initial.values())\nCsurvival <- compileNimble(survival)\nsurvivalConf <- configureMCMC(survival)\n## ===== Monitors =====\n## thin = 1: theta\n## ===== Samplers =====\n## RW sampler (1)\n##   - theta\nsurvivalConf$printSamplers()\n## [1] RW sampler: theta\nsurvivalConf$removeSamplers(c('theta'))\nsurvivalConf$addSampler(target = 'theta', \n                        type = 'my_metropolis', \n                        control = list(scale = 0.1)) # standard deviation\n                                                     # of proposal distribution\nsurvivalConf$printSamplers()\n## [1] my_metropolis sampler: theta,  scale: 0.10000000000000001\nsurvivalMCMC <- buildMCMC(survivalConf)\nCsurvivalMCMC <- compileNimble(survivalMCMC, \n                               project = survival)\nsamples <- runMCMC(mcmc = CsurvivalMCMC, \n                   niter = 5000, \n                   nburnin = 1000)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nsamplesSummary(samples)\n##        Mean Median St.Dev. 95%CI_low 95%CI_upp\n## theta 0.339 0.3377 0.05592    0.2374    0.4528"},{"path":"intronimble.html","id":"tips-and-tricks","chapter":"2 NIMBLE tutorial","heading":"2.7 Tips and tricks","text":"closing chapter NIMBLE, thought ’d useful section gathering tips tricks make life easier. tips tricks, NIMBLE users, ’d happy hear : email , edit chapter file issue GitHub.","code":""},{"path":"intronimble.html","id":"precision-vs-standard-deviation","chapter":"2 NIMBLE tutorial","heading":"2.7.1 Precision vs standard deviation","text":"sotware like JAGS, normal distribution parameterized mean mu parameter called precision, often denoted tau, inverse variance used . Say use normal prior parameter epsilon epsilon ~ dnorm(mu, tau). ’d like prior vague, therefore tau small, say 0.01 variance normal distribution large, 1/0.01 = 100 . subtlety source problems (frustration) forget second parameter precision use epsilon ~ dnorm(mu, 100), variance actually 1/100 = 0.01 prior informative, peaked mu. NIMBLE can use parameterisation well natural parameterisation epsilon ~ dnorm(mu, sd = 100) avoids confusion.","code":""},{"path":"intronimble.html","id":"indexing","chapter":"2 NIMBLE tutorial","heading":"2.7.2 Indexing","text":"NIMBLE guess dimensions objects. software like JAGS can write sum.x <- sum(x[]) calculate sum components x. NIMBLE need write sum.x <- sum(x[1:n]) sum components x 1 n. Specifying dimensions can annoying, find useful forces think keep code self-explaining.","code":""},{"path":"intronimble.html","id":"faster-compilation","chapter":"2 NIMBLE tutorial","heading":"2.7.3 Faster compilation","text":"might noticed compilation NIMBLE takes time. large models (lots nodes), compilation can take forever. can set calculate = FALSE nimbleModel() disable calculation deterministic nodes log-likelihood. can also use useConjugacy = FALSE configureMCMC() disable search conjugate samplers. animal survival example, :","code":"\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n})\nmy.data <- list(survived = 19, released = 57)\ninitial.values <- function() list(theta = runif(1,0,1))\nsurvival <- nimbleModel(code = model, \n                        data = my.data, \n                        inits = initial.values(),\n                        calculate = FALSE) # first tip\nCsurvival <- compileNimble(survival)\nsurvivalConf <- configureMCMC(survival)\n## ===== Monitors =====\n## thin = 1: theta\n## ===== Samplers =====\n## RW sampler (1)\n##   - theta\nsurvivalMCMC <- buildMCMC(survivalConf, useConjugacy = FALSE) # second tip\nCsurvivalMCMC <- compileNimble(survivalMCMC, \n                               project = survival)\nsamples <- runMCMC(mcmc = CsurvivalMCMC, \n                   niter = 5000, \n                   nburnin = 1000)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nsamplesSummary(samples)\n##         Mean Median St.Dev. 95%CI_low 95%CI_upp\n## theta 0.3402 0.3391 0.06029    0.2258    0.4616"},{"path":"intronimble.html","id":"updating-mcmc-chains","chapter":"2 NIMBLE tutorial","heading":"2.7.4 Updating MCMC chains","text":"Sometimes useful run MCMC chains little bit longer improve convergence. Re-starting run previous section, can use:can extract matrix previous MCMC samples augmented new ones obtain numerical summaries:can check more_samples contains 10000 samples, 4000 call runMCMC() plus 6000 additional samples.","code":"\nniter_ad <- 6000\nCsurvivalMCMC$run(niter_ad, reset = FALSE)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## NULL\nmore_samples <- as.matrix(CsurvivalMCMC$mvSamples)\nsamplesSummary(more_samples)\n##         Mean Median St.Dev. 95%CI_low 95%CI_upp\n## theta 0.3402 0.3382 0.05975    0.2281    0.4632"},{"path":"intronimble.html","id":"reproducibility","chapter":"2 NIMBLE tutorial","heading":"2.7.5 Reproducibility","text":"want results reproducible, can control state R random number generator setSeed argument functions nimbleMCMC() runMCMC(). Going back animal survival example, can check two calls nimbleMCMC() give results setSeed set value:","code":"\n# first call to nimbleMCMC()\nmcmc.output1 <- nimbleMCMC(code = model,\n                           data = my.data,\n                           inits = initial.values,\n                           niter = 5000,\n                           nburnin = 1000,\n                           nchains = 3,\n                           summary = TRUE,\n                           setSeed = 123)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n# second call to nimbleMCMC()\nmcmc.output2 <- nimbleMCMC(code = model,\n                           data = my.data,\n                           inits = initial.values,\n                           niter = 5000,\n                           nburnin = 1000,\n                           nchains = 3,\n                           summary = TRUE,\n                           setSeed = 123)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n# outputs from both calls are the same\nmcmc.output1$summary$all.chains\n##         Mean Median St.Dev. 95%CI_low 95%CI_upp\n## theta 0.3387  0.336 0.05968    0.2282    0.4608\nmcmc.output2$summary$all.chains\n##         Mean Median St.Dev. 95%CI_low 95%CI_upp\n## theta 0.3387  0.336 0.05968    0.2282    0.4608"},{"path":"intronimble.html","id":"parallelization","chapter":"2 NIMBLE tutorial","heading":"2.7.6 Parallelization","text":"speed analyses, can run MCMC chains parallel. package jagsUI22 accomplishes JAGS users. , use parallel package parallel computation:First create cluster using total amount cores one make sure computer can go working:wrap workflow function run parallel:Now run code using parLapply(), uses cluster nodes execute workflow:call parLapply, specify X = c(2022, 666) ensure reproducibility. use two alues 2022 666 set seed workflow(), means run two instances workflow, two MCMC chains. Note also line set.seed(123) workflow() function ensure reproducibility drawing randomly initial values.’s good practice close cluster stopCluster() processes continue run background slow processes:inspecting results, can see object output list two components, one MCMC chain:Eventually, can obtain numerical summaries:","code":"\nlibrary(parallel)\nnbcores <- detectCores() - 1\nmy_cluster <- makeCluster(nbcores)\nworkflow <- function(seed, data) {\n  \n  library(nimble)\n  \n  model <- nimbleCode({\n    # likelihood\n    survived ~ dbinom(theta, released)\n    # prior\n    theta ~ dunif(0, 1)\n  })\n  \n  set.seed(123) # for reproducibility\n  initial.values <- function() list(theta = runif(1,0,1))\n  \n  survival <- nimbleModel(code = model, \n                          data = data, \n                          inits = initial.values())\n  Csurvival <- compileNimble(survival)\n  survivalMCMC <- buildMCMC(Csurvival)\n  CsurvivalMCMC <- compileNimble(survivalMCMC)\n  \n  samples <- runMCMC(mcmc = CsurvivalMCMC, \n                     niter = 5000, \n                     nburnin = 1000,\n                     setSeed = seed)\n  \n  return(samples)\n}\noutput <- parLapply(cl = my_cluster, \n                    X = c(2022, 666),\n                    fun = workflow, \n                    data = list(survived = 19, released = 57))\nstopCluster(my_cluster)\nstr(output)\n## List of 2\n##  $ : num [1:4000, 1] 0.393 0.369 0.346 0.346 0.346 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr \"theta\"\n##  $ : num [1:4000, 1] 0.435 0.435 0.435 0.435 0.243 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr \"theta\"\nMCMCsummary(output)\n##         mean      sd   2.5%    50%  97.5% Rhat n.eff\n## theta 0.3361 0.06148 0.2215 0.3335 0.4594    1  1779"},{"path":"intronimble.html","id":"incomplete-initialization","chapter":"2 NIMBLE tutorial","heading":"2.7.7 Incomplete initialization","text":"run nimbleMCMC() nimbleModel(), may get warnings thrown NIMBLE like ‘model fully initialized’ ‘value NA NaN even trying calculate’. necessarily error, ‘reflects missing values model variables’ (incomplete initialization). situation, NIMBLE initialize nodes NAs drawing priors, work . possible, try initialize nodes (full initialization). process can bit headache, helps understanding model structure better. Going back animal survival example, let’s purposedly forget provide initial value theta:see variables initialized, use initializeInfo():Now know theta initialized, can fix issue resume workflow:","code":"\nmodel <- nimbleCode({\n  # likelihood\n  survived ~ dbinom(theta, released)\n  # prior\n  theta ~ dunif(0, 1)\n})\n#initial.values <- list(theta = runif(1,0,1))\nsurvival <- nimbleModel(code = model, \n                        data = list(survived = 19, released = 57))\n# survival$calculate() # gives NA\nsurvival$initializeInfo()\nsurvival$theta <- 0.5 # assign initial value to theta\nsurvival$calculate() \n## [1] -5.422\n\nCsurvival <- compileNimble(survival)\nsurvivalMCMC <- buildMCMC(Csurvival)\n## ===== Monitors =====\n## thin = 1: theta\n## ===== Samplers =====\n## RW sampler (1)\n##   - theta\nCsurvivalMCMC <- compileNimble(survivalMCMC)\n\nsamples <- runMCMC(mcmc = CsurvivalMCMC, \n                   niter = 5000, \n                   nburnin = 1000)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n\nsamplesSummary(samples)\n##         Mean Median St.Dev. 95%CI_low 95%CI_upp\n## theta 0.3359 0.3335 0.06088    0.2191    0.4602"},{"path":"intronimble.html","id":"vectorization","chapter":"2 NIMBLE tutorial","heading":"2.7.8 Vectorization","text":"Vectorization process replacing loop vector instead processing single value time, process set values . example, instead writing:write:Vectorization can make code efficient manipulating one vector node x[1:n] instead n nodes x[1], …, x[n]. Think example relation animal survival? Illustrate vectorized Bernoulli vectorized Binomial?","code":"\nfor(i in 1:n){ \n  x[i] <- mu + epsilon[i] \n}\nx[1:n] <- mu + epsilon[1:n]"},{"path":"intronimble.html","id":"summary-1","chapter":"2 NIMBLE tutorial","heading":"2.8 Summary","text":"NIMBLE R package implements MCMC algorithms generate samples posterior distribution model parameters. specify likelihood priors using BUGS language apply Bayes theorem.NIMBLE R package implements MCMC algorithms generate samples posterior distribution model parameters. specify likelihood priors using BUGS language apply Bayes theorem.NIMBLE just another MCMC engine. provides programming environment full control building models estimating parameters.NIMBLE just another MCMC engine. provides programming environment full control building models estimating parameters.core NIMBLE nimbleFunctions can write compile faster computation. nimbleFunctions can mimic basic R syntax, work vectors matrices, use logical operators flow control, specify many distributions.core NIMBLE nimbleFunctions can write compile faster computation. nimbleFunctions can mimic basic R syntax, work vectors matrices, use logical operators flow control, specify many distributions.two workflows run NIMBLE. situations, nimbleMCMC() serve well. need control, can adopt detailed workflow nimbleModel(), configureMCMC(), buildMCMC(), compileNimble() runMCMC().two workflows run NIMBLE. situations, nimbleMCMC() serve well. need control, can adopt detailed workflow nimbleModel(), configureMCMC(), buildMCMC(), compileNimble() runMCMC().full control workflow, can change default MCMC samplers even write samplers.full control workflow, can change default MCMC samplers even write samplers.","code":""},{"path":"intronimble.html","id":"suggested-reading-1","chapter":"2 NIMBLE tutorial","heading":"2.9 Suggested reading","text":"chapter, scratched surface NIMBLE capable . list pointers help going NIMBLE.NIMBLE folks make lot useful resources available official website https://r-nimble.org.NIMBLE folks make lot useful resources available official website https://r-nimble.org.NIMBLE manual https://r-nimble.org/html_manual/cha-welcome-nimble.html reads like book clear explanations relevant examples.NIMBLE manual https://r-nimble.org/html_manual/cha-welcome-nimble.html reads like book clear explanations relevant examples.can learn lot going examples https://r-nimble.org/examples training material NIMBLE workshops https://github.com/nimble-training.can learn lot going examples https://r-nimble.org/examples training material NIMBLE workshops https://github.com/nimble-training.can keep NIMBLE cheatsheet https://r-nimble.org/cheatsheets/NimbleCheatSheet.pdf near remind workflow, write use models, functions distributions available.can keep NIMBLE cheatsheet https://r-nimble.org/cheatsheets/NimbleCheatSheet.pdf near remind workflow, write use models, functions distributions available.motivation write book comes workshop co-teach colleagues, including Perry de Valpine Daniel Turek NIMBLE development team. material (slides videos) available https://github.com/oliviergimenez/bayesian-cr-workshop.motivation write book comes workshop co-teach colleagues, including Perry de Valpine Daniel Turek NIMBLE development team. material (slides videos) available https://github.com/oliviergimenez/bayesian-cr-workshop.questions, feel free get touch community NIMBLE users emailing discussion group https://groups.google.com/forum/#!forum/nimble-users. great place learn, folks take time answer questions kind provide constructive answers. possible, make sure provide reproducible example illustrating problem.questions, feel free get touch community NIMBLE users emailing discussion group https://groups.google.com/forum/#!forum/nimble-users. great place learn, folks take time answer questions kind provide constructive answers. possible, make sure provide reproducible example illustrating problem.Last, can cite following reference using NIMBLE publication:Last, can cite following reference using NIMBLE publication:de Valpine, P., D. Turek, C. J. Paciorek, C. Anderson-Bergman, D. Temple Lang, R. Bodik (2017). Programming Models: Writing Statistical Algorithms General Model Structures NIMBLE. Journal Computational Graphical Statistics 26 (2): 403–13.","code":""},{"path":"hmmcapturerecapture.html","id":"hmmcapturerecapture","chapter":"3 Hidden Markov models","heading":"3 Hidden Markov models","text":"","code":""},{"path":"hmmcapturerecapture.html","id":"introduction-3","chapter":"3 Hidden Markov models","heading":"3.1 Introduction","text":"third chapter, learn basics Markov models fit longitudinal data using NIMBLE. real life however, individuals may go undetected status unknown. also learn manipulate extension Markov models hidden states, -called hidden Markov models.","code":""},{"path":"hmmcapturerecapture.html","id":"longitudinal-data","chapter":"3 Hidden Markov models","heading":"3.2 Longitudinal data","text":"Let’s get back survival example, denote \\(z_i\\) state individual \\(\\) \\(z_i = 1\\) alive \\(z_i = 0\\) dead. total \\(z = \\displaystyle{\\sum_{=1}^{n}{z_i}}\\) survivors \\(n\\) released animals winter survival probability \\(\\phi\\). model far combination binomial likelihood Beta prior parameters 1 1, also uniform distribution 0 1. can written as23:\\[\\begin{align*}\n   z &\\sim \\text{Binomial}(n, \\phi) &\\text{[likelihood]}\n   \\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\\n\\end{align*}\\]binomial distribution just sum independent Bernoulli outcomes, can rewrite model :\\[\\begin{align*}\n   z_i &\\sim \\text{Bernoulli}(\\phi), \\; = 1, \\ldots, N &\\text{[likelihood]}\n   \\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\\n\\end{align*}\\]like flipping coin individual get survivor probability \\(\\phi\\).set , consider single winter. many species, need collect data long term get representative estimate survival. Therefore say \\(T = 5\\) winters?Let us denote \\(z_{,t} = 1\\) individual \\(\\) alive winter \\(t\\), \\(z_{,t} = 2\\) dead. longitudinal data look like table . row individual \\(\\), columns winters \\(t\\), sampling occasions. Variable \\(z\\) indexed \\(\\) \\(t\\), takes value 1 individual \\(\\) alive winter \\(t\\), 2 otherwise.","code":""},{"path":"hmmcapturerecapture.html","id":"a-markov-model-for-longitudinal-data","chapter":"3 Hidden Markov models","heading":"3.3 A Markov model for longitudinal data","text":"Let’s think model data. objective remains , estimating survival. build model, ’ll make assumptions, go components write likelihood. Note already encountered Markov models Section 1.5.2.","code":""},{"path":"hmmcapturerecapture.html","id":"assumptions","chapter":"3 Hidden Markov models","heading":"3.3.1 Assumptions","text":"First, assume state animal given winter, alive dead, dependent state winter . words, future depends present, past. Markov process.Second, animal alive given winter, probability survives next winter \\(\\phi\\). probability dies \\(1 - \\phi\\).Third, animal dead winter, remains dead, unless believe zombies.Markov process can represented way:example Markov process , example:animal remains alive first two time intervals \\((z_{,1} = z_{,2} = z_{,3} = 1)\\) probability \\(\\phi\\) dies fourth time interval \\((z_{,4} = 2)\\) probability \\(1-\\phi\\) remains dead onwards \\((z_{,5} = 2)\\) probability 1.","code":""},{"path":"hmmcapturerecapture.html","id":"transition-matrix","chapter":"3 Hidden Markov models","heading":"3.3.2 Transition matrix","text":"might figured already (, problem), core Markov process made transition probabilities states alive dead. example, probability transitioning state alive \\(t-1\\) state alive \\(t\\) \\(\\Pr(z_{,t} = 1 | z_{,t-1} = 1) = \\gamma_{1,1}\\). survival probability \\(\\phi\\). probability dying interval \\((t-1, t)\\) \\(\\Pr(z_{,t} = 2 | z_{,t-1} = 1) = \\gamma_{1,2} = 1 - \\phi\\). Now animal dead \\(t-1\\), \\(\\Pr(z_t = 1 | z_{t-1} = 2) = 0\\) \\(\\Pr(z_{,t} = 2 | z_{,t-1} = 2) = 1\\).can gather probabilities transition states one occasion next matrix, say \\(\\mathbf{\\Gamma}\\), call transition matrix:\\[\\begin{align*}\n\\mathbf{\\Gamma} =\n\\left(\\begin{array}{cc}\n\\gamma_{1,1} & \\gamma_{1,2}\\\\\n\\gamma_{2,1} & \\gamma_{2,2}\n\\end{array}\\right) =\n\\left(\\begin{array}{cc}\n\\phi & 1 - \\phi\\\\\n0 & 1\n\\end{array}\\right)\n\\end{align*}\\]try remember states \\(t-1\\) rows, states \\(t\\) columns, often write:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=1 & z_t=2 \\\\ \\hdashline\n\\phi & 1-\\phi \\\\\n0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=1 \\; \\mbox{(alive)} \\\\ z_{t-1}=2 \\; \\mbox{(dead)}\n    \\end{matrix}\n\\end{matrix}\n\\]Take time need navigate matrix, get familiar . example, may start alive \\(t\\) (first row) end dead \\(t+1\\) (first column) probability \\(1-\\phi\\).","code":""},{"path":"hmmcapturerecapture.html","id":"initial-states","chapter":"3 Hidden Markov models","heading":"3.3.3 Initial states","text":"Markov process start somewhere. need probabilities initial states, .e. states individual \\(t = 1\\). gather probability state (alive 1 dead 2) first winter vector. use \\(\\mathbf{\\delta} = \\left(\\Pr(z_{,1} = 1), \\Pr(z_{,1} = 2)\\right)\\). simplicity, assume individuals marked released first winter, hence alive first captured, means state alive 1 sure. Therefore \\(\\mathbf{\\delta} = \\left(1, 0\\right)\\).","code":""},{"path":"hmmcapturerecapture.html","id":"likelihood","chapter":"3 Hidden Markov models","heading":"3.3.4 Likelihood","text":"Now built Markov model, need likelihood apply Bayes theorem. likelihood probability data, given model. data \\(z\\), therefore need \\(\\Pr(\\mathbf{z}) = \\Pr(z_1, z_2, \\ldots, z_{T-2}, z_{T-1}, z_T)\\).’re gonna work backward, starting last sampling occasion. Using conditional probabilities, likelihood can written product probability \\(z_T\\) .e. ’re alive last occasion given past history, states previous occasions, times probability past history:\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\color{blue}{\\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1)} \\\\\n\\end{align*}\\]Markov model, ’re memory less, probabilty next state, \\(z_T\\), depends current state, \\(z_{T-1}\\), previous states:\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\color{blue}{\\Pr(z_T | z_{T-1})} \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n\\end{align*}\\]can apply reasoning \\(T-1\\). First use conditional probabilities:\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\color{blue}{\\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n\\end{align*}\\]apply Markovian property:\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\color{blue}{\\Pr(z_{T-1} | z_{T-2})} \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n\\end{align*}\\]\\(z_2\\). end expression likelihood:\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\ldots \\\\\n                &= \\color{blue}{\\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\ldots \\Pr(z_{2} | z_{1}) \\Pr(z_{1})}\\\\\n\\end{align*}\\]product conditional probabilities states given previous states, probability initial states \\(\\Pr(z_1)\\). Using compact notation product conditional probabilities, get:\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_T | z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}, \\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\Pr(z_{T-2}, \\ldots, z_1)\\\\\n                &= \\ldots \\\\\n                &= \\Pr(z_T | z_{T-1}) \\Pr(z_{T-1} | z_{T-2}) \\ldots \\Pr(z_{2} | z_{1}) \\Pr(z_{1})\\\\\n                &= \\color{blue}{\\Pr(z_{1}) \\prod_{t=2}^T{\\Pr(z_{t} | z_{t-1})}}\\\\\n\\end{align*}\\]product, can recognize transition parameters \\(\\gamma\\) defined , likelihood Markov model can written :\\[\\begin{align*}\n\\Pr(\\mathbf{z}) &= \\Pr(z_T, z_{T-1}, z_{T-2}, \\ldots, z_1) \\color{white}{\\Pr(z_{T-1}, z_{T-2},\\ldots, z_1) \\Pr(z_{T-2}, \\ldots, z_1)}\\\\\n                &= \\Pr(z_{1}) \\prod_{t=2}^T{\\gamma_{z_{t-1},z_{t}}}\\\\\n\\end{align*}\\]","code":""},{"path":"hmmcapturerecapture.html","id":"example","chapter":"3 Hidden Markov models","heading":"3.3.5 Example","text":"realise calculations bit difficult follow. Let’s take example fix ideas. Let’s assume animal alive, alive time 2 dies time 3. \\(\\mathbf{z} = (1, 1, 2)\\). contribution animal likelihood? Let’s apply formula just derived:\\[\\begin{align*}\n\\Pr(\\mathbf{z} = (1, 1, 2)) &= \\Pr(z_1 = 1) \\; \\gamma_{z_{1} = 1, z_{2} = 1} \\; \\gamma_{z_{2} = 1, z_{3} = 2}\\\\\n                            &= 1 \\; \\phi \\; (1 - \\phi).\n\\end{align*}\\]probability sequence alive, alive dead probability alive first, stay alive, eventually die. probability alive first occasion 1, contribution individual likelihood \\(\\phi (1 - \\phi)\\).","code":""},{"path":"hmmcapturerecapture.html","id":"bayesian-formulation","chapter":"3 Hidden Markov models","heading":"3.4 Bayesian formulation","text":"implementing model NIMBLE, provide Bayesian formulation model. first note likelihood product conditional probabilities binary events (alive dead). Usually binary events associated Bernoulli distribution. however, use extension several outcomes (coin two sides dice two faces) known categorical distribution24. get better idea categorical distribution works, let’s simulate rcat() function. Consider example random value drawn categorical distribution probability 0.1, 0.3 0.6. Think dice three faces, face 1 probability 0.1 occurring, face 2 probability 0.3 face 3 probability 0.6, sum probabilities 1. expect get 3 often 2 rarely 125:another example sample 20 times categorical distribution probabilities 0.1, 0.1, 0.4, 0.2 0.2, hence dice 5 faces:chapter, familiarise categorical distribution binary situations, make transition states just alive dead smoother next chapters.Initial state categorical random variable probability \\(\\delta\\). dice two faces, coin, probability alive, one minus probability dead. course, want Markov chain start, ’d better say ’s alive \\(\\delta\\) just \\((1,0)\\):\\[\\begin{align*}\n   z_1 &\\sim \\text{Categorical}(\\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n\\end{align*}\\]Now main part dynamic states. state \\(z_t\\) \\(t\\) depends known state \\(z_{t-1}\\) \\(t-1\\), categorical random variable probabilities given row \\(z_{t-1}\\) transition matrix \\(\\mathbf{\\Gamma} = \\gamma_{z_{t-1},z_{t}}\\):\\[\\begin{align*}\n   z_1 &\\sim \\text{Categorical}(\\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Categorical}(\\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood, }t > 1 \\text{]}\\\\\n\\end{align*}\\]example, individual \\(\\) alive \\((t-1,t)\\) .e. \\(z_{t-1} = 1\\), need first row \\(\\mathbf{\\Gamma}\\),\\[\\begin{align*}\n\\mathbf{\\Gamma} =\n\\left(\\begin{array}{cc}\n\\color{blue}{\\phi} & \\color{blue}{1 - \\phi}\\\\\n0 & 1\n\\end{array}\\right)\n\\end{align*}\\]\\(\\color{blue}{\\gamma_{z_{t-1} = 1,z_{t}} = (\\phi, 1-\\phi)}\\) \\(z_t | z_{t-1} = 1 \\sim \\text{Categorical}((\\phi, 1-\\phi))\\).Otherwise, individual \\(\\) dies \\((t-1,t)\\) .e. \\(z_{t-1} = 2\\), need second row \\(\\mathbf{\\Gamma}\\):\\[\\begin{align*}\n\\mathbf{\\Gamma} =\n\\left(\\begin{array}{cc}\n\\phi & 1 - \\phi\\\\\n\\color{blue}{0} & \\color{blue}{1}\n\\end{array}\\right)\n\\end{align*}\\]\\(\\color{blue}{\\gamma_{z_{t-1} = 2,z_{t}} = (0, 1)}\\) \\(z_t | z_{t-1} = 2 \\sim \\text{Categorical}((0, 1))\\) (individual dead, remains dead probability 1).also need prior survival. Without surprise, use uniform distribution 0 1, also Beta distribution parameters 1 1. Overall model :\\[\\begin{align*}\n   z_1 &\\sim \\text{Categorical}(\\delta) &\\text{[likelihood, }t = 1 \\text{]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Categorical}(\\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood, }t > 1 \\text{]}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\\n\\end{align*}\\]","code":"\nrcat(n = 1, prob = c(0.1, 0.3, 0.6))\n## [1] 3\nrcat(n = 20, prob = c(0.1, 0.1, 0.4, 0.2, 0.2))\n##  [1] 5 3 4 5 4 3 4 2 2 3 1 3 5 5 3 4 2 3 2 3"},{"path":"hmmcapturerecapture.html","id":"nimble-implementation","chapter":"3 Hidden Markov models","heading":"3.5 NIMBLE implementation","text":"implement NIMBLE Markov model just built? need put place bricks running model. Let’s start prior survival, vector initial state probabilities transition matrix:Alternatively, can define vectors matrices NIMBLE like R. can write:Now two important dimensions model, along need repeat tasks, namely individual time. time, describe successive events survival using categorical distribution dcat(), say individual \\(\\):efficient way write piece code using loop, sequence instructions repeat. , condense previous code :Now just need individuals. use another loop:Puting everything together, NIMBLE code Markov model :Note example, \\(\\delta\\) used placeholder complex models build chapters come. , simply write z[,1] <- 1.Now ’re ready resume NIMBLE workflow. First read data. loops indices change, use constants explained Section 2.3:also specify initial values survival function:single parameter monitor:run 2 chains 5000 iterations including 1000 iterations burnin:Let’s run NIMBLE:Let’s calculate usual posterior numerical summaries survival:Posterior mean median close \\(0.8\\). fortunate since data simulated (actual) survival \\(\\phi = 0.8\\). code used :replace dcat() dbern() everywhere code binary events alive/dead. make difference? Although dcat() uses less efficient samplers dbern() (check w/ Perry/Daniel), dcat() convenient model building accomodate two outcomes, feature become handy next chapters.","code":"markov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n...markov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  delta[1:2] <- c(1, 0) # vector of initial state probabilities\n  gamma[1:2,1:2] <- matrix( c(phi, 0, 1 - phi, 1), nrow = 2) # transition matrix\n...\nz[i,1] ~ dcat(delta[1:2])           # t = 1\nz[i,2] ~ dcat(gamma[z[i,1], 1:2])   # t = 2\nz[i,3] ~ dcat(gamma[z[i,2], 1:2])   # t = 3\n...\nz[i,T] ~ dcat(gamma[z[i,T-1], 1:2]) # t = T\nz[i,1] ~ dcat(delta[1:2])             # t = 1\nfor (t in 2:T){ # loop over time t\n  z[i,t] ~ dcat(gamma[z[i,t-1], 1:2]) # t = 2,...,T\n}\nfor (i in 1:N){ # loop over individual i\n  z[i,1] ~ dcat(delta[1:2]) # t = 1\n  for (j in 2:T){ # loop over time t\n    z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) # t = 2,...,T\n  } # t\n} # i\nmarkov.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  # likelihood\n  for (i in 1:N){ # loop over individual i\n    z[i,1] ~ dcat(delta[1:2]) # t = 1\n    for (j in 2:T){ # loop over time t\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) # t = 2,...,T\n    } # t\n  } # i\n})\nmy.constants <- list(N = 57, T = 5)\nmy.data <- list(z = z)\ninitial.values <- function() list(phi = runif(1,0,1))\ninitial.values()\n## $phi\n## [1] 0.1265\nparameters.to.save <- c(\"phi\")\nparameters.to.save\n## [1] \"phi\"\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nmcmc.output <- nimbleMCMC(code = markov.survival,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi 0.79 0.03 0.73 0.79  0.85    1  1755\n# 1 = alive, 2 = dead\nnind <- 57\nnocc <- 5\nphi <- 0.8 # survival probability\ndelta <- c(1,0) # (Pr(alive at t = 1), Pr(dead at t = 1))\nGamma <- matrix(NA, 2, 2) # transition matrix\nGamma[1,1] <- phi      # Pr(alive t -> alive t+1)\nGamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\nGamma[2,1] <- 0        # Pr(dead t -> alive t+1)\nGamma[2,2] <- 1        # Pr(dead t -> dead t+1)\nz <- matrix(NA, nrow = nind, ncol = nocc)\nset.seed(2022)\nfor (i in 1:nind){\n  z[i,1] <- rcat(n = 1, prob = delta) # 1 for sure\n  for (t in 2:nocc){\n    z[i,t] <- rcat(n = 1, prob = Gamma[z[i,t-1],1:2]) \n  }\n}\nhead(z) \n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    1    1    1    1\n## [2,]    1    1    1    1    1\n## [3,]    1    1    1    1    1\n## [4,]    1    1    1    1    2\n## [5,]    1    1    1    1    1\n## [6,]    1    1    2    2    2"},{"path":"hmmcapturerecapture.html","id":"hidden-markov-models","chapter":"3 Hidden Markov models","heading":"3.6 Hidden Markov models","text":"","code":""},{"path":"hmmcapturerecapture.html","id":"capturerecapturedata","chapter":"3 Hidden Markov models","heading":"3.6.1 Capture-recapture data","text":"Let’s get back data previous section. truth \\(z\\) contains fate individuals \\(z = 1\\) alive, \\(z = 2\\) dead:Unfortunately, partial access \\(z\\). observe \\(y\\) detections non-detections. \\(z\\) \\(y\\) connected?easiest connection dead animals go undetected sure. Therefore animal dead .e. \\(z = 2\\), detected, therefore \\(y = 0\\): use 1 non-detected 2 detected , mention somewhere usually people use 0 1?Now alive animals may detected . animal alive \\(z = 1\\), detected \\(y = 1\\) probability \\(p\\) \\(y = 0\\) probability \\(1-p\\). example, first detection coincides first winter individuals.Compare previous table. 1’s alive become 0’s non-detection, 1’s alive remained 1’s detection. table \\(y\\) observe real life. hope convinced make connection observations, \\(y\\), true states, \\(z\\), need describe observations made (emitted HMM terminology) states.","code":""},{"path":"hmmcapturerecapture.html","id":"observation-matrix","chapter":"3 Hidden Markov models","heading":"3.6.2 Observation matrix","text":"novelty HMMs link observations states. link made observation probabilities. example, probability detecting animal \\(\\) \\(t\\) given alive \\(t\\) \\(\\Pr(y_{,t}=2|z_{,t}=1)=\\omega_{1,2}\\). detection probability \\(p\\). individual \\(\\) dead \\(t\\), missed sure, \\(\\Pr(y_{,t}=1|z_{,t}=2)=\\omega_{2,1}=1\\).can gather observation probabilities observation matrix \\(\\mathbf{\\Omega}\\). rows states alive \\(z = 1\\) dead \\(z = 2\\), columns observations non-detected \\(y = 1\\) detected \\(y = 2\\) (previously coded 0 1 respectively): go 1 2, wee need comment parentheses?\\[\\begin{align*}\n\\mathbf{\\Omega} =\n\\left(\\begin{array}{cc}\n\\omega_{1,1} & \\omega_{1,2}\\\\\n\\omega_{2,1} & \\omega_{2,2}\n\\end{array}\\right) =\n\\left(\\begin{array}{cc}\n1 - p & p\\\\\n1 & 0\n\\end{array}\\right)\n\\end{align*}\\]Observation matrix:\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=1 & y_t=2 \\\\\n    \\mbox{(non-detected)} & \\mbox{(detected)} \\\\ \\hdashline\n1 - p & p\\\\\n1 & 0\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=1 \\; \\mbox{(alive)}\\\\ z_{t}=2 \\; \\mbox{(dead)}\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"hmmcapturerecapture.html","id":"hidden-markov-model","chapter":"3 Hidden Markov models","heading":"3.6.3 Hidden Markov model","text":"hidden Markov model can represented way:States \\(z\\) gray. Observations \\(y\\) white. individuals first captured first winter \\(t = 1\\), therefore alive \\(z_1 = 1\\) detected \\(y_1 = 2\\).look example , individual detected first sampling occasion, detected , missed rest study. occasion \\(t=3\\) individual alive \\(z_3=1\\) went undetected \\(y_3=1\\), occasions \\(t=4\\) \\(t=5\\) went undetected \\(y_4=y_5=1\\) dead \\(z_4=z_5=2\\).","code":""},{"path":"hmmcapturerecapture.html","id":"likelihoodhmm","chapter":"3 Hidden Markov models","heading":"3.6.4 Likelihood","text":"Bayesian framework, usually work -called complete likelihood, probability observed data \\(y\\) latent states \\(z\\) given parameters model, survival detection probabilities \\(\\phi\\) \\(p\\). complete likelihood individual \\(\\) :\\[\\begin{align*}\n\\Pr(\\mathbf{y}_i, \\mathbf{z}_i) &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T}, z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n\\end{align*}\\]Using definition conditional probability, :\\[\\begin{align*}\n\\Pr(\\mathbf{y}_i, \\mathbf{z}_i) &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T}, z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n                  &= \\color{blue}{\\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T} | z_{,1}, z_{,2}, \\ldots, z_{,T}) \\Pr(z_{,1}, z_{,2}, \\ldots, z_{,T})}\\\\\n\\end{align*}\\]using independence \\(y\\) conditional \\(z\\), likelihood Markov chain, get :\\[\\begin{align*}\n\\Pr(\\mathbf{y}_i, \\mathbf{z}_i) &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T}, z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n                  &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T} | z_{,1}, z_{,2}, \\ldots, z_{,T}) \\Pr(z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n                &= \\color{blue}{\\left(\\prod_{t=1}^T{\\Pr{(y_{,t} | z_{,t})}}\\right) \\left(\\Pr(z_{,1}) \\prod_{t=2}^T{\\Pr{(z_{,t} | z_{,t-1})}}\\right)}\\\\\n\\end{align*}\\]Finally, recognizing observation transition probabilities, complete likelihood individual \\(\\) :\\[\\begin{align*}\n\\Pr(\\mathbf{y}_i, \\mathbf{z}_i) &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T}, z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n                  &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T} | z_{,1}, z_{,2}, \\ldots, z_{,T}) \\Pr(z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n                &= \\color{blue}{\\left(\\prod_{t=1}^T{\\omega_{z_{,t}, y_{,t}}}\\right) \\left(\\Pr(z_{,1}) \\prod_{t=2}^T{\\gamma_{z_{,t-1},z_{,t}}}\\right)}\\\\\n\\end{align*}\\]obtain complete likelihood whole dataset, need multiply individual likelihood animal \\(\\displaystyle{\\prod_{=1}^N{\\Pr(\\mathbf{y}_i,\\mathbf{z}_i)}}\\). several individuals contribution, calculating individual contribution can greatly reduce computational burden, illustrated Section 3.9.Bayesian approach MCMC methods allows treating latent states \\(z_{,t}\\) parameters, estimated . However, likelihood rather complex large number latent states \\(z_{,t}\\), comes computational costs slow mixing. situations latent states focus ecological inference need estimated (see Suggested reading ). However, needed, might want get rid latent states rely -called marginal likelihood. , can avoid sampling latent states, focus ecological parameters, often speeds computations improves mixing shown Section 3.8. Actually, can even estimate latent states afterwards, illustrated Section 3.10.","code":""},{"path":"hmmcapturerecapture.html","id":"fittinghmmnimble","chapter":"3 Hidden Markov models","heading":"3.7 Fitting HMM with NIMBLE","text":"model far written follows:\\[\\begin{align*}\n   z_{\\text{first}} &\\sim \\text{Categorical}(1, \\delta) &\\text{[likelihood]}\\\\\n   z_t | z_{t-1} &\\sim \\text{Categorical}(1, \\gamma_{z_{t-1},z_{t}}) &\\text{[likelihood]}\\\\\n   y_t | z_{t} &\\sim \\text{Categorical}(1, \\omega_{z_{t}}) &\\text{[likelihood]}\\\\\n  \\phi &\\sim \\text{Beta}(1, 1) &\\text{[prior }\\phi \\text{]} \\\\\n  p &\\sim \\text{Beta}(1, 1) &\\text{[prior }p \\text{]} \\\\\n\\end{align*}\\]observation layer \\(y\\)’s, conditional \\(z\\)’s. also consider uniform priors detection survival probabilities. implement model NIMBLE?start priors survival detection probabilities:define initial states, transition observation matrices:likelihood:Overall, code looks like:Now specify constants:data made 0’s non-detections 1’s detections. use categorical distribution, need code 1’s 2’s. simply add 1 get correct format, \\(y = 1\\) non-detection \\(y = 2\\) detection: Using 1 2 make life easier… 0/1 coding convention; Using 1/2 coding make clear non-detections actual data (use 0s non-detections sometimes confusing). Also, might help replace states 1 2 D dead alive. Even mathematically convenient, guess help understanding. , . want non-detection first, always 1’s.Now let’s write function initial values:specify parameters ’d like monitor:provide MCMC details:last, ’re ready run NIMBLE:can look numerical summaries:estimates survival detection close true survival \\(\\phi = 0.8\\) detection \\(p = 0.6\\) simulated data. code used :","code":"hmm.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n...\n...\n  # parameters\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n......\n    # likelihood\n    for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nhmm.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n  # likelihood\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    z[i,1] ~ dcat(delta[1:2])\n    for (j in 2:T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y), T = 5)\nmy.constants\n## $N\n## [1] 57\n## \n## $T\n## [1] 5\nmy.data <- list(y = y + 1)\nzinits <- y + 1 # non-detection -> alive\nzinits[zinits == 2] <- 1 # dead -> alive\ninitial.values <- function() list(phi = runif(1,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"phi\", \"p\")\nparameters.to.save\n## [1] \"phi\" \"p\"\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nstart_time <- Sys.time()\nmcmc.output <- nimbleMCMC(code = hmm.survival,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\nend_time <- Sys.time()\nend_time - start_time## Time difference of 19.06 secs\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.61 0.06 0.50 0.61  0.72    1   740\n## phi 0.75 0.04 0.67 0.75  0.83    1   805\nset.seed(2022) # for reproducibility\nnocc <- 5 # nb of winters or sampling occasions\nnind <- 57 # nb of animals\np <- 0.6 # detection prob\nphi <- 0.8 # survival prob\n# Vector of initial states probabilities\ndelta <- c(1,0) # all individuals are alive in first winter\n# Transition matrix\nGamma <- matrix(NA, 2, 2)\nGamma[1,1] <- phi      # Pr(alive t -> alive t+1)\nGamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\nGamma[2,1] <- 0        # Pr(dead t -> alive t+1)\nGamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n# Observation matrix \nOmega <- matrix(NA, 2, 2)\nOmega[1,1] <- 1 - p      # Pr(alive t -> non-detected t)\nOmega[1,2] <- p          # Pr(alive t -> detected t)\nOmega[2,1] <- 1          # Pr(dead t -> non-detected t)\nOmega[2,2] <- 0          # Pr(dead t -> detected t)\n# Matrix of states\nz <- matrix(NA, nrow = nind, ncol = nocc)\ny <- z\ny[,1] <- 2 # all individuals are detected in first winter\nfor (i in 1:nind){\n  z[i,1] <- rcat(n = 1, prob = delta) # 1 for sure\n  for (t in 2:nocc){\n    # state at t given state at t-1\n    z[i,t] <- rcat(n = 1, prob = Gamma[z[i,t-1],1:2]) \n    # observation at t given state at t\n    y[i,t] <- rcat(n = 1, prob = Omega[z[i,t],1:2]) \n  }\n}\ny\ny <- y - 1 # non-detection = 0, detection = 1"},{"path":"hmmcapturerecapture.html","id":"marginalization","chapter":"3 Hidden Markov models","heading":"3.8 Marginalization","text":"situations, interested inferring hidden states \\(z_{,t}\\), bother estimating ? good news can get rid states, marginal likelihood function survival detection probabilities \\(\\phi\\) \\(p\\) .","code":""},{"path":"hmmcapturerecapture.html","id":"brute-force-approach","chapter":"3 Hidden Markov models","heading":"3.8.1 Brute-force approach","text":"Using formula total probability, get marginal likelihood summing possible states complete likelihood:\\[\\begin{align*}\n\\Pr(\\mathbf{y}_i) &= \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T})\\\\\n                &= \\sum_{\\mathbf{z}_i} \\Pr(\\mathbf{y}_i, \\mathbf{z}_i)\\\\\n                &= \\sum_{z_{,1}} \\cdots \\sum_{z_{,T}} \\Pr(y_{,1}, y_{,2}, \\ldots, y_{,T}, z_{,1}, z_{,2}, \\ldots, z_{,T})\\\\\n\\end{align*}\\]Going steps deriving complete likelihood, obtain marginal likelihood:\\[\\begin{align*}\n\\Pr(\\mathbf{y}_i) &= \\sum_{z_{,1}} \\cdots \\sum_{z_{,T}} \\left(\\prod_{t=1}^T{\\omega_{z_{,t}, y_{,t}}}\\right) \\left(\\Pr(z_{,1}) \\prod_{t=2}^T{\\gamma_{z_{,t-1},z_{,t}}}\\right)\\\\\n\\end{align*}\\]Let’s go example. Let’s imagine \\(T = 3\\) winters, ’d like write likelihood individual encounter history detected, detected non-detected. Remember non-detected coded 1 detected coded 2, alive coded 1 dead coded 2. need calculate \\(\\Pr(y_1 = 2, y_2 = 2, y_3 = 1)\\) , according formula , given :\\[\\begin{align*}\n\\begin{split}\n\\Pr(y_1 = 2, y_2 = 2, y_3 = 1) &= \\sum_{=1}^{2} \\sum_{j=1}^{2} \\sum_{k=1}^{2} \\Pr(y_1 = 2 | z_1 = ) \\Pr(y_2 = 2 | z_2 = j) \\Pr(y_3 = 1 | z_3 = k) \\\\\n& \\qquad \\Pr(z_1=) \\Pr(z_2 = j | z_1 = ) \\Pr(z_3 = k | z_2 = j)\\\\\n\\end{split}\n\\end{align*}\\]Expliciting sums \\(\\Pr(y_1 = 2, y_2 = 2, y_3 = 1)\\), get long ugly expression:\\[\\begin{align*}\n\\begin{split}\n\\Pr(y_1 = 2, y_2 = 2, y_3 = 1) &= \\\\\n& \\Pr(y_1 = 2 | z_1 = 1) \\Pr(y_2 = 2 | z_2 = 1) \\Pr(y_3 = 1 | z_3 = 1) \\times \\\\\n& \\qquad \\Pr(z_1 = 1) \\Pr(z_2 = 1 | z_1 = 1) \\Pr(z_3 = 1 | z_2 = 1) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 2) \\Pr(y_2 = 2 | z_2 = 1) \\Pr(y_3 = 1 | z_3 = 1) \\times\\\\\n& \\qquad \\Pr(z_1 = 2) \\Pr(z_2 = 1 | z_1 = 2) \\Pr(z_3 = 1 | z_2 = 1) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 1) \\Pr(y_2 = 2 | z_2 = 2) \\Pr(y_3 = 1 | z_3 = 1) \\times\\\\\n& \\qquad \\Pr(z_1 = 1) \\Pr(z_2 = 2 | z_1 = 1) \\Pr(z_3 = 1 | z_2 = 2) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 2) \\Pr(y_2 = 2 | z_2 = 2) \\Pr(y_3 = 1 | z_3 = 1) \\times\\\\\n& \\qquad \\Pr(z_1 = 2) \\Pr(z_2 = 2 | z_1 = 2) \\Pr(z_3 = 1 | z_2 = 2) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 1) \\Pr(y_2 = 2 | z_2 = 1) \\Pr(y_3 = 1 | z_3 = 2) \\times\\\\\n& \\qquad \\Pr(z_1 = 1) \\Pr(z_2 = 1 | z_1 = 1) \\Pr(z_3 = 2 | z_2 = 1) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 2) \\Pr(y_2 = 2 | z_2 = 1) \\Pr(y_3 = 1 | z_3 = 2) \\times\\\\\n& \\qquad \\Pr(z_1 = 2) \\Pr(z_2 = 1 | z_1 = 2) \\Pr(z_3 = 2 | z_2 = 1) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 1) \\Pr(y_2 = 2 | z_2 = 2) \\Pr(y_3 = 1 | z_3 = 2) \\times\\\\\n& \\qquad \\Pr(z_1 = 1) \\Pr(z_2 = 2 | z_1 = 1) \\Pr(z_3 = 2 | z_2 = 2) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 2) \\Pr(y_2 = 2 | z_2 = 2) \\Pr(y_3 = 1 | z_3 = 2) \\times\\\\\n& \\qquad \\Pr(z_1 = 2) \\Pr(z_2 = 2 | z_1 = 2) \\Pr(z_3 = 2 | z_2 = 2)\\\\\n\\end{split}\n\\end{align*}\\]can simplify expression noticing ) individuals alive sure marked released first winter, \\(\\Pr(z_1=2) = 0\\) ii) dead individuals non-detected sure, \\(\\Pr(y_t = 2|z_t = 2) = 0\\), lead :\\[\\begin{align*}\n\\begin{split}\n\\Pr(y_1 = 2, y_2 = 2, y_3 = 1) &= \\\\\n& \\Pr(y_1 = 2 | z_1 = 1) \\Pr(y_2 = 2 | z_2 = 1) \\Pr(y_3 = 1 | z_3 = 1) \\times \\\\\n& \\qquad \\Pr(z_1 = 1) \\Pr(z_2 = 1 | z_1 = 1) \\Pr(z_3 = 1 | z_2 = 1) +\\\\\n&  \\Pr(y_1 = 2 | z_1 = 1) \\Pr(y_2 = 2 | z_2 = 1) \\Pr(y_3 = 1 | z_3 = 2) \\times\\\\\n& \\qquad \\Pr(z_1 = 1) \\Pr(z_2 = 1 | z_1 = 1) \\Pr(z_3 = 2 | z_2 = 1)\\\\\n\\end{split}\n\\end{align*}\\]individuals captured first winter, \\(\\Pr(y_1 = 2 | z_1 = 1) = 1\\), get:\\[\\begin{align*}\n\\Pr(y_1 = 2, y_2 = 2, y_3 = 1) =  1 (1-p) \\times 1 \\phi \\phi + 1 p 1 \\times 1 \\phi (1-\\phi)\n\\end{align*}\\]end \\(\\Pr(y_1 = 2, y_2 = 2, y_3 = 1) = \\phi p (1 - p\\phi)\\).latent states longer involved likelihood individual. However, even rather simple example, marginal likelihood quite complex evaluate involves many operations. \\(T\\) length encounter histories \\(N\\) number hidden states (two alive dead, deal states chapters come), need calculate sum \\(N^T\\) terms (sums formula ), two products \\(T\\) factors (products formula ), hence \\(2TN^T\\) calculations total. can check simple example , \\(T^N = 2^3 = 8\\) terms summed, product \\(2T = 2 \\times 3 = 6\\) terms. means number operations increases exponentially number states increases. cases, complexity precludes using method get rid states. Fortunately, another algorithm HMM toolbox useful calculate marginal likelihood efficiently.","code":""},{"path":"hmmcapturerecapture.html","id":"forward-algorithm","chapter":"3 Hidden Markov models","heading":"3.8.2 Forward algorithm","text":"brute-force approach, products computed several times calculate marginal likelihood. store products use later computing probability observation sequence? precisely forward algorithm .introduce \\(\\alpha_t(j)\\) probability latent state \\(z\\) state \\(j\\) \\(t\\) seeing first \\(j\\) observations \\(y_1, \\ldots, y_t\\), \\(\\alpha_t(j) = \\Pr(y_1, \\ldots, y_t, z_t = j)\\).Using law total probability, can write marginal likelihood function \\(\\alpha_T(j)\\), namely \\(\\Pr(\\mathbf{y}) = \\displaystyle{\\sum_{j=1}^N\\Pr(y_1, \\ldots, y_t, z_t = j)} = \\displaystyle{\\sum_{j=1}^N\\alpha_T(j)}\\).calculate \\(\\alpha_T(j)\\)s? magic forward algorithm happens. use recurrence relationship saves us many computations.recurrence states :\\[\\begin{align*}\n\\alpha_t(j) &= \\sum_{=1}^N \\alpha_{t-1}() \\gamma_{,j} \\omega_{j,y_t}\n\\end{align*}\\]obtain recurrence? First, using law total probability \\(z_{t-1}\\), :\n\\[\\begin{align*}\n\\alpha_t(j) &= \\sum_{=1}^N \\Pr(y_1, \\ldots, y_t, z_{t-1} = , z_t = j)\\\\\n\\end{align*}\\]Second, using conditional probabilities, get:\n\\[\\begin{align*}\n\\alpha_t(j) &= \\sum_{=1}^N \\Pr(y_t | z_{t-1} = , z_t = j, y_1, \\ldots, y_t) \\Pr(z_{t-1} = , z_t = j, y_1, \\ldots, y_t)\n\\end{align*}\\]Third, using conditional probabilities , second term product, get:\n\\[\\begin{align*}\n\\alpha_t(j) &= \\sum_{=1}^N \\Pr(y_t | z_{t-1} = , z_t = j, y_1, \\ldots, y_t) \\times \\\\ & \\Pr(z_t = j | z_{t-1} = , y_1, \\ldots, y_t) \\Pr(z_{t-1} = , y_1, \\ldots, y_t)\n\\end{align*}\\], using conditional independence, simplifies :\\[\\begin{align*}\n\\alpha_t(j) &= \\sum_{=1}^N \\Pr(y_t | z_t = j) \\Pr(z_t = j | z_{t-1} = ) \\Pr(z_{t-1} = , y_1, \\ldots, y_t)\n\\end{align*}\\]Recognizing \\(\\Pr(y_{t}|z_{t}=j)=\\omega_{j,y_t}\\), \\(\\Pr(z_{t} = j | z_{t-1} = ) = \\gamma_{,j}\\) \\(\\Pr(z_{t-1} = , y_1, \\ldots, y_t) = \\alpha_{t-1}()\\), obtain recurrence.practice, forward algorithm works follows. First initialize procedure calculating states \\(j=1,\\ldots,N\\) quantities \\(\\alpha_1(j) = Pr(z_1 = j) \\omega_{j,y_1}\\). compute states \\(j=1,\\ldots,N\\) relationship \\(\\alpha_t(j) = \\displaystyle{\\sum_{=1}^N \\alpha_{t-1}() \\gamma_{,j} \\omega_{j,y_t}}\\) \\(t = 2, \\ldots, T\\). Finally, compute marginal likelihood \\(\\Pr(\\mathbf{y}) = \\displaystyle{\\sum_{j=1}^N\\alpha_T(j)}\\). time \\(t\\), need calculate \\(N\\) values \\(\\alpha_t(j)\\), \\(\\alpha_t(j)\\) sum \\(N\\) products \\(\\alpha_{t-1}\\), \\(\\gamma_{,j}\\) \\(\\omega_{j,y_t}\\), hence \\(TN^2\\) computations total, much less \\(2TN^T\\) calculations brute-force approach.Going back example, wish calculate \\(\\Pr(y_1 = 2, y_2 = 2, y_3 = 1)\\). First initialize compute \\(\\alpha_1(1)\\) \\(\\alpha_1(2)\\). :\\[\\begin{align*}\n\\alpha_1(1) = \\Pr(z_1=1) \\omega_{1,y_1=2} = 1\n\\end{align*}\\]animals alive captured first winter. also :\\[\\begin{align*}\n\\alpha_1(2) = \\Pr(z_1=2) \\omega_{2,y_1=2} = 0\n\\end{align*}\\]compute \\(\\alpha_2(1)\\) \\(\\alpha_2(2)\\). :\\[\\begin{align*}\n\\alpha_2(1) &= \\sum_{=1}^2 \\alpha_1() \\gamma_{,1} \\omega_{1,y_2=2}\\\\\n            &= \\gamma_{1,1} \\omega_{1,y_2=2}\\\\\n            &= \\phi p\n\\end{align*}\\]\\(\\alpha_1(2) = 0\\). Also, :\\[\\begin{align*}\n\\alpha_2(2) &= \\sum_{=1}^2 \\alpha_1() \\gamma_{,2} \\omega_{2,y_2=2}\\\\\n            &= \\gamma_{1,2} \\omega_{2,y_2=2}\\\\\n            &= (1-\\phi) 0\n\\end{align*}\\]Finally compute \\(\\alpha_3(1)\\) \\(\\alpha_3(2)\\). :\\[\\begin{align*}\n\\alpha_3(1) &= \\sum_{=1}^2 \\alpha_2() \\gamma_{,1} \\omega_{1,y_3=1}\\\\\n            &= \\alpha_2(1) \\gamma_{1,1} \\omega_{1,y_3=1}\\\\\n            &= \\phi p \\phi (1-p)\n\\end{align*}\\]:\\[\\begin{align*}\n\\alpha_3(2) &= \\sum_{=1}^2 \\alpha_2() \\gamma_{,2} \\omega_{2,y_3=1}\\\\\n            &= \\alpha_2(1) \\gamma_{1,2} \\omega_{2,y_3=1}\\\\\n            &= \\phi p (1-\\phi) 1\n\\end{align*}\\]Eventually, compute \\(\\Pr(y_1=2,y_2=2,y_3=1)\\):\\[\\begin{align*}\n\\Pr(y_1=2,y_2=2,y_3=1) &= \\alpha_3(1) + \\alpha_3(2)\\\\\n            &= \\phi p (\\phi) (1-p) + \\phi p (1-\\phi)\\\\\n            &= \\phi p (1-\\phi p)\n\\end{align*}\\]can check total \\(3 \\times 2^2 = 12\\) operations.","code":""},{"path":"hmmcapturerecapture.html","id":"nimble-implementation-1","chapter":"3 Hidden Markov models","heading":"3.8.3 NIMBLE implementation","text":"NIMBLE, use functions implement forward algorithm. differences theory ) work log scale numerical stability ii) use matrix formulation recurrence.\nFirst write density function:passing, function maximize Frequentist approach28. write function simulate values HMM:assign functions global R environment:Now resume workflow:run NIMBLE:numerical summaries similar obtained complete likelihood, effective samples sizes larger denoting better mixing:","code":"\ndHMM <- nimbleFunction(\n  run = function(x = double(1), \n                 probInit = double(1),\n                 probObs = double(2),\n                 probTrans = double(2),\n                 len = double(0, default = 0),\n                 log = integer(0, default = 0)) {\n    alpha <- probInit[1:2]\n    for (t in 2:len) {\n      alpha[1:2] <- (alpha[1:2] %*% probTrans[1:2,1:2]) * probObs[1:2,x[t]]\n    }\n    logL <- log(sum(alpha[1:2]))\n    returnType(double(0))\n    if (log) return(logL)\n    return(exp(logL))\n  }\n)\nrHMM <- nimbleFunction(\n  run = function(n = integer(),\n                 probInit = double(1),\n                 probObs = double(2),\n                 probTrans = double(2),\n                 len = double(0, default = 0)) {\n    returnType(double(1))\n    z <- numeric(len)\n    z[1] <- rcat(n = 1, prob = probInit[1:2]) # all individuals alive at t = 0\n    y <- z\n    y[1] <- 2 # all individuals are detected at t = 0\n    for (t in 2:len){\n      # state at t given state at t-1\n      z[t] <- rcat(n = 1, prob = probTrans[z[t-1],1:2]) \n      # observation at t given state at t\n      y[t] <- rcat(n = 1, prob = probObs[z[t],1:2]) \n    }\n    return(y)\n  })\nassign('dHMM', dHMM, .GlobalEnv)\nassign('rHMM', rHMM, .GlobalEnv)\n# code\nhmm.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n  # likelihood\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    y[i,1:T] ~ dHMM(probInit = delta[1:2], \n                    probObs = omega[1:2,1:2], # observation matrix\n                    probTrans = gamma[1:2,1:2], # transition matrix\n                    len = T) # nb of sampling occasions\n  }\n})\n# constants\nmy.constants <- list(N = nrow(y), T = 5)\n# data\nmy.data <- list(y = y + 1)\n# initial values - no need to specify values for z anymore\ninitial.values <- function() list(phi = runif(1,0,1),\n                                  p = runif(1,0,1))\n# parameters to save\nparameters.to.save <- c(\"phi\", \"p\")\n# MCMC details\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nstart_time <- Sys.time()\nmcmc.output <- nimbleMCMC(code = hmm.survival,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nend_time <- Sys.time()\nend_time - start_time\n## Time difference of 17.57 secs\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.61 0.06 0.49 0.61  0.72    1  1211\n## phi 0.76 0.04 0.67 0.76  0.84    1  1483"},{"path":"hmmcapturerecapture.html","id":"pooled-likelihood","chapter":"3 Hidden Markov models","heading":"3.9 Pooled encounter histories","text":"can go one step make convergence even faster. mentionned earlier Section 3.6.4, likelihood HMM fitted capture-recapture data often involves individuals share encounter histories. Instead repeating calculations several times, likelihood contribution shared say \\(x\\) individuals raised power \\(x\\) likelihood whole dataset, hence making operations once29.section, amend NIMBLE functions wrote marginalizing latent states Section 3.8 express likelihood using pooled encounter histories. use vector size contains number individuals encounter history.density function function dHMM add size argument, raise individual likelihood power size, multiply size work log scale log(sum(alpha[1:2])) * size:rHMM function renamed rHMMpooled compatibility remains unchanged:assign two function global R environment can use :can now plug pooled HMM density function NIMBLE code:running NIMBLE, need actually pool individuals encounter history together:example, 21 individuals encounter history (1, 0, 0, 0, 0).Now can resume NIMBLE workflow:results obtained previously. gain computation times bigger complex models see next chapters.","code":"\ndHMMpooled <- nimbleFunction(\n  run = function(x = double(1), \n                 probInit = double(1),\n                 probObs = double(2),\n                 probTrans = double(2),\n                 len = double(0),\n                 size = double(0),\n                 log = integer(0, default = 0)) {\n    alpha <- probInit[1:2]\n    for (t in 2:len) {\n      alpha[1:2] <- (alpha[1:2] %*% probTrans[1:2,1:2]) * probObs[1:2,x[t]]\n    }\n    logL <- log(sum(alpha[1:2])) * size\n    returnType(double(0))\n    if (log) return(logL)\n    return(exp(logL))\n  }\n)\nrHMMpooled <- nimbleFunction(\n  run = function(n = integer(),\n                 probInit = double(1),\n                 probObs = double(2),\n                 probTrans = double(2),\n                 len = double(0),\n                 size = double(0)) {\n    returnType(double(1))\n    z <- numeric(len)\n    z[1] <- rcat(n = 1, prob = probInit[1:2]) # all individuals alive at t = 0\n    y <- z\n    y[1] <- 2 # all individuals are detected at t = 0\n    for (t in 2:len){\n      # state at t given state at t-1\n      z[t] <- rcat(n = 1, prob = probTrans[z[t-1],1:2]) \n      # observation at t given state at t\n      y[t] <- rcat(n = 1, prob = probObs[z[t],1:2]) \n    }\n    return(y)\n  })\nassign('dHMMpooled', dHMMpooled, .GlobalEnv)\nassign('rHMMpooled', rHMMpooled, .GlobalEnv)\nhmm.survival <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  p ~ dunif(0, 1) # prior detection\n  # likelihood\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    y[i,1:T] ~ dHMMpooled(probInit = delta[1:2], \n                          probObs = omega[1:2,1:2], # observation matrix\n                          probTrans = gamma[1:2,1:2], # transition matrix\n                          len = T, # nb of sampling occasions\n                          size = size[i]) # number of individuals with encounter history i\n  }\n})\ny_pooled <- y %>% \n  as_tibble() %>% \n  group_by_all() %>% # group\n  summarise(size = n()) %>% # count\n  relocate(size) %>% # put size in front\n  arrange(-size) %>% # sort along size\n  as.matrix()\ny_pooled\n##       size winter 1 winter 2 winter 3 winter 4 winter 5\n##  [1,]   21        1        0        0        0        0\n##  [2,]    8        1        1        0        0        0\n##  [3,]    8        1        1        1        1        0\n##  [4,]    4        1        1        0        0        1\n##  [5,]    4        1        1        1        0        0\n##  [6,]    2        1        0        0        1        0\n##  [7,]    2        1        0        1        1        0\n##  [8,]    2        1        1        0        1        0\n##  [9,]    1        1        0        1        0        0\n## [10,]    1        1        0        1        0        1\n## [11,]    1        1        0        1        1        1\n## [12,]    1        1        1        0        1        1\n## [13,]    1        1        1        1        0        1\n## [14,]    1        1        1        1        1        1\nmy.constants <- list(N = nrow(y_pooled), T = 5, size = y_pooled[,'size'])\nmy.data <- list(y = y_pooled[,-1] + 1) # delete size from dataset\ninitial.values <- function() list(phi = runif(1,0,1),\n                                  p = runif(1,0,1))\nparameters.to.save <- c(\"phi\", \"p\")\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nstart_time <- Sys.time()\nmcmc.output <- nimbleMCMC(code = hmm.survival,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\n## |-------------|-------------|-------------|-------------|\n## |-------------------------------------------------------|\nend_time <- Sys.time()\nend_time - start_time\n## Time difference of 17.54 secs\nMCMCsummary(mcmc.output, round = 2)\n##     mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p   0.61 0.06 0.49 0.61  0.72    1  1453\n## phi 0.76 0.04 0.67 0.76  0.84    1  1359"},{"path":"hmmcapturerecapture.html","id":"decoding","chapter":"3 Hidden Markov models","heading":"3.10 Decoding after marginalization","text":"need infer latent states, afford computation times complete likelihood Section 3.6.4, can still use marginal likelihood forward algorithm Section 3.8.2. need extra step decode latent states Viterbi algorithm. Viterbi algorithm allows compute sequence states likely generated sequence observations.","code":""},{"path":"hmmcapturerecapture.html","id":"viterbi-theory","chapter":"3 Hidden Markov models","heading":"3.10.1 Theory","text":"simulated dataset, animal #15 encounter history (2, 1, 1, 1, 1) generated sequence states (1, 1, 2, 2, 2) survival probability \\(\\phi = 0.8\\) detection probability \\(p = 0.6\\).Imagine know truth. chance animal #15 alive throughout study observing encounter history detected first winter, missed subsequent winter? chance alive first winter detected alive 1. chance alive second winter non-detected \\(0.8 \\times (1-0.6) = 0.32\\). goes third, fourth fifth winters. total, probability alive throughout study animal encounter history (2, 1, 1, 1, 1) \\(1 \\times 0.32 \\times 0.32 \\times 0.32 \\times 0.32 = 0.01048576\\).Now chance animal #15 alive, dead rest study, observing encounter history (2, 1, 1, 1, 1)? chance alive first second winters, dead observing encounter history? . need enumerate possible sequences states compute probability , choose probable sequence, maximum probability. example, need compute \\(2^5 = 32\\) probabilities, \\(N^T\\) general. Needless say, calculations quickly become cumbersome, impossible, number states /number sampling occasions increases.Viterbi algorithm comes . idea decompose overall complex problem sequence smallers problems easier solve30. Viterbi algorithm based fact optimal path winter state can deduced optimal path previous winter state.first winter, probability alive detected 1, probability dead detected 0. Now probability alive second winter non-detected? animal alive first winter, remains alive missed probability \\(1 \\times \\phi (1-p) = 0.32\\). dead first winter, probability 0. maximum probability 0.32 obviously probable scenario alive second winter alive first winter. dead second winter? animal alive first winter, probability \\(1 \\times (1-\\phi) \\times 1 = 0.2\\). dead, probability \\(0 \\times 0 \\times (1-p) = 0\\). maximum probability 0.2 obviously probable scenario dead second winter alive first winter. calculations third, fourth fifth winters, get probabilities:Finally, get (decode) optimal path, work backwards trace back previous value yielded maximum probability. probable state last winter dead (1 > 0.05308416), dead fourth winter (1 > 0.110592), dead third winter (1 > 0.2304), alive second winter (1 > 0.48) alive firt winter (1 > 0). According Viterbi algorithm, sequence states likelily generated sequence observations (2, 1, 1, 1, 1) alive dead, dead, dead dead (1 2 2 2 2). differs slightly actual sequence states (1, 1, 2, 2, 2) state second winter decoded dead animal #15 dies third winter.contrast brute force approach, calculations duplicated stored used like forward algorithm. Briefly speaking, Viterbi algorithm works like forward algorithm sums replaced calculating maximums.practice, Viterbi algorithm works illustrated Figure 3.1. First initialize procedure calculating \\(t=1\\) states \\(j=1,\\ldots,N\\) values \\(\\nu_1(j) = Pr(z_1 = j) \\omega_{j,y_1}\\). compute states \\(j=1,\\ldots,N\\) values \\(\\nu_t(j) = \\displaystyle{\\max_{=1,\\ldots,N} \\nu_{t-1}() \\gamma_{,j} \\omega_{j,y_t}}\\) \\(t = 2, \\ldots, T\\). time \\(t\\) determine probability best path ending states \\(j=1,\\ldots,N\\). Finally, compute probability best global path \\(\\displaystyle{\\max_{j=1,\\ldots,N}\\nu_T(j)}\\).\nFigure 3.1: Graphical representation Viterbi algorithm \\(\\phi = 0.8\\) \\(p = 0.6\\). States alive \\(z = 1\\) dead \\(z = 2\\) observations non-detected \\(y = 1\\) detected \\(y = 2\\). done properly w/ tikz.\n","code":""},{"path":"hmmcapturerecapture.html","id":"implementation","chapter":"3 Hidden Markov models","heading":"3.10.2 Implementation","text":"Let’s write R function implement Viterbi algorithm. parameters, function take transition observation matrices, vector initial state probabilities observed sequence detections non-detections aim compute sequence states likely generated:Note instead writing R function, use built-function existing R package implement Viterbi algorithm31, call NIMBLE seen Section 2.4.2. difficulty HMM capture-recapture data specific features make standard functions adapted requires coding Viterbi function. particular, deal detection first encounter, estimated always one individual captured marked released first time. Also, transition observation matrices always homogeneous may depend time.Let’s test getViterbi() function previous example. Remember animal #15 encounter history (2, 1, 1, 1, 1) generated sequence states (1, 1, 2, 2, 2). Applying function animal encounter history, get:Viterbi algorithm pretty well recovering latent states, despite incorrectly decoding death second winter individual #15 dies third winter. obtained results implementing Viterbi algorithm hand Section 3.10.1.Now function implements Viterbi algorithm, can use MCMC outputs. two options, either apply Viterbi MCMC iteration compute posterior median mode path individual, compute posterior mean median transition observation matrices apply Viterbi individual encounter history.options, need values posterior distributions survival detection probabilities:","code":"\n# getViterbi() returns sequence of states that most likely generated sequence of observations\n# adapted from https://github.com/vbehnam/viterbi\ngetViterbi <- function(Omega, Gamma, delta, y) {\n# Omega: transition matrix\n# Gamma: observation matrix\n# delta: vector of initial state probabilities\n# y: observed sequence of detections and non-detections\n  \n# get number of states and sampling occasions\nN <- nrow(Gamma)\nT <- length(y)\n  \n# nu is the corresponding likelihood\nnu <- matrix(0, nrow = N, ncol = T)\n# zz contains the most likely states up until this point\nzz <- matrix(0, nrow = N, ncol = T)\nfirstObs <- y[1]\n  \n# fill in first columns of both matrices\n#nu[,1] <- initial * emission[,firstObs]\n#zz[,1] <- 0\nnu[,1] <- c(1,0) # initial = (1, 0) * emission[,firstObs] = (1, 0)\nzz[,1] <- 1 # alive at first occasion\n\nfor (i in 2:T) {\n    for (j in 1:N) {\n      obs <- y[i]\n      # initialize to -1, then overwritten by for loop coz all possible values are >= 0\n      nu[j,i] <- -1\n      # loop to find max and argmax for k\n      for (k in 1:N) {\n        value <- nu[k,i-1] * Gamma[k,j] * Omega[j,obs]\n        if (value > nu[j,i]) {\n          # maximizing for k\n          nu[j,i] <- value\n          # argmaximizing for k\n          zz[j,i] <- k\n        }\n      }\n    }\n  }\n  # mlp = most likely path\n  mlp <- numeric(T)\n  # argmax for stateSeq[,T]\n  am <- which.max(nu[,T])\n  mlp[T] <- zz[am,T]\n  \n  # backtrace using backpointers\n  for (i in T:2) {\n    zm <- which.max(nu[,i])\n    mlp[i-1] <- zz[zm,i]\n  }\n  return(mlp)\n}\ndelta # Vector of initial states probabilities\n## [1] 1 0\nGamma # Transition matrix\n##      [,1] [,2]\n## [1,]  0.8  0.2\n## [2,]  0.0  1.0\nOmega # Observation matrix\n##      [,1] [,2]\n## [1,]  0.4  0.6\n## [2,]  1.0  0.0\ngetViterbi(Omega = Omega, \n           Gamma = Gamma, \n           delta = delta, \n           y = y[15,] + 1)\n## [1] 1 2 2 2 2\nphi <- c(mcmc.output$chain1[,'phi'], mcmc.output$chain2[,'phi'])\np <- c(mcmc.output$chain1[,'p'], mcmc.output$chain2[,'p'])"},{"path":"hmmcapturerecapture.html","id":"compute-average","chapter":"3 Hidden Markov models","heading":"3.10.3 Compute first, average after","text":"First option apply Viterbi MCMC sample, compute median MCMC Viterbi paths observed sequence:\nFigure 3.2: Comparison actual sequences states sequences states decoded Viterbi average first, compute method.\nDecoding correct except alive actual state often decoded dead state Viterbi algorithm. Note compute Viterbi paths run NIMBLE. turn R function getViterbi() NIMBLE function plug model code apply Viterbi. make difference except perhaps increase MCMC computation times.","code":"\nniter <- length(p)\nT <- 5\nres <- matrix(NA, nrow = nrow(y), ncol = T)\nfor (i in 1:nrow(y)){\n  res_mcmc <- matrix(NA, nrow = niter, ncol = T)\n  for (j in 1:niter){\n    # Initial states\n    delta <- c(1, 0)\n    # Transition matrix\n    transition <- matrix(NA, 2, 2)\n    transition[1,1] <- phi[j]      # Pr(alive t -> alive t+1)\n    transition[1,2] <- 1 - phi[j]  # Pr(alive t -> dead t+1)\n    transition[2,1] <- 0        # Pr(dead t -> alive t+1)\n    transition[2,2] <- 1        # Pr(dead t -> dead t+1)\n    # Observation matrix \n    emission <- matrix(NA, 2, 2)\n    emission[1,1] <- 1 - p[j]      # Pr(alive t -> non-detected t)\n    emission[1,2] <- p[j]          # Pr(alive t -> detected t)\n    emission[2,1] <- 1          # Pr(dead t -> non-detected t)\n    emission[2,2] <- 0          # Pr(dead t -> detected t)\n    res_mcmc[j,1:T] <- getViterbi(emission, transition, delta, y[i,] + 1)\n  }\n  res[i, 1:length(y[1,])] <- apply(res_mcmc, 2, median)\n}"},{"path":"hmmcapturerecapture.html","id":"average-first-compute-after","chapter":"3 Hidden Markov models","heading":"3.10.4 Average first, compute after","text":"Second option compute posterior mean observation transition matrices, apply Viterbi:\nFigure 3.3: Comparison actual sequences states sequences states decoded Viterbi compute first, average approach.\nresults similar obtained Section 3.10.3, Figure 3.3 indisguishable Figure 3.2.","code":"\n# Initial states\ndelta <- c(1, 0)\n# Transition matrix\ntransition <- matrix(NA, 2, 2)\ntransition[1,1] <- mean(phi)      # Pr(alive t -> alive t+1)\ntransition[1,2] <- 1 - mean(phi)  # Pr(alive t -> dead t+1)\ntransition[2,1] <- 0              # Pr(dead t -> alive t+1)\ntransition[2,2] <- 1              # Pr(dead t -> dead t+1)\n# Observation matrix \nemission <- matrix(NA, 2, 2)\nemission[1,1] <- 1 - mean(p)      # Pr(alive t -> non-detected t)\nemission[1,2] <- mean(p)          # Pr(alive t -> detected t)\nemission[2,1] <- 1                # Pr(dead t -> non-detected t)\nemission[2,2] <- 0                # Pr(dead t -> detected t)\nres <- matrix(NA, nrow = nrow(y), ncol = T)\nfor (i in 1:nrow(y)){\n  res[i, 1:length(y[1,]) ] <- getViterbi(emission, transition, delta, y[i,] + 1)\n}"},{"path":"hmmcapturerecapture.html","id":"summary-2","chapter":"3 Hidden Markov models","heading":"3.11 Summary","text":"HMM model consists two parts: ) unobserved sequence discrete random variables - states - satisfying Markovian property (future states depends current states past states) ii) observed sequence discrete random variables - observations - depending current state.HMM model consists two parts: ) unobserved sequence discrete random variables - states - satisfying Markovian property (future states depends current states past states) ii) observed sequence discrete random variables - observations - depending current state.Bayesian approach together MCMC simulations allow estimating survival detection probabilities well individual latent states alive dead complete likelihood. can afford computation times, using complete likelihood easiest path model fitting.Bayesian approach together MCMC simulations allow estimating survival detection probabilities well individual latent states alive dead complete likelihood. can afford computation times, using complete likelihood easiest path model fitting.need infer latent states, can use marginal likelihood via forward algorithm. avoiding sample latent states, usually get better mixing faster convergence.need infer latent states, can use marginal likelihood via forward algorithm. avoiding sample latent states, usually get better mixing faster convergence.need infer latent states, afford computation times complete likelihood, can go marginal likelihood conjunction Viterbi algorithm decode latent states.need infer latent states, afford computation times complete likelihood, can go marginal likelihood conjunction Viterbi algorithm decode latent states.computational burden still issue, individuals share encounter history, can use pooled likelihood speed marginal likelihood evaluation MCMC convergence.computational burden still issue, individuals share encounter history, can use pooled likelihood speed marginal likelihood evaluation MCMC convergence.","code":""},{"path":"hmmcapturerecapture.html","id":"suggested-reading-2","chapter":"3 Hidden Markov models","heading":"3.12 Suggested reading","text":"Jurafsky D. Martin J.H. (2021) Hidden Markov models. Speech Language Processing. 3rd edition. Pearson Education UK, 2021.Jurafsky D. Martin J.H. (2021) Hidden Markov models. Speech Language Processing. 3rd edition. Pearson Education UK, 2021.McClintock B.T., Langrock R., Gimenez O., Cam E., Borchers D.L., Glennie R. Patterson T.. (2020), Uncovering ecological state dynamics hidden Markov models. Ecology Letters, 23: 1878-1903.McClintock B.T., Langrock R., Gimenez O., Cam E., Borchers D.L., Glennie R. Patterson T.. (2020), Uncovering ecological state dynamics hidden Markov models. Ecology Letters, 23: 1878-1903.Rabiner L.R. (1989). tutorial hidden Markov models selected applications speech recognition. Proceedings IEEE, 77:257-286.Rabiner L.R. (1989). tutorial hidden Markov models selected applications speech recognition. Proceedings IEEE, 77:257-286.Zucchini W., MacDonald .L. Langrock R. (2016) Hidden Markov Models Time Series: Introduction Using R (2nd ed). Chapman Hall/CRC.","code":""},{"path":"introduction-4.html","id":"introduction-4","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"survival.html","id":"survival","chapter":"4 Survival","heading":"4 Survival","text":"","code":""},{"path":"survival.html","id":"introduction-5","chapter":"4 Survival","heading":"4.1 Introduction","text":"fourth chapter, learn Cormack-Jolly-Seber model allows estimating survival based capture-recapture data. also see deal covariates try explain temporal /individual variation survival. chapter also opportunity illustrate incorporate prior information improve model inference.","code":""},{"path":"survival.html","id":"the-cormack-jolly-seber-cjs-model","chapter":"4 Survival","heading":"4.2 The Cormack-Jolly-Seber (CJS) model","text":"chapter 3, introduced capture-recapture model constant survival detection probabilities formulated HMM fitted data NIMBLE. Historically, however, slightly complicated model first proposed – -called Cormack-Jolly-Seber (CJS) model – survival recapture probabilities time-varying. feature CJS model useful account variation due environmental conditions survival sampling effort detection. Schematically CJS model can represented way:Note states (gray) observations (white) change. still \\(z = 1\\) alive, \\(z = 2\\) dead, \\(y = 1\\) non-detected, \\(y = 2\\) detected.Parameters now indexed time. survival probability defined probability staying alive (“ah, ha, ha, ha, stayin’ alive” like Bee Gees say) interval \\(t\\) \\(t+1\\), \\(\\phi_t = \\Pr(z_{t+1} = 1 | z_t = 1)\\). detection probability defined probability observed \\(t\\) given ’re alive \\(t\\), \\(p_t = \\Pr(y_{t} = 1 | z_t = 1)\\). important bear mind survival operates interval detection occurs specific time (see Section 4.8).CJS model named three statisticians published independently paper introducing less approach, year apart ! fact, Richard Cormack George Jolly working corridor Scotland back 1960’s. meet every day coffee play game together, never mention work aware ’s work.","code":""},{"path":"survival.html","id":"capture-recapture-data","chapter":"4 Survival","heading":"4.3 Capture-recapture data","text":"turn fitting CJS model actual data, let’s talk capture-recapture minute. said Section 3.6.1 animals individually marked. can accomplished two ways, either artificial marks like rings birds ear tags mammals, (non-invasive) natural marks like coat patterns feces DNA sequencing (Figure 4.1).\nFigure 4.1: Animal individual marking. Top-left: rings; Top-right: ear-tags; Bottom left: coat patterns; Bottom right: ADN feces\nThroughout chapter, use data White-throated Dipper (Cinclus cinclus; dipper hereafter) kindly provided Gilbert Marzolin (Figure 4.2). total, 294 dippers known sex wing length captured recaptured 1981 1987 March-June period. Birds least 1 year old initially banded.\nFigure 4.2: White-throated Dipper (Cinclus cinclus)\nmay scroll data :first seven columns years Gilbert went field captured birds. 0 stands non-detection, 1 detection. eighth column informs sex bird, F female M male. last column gives measure wing length first time bird captured.","code":""},{"path":"survival.html","id":"fitting-the-cjs-model-to-the-dipper-data-with-nimble","chapter":"4 Survival","heading":"4.4 Fitting the CJS model to the dipper data with NIMBLE","text":"write NIMBLE code corresponding CJS model, need make adjustments NIMBLE code model constant parameters Section 3.7. main modification concerns observation transition matrices need make time-varying. matrices therefore become arrays inherit third dimension besides rows columns. Also need priors time-varying survival detection probabilities. write:likelihood change, except time-varying observation transition matrices need used appropriately. Also, now deal several cohorts animals first captured, marked released year (contrast single cohort Chapter 3), need start loop time first capture individual. Therefore, write:Overall, code looks like:read data:get occasion first capture individuals, finding position detections encounter history ((x !=0)), keeping first one:Now specify constants:Now put data list. add 1 data code non-detections 1’s detections 2’s (see Section @ref{fittinghmmnimble}).Now let’s write function initial values. latent states, go easy way, say individuals alive study period:specify parameters like monitor:provide MCMC details:Now ready run NIMBLE:may look numerical summaries:much time variation detection probability estimated high around 0.90. Note p[1] corresponds detection probability 1982 \\(p_2\\), p[2] detection 1983 therefore \\(p_3\\), . contrast, dippers seem experienced decrease survival years 1982-1983 (phi[2]) 1983-1984 (phi[4]). get back Section 4.8.may noticed small effective sample size last survival (phi[6]) detection (p[6]) probabilities. Let’s look mixing parameter phi[6] example:Clearly mixing (left panel plot ) bad big overlap prior posterior parameter (right panel) suggesting prior well updated data. going ? inspect likelihood CJS model, realise two parameters \\(\\phi_6\\) \\(p_7\\) appear product \\(\\phi_6 p_7\\) estimated separately. words, one parameters redundant, ’d need extra sampling occasion able disentangle . big issue long ’re aware attempt ecologically interpret parameters.","code":"\n...\n# parameters\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n...\n...\n# likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n...\nhmm.phitpt <- nimbleCode({\n  # parameters\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})\ndipper <- read_csv(here::here(\"dat\", \"dipper.csv\"), show_col_types = FALSE)\ny <- dipper %>%\n  select(year_1981:year_1987) %>%\n  as.matrix()\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nmy.constants <- list(N = nrow(y),   # number of animals\n                     T = ncol(y),   # number of sampling occasions\n                     first = first) # first capture for all animales\nmy.constants\n## $N\n## [1] 294\n## \n## $T\n## [1] 7\n## \n## $first\n##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n##  [28] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n##  [55] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n##  [82] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n## [109] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4\n## [136] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n## [163] 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n## [190] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6\n## [217] 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n## [244] 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n## [271] 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\nmy.data <- list(y = y + 1)\nzinits <- y + 1 # non-detection -> alive\nzinits[zinits == 2] <- 1 # dead -> alive\ninitial.values <- function() list(phi = runif(my.constants$T-1,0,1),\n                                  p = runif(my.constants$T-1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"phi\", \"p\")\nn.iter <- 5000\nn.burnin <- 1000\nn.chains <- 2\nmcmc.phitpt <- nimbleMCMC(code = hmm.phitpt,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains)\nMCMCsummary(mcmc.phitpt, params = c(\"phi\",\"p\"), round = 2)\n##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi[1] 0.73 0.14 0.46 0.72  0.99 1.02   199\n## phi[2] 0.45 0.07 0.32 0.44  0.59 1.02   410\n## phi[3] 0.48 0.06 0.35 0.48  0.59 1.01   506\n## phi[4] 0.63 0.06 0.52 0.63  0.75 1.03   415\n## phi[5] 0.60 0.06 0.49 0.60  0.72 1.01   365\n## phi[6] 0.74 0.13 0.51 0.74  0.97 1.10    38\n## p[1]   0.66 0.14 0.38 0.67  0.89 1.01   344\n## p[2]   0.87 0.08 0.68 0.89  0.98 1.02   249\n## p[3]   0.88 0.07 0.73 0.89  0.97 1.02   307\n## p[4]   0.87 0.06 0.74 0.88  0.96 1.05   333\n## p[5]   0.90 0.05 0.77 0.91  0.98 1.01   224\n## p[6]   0.72 0.13 0.50 0.72  0.97 1.08    37\npriors <- runif(3000, 0, 1)\nMCMCtrace(object = mcmc.phitpt,\n          ISB = FALSE,\n          exact = TRUE, \n          params = c(\"phi[6]\"),\n          pdf = FALSE, \n          priors = priors)"},{"path":"survival.html","id":"cjs-model-derivatives","chapter":"4 Survival","heading":"4.5 CJS model derivatives","text":"Besides model considered constant parameters (see Chapter 3) CJS model time-varying parameters, might want fit -models time variation either detection survival.Let’s start model time-varying survival constant detection. modify CJS model NIMBLE code longer observation matrix time-specific:obtain following numerical summaries parameters, confirming high detection temporal variation survival:Now model time-varying detection constant survival, NIMBLE code constant time transition matrix:Numerical summaries parameters :note two models longer parameter redundancy issues. left four models, saying different story data, temporal variation either survival detection probabilty. quantify plausible four ecological hypotheses? Rendez-vous next section.","code":"\nhmm.phitp <- nimbleCode({\n  for (t in 1:(T-1)){\n    phi[t] ~ dunif(0, 1) # prior survival\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi[1] 0.63 0.10 0.42 0.63  0.82 1.04   564\n## phi[2] 0.46 0.06 0.35 0.46  0.59 1.01   629\n## phi[3] 0.48 0.05 0.37 0.48  0.59 1.00   610\n## phi[4] 0.62 0.06 0.51 0.62  0.73 1.00   553\n## phi[5] 0.61 0.05 0.50 0.61  0.72 1.00   568\n## phi[6] 0.59 0.05 0.48 0.59  0.69 1.03   463\n## p      0.89 0.03 0.82 0.89  0.95 1.04   211\nhmm.phipt <- nimbleCode({\n  phi ~ dunif(0, 1) # prior survival\n  gamma[1,1] <- phi      # Pr(alive t -> alive t+1)\n  gamma[1,2] <- 1 - phi  # Pr(alive t -> dead t+1)\n  gamma[2,1] <- 0        # Pr(dead t -> alive t+1)\n  gamma[2,2] <- 1        # Pr(dead t -> dead t+1)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    p[t] ~ dunif(0, 1) # prior detection\n    omega[1,1,t] <- 1 - p[t]    # Pr(alive t -> non-detected t)\n    omega[1,2,t] <- p[t]        # Pr(alive t -> detected t)\n    omega[2,1,t] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2,t] <- 0        # Pr(dead t -> detected t)\n  }\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1])\n    }\n  }\n})##      mean   sd 2.5%  50% 97.5% Rhat n.eff\n## phi  0.56 0.03 0.52 0.56  0.61 1.02   381\n## p[1] 0.75 0.12 0.48 0.77  0.93 1.03   452\n## p[2] 0.85 0.08 0.68 0.86  0.97 1.02   359\n## p[3] 0.85 0.07 0.69 0.85  0.96 1.00   316\n## p[4] 0.89 0.05 0.77 0.89  0.97 1.00   412\n## p[5] 0.91 0.04 0.82 0.92  0.98 1.00   376\n## p[6] 0.90 0.07 0.73 0.91  1.00 1.07   111"},{"path":"survival.html","id":"waic","chapter":"4 Survival","heading":"4.6 Model comparison with WAIC","text":"four models best supported data? answer question, need bear mind used observed data fit models, close truth models perform predicting future data – predictive accuracy – assessed. natural candidate measure predictive accuracy likelihood often referred context model comparison predictive density. However, know neither true process, future data, can estimate predictive density bias.may heard Akaike Information Criterion (AIC) Frequentist framework, Deviance Information Criterion (DIC) Bayesian framework. consider Widely Applicable Information Criterion Watanabe Information Criterion (WAIC). AIC, DIC WAIC aim provide approximation predictive accuracy.AIC predictive measure choice Frequentist framework ecologists, DIC around time Bayesian applications due availability population BUGS pieces software. However, methods utilize point estimate unknown parameters. Also, various difficulties noted DIC may give nonsensical results posterior distribution well summarized mean. fully Bayesian approach like use entire posterior distribution evaluate predictive performance, exactly WAIC .Conveniently, NIMBLE calculates WAIC . modifications need make ) monitor nodes, including latent states ii) add WAIC = TRUE call nimbleMCMC() function. example, CJS model, write:re-ran four models calculate WAIC value themLower values WAIC imply higher predictive accuracy, thefore favor model constant parameters.","code":"\nparameters.to.save <- c(\"phi\", \"p\", \"z\") \nmcmc.phitpt <- nimbleMCMC(code = hmm.phitpt,\n                          constants = my.constants,\n                          data = my.data,\n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin,\n                          nchains = n.chains,\n                          WAIC = TRUE) ##                                         model  WAIC\n## 1          both survival & detection constant 265.9\n## 2 time-dependent survival, constant detection 277.6\n## 3 constant survival, time-dependent detection 270.2\n## 4    both survival & detection time-dependent 308.8"},{"path":"survival.html","id":"gof","chapter":"4 Survival","heading":"4.7 Goodness of fit","text":"previous section, Section 4.6, compared models based predictive accuracy – assessed relative fit. However, even though able rank models according predictive accuracy, happen models actually poor predictive performance – absolute fit.assess goodness fit CJS model capture-recapture data? particular assess homogeneity survival detection probabilities fundamental assumption model?","code":""},{"path":"survival.html","id":"posterior-predictive-checks","chapter":"4 Survival","heading":"4.7.1 Posterior predictive checks","text":"Bayesian framework, rely posterior predictive checks assess absolute fit. Briefly speaking, idea compare observed data replicated data generated model. model good fit data, replicated data predicted model look similar observed data. simplify comparison, summary statistics generally used. CJS model, use -called m-array gathers elements \\(m_{ij}\\) number marked individuals initially released time \\(\\) first detected time \\(j\\). include example? yes, refer paper Paganin & de Valpine use code https://github.com/salleuska/fastCPPP","code":""},{"path":"survival.html","id":"classical-tests","chapter":"4 Survival","heading":"4.7.2 Classical tests","text":"Frequentist literature, well established procedures assessing absolute fit departures specific CJS model assumptions shame just ignore.focus two assumptions ecological interpretation, transience trap-dependence. transience procedure assesses whether newly encountered individuals (‘new’ individuals) chance later re-observed recaptured (previously encountered) individuals (‘old’ individuals). trap-dependence procedure assesses whether missed individuals chance recaptured next occasion currently captured individuals. Although procedures called test transience test trap-dependence, comes interpretation, keep mind transience – excess individuals never seen – trap-dependence – effect trapping detection – just two specific reasons tests might detect lack fit.tests implemented package R2ucare, illustrate use dipper data.get capture-recapture data:sake illustration, consider females :overall test shows reject hypothesis CJS models fits data well:may perform test specifically assess transient effect:trap-dependence:tests significant? Transience may occur animals transit belong study population (true transients), reproduce die permanently disperse (cost first reproduction), die permanently disperse due effect marking (marking effect). transient individuals never detected initial capture, means zero probability local survival initial capture. suggests way account transience issue cover case study (see transience case study).Trap-dependence may occur animals affected (positively negatively) trapping (true trap-dependence), observers tend visit parts study area often individuals detected (preferential sampling), patches heterogeneous habitat accessible individuals stationed higher detection probabilities (access bias), age, sex social status unknown, determine individual movements activity patterns susceptibility detected varies (individual heterogeneity), non random temporary emigration occurs (skipped reproduction). Trap-dependence therefore designates correlation detection events. account trap-dependence issue, correlation needs accounted , show case study (see trap dep case study).","code":"\nlibrary(R2ucare)\n# capture-recapture data\ndipper <- read_csv(here::here(\"dat\", \"dipper.csv\"))\ndip.hist <- dipper %>%\n  select(year_1981:year_1987) %>%\n  as.matrix()\n# number of birds with that particular capture-recapture history\ndip.freq <- rep(1, nrow(dip.hist))\n# sex of each bird\ndip.group <- dipper$sex\nmask <- (dip.group == 'F')\ndip.fem.hist <- dip.hist[mask,]\ndip.fem.freq <- dip.freq[mask]\noverall_CJS(dip.fem.hist, dip.fem.freq)\n##                          chi2 degree_of_freedom p_value\n## Gof test for CJS model: 10.28                12   0.592\ntest3sr(dip.fem.hist, dip.fem.freq)\n## $test3sr\n##      stat        df     p_val sign_test \n##     4.985     5.000     0.418     1.428 \n## \n## $details\n##   component  stat p_val signed_test  test_perf\n## 1         2 0.858 0.354       0.926 Chi-square\n## 2         3 3.586 0.058       1.894 Chi-square\n## 3         4 0.437 0.509       0.661 Chi-square\n## 4         5 0.103 0.748      -0.321 Chi-square\n## 5         6 0.001 0.982       0.032 Chi-square\ntest2ct(dip.fem.hist, dip.fem.freq)\n## $test2ct\n##      stat        df     p_val sign_test \n##     3.250     4.000     0.517    -0.901 \n## \n## $details\n##   component dof stat p_val signed_test test_perf\n## 1         2   1    0     1           0    Fisher\n## 2         3   1    0     1           0    Fisher\n## 3         4   1    0     1           0    Fisher\n## 4         5   1 3.25 0.071      -1.803    Fisher"},{"path":"survival.html","id":"design-considerations","chapter":"4 Survival","heading":"4.7.3 Design considerations","text":"far, addressed assumptions relative model. also assumptions relative design. particular, survival refers study area, need think carefully survival actually mean. actually estimate usually call apparent survival, exactly true survival. Apparent survival probability product true survival study area fidelity. Consequently, apparent survival always lower true survival unless study area fidelity exactly 1.\nassumptions relative design, simply list . mark loss, identity individuals recorded without error (false positives), captured animals random sample population.","code":""},{"path":"survival.html","id":"covariates","chapter":"4 Survival","heading":"4.8 Covariates","text":"models considered far, survival detection probabilities may vary time, include ecological drivers might explain variation. Luckily, spirit generalized linear models, can make parameters dependent external covariates time, environmental conditions survival sampling effort detection.Besides variation time, also cover individual variation parameters, example survival vary according sex phenotypic characteristics (e.g. size body mass).Let’s illustrate use covariates dipper example.","code":""},{"path":"survival.html","id":"temporal-covariates","chapter":"4 Survival","heading":"4.8.1 Temporal covariates","text":"","code":""},{"path":"survival.html","id":"discrete","chapter":"4 Survival","heading":"4.8.1.1 Discrete","text":"major flood occurred 1983 breeding season (October 1982 May 1983). captures breding season occurred flood, survival two years 1982-1983 1983-1984 likely affected. Indeed survival species living along feeding river two flood years likely lower nonflood years.Let’s use covariate \\(\\text{flood}\\) contains 1s 2s, indicating whether flood nonflood year year: 1 nonflood year, 2 flood year.write model code:use nested indexing specifying survival transition matrix. E.g. year \\(t = 2\\), phi[flood[t]] gives phi[flood[2]] phi[2] flood[2] 2 flood year.Let’s provide constants list:function generate initial values:parameters monitored:’re set, ready run NIMBLE:look numerical summaries, see expected, survival flood years (phi[2]) much lower survival non-flood years (phi[1]):important point formulated ecological hypothesis translated model. next step consist calculating WAIC model compare four model fitted far (see Section 4.6).Another method include discrete covariate consists considering effect difference levels. example, consider survival nonflood years reference test difference survival flood years., write survival linear function covariate scale, e.g. \\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 \\;\\text{flood}_t\\) \\(\\beta\\)’s regression coefficient need estimate (intercept \\(\\beta_1\\) slope \\(\\beta_2\\)), \\(\\displaystyle{\\text{logit}(x) = \\log \\left(\\frac{x}{1-x}\\right)}\\) logit function. logit function lives \\(-\\infty\\) \\(+\\infty\\), sends values 0 1 onto real line. example \\(\\log(0.2/(1-0.2))=-1.39\\), \\(\\log(0.5/(1-0.5))=0\\) \\(\\log(0.8/(1-0.8))=1.39\\). use logit function? survival probability bounded 0 1, used directly \\(\\phi_t = \\beta_1 + \\beta_2 \\;\\text{flood}_t\\) might end estimates regression coefficients make survival bound. Therefore, consider survival linear function covariates scale logit function, working real line, back-transform using inverse-logit (reciprocal function) obtain survival natural scale. inverse-logit function \\(\\displaystyle{\\text{logit}^{-1}(x) = \\frac{\\exp(x)}{1+\\exp(x)} = \\frac{1}{1+\\exp(-x)}}\\). logit function often called link function like generalized linear models.Another point attention prior assign regression coefficients. longer assign prior survival directly like previously, need assign prior \\(\\beta\\)’s induce prior survival. sometimes, priors regression coefficients non-informative, prior survival . Consider example case single intercept covariate. assign prior regression coefficient normal distribution mean 0 large standard deviation, first reflex, end informative prior survival bathtub shape, putting much importance low high values:Now go lower standard deviation intercept prior, prior survival non-informative, looking like uniform distribution 0 1:Now let’s go back model. first define flood covariate 0 nonflood year, 1 flood year.write NIMBLE code:wrote \\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 \\; \\text{flood}_t\\), meaning survival nonflood years (\\(\\text{flood}_t = 0\\)) \\(\\text{logit}(\\phi_t) = \\beta_1\\) survival flood years (\\(\\text{flood}_t = 1\\)) \\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2\\). see \\(\\beta_1\\) survival nonflood years (logit scale) \\(\\beta_2\\) difference survival flood years survival nonflood years (, logit scale).Let’s put constants list:function generating initial values:parameters monitored.Finaly, may run NIMBLE:may check get numerical summaries survival nonflood years (phi[1], phi[4], phi[5] phi[6]) flood years (phi[2] phi[3]):may also check go \\(\\beta\\)’s survival probabilities \\(\\phi\\). Let’s get draws posterior distribution \\(\\beta\\)’s first:apply inverse-logit function get survival nonflood years, e.g. posterior mean credible interval:thing survival flood years:","code":"\nflood <- c(1, # 1981-1982 (nonflood)\n           2, # 1982-1983 (flood)\n           2, # 1983-1984 (flood)\n           1, # 1984-1985 (nonflood)\n           1, # 1985-1986 (nonflood)\n           1) # 1986-1987 (nonflood)\nhmm.phifloodp <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    gamma[1,1,t] <- phi[flood[t]]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[flood[t]]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  phi[1] ~ dunif(0, 1) # prior for survival in nonflood years\n  phi[2] ~ dunif(0, 1) # prior for survival in flood years\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y),\n                     T = ncol(y),\n                     first = first,\n                     flood = flood)\ninitial.values <- function() list(phi = runif(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"p\", \"phi\")\nmcmc.phifloodp <- nimbleMCMC(code = hmm.phifloodp, \n                             constants = my.constants,\n                             data = my.data,              \n                             inits = initial.values,\n                             monitors = parameters.to.save,\n                             niter = n.iter,\n                             nburnin = n.burnin, \n                             nchains = n.chains)##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p      0.89 0.03 0.83 0.90  0.95    1   609\n## phi[1] 0.61 0.03 0.55 0.61  0.67    1  1474\n## phi[2] 0.47 0.04 0.38 0.47  0.56    1  1700\nMCMCsummary(mcmc.phifloodp, round = 2)\n# 1000 random values from a N(0,10)\nintercept <- rnorm(1000, mean = 0, sd = 10) \n# plogis() is the inverse-logit function in R\nsurvival <- plogis(intercept) \ndf <- data.frame(intercept = intercept, survival = survival)\nplot1 <- df %>%\n  ggplot(aes(x = intercept)) +\n  geom_density() +\n  labs(x = \"prior on intercept\")\nplot2 <- df %>%\n  ggplot(aes(x = survival)) +\n  geom_density() +\n  labs(x = \"prior on survival\")\nplot1 + plot2\nset.seed(123)\n# 1000 random values from a N(0,1.5)\nintercept <- rnorm(1000, mean = 0, sd = 1.5) \n# plogis() is the inverse-logit function in R\nsurvival <- plogis(intercept) \ndf <- data.frame(intercept = intercept, survival = survival)\nplot1 <- df %>%\n  ggplot(aes(x = intercept)) +\n  geom_density() +\n  labs(x = \"prior on intercept\")\nplot2 <- df %>%\n  ggplot(aes(x = survival)) +\n  geom_density() +\n  labs(x = \"prior on survival\")\nplot1 + plot2\nflood <- c(0, # 1981-1982 (nonflood)\n           1, # 1982-1983 (flood)\n           1, # 1983-1984 (flood)\n           0, # 1984-1985 (nonflood)\n           0, # 1985-1986 (nonflood)\n           0) # 1986-1987 (nonflood)\nhmm.phifloodp <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    logit(phi[t]) <- beta[1] + beta[2] * flood[t]\n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  beta[1] ~ dnorm(0, sd = 1.5) # prior intercept\n  beta[2] ~ dnorm(0, sd = 1.5) # prior slope\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y),\n                     T = ncol(y),\n                     first = first,\n                     flood = flood)\ninitial.values <- function() list(beta = rnorm(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"beta\", \"p\", \"phi\")\nmcmc.phifloodp <- nimbleMCMC(code = hmm.phifloodp, \n                             constants = my.constants,\n                             data = my.data,              \n                             inits = initial.values,\n                             monitors = parameters.to.save,\n                             niter = n.iter,\n                             nburnin = n.burnin, \n                             nchains = n.chains)\nMCMCsummary(mcmc.phifloodp, round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.44 0.13  0.17  0.44  0.69 1.01   725\n## beta[2] -0.54 0.22 -0.96 -0.54 -0.11 1.00   770\n## p        0.89 0.03  0.83  0.89  0.94 1.00   631\n## phi[1]   0.61 0.03  0.54  0.61  0.67 1.01   724\n## phi[2]   0.47 0.04  0.39  0.47  0.56 1.00  1597\n## phi[3]   0.47 0.04  0.39  0.47  0.56 1.00  1597\n## phi[4]   0.61 0.03  0.54  0.61  0.67 1.01   724\n## phi[5]   0.61 0.03  0.54  0.61  0.67 1.01   724\n## phi[6]   0.61 0.03  0.54  0.61  0.67 1.01   724\nbeta1 <- c(mcmc.phifloodp$chain1[,'beta[1]'], # beta1 chain 1\n           mcmc.phifloodp$chain2[,'beta[1]']) # beta1 chain 2\nbeta2 <- c(mcmc.phifloodp$chain1[,'beta[2]'], # beta2 chain 1\n           mcmc.phifloodp$chain2[,'beta[2]']) # beta2 chain 2\nmean(plogis(beta1))\n## [1] 0.6066\nquantile(plogis(beta1), probs = c(2.5, 97.5)/100)\n##   2.5%  97.5% \n## 0.5435 0.6651\nmean(plogis(beta1 + beta2))\n## [1] 0.4744\nquantile(plogis(beta1 + beta2), probs = c(2.5, 97.5)/100)\n##   2.5%  97.5% \n## 0.3895 0.5606"},{"path":"survival.html","id":"continuous","chapter":"4 Survival","heading":"4.8.1.2 Continuous","text":"Instead discrete covariate varying time, may want consider continuous covariate, say \\(x_t\\), \\(\\text{logit}(\\phi_t) = \\beta_1 + \\beta_2 x_t\\). example, let’s investigate effect water flow dipper survival, reflect flood occurred 1983 breeding season.build covariate water flow liters per second measured March May period year, starting year 1982:need water flow 1981 write probability \\(\\phi_t\\) alive year \\(t + 1\\) given bird alive year \\(t\\) linear function water flow year \\(t + 1\\).may noticed high value water flow 1983, twice much years, corresponding flood. Importantly, standardize covariate improve convergence:Now write model code:put constants list:Initial values usual:parameters monitored:Eventually, run NIMBLE:can look results caterpillar plot regression parameters:posterior distribution slope (beta[2]) centered negative values, suggesting water flow increases, survival decreases.Let’s inspect time-dependent survival probability:Survival 1982 1983 (phi[2]) greatly affected much lower average. decrease corresponds high water flow 1983 flood. results line previous findings obtained considering covariate nonflood vs. flood years.","code":"\n# water flow in L/s\nwater_flow <- c(443,  # March-May 1982\n                1114, # March-May 1983\n                529,  # March-May 1984\n                434,  # March-May 1985\n                627,  # March-May 1986\n                466)  # March-May 1987\nwater_flow_st <- (water_flow - mean(water_flow))/sd(water_flow)\nhmm.phiflowp <- nimbleCode({\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  for (t in 1:(T-1)){\n    logit(phi[t]) <- beta[1] + beta[2] * flow[t] \n    gamma[1,1,t] <- phi[t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,t] <- 1 - phi[t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,t] <- 0        # Pr(dead t -> alive t+1)\n    gamma[2,2,t] <- 1        # Pr(dead t -> dead t+1)\n  }\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  beta[1] ~ dnorm(0, 1.5) # prior intercept\n  beta[2] ~ dnorm(0, 1.5) # prior slope\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y),\n                     T = ncol(y),\n                     first = first,\n                     flow = water_flow_st)\ninitial.values <- function() list(beta = rnorm(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"beta\", \"p\", \"phi\")\nmcmc.phiflowp <- nimbleMCMC(code = hmm.phiflowp, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin, \n                          nchains = n.chains)\nMCMCplot(object = mcmc.phiflowp, params = \"beta\")\nMCMCplot(object = mcmc.phiflowp, params = \"phi\", ISB = TRUE)"},{"path":"survival.html","id":"individual-covariates","chapter":"4 Survival","heading":"4.8.2 Individual covariates","text":"previous section, learnt explain temporal heterogeneity survival detection. Heterogeneity also originate individual differences animals. may think diffence survival males females discrete covariate example, size body mass examples continuous covariate. Let’s illustrate discrete continuous covariates dipper.","code":""},{"path":"survival.html","id":"discrete-1","chapter":"4 Survival","heading":"4.8.2.1 Discrete","text":"first consider covariate \\(\\text{sex}\\) contains 1’s 2’s indicating sex bird: 1 male, 2 female. implement model sex effect using nested indexing, similarly model flood vs. nonflood years. section NIMBLE code needs amended :running NIMBLE, get:Male survival (phi[1]) looks similar female survival (phi[2]). Give entire NIMBLE code? Alternatively, chapter others, provide fragments code emphasize specific point adjustments, file whole code elsewhere convenience, R script. avoid repeating data/constants/initial values/MCMC details/nimble run steps, save space well.","code":"\n...\nfor (i in 1:N){\n  gamma[1,1,i] <- phi[sex[i]]      # Pr(alive t -> alive t+1)\n  gamma[1,2,i] <- 1 - phi[sex[i]]  # Pr(alive t -> dead t+1)\n  gamma[2,1,i] <- 0                # Pr(dead t -> alive t+1)\n  gamma[2,2,i] <- 1                # Pr(dead t -> dead t+1)\n}\nphi[1] ~ dunif(0,1) # male survival\nphi[2] ~ dunif(0,1) # female survival\n...\nMCMCsummary(object = mcmc.phisexp.ni, round = 2)##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p      0.90 0.03 0.84 0.90  0.95    1   643\n## phi[1] 0.57 0.03 0.50 0.57  0.64    1  1668\n## phi[2] 0.55 0.03 0.48 0.55  0.62    1  1482"},{"path":"survival.html","id":"continuous-1","chapter":"4 Survival","heading":"4.8.2.2 Continuous","text":"Besides discrete individual covariates, might want continuous individual covariates, e.g. wing length dipper example. Note ’re considering individual trait takes value whatever occasion. consider wing length , precisely measurement first detection. first standardize covariate:Now write model:put constants list:write function generating initial values:run NIMBLE:Let’s inspect numerical summaries regression parameters:Wing length seem explain much individual--individual variation survival – posterior distribution slope (beta[2]) centered 0 can see credible interval.Let’s plot relationship survival wing length. First, gather values generated posterior distribution regression parameters two chains:define grid values wing length, predict survival MCMC iteration:Now calculate posterior mean credible interval (note ordering):Now time visualize:flat relationship survival wing length confirmed.","code":"\nwing.length.st <- as.vector(scale(dipper$wing_length))\nhead(wing.length.st)\n## [1]  0.7581 -0.8671  0.5260 -1.5637 -1.3315  1.2225\nhmm.phiwlp <- nimbleCode({\n    p ~ dunif(0, 1) # prior detection\n    omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n    omega[1,2] <- p        # Pr(alive t -> detected t)\n    omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i]\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5)\n  beta[2] ~ dnorm(mean = 0, sd = 1.5)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first,\n                     winglength = wing.length.st)\ninitial.values <- function() list(beta = rnorm(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nmcmc.phiwlp <- nimbleMCMC(code = hmm.phiwlp, \n                          constants = my.constants,\n                          data = my.data,              \n                          inits = initial.values,\n                          monitors = parameters.to.save,\n                          niter = n.iter,\n                          nburnin = n.burnin, \n                          nchains = n.chains)\nMCMCsummary(mcmc.phiwlp, params = \"beta\", round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.25 0.10  0.04  0.25  0.45    1  1472\n## beta[2] -0.02 0.09 -0.20 -0.02  0.17    1  1555\nbeta1 <- c(mcmc.phiwlp$chain1[,'beta[1]'], # intercept, chain 1\n           mcmc.phiwlp$chain2[,'beta[1]']) # intercept, chain 2\nbeta2 <- c(mcmc.phiwlp$chain1[,'beta[2]'], # slope, chain 1\n           mcmc.phiwlp$chain2[,'beta[2]']) # slope, chain 2\npredicted_survival <- matrix(NA, \n                             nrow = length(beta1), \n                             ncol = length(my.constants$winglength))\nfor (i in 1:length(beta1)){\n  for (j in 1:length(my.constants$winglength)){\n    predicted_survival[i,j] <- plogis(beta1[i] + \n                               beta2[i] * my.constants$winglength[j])\n  }\n}\nmean_survival <- apply(predicted_survival, 2, mean)\nlci <- apply(predicted_survival, 2, quantile, prob = 2.5/100)\nuci <- apply(predicted_survival, 2, quantile, prob = 97.5/100)\nord <- order(my.constants$winglength)\ndf <- data.frame(wing_length = my.constants$winglength[ord],\n                 survival = mean_survival[ord],\n                 lci = lci[ord],\n                 uci = uci[ord])\ndf %>%\n  ggplot() + \n  aes(x = wing_length, y = survival) + \n  geom_line() + \n  geom_ribbon(aes(ymin = lci, ymax = uci), \n              fill = \"grey70\", \n              alpha = 0.5) + \n  ylim(0,1) + \n  labs(x = \"wing length\", y = \"estimated survival\")"},{"path":"survival.html","id":"several-covariates","chapter":"4 Survival","heading":"4.8.3 Several covariates","text":"may test effect sex wing length. Let’s consider additive effect covariates. use covariate \\(\\text{sex}\\) takes value 0 male, 1 female. \\(\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2 \\text{sex}_i + \\beta_3 \\text{winglength}_i\\) bird \\(\\), male survival \\(\\beta_1 + \\beta_3 \\text{winglength}_i\\) female survival \\(\\beta_1 + \\beta_2 + \\beta_3 \\text{winglength}_i\\) (logit scale). relationship survival wing length parallel males females, logit scale, gap two measured \\(\\beta_2\\) (hence term additive effect).NIMBLE code :put constants data lists:write fuction generate initial values:specify parameters monitored:now run NIMBLE:Let’s display numerical summaries parameters:slope males females. Although posterior mean negative, crebible interval suggest posterior distribution largely encompasses 0, therefore weak signal, .Let’s visualize survival function wing length sexes. First put together values two chains generated posterior distributions regression parameters:get survival estimates MCMC iteration:, may calculate posterior mean credible intervals:Now plot:Note two curves exactly parallel back-transformed linear part relationship survival wing length. may check parallelism occurs logit scale:Show use values covariate de-standardized.Mention interaction bw sex wing length w/ logit(phi[]) <- beta[1] + beta[2] * sex[] + beta[3] * winglength[] + beta[4] * sex[] * winglength[] explain.","code":"\nhmm.phisexwlp <- nimbleCode({\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    logit(phi[i]) <- beta[1] + beta[2] * sex[i] + beta[3] * winglength[i]\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5) # intercept male\n  beta[2] ~ dnorm(mean = 0, sd = 1.5) # difference bw male and female\n  beta[3] ~ dnorm(mean = 0, sd = 1.5) # slope wing length\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nwing.length.st <- as.vector(scale(dipper$wing_length))\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first,\n                     winglength = wing.length.st,\n                     sex = if_else(dipper$sex == \"M\", 0, 1))\nmy.data <- list(y = y + 1)\nzinits <- y\nzinits[zinits == 0] <- 1\ninitial.values <- function() list(beta = rnorm(3,0,2),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"beta\", \"p\")\nmcmc.phisexwlp <- nimbleMCMC(code = hmm.phisexwlp, \n                             constants = my.constants,\n                             data = my.data,              \n                             inits = initial.values,\n                             monitors = parameters.to.save,\n                             niter = n.iter,\n                             nburnin = n.burnin, \n                             nchains = n.chains)\nMCMCsummary(mcmc.phisexwlp, round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.47 0.24 -0.02  0.48  0.94 1.01   102\n## beta[2] -0.43 0.43 -1.28 -0.44  0.46 1.01    85\n## beta[3] -0.19 0.20 -0.60 -0.19  0.22 1.00   106\n## p        0.89 0.03  0.83  0.90  0.94 1.01   643\nbeta1 <- c(mcmc.phisexwlp$chain1[,'beta[1]'], # beta1 chain 1\n           mcmc.phisexwlp$chain2[,'beta[1]']) # beta1 chain 2\nbeta2 <- c(mcmc.phisexwlp$chain1[,'beta[2]'], # beta2 chain 1\n           mcmc.phisexwlp$chain2[,'beta[2]']) # beta2 chain 2\nbeta3 <- c(mcmc.phisexwlp$chain1[,'beta[3]'], # beta3 chain 1\n           mcmc.phisexwlp$chain2[,'beta[3]']) # beta3 chain 2\npredicted_survivalM <- matrix(NA, nrow = length(beta1), \n                              ncol = length(my.constants$winglength))\npredicted_survivalF <- matrix(NA, nrow = length(beta1), \n                              ncol = length(my.constants$winglength))\nfor (i in 1:length(beta1)){\n  for (j in 1:length(my.constants$winglength)){\n    predicted_survivalM[i,j] <- plogis(beta1[i] + \n                                beta3[i] * my.constants$winglength[j]) \n    predicted_survivalF[i,j] <- plogis(beta1[i] + \n                                beta2[i] + \n                                beta3[i] * my.constants$winglength[j])\n  }\n}\nmean_survivalM <- apply(predicted_survivalM, 2, mean)\nlciM <- apply(predicted_survivalM, 2, quantile, prob = 2.5/100)\nuciM <- apply(predicted_survivalM, 2, quantile, prob = 97.5/100)\nmean_survivalF <- apply(predicted_survivalF, 2, mean)\nlciF <- apply(predicted_survivalF, 2, quantile, prob = 2.5/100)\nuciF <- apply(predicted_survivalF, 2, quantile, prob = 97.5/100)\nord <- order(my.constants$winglength)\ndf <- data.frame(wing_length = c(my.constants$winglength[ord], \n                                 my.constants$winglength[ord]),\n                 survival = c(mean_survivalM[ord], \n                              mean_survivalF[ord]),\n                 lci = c(lciM[ord],lciF[ord]),\n                 uci = c(uciM[ord],uciF[ord]),\n                 sex = c(rep(\"male\", length(mean_survivalM)), \n                         rep(\"female\", length(mean_survivalF))))\ndf %>%\n  ggplot() + \n  aes(x = wing_length, y = survival, color = sex) + \n  geom_line() + \n  geom_ribbon(aes(ymin = lci, ymax = uci, fill = sex), alpha = 0.5) + \n  ylim(0,1) + \n  labs(x = \"wing length\", y = \"estimated survival\", color = \"\", fill = \"\")\npredicted_lsurvivalM <- matrix(NA, nrow = length(beta1), \n                              ncol = length(my.constants$winglength))\npredicted_lsurvivalF <- matrix(NA, nrow = length(beta1), \n                              ncol = length(my.constants$winglength))\nfor (i in 1:length(beta1)){\n  for (j in 1:length(my.constants$winglength)){\n    predicted_lsurvivalM[i,j] <- beta1[i] + beta3[i] * my.constants$winglength[j] \n    predicted_lsurvivalF[i,j] <- beta1[i] + beta2[i] + beta3[i] * my.constants$winglength[j]\n  }\n}\nmean_lsurvivalM <- apply(predicted_lsurvivalM, 2, mean)\nmean_lsurvivalF <- apply(predicted_lsurvivalF, 2, mean)\nord <- order(my.constants$winglength)\ndf <- data.frame(wing_length = c(my.constants$winglength[ord], \n                                 my.constants$winglength[ord]),\n                 survival = c(mean_lsurvivalM[ord], \n                              mean_lsurvivalF[ord]),\n                 sex = c(rep(\"male\", length(mean_lsurvivalM)), \n                         rep(\"female\", length(mean_lsurvivalF))))\ndf %>%\n  ggplot() + \n  aes(x = wing_length, y = survival, color = sex) + \n  geom_line() + \n  ylim(-2,2) + \n  labs(x = \"wing length\", \n       y = \"estimated survival (on the lgit scale)\", \n       color = \"\")"},{"path":"survival.html","id":"random-effects","chapter":"4 Survival","heading":"4.8.4 Random effects","text":"individual variation survival fully explained covariates, may add random effects \\(\\text{logit}(\\phi_i) = \\beta_1 + \\beta_2 x_i + \\varepsilon_i\\) \\(\\varepsilon_i \\sim N(0,\\sigma^2)\\). consider individual variation section, reasoning holds temporal variation. essence, treating individual survival probabilities \\(\\phi_i\\) sample population survival probabilities, assume normal distribution mean linear component (without covariate) standard deviation \\(\\sigma\\). variation unexplained covariate \\(x_i\\) measured variation \\(\\sigma\\) residuals \\(\\varepsilon_i\\). Ignoring individual heterogeneity generated individuals contrasted performances life may mask senescence hamper understanding life history trade-offs.Overall, failing incorporate unexplained residual variance may induce bias parameter estimates lead detecting effect covariate often .Let’s go back dipper example wing length covariate, write NIMBLE code:prior standard deviation random effect uniform 0 10. Explain pick prior SD.now write function generating initial values:specify parameters monitored:increase number iterations length burn-period reach better convergence:finally, run NIMBLE:inspect numerical summaries:effective sample size standard deviation random effect low. Let’s try something else. use non-centering reparameterize model. Explain.running NIMBLE, inspect numerical summaries, see effective sample sizes much better:","code":"\nhmm.phiwlrep <- nimbleCode({\n    p ~ dunif(0, 1) # prior detection\n    omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n    omega[1,2] <- p        # Pr(alive t -> detected t)\n    omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n    omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i] + eps[i]\n    eps[i] ~ dnorm(mean = 0, sd = sdeps)\n    gamma[1,1,i] <- phi[i]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i] <- 1 - phi[i]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i] <- 1           # Pr(dead t -> dead t+1)\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5)\n  beta[2] ~ dnorm(mean = 0, sd = 1.5)\n  sdeps ~ dunif(0, 10)\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\ninitial.values <- function() list(beta = rnorm(2,0,1.5),\n                                  sdeps = runif(1,0,3),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"beta\", \"sdeps\", \"p\")\nn.iter <- 10000\nn.burnin <- 5000\nn.chains <- 2\nmcmc.phiwlrep <- nimbleMCMC(code = hmm.phiwlrep, \n                            constants = my.constants,\n                            data = my.data,              \n                            inits = initial.values,\n                            monitors = parameters.to.save,\n                            niter = n.iter,\n                            nburnin = n.burnin, \n                            nchains = n.chains)\nMCMCsummary(mcmc.phiwlrep, round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.22 0.12 -0.02  0.22  0.44 1.24  1335\n## beta[2] -0.01 0.10 -0.20 -0.01  0.19 1.02  1894\n## p        0.90 0.03  0.84  0.90  0.95 1.03   752\n## sdeps    0.27 0.25  0.01  0.16  0.83 4.68    12...\n  for (i in 1:N){\n    logit(phi[i]) <- beta[1] + beta[2] * winglength[i] + sdeps * eps[i]\n    eps[i] ~ dnorm(mean = 0, sd = 1)\n...\nMCMCsummary(mcmc.phiwlrep, round = 2)##          mean   sd  2.5%   50% 97.5% Rhat n.eff\n## beta[1]  0.21 0.12 -0.04  0.21  0.43 1.00  1202\n## beta[2] -0.01 0.10 -0.20 -0.01  0.19 1.00  1789\n## p        0.90 0.03  0.83  0.90  0.95 1.01   790\n## sdeps    0.40 0.26  0.02  0.37  0.95 1.01   170"},{"path":"survival.html","id":"individual-time-varying-covariates","chapter":"4 Survival","heading":"4.8.5 Individual time-varying covariates","text":"far, allowed covariates vary along single dimension, either time individual. need consider covariate varies one animal , time. Think age example, value specific individual, (sadly) changes time.Age particular meaning capture-recapture framework. time elapsed since first encounter, proxy true age, true age. age known first encounter, true age. example, dippers marked young, true biological age bird.convenient thing age missing value age \\(t+1\\) just age \\(t\\) add 1. suggests way code age effect NIMBLE follows:used equals(t, first[]) renders 1 \\(t\\) first encounter 0 otherwise. Therefore distinguish survival first interval first encounter \\(\\phi_1\\) (logit(phi[,t]) <- beta[1] + beta[2]) survival afterwards \\(\\phi_{1+}\\) (logit(phi[,t]) <- beta[1]).put constants list:data list:write function generate initial values:specify parameters monitored:now run NIMBLE:display results:Age time elapsed since first encounter seem effect survival .Another method include age effect create individual time covariate use nested indexing (flood/nonflood example) distinguish survival interval first detection survival afterwards:Now may write NIMBLE code model. just need remember survival longer defined logit scale previous model, use uniform priors:put constants list, including age covariate:re-write function generate initial values:run NIMBLE:display numerical summaries model parameters, acknowledge obtain similar results parameterization:Like mentioned earlier, age easy deal contain missing values. Now think size body mass minute. problem record size body mass animal non-detected. easiest way cope individual time-varying covariates discretize e.g. small, medium large Chapter 5. Another option come model covariate fill missing values simulating model (see case study).","code":"\nhmm.phiage.in <- nimbleCode({\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    for (t in first[i]:(T-1)){\n    # phi1 = beta1 + beta2; phi1+ = beta1\n    logit(phi[i,t]) <- beta[1] + beta[2] * equals(t, first[i]) \n    gamma[1,1,i,t] <- phi[i,t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i,t] <- 1 - phi[i,t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i,t] <- 0             # Pr(dead t -> alive t+1)\n    gamma[2,2,i,t] <- 1             # Pr(dead t -> dead t+1)\n    }\n  }\n  beta[1] ~ dnorm(mean = 0, sd = 1.5) # phi1+\n  beta[2] ~ dnorm(mean = 0, sd = 1.5) # phi1 - phi1+\n  phi1plus <- plogis(beta[1])         # phi1+\n  phi1 <- plogis(beta[1] + beta[2])   # phi1\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first)\nmy.data <- list(y = y + 1)\nzinits <- y\nzinits[zinits == 0] <- 1\ninitial.values <- function() list(beta = rnorm(2,0,5),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nparameters.to.save <- c(\"phi1\", \"phi1plus\", \"p\")\nmcmc.phi.age.in <- nimbleMCMC(code = hmm.phiage.in, \n                              constants = my.constants,\n                              data = my.data,              \n                              inits = initial.values,\n                              monitors = parameters.to.save,\n                              niter = n.iter,\n                              nburnin = n.burnin, \n                              nchains = n.chains)\nMCMCsummary(mcmc.phi.age.in, round = 2)##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p        0.89 0.03 0.83 0.90  0.94 1.00   402\n## phi1     0.56 0.03 0.49 0.55  0.63 1.01   689\n## phi1plus 0.57 0.04 0.50 0.57  0.64 1.00   309\nage <- matrix(NA, nrow = nrow(y), ncol = ncol(y) - 1)\nfor (i in 1:nrow(age)){\n  for (j in 1:ncol(age)){\n    if (j == first[i]) age[i,j] <- 1 # age = 1\n    if (j > first[i]) age[i,j] <- 2  # age > 1\n  }\n}\nhmm.phiage.out <- nimbleCode({\n  p ~ dunif(0, 1) # prior detection\n  omega[1,1] <- 1 - p    # Pr(alive t -> non-detected t)\n  omega[1,2] <- p        # Pr(alive t -> detected t)\n  omega[2,1] <- 1        # Pr(dead t -> non-detected t)\n  omega[2,2] <- 0        # Pr(dead t -> detected t)\n  for (i in 1:N){\n    for (t in first[i]:(T-1)){\n    phi[i,t] <- beta[age[i,t]] # beta1 = phi1, beta2 = phi1+\n    gamma[1,1,i,t] <- phi[i,t]      # Pr(alive t -> alive t+1)\n    gamma[1,2,i,t] <- 1 - phi[i,t]  # Pr(alive t -> dead t+1)\n    gamma[2,1,i,t] <- 0           # Pr(dead t -> alive t+1)\n    gamma[2,2,i,t] <- 1           # Pr(dead t -> dead t+1)\n    }\n  }\n  beta[1] ~ dunif(0, 1) # phi1\n  beta[2] ~ dunif(0, 1) # phi1+\n  phi1 <- beta[1]\n  phi1plus <- beta[2]\n  delta[1] <- 1          # Pr(alive t = 1) = 1\n  delta[2] <- 0          # Pr(dead t = 1) = 0\n  # likelihood\n  for (i in 1:N){\n    z[i,first[i]] ~ dcat(delta[1:2])\n    for (j in (first[i]+1):T){\n      z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, i, j-1])\n      y[i,j] ~ dcat(omega[z[i,j], 1:2])\n    }\n  }\n})\nfirst <- apply(y, 1, function(x) min(which(x !=0)))\nmy.constants <- list(N = nrow(y), \n                     T = ncol(y), \n                     first = first,\n                     age = age)\nzinits <- y\nzinits[zinits == 0] <- 1\ninitial.values <- function() list(beta = runif(2,0,1),\n                                  p = runif(1,0,1),\n                                  z = zinits)\nmcmc.phi.age.out <- nimbleMCMC(code = hmm.phiage.out, \n                               constants = my.constants,\n                               data = my.data,              \n                               inits = initial.values,\n                               monitors = parameters.to.save,\n                               niter = n.iter,\n                               nburnin = n.burnin, \n                               nchains = n.chains)\nMCMCsummary(mcmc.phi.age.out, round = 2)##          mean   sd 2.5%  50% 97.5% Rhat n.eff\n## p        0.90 0.03 0.84 0.90  0.95 1.02   438\n## phi1     0.55 0.03 0.48 0.55  0.62 1.00   878\n## phi1plus 0.57 0.04 0.50 0.57  0.64 1.02  1048"},{"path":"survival.html","id":"summary-3","chapter":"4 Survival","heading":"4.9 Summary","text":"CJS model HMM time-varying parameters account variation due environmental conditions survival sampling effort detection.CJS model HMM time-varying parameters account variation due environmental conditions survival sampling effort detection.Covariates can considered try explain temporal /individual variation survival detection probabilities. needed, random effects can added cope unexplained variation.Covariates can considered try explain temporal /individual variation survival detection probabilities. needed, random effects can added cope unexplained variation.model comparison, WAIC can used evaluate relative predictive performance capture-recapture models.model comparison, WAIC can used evaluate relative predictive performance capture-recapture models.Statistical models rely assumptions, CJS model makes exception. procedures assess goodness fit CJS model capture-recapture data.Statistical models rely assumptions, CJS model makes exception. procedures assess goodness fit CJS model capture-recapture data.","code":""},{"path":"survival.html","id":"suggested-reading-3","chapter":"4 Survival","heading":"4.10 Suggested reading","text":"Buckland (2016) provides historical perspective CJS model anecdotes. monography Lebreton et al. (1992) must-read better understand CJS model applications. HMM formulation CJS model proposed Gimenez et al. (2007) Royle (2008).Buckland (2016) provides historical perspective CJS model anecdotes. monography Lebreton et al. (1992) must-read better understand CJS model applications. HMM formulation CJS model proposed Gimenez et al. (2007) Royle (2008).Gimenez et al. (2009) deals parameter redundandy capture-recapture models Bayesian framework. exhaustive treatment, see Cole’s excellent book.Gimenez et al. (2009) deals parameter redundandy capture-recapture models Bayesian framework. exhaustive treatment, see Cole’s excellent book.Relative model comparison, warmly recommend McElreath’s book better understand WAIC (video well, see https://www.youtube.com/watch?v=vSjL2Zc-gEQ). paper Gelman et al. 2014 also much helpful.Relative model comparison, warmly recommend McElreath’s book better understand WAIC (video well, see https://www.youtube.com/watch?v=vSjL2Zc-gEQ). paper Gelman et al. 2014 also much helpful.posterior predictive checks, may check Conn et al. 2018. R2ucare package introduced Gimenez et al. 2018.posterior predictive checks, may check Conn et al. 2018. R2ucare package introduced Gimenez et al. 2018.Temporal heterogeneity addressed papers Grosbois et al. 2008 Frederiksen et al. 2014, individual heterogeneity reviewed Gimenez et al. 2018.Temporal heterogeneity addressed papers Grosbois et al. 2008 Frederiksen et al. 2014, individual heterogeneity reviewed Gimenez et al. 2018.","code":""},{"path":"dispersal.html","id":"dispersal","chapter":"5 Movements between sites, and states","heading":"5 Movements between sites, and states","text":"WORK PROGRESS.","code":""},{"path":"dispersal.html","id":"introduction-6","chapter":"5 Movements between sites, and states","heading":"5.1 Introduction","text":"Blabla.Thank Canada!","code":"\nknitr::include_graphics(\"images/arnason1973.png\")\nknitr::include_graphics(\"images/schwarz1993.png\")\nknitr::include_graphics(\"images/deadpool.gif\")\nknitr::include_graphics(\"images/nichols.png\")"},{"path":"dispersal.html","id":"wintering-site-fidelity-in-canada-geese","chapter":"5 Movements between sites, and states","heading":"5.2 Wintering site fidelity in Canada Geese","text":"","code":""},{"path":"dispersal.html","id":"sites-carolinas-chesapeake-mid-atlantic","chapter":"5 Movements between sites, and states","heading":"5.2.1 3 sites Carolinas, Chesapeake, Mid-Atlantic,","text":"21277 banded geese, data kindly provided Jay Hestbeck (Hestbeck et al. 1991)(large areas along East coast US)","code":""},{"path":"dispersal.html","id":"biological-inference","chapter":"5 Movements between sites, and states","heading":"5.2.2 Biological inference","text":"Observations states closely related, entirely.","code":""},{"path":"dispersal.html","id":"the-model-construction-how-we-should-think.","chapter":"5 Movements between sites, and states","heading":"5.2.3 The model construction: How we should think.","text":"Generative model. States generate observations.","code":""},{"path":"dispersal.html","id":"the-model-construction-how-we-should-think.-1","chapter":"5 Movements between sites, and states","heading":"5.2.4 The model construction: How we should think.","text":"","code":""},{"path":"dispersal.html","id":"the-model-construction-how-we-should-think.-2","chapter":"5 Movements between sites, and states","heading":"5.2.5 The model construction: How we should think.","text":"","code":""},{"path":"dispersal.html","id":"the-model-construction-how-we-should-think.-3","chapter":"5 Movements between sites, and states","heading":"5.2.6 The model construction: How we should think.","text":"","code":""},{"path":"dispersal.html","id":"hmm-model-for-dispersal-with-2-sites-drop-carolinas","chapter":"5 Movements between sites, and states","heading":"5.2.7 HMM model for dispersal with 2 sites (drop Carolinas)","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_{t}=& z_{t}=B & z_{t}=D \\\\ \\hdashline\n\\phi_A (1-\\psi_{AB}) & \\phi_A \\psi_{AB} & 1 - \\phi_A\\\\\n\\phi_B \\psi_{BA} & \\phi_B (1-\\psi_{BA}) & 1 - \\phi_B\\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=\\\\ z_{t-1}=B \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"dispersal.html","id":"hmm-model-for-dispersal-with-2-sites-drop-carolinas-1","chapter":"5 Movements between sites, and states","heading":"5.2.8 HMM model for dispersal with 2 sites (drop Carolinas)","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_A & p_A & 0\\\\\n1 - p_B & 0 & p_B\\\\\n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\\\ z_{t}=B \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"dispersal.html","id":"hmm-model-for-dispersal-with-2-sites-drop-carolinas-2","chapter":"5 Movements between sites, and states","heading":"5.2.9 HMM model for dispersal with 2 sites (drop Carolinas)","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_A & p_A & 0\\\\\n1 - p_B & 0 & p_B\\\\\n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=\\\\ z_{t}=B \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]Note: may code non-detections \\(y_t = 2\\), first column observation matrix go last.Quick answer -1 important issue coding states obs. purpose, folks think difference observations states (non-detection obs confused state dead). becomes even crucial get multievent models several observations may generated single state. get intuition argument perfectly, ’d like fight first, ’re comfortable difference, may code obs/states see fit. Let’s see goes. agree mention multistate lecture, spirit « ’re free code states jobs way like ». ’ll add something.","code":""},{"path":"dispersal.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b","chapter":"5 Movements between sites, and states","heading":"5.2.10 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"multisite <- nimbleCode({\n  # -------------------------------------------------\n  # Parameters:\n  # phiA: survival probability site A\n  # phiB: survival probability site B\n  # psiAB: movement probability from site A to site B\n  # psiBA: movement probability from site B to site A\n  # pA: recapture probability site A\n  # pB: recapture probability site B\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive at A\n  # 2 alive at B\n  # 3 dead\n  # Observations (y):\n  # 1 not seen\n  # 2 seen at A\n  # 3 seen at B\n  # -------------------------------------------------\n..."},{"path":"dispersal.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-1","chapter":"5 Movements between sites, and states","heading":"5.2.11 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"multisite <- nimbleCode({\n...\n  # Priors\n  phiA ~ dunif(0, 1)\n  phiB ~ dunif(0, 1)\n  psiAB ~ dunif(0, 1)\n  psiBA ~ dunif(0, 1)\n  pA ~ dunif(0, 1)\n  pB ~ dunif(0, 1)\n..."},{"path":"dispersal.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-2","chapter":"5 Movements between sites, and states","heading":"5.2.12 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"Actually, initial state known exactly. alive site initial capture, \\(\\pi_A\\) just proportion individuals first captured site , need estimate .Instead z[,first[]] ~ dcat(delta[1:3]), use z[,first[]] <- y[,first[]]-1 instead likelihood.trick applies CJS models.","code":"multisite <- nimbleCode({\n...\n  # initial state probabilities\n  delta[1] <- piA          # Pr(alive in A t = 1)\n  delta[2] <- 1 - piA      # Pr(alive in B t = 1)\n  delta[3] <- 0            # Pr(dead t = 1) = 0\n..."},{"path":"dispersal.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-3","chapter":"5 Movements between sites, and states","heading":"5.2.13 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"multisite <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  # (read as gamma[z(t),z(t+1)] = gamma[fromState,toState])\n\n  gamma[1,1] <- phiA * (1 - psiAB)\n  gamma[1,2] <- phiA * psiAB\n  gamma[1,3] <- 1 - phiA\n  gamma[2,1] <- phiB * psiBA\n  gamma[2,2] <- phiB * (1 - psiBA)\n  gamma[2,3] <- 1 - phiB\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n..."},{"path":"dispersal.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-4","chapter":"5 Movements between sites, and states","heading":"5.2.14 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"multisite <- nimbleCode({\n...\n  # probabilities of y(t) given z(t)\n  # (read as omega[y(t),z(t)] = omega[Observation,State])\n\n  omega[1,1] <- 1 - pA     # Pr(alive A t -> non-detected t)\n  omega[1,2] <- pA         # Pr(alive A t -> detected A t)\n  omega[1,3] <- 0          # Pr(alive A t -> detected B t)\n  omega[2,1] <- 1 - pB     # Pr(alive B t -> non-detected t)\n  omega[2,2] <- 0          # Pr(alive B t -> detected A t)\n  omega[2,3] <- pB         # Pr(alive B t -> detected B t)\n  omega[3,1] <- 1          # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0          # Pr(dead t -> detected A t)\n  omega[3,3] <- 0          # Pr(dead t -> detected B t)\n..."},{"path":"dispersal.html","id":"our-model-phi_a-phi_b-psi_ab-psi_ba-p_a-p_b-5","chapter":"5 Movements between sites, and states","heading":"5.2.15 Our model \\((\\phi_A, \\phi_B, \\psi_{AB}, \\psi_{BA}, p_A, p_B)\\)","text":"","code":"\nmultisite <- nimbleCode({\n...\n  # likelihood\n  for (i in 1:N){\n    # latent state at first capture\n    z[i,first[i]] <- y[i,first[i]] - 1\n    for (t in (first[i]+1):K){\n      # z(t) given z(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # y(t) given z(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:3])\n    }\n  }\n})##       mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pA    0.53 0.09 0.36 0.52  0.73 1.04   122\n## pB    0.40 0.04 0.32 0.40  0.48 1.07   165\n## phiA  0.60 0.05 0.50 0.60  0.71 1.01   195\n## phiB  0.69 0.04 0.62 0.69  0.76 1.04   199\n## psiAB 0.27 0.06 0.16 0.26  0.40 1.04   244\n## psiBA 0.07 0.02 0.04 0.07  0.12 1.03   360"},{"path":"dispersal.html","id":"what-if-there-are-three-sites","chapter":"5 Movements between sites, and states","heading":"5.3 What if there are three sites?","text":"transition probabilities still need 0 1.Another constraint sum three probabilities departure given site one.Two methods fulfill constraints. Dirichlet prior multinomial logit link.Dirichlet prior parameter alpha\nFigure 5.1: Dirichlet prior parameter alpha\n","code":""},{"path":"dispersal.html","id":"nimble-implementation-of-the-dirichlet-prior","chapter":"5 Movements between sites, and states","heading":"5.3.1 Nimble implementation of the Dirichlet prior","text":"","code":"multisite <- nimbleCode({\n...\n  # transitions: Dirichlet priors\n  psiA[1:3] ~ ddirch(alpha[1:3]) # psiAA, psiAB, psiAC\n  psiB[1:3] ~ ddirch(alpha[1:3]) # psiBA, psiBB, psiCC\n  psiC[1:3] ~ ddirch(alpha[1:3]) # psiCA, psiCB, psiCC\n..."},{"path":"dispersal.html","id":"nimble-implementation-of-the-dirichlet-prior-1","chapter":"5 Movements between sites, and states","heading":"5.3.2 Nimble implementation of the Dirichlet prior","text":"","code":"multisite <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiA * psiA[1]\n  gamma[1,2] <- phiA * psiA[2]\n  gamma[1,3] <- phiA * psiA[3]\n  gamma[1,4] <- 1 - phiA\n  gamma[2,1] <- phiB * psiB[1]\n  gamma[2,2] <- phiB * psiB[2]\n  gamma[2,3] <- phiB * psiB[3]\n  gamma[2,4] <- 1 - phiB\n  gamma[3,1] <- phiC * psiC[1]\n  gamma[3,2] <- phiC * psiC[2]\n  gamma[3,3] <- phiC * psiC[3]\n  gamma[3,4] <- 1 - phiC\n  gamma[4,1] <- 0\n  gamma[4,2] <- 0\n  gamma[4,3] <- 0\n  gamma[4,4] <- 1\n...##         mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pA      0.50 0.09 0.34 0.50  0.70 1.00   153\n## pB      0.47 0.05 0.38 0.46  0.58 1.01   152\n## pC      0.24 0.06 0.14 0.23  0.37 1.01   117\n## phiA    0.61 0.05 0.50 0.61  0.71 1.00   230\n## phiB    0.70 0.04 0.62 0.70  0.77 1.04   183\n## phiC    0.77 0.07 0.64 0.77  0.92 1.07   104\n## psiA[1] 0.75 0.05 0.63 0.75  0.84 1.01   463\n## psiA[2] 0.23 0.05 0.14 0.22  0.34 1.01   441\n## psiA[3] 0.02 0.02 0.00 0.02  0.08 1.03   201\n## psiB[1] 0.07 0.02 0.04 0.07  0.12 1.00   275\n## psiB[2] 0.83 0.04 0.72 0.83  0.90 1.04   129\n## psiB[3] 0.10 0.04 0.04 0.09  0.18 1.06   129\n## psiC[1] 0.02 0.01 0.00 0.02  0.06 1.00   624\n## psiC[2] 0.21 0.05 0.12 0.21  0.33 1.02   420\n## psiC[3] 0.77 0.06 0.64 0.77  0.86 1.02   419"},{"path":"dispersal.html","id":"multinomial-logit","chapter":"5 Movements between sites, and states","heading":"5.3.3 Multinomial logit","text":"Say \\(P\\) sites states.Specify normal prior distribution \\(P-1\\) transition parameters \\(\\alpha_j\\). probabilities multinomial logit scale, possibly function covariates.back-transform parameters, use:\\[\\beta_j = \\displaystyle{\\frac{\\exp(\\alpha_j)}{1+\\displaystyle{\\sum_{p=1}^P{\\exp(\\alpha_p)}}}}, j = 1,\\ldots,P-1\\]ensures \\(\\beta_j\\) 0 1, sum 1.Last parameter calculated complement \\(\\beta_P = 1 - \\displaystyle{\\sum_{j=1}^{P-1}{\\exp(\\beta_j)}}\\)","code":""},{"path":"dispersal.html","id":"nimble-implementation-of-the-dirichlet-prior-2","chapter":"5 Movements between sites, and states","heading":"5.3.4 Nimble implementation of the Dirichlet prior","text":"","code":"multisite <- nimbleCode({\n...\n  # transitions: multinomial logit\n  # normal priors on logit of all but one transition probs\n  for (i in 1:2){\n    lpsiA[i] ~ dnorm(0, sd = 1000)\n    lpsiB[i] ~ dnorm(0, sd = 1000)\n    lpsiC[i] ~ dnorm(0, sd = 1000)\n  }\n  # constrain the transitions such that their sum is < 1\n  for (i in 1:2){\n    psiA[i] <- exp(lpsiA[i]) / (1 + exp(lpsiA[1]) + exp(lpsiA[2]))\n    psiB[i] <- exp(lpsiB[i]) / (1 + exp(lpsiB[1]) + exp(lpsiB[2]))\n    psiC[i] <- exp(lpsiC[i]) / (1 + exp(lpsiC[1]) + exp(lpsiC[2]))\n  }\n  # last transition probability\n  psiA[3] <- 1 - psiA[1] - psiA[2]\n  psiB[3] <- 1 - psiB[1] - psiB[2]\n  psiC[3] <- 1 - psiC[1] - psiC[2]\n..."},{"path":"dispersal.html","id":"nimble-implementation-of-the-dirichlet-prior-3","chapter":"5 Movements between sites, and states","heading":"5.3.5 Nimble implementation of the Dirichlet prior","text":"","code":"multisite <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiA * psiA[1]\n  gamma[1,2] <- phiA * psiA[2]\n  gamma[1,3] <- phiA * psiA[3]\n  gamma[1,4] <- 1 - phiA\n  gamma[2,1] <- phiB * psiB[1]\n  gamma[2,2] <- phiB * psiB[2]\n  gamma[2,3] <- phiB * psiB[3]\n  gamma[2,4] <- 1 - phiB\n  gamma[3,1] <- phiC * psiC[1]\n  gamma[3,2] <- phiC * psiC[2]\n  gamma[3,3] <- phiC * psiC[3]\n  gamma[3,4] <- 1 - phiC\n  gamma[4,1] <- 0\n  gamma[4,2] <- 0\n  gamma[4,3] <- 0\n  gamma[4,4] <- 1\n...##         mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pA      0.52 0.08 0.36 0.52  0.69 1.02   154\n## pB      0.45 0.05 0.35 0.44  0.55 1.10   129\n## pC      0.26 0.06 0.15 0.25  0.39 1.01    94\n## phiA    0.60 0.05 0.50 0.60  0.71 1.01   244\n## phiB    0.70 0.04 0.63 0.70  0.77 1.11   168\n## phiC    0.76 0.07 0.63 0.76  0.88 1.03   126\n## psiA[1] 0.76 0.05 0.64 0.76  0.85 1.02   477\n## psiA[2] 0.24 0.05 0.15 0.24  0.36 1.01   486\n## psiA[3] 0.00 0.00 0.00 0.00  0.00 1.35    47\n## psiB[1] 0.07 0.02 0.04 0.06  0.11 1.03   394\n## psiB[2] 0.85 0.04 0.77 0.86  0.91 1.04   133\n## psiB[3] 0.08 0.03 0.04 0.08  0.16 1.01    79\n## psiC[1] 0.01 0.01 0.00 0.01  0.04 1.00   514\n## psiC[2] 0.21 0.05 0.12 0.21  0.33 1.00   299\n## psiC[3] 0.78 0.06 0.65 0.78  0.88 1.00   270"},{"path":"dispersal.html","id":"sites-may-be-states.","chapter":"5 Movements between sites, and states","heading":"5.4 Sites may be states.","text":"","code":""},{"path":"dispersal.html","id":"examples-of-multistate-models","chapter":"5 Movements between sites, and states","heading":"5.5 Examples of multistate models","text":"Epidemiological disease states: sick/healthy, uninfected/infected/recovered.Epidemiological disease states: sick/healthy, uninfected/infected/recovered.Morphological states: small/medium/big, light/medium/heavy.Morphological states: small/medium/big, light/medium/heavy.Breeding states: e.g. breeder/non-breeder, failed breeder, first-time breeder.Breeding states: e.g. breeder/non-breeder, failed breeder, first-time breeder.Developmental life-history states: e.g. juvenile/subadult/adult.Developmental life-history states: e.g. juvenile/subadult/adult.Social states: e.g. solitary/group-living, subordinate/dominant.Social states: e.g. solitary/group-living, subordinate/dominant.Death states: e.g. alive, dead harvest, dead natural causes.Death states: e.g. alive, dead harvest, dead natural causes.States = individual, time-specific categorical covariates.","code":"\nknitr::include_graphics(\"images/sooty.jpg\")"},{"path":"dispersal.html","id":"sooty-shearwater-david-boyle","chapter":"5 Movements between sites, and states","heading":"5.5.1 Sooty shearwater (David Boyle)","text":"","code":""},{"path":"dispersal.html","id":"sooty-shearwaters-and-life-history-tradeoffs","chapter":"5 Movements between sites, and states","heading":"5.6 Sooty shearwaters and life-history tradeoffs","text":"consider data collected 1940 1957 Lance Richdale Sooty shearwaters (aka titis).data reanalyzed multistate models Scofield et al. (2001) kindly provided us data.Following way data collected, four states originally considered: Alive breeder; Accompanied another bird burrow; Alone burrow; surface; Dead.","code":""},{"path":"dispersal.html","id":"sooty-shearwaters-and-life-history-tradeoffs-1","chapter":"5 Movements between sites, and states","heading":"5.7 Sooty shearwaters and life-history tradeoffs","text":"numerical issues, pooled alive states breeder together non-breeder state (NB) includes:failed breeders (birds bred previously – skip reproduction divorce) pre-breeders (birds yet breed).failed breeders (birds bred previously – skip reproduction divorce) pre-breeders (birds yet breed).Note burrows checked hatching, birds category NB might already failed.Note burrows checked hatching, birds category NB might already failed.therefore regard birds B state successful breeders, NB state nonbreeders plus prebreeders failed breeders.therefore regard birds B state successful breeders, NB state nonbreeders plus prebreeders failed breeders.Observations non-detections, detections breeder non-breederDoes breeding affect survival? breeding current year affect breeding next year?","code":""},{"path":"dispersal.html","id":"hmm-model-for-transition-between-states","chapter":"5 Movements between sites, and states","heading":"5.7.1 HMM model for transition between states","text":"Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=B & z_t=NB & z_t=D \\\\ \\hdashline\n\\phi_B (1-\\psi_{BNB}) & \\phi_B \\psi_{BNB} & 1 - \\phi_B\\\\\n\\phi_{NB} \\psi_{NBB} & \\phi_{NB} (1-\\psi_{NBB}) & 1 - \\phi_{NB}\\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=B \\\\ z_{t-1}=NB \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]Costs reproduction reflect future reproduction \\(\\psi_{BB} = 1 - \\psi_{BNB} < \\psi_{NBB}\\) survival \\(\\phi_B < \\phi_{NB}\\).","code":""},{"path":"dispersal.html","id":"hmm-model-for-transition-between-states-1","chapter":"5 Movements between sites, and states","heading":"5.7.2 HMM model for transition between states","text":"Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 \\\\ \\hdashline\n1 - p_B & p_B & 0\\\\\n1 - p_{NB} & 0 & p_{NB}\\\\\n1 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=B \\\\ z_{t}=NB \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]","code":""},{"path":"dispersal.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b","chapter":"5 Movements between sites, and states","heading":"5.7.3 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"","code":"multistate <- nimbleCode({\n  # -------------------------------------------------\n  # Parameters:\n  # phiB: survival probability state B\n  # phiNB: survival probability state NB\n  # psiBNB: transition probability from B to NB\n  # psiNBB: transition probability from NB to B\n  # pB: recapture probability B\n  # pNB: recapture probability NB\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive B\n  # 2 alive NB\n  # 3 dead\n  # Observations (y):\n  # 1 not seen\n  # 2 seen as B\n  # 3 seen as NB\n  # -------------------------------------------------\n..."},{"path":"dispersal.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-1","chapter":"5 Movements between sites, and states","heading":"5.7.4 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"","code":"multistate <- nimbleCode({\n...\n  # Priors\n  phiB ~ dunif(0, 1)\n  phiNB ~ dunif(0, 1)\n  psiBNB ~ dunif(0, 1)\n  psiNBB ~ dunif(0, 1)\n  pB ~ dunif(0, 1)\n  pNB ~ dunif(0, 1)\n..."},{"path":"dispersal.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-2","chapter":"5 Movements between sites, and states","heading":"5.7.5 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"","code":"multistate <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiB * (1 - psiBNB)\n  gamma[1,2] <- phiB * psiBNB\n  gamma[1,3] <- 1 - phiB\n  gamma[2,1] <- phiNB * psiNBB\n  gamma[2,2] <- phiNB * (1 - psiNBB)\n  gamma[2,3] <- 1 - phiNB\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n..."},{"path":"dispersal.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-3","chapter":"5 Movements between sites, and states","heading":"5.7.6 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"","code":"multistate <- nimbleCode({\n...\n  # probabilities of y(t) given z(t)\n  omega[1,1] <- 1 - pB    # Pr(alive B t -> non-detected t)\n  omega[1,2] <- pB        # Pr(alive B t -> detected B t)\n  omega[1,3] <- 0         # Pr(alive B t -> detected NB t)\n  omega[2,1] <- 1 - pNB   # Pr(alive NB t -> non-detected t)\n  omega[2,2] <- 0         # Pr(alive NB t -> detected B t)\n  omega[2,3] <- pNB       # Pr(alive NB t -> detected NB t)\n  omega[3,1] <- 1         # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0         # Pr(dead t -> detected N t)\n  omega[3,3] <- 0         # Pr(dead t -> detected NB t)\n..."},{"path":"dispersal.html","id":"our-model-phi_nb-phi_b-psi_nbb-psi_bnb-p_nb-p_b-4","chapter":"5 Movements between sites, and states","heading":"5.7.7 Our model \\((\\phi_{NB}, \\phi_B, \\psi_{NBB}, \\psi_{BNB}, p_{NB}, p_B)\\)","text":"\nFigure 5.2: Dirichlet prior parameter alpha\n","code":"\nmultistate <- nimbleCode({\n...\n  # likelihood\n  for (i in 1:N){\n    # latent state at first capture\n    z[i,first[i]] <- y[i,first[i]] - 1\n    for (t in (first[i]+1):K){\n      # z(t) given z(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # y(t) given z(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:3])\n    }\n  }\n})##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## pB     0.60 0.03 0.54 0.59  0.66 1.00   202\n## pNB    0.57 0.03 0.51 0.57  0.62 1.01   281\n## phiB   0.80 0.02 0.77 0.80  0.83 1.01   313\n## phiNB  0.85 0.02 0.82 0.85  0.88 1.00   404\n## psiBNB 0.25 0.02 0.21 0.25  0.30 1.00   434\n## psiNBB 0.24 0.02 0.20 0.24  0.29 1.03   478"},{"path":"dispersal.html","id":"issue-of-local-minima","chapter":"5 Movements between sites, and states","heading":"5.8 Issue of local minima","text":"Simulated data: 2 sites states, 7 occasions, Survival \\(\\phi = 1\\), detection \\(p = 0.6\\), Transition \\(\\psi_{12} = 0.6\\), Transition \\(\\psi_{21} = 0.85\\).Courtesy Jérôme Dupuis, used Gimenez et al. (2005).","code":""},{"path":"dispersal.html","id":"data","chapter":"5 Movements between sites, and states","heading":"5.8.1 Data","text":"","code":"\nknitr::include_graphics(\"images/multistate_local_minimav2_Page_05.png\")\nknitr::include_graphics(\"images/multistate_local_minimav2_Page_06.png\")\nknitr::include_graphics(\"images/multistate_local_minimav2_Page_07.png\")"},{"path":"dispersal.html","id":"uncertainty","chapter":"5 Movements between sites, and states","heading":"5.9 Uncertainty","text":"’re going talk multievent models. Multievent models extend multistate models uncertainty state assignment. Let’s see examples fix ideas. examples published papers used multievent models.Breeding status female roe deer ascertained based fawn detectionBreeding status female roe deer ascertained based fawn detectionSex status ascertained based morphological criteria Audouin’s gullsSex status ascertained based morphological criteria Audouin’s gullsDisease status house finches ascertained based birds’ eyes examinationDisease status house finches ascertained based birds’ eyes examinationHybrid status wolves ascertained based geneticsHybrid status wolves ascertained based geneticsDominance status wolves ascertained based heterogeneity detectionDominance status wolves ascertained based heterogeneity detectionThe common thing examples . need explicitly consider state assignment model. HMMs rescue! , ’ll use HMMs !ExamplesTesting life-history trade-offs accounting uncertainty breeding statusTesting life-history trade-offs accounting uncertainty breeding statusQuantifying disease dynamics accounting uncertainty disease statusQuantifying disease dynamics accounting uncertainty disease statusEstimating survival accounting individual heterogeneity detectionEstimating survival accounting individual heterogeneity detectionIn module, ’ll go 3 examples.module, ’ll go 3 examples.Testing life-history trade-offs accounting uncertainty breeding status.Testing life-history trade-offs accounting uncertainty breeding status.Quantifying disease dynamics accounting uncertainty disease status.Quantifying disease dynamics accounting uncertainty disease status.Estimating survival accounting individual heterogeneity detection.Estimating survival accounting individual heterogeneity detection.Testing life-history trade-offs accounting uncertainty breeding statusTesting life-history trade-offs accounting uncertainty breeding statusQuantifying disease dynamics accounting uncertainty disease statusQuantifying disease dynamics accounting uncertainty disease statusEstimating survival accounting individual heterogeneity detectionEstimating survival accounting individual heterogeneity detection","code":"\nknitr::include_graphics(\"images/sooty.jpg\")"},{"path":"dispersal.html","id":"uncertainty-in-breeding-status-sooty-shearwater-david-boyle","chapter":"5 Movements between sites, and states","heading":"5.9.1 Uncertainty in breeding status: Sooty shearwater (David Boyle)","text":"Ingredients3 states\nbreeding (B)\nnon-breeding (NB)\ndead (D)\nbreeding (B)non-breeding (NB)dead (D)4 observations\nencountered (0)\nfound, ascertained breeder (1)\nfound, ascertained non-breeder (2)\nfound, status unknown (3)\nencountered (0)found, ascertained breeder (1)found, ascertained non-breeder (2)found, status unknown (3)still 3 states, breeding, non-breeding dead.regard observations, bird may encountered.may also encountered, contrast multistate CR data, don’t know state sure.may found ascertained classified breeder.may found ascertained classified non-breeder.may found unable determine whether ’s breeding non-breeding.states generate observationsNow states generate observations?wrap live state can generate 3 observations. deterministic link dead state observation non-encountered. Cause ’re dead, detected sure.","code":""},{"path":"dispersal.html","id":"hmm-model-for-breeding-states-with-uncertainty","chapter":"5 Movements between sites, and states","heading":"5.9.2 HMM model for breeding states with uncertainty","text":"Vector initial state probabilities\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\delta} =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=B & z_t=NB & z_t=D \\\\ \\hdashline\n\\pi_B & 1 - \\pi_{B} & 0\\\\\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\pi_B\\) probability newly encountered individual breeder. \\(\\pi_{NB} = 1 - \\pi_B\\) probability newly encountered individual non-breederOK now let’s specify model. First thing need, ’s big difference multistate models, need initial state probabilities cause assign states individuals w/ certainty. Let’s define pi_B prob newly encountered individual breeding individual. write prob state first encounter. pi_B, prob NB complementary. prob dead first encounter 0 course.Transition matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Gamma} =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    z_t=B & z_t=NB & z_t=D \\\\ \\hdashline\n\\phi_B (1-\\psi_{BNB}) & \\phi_B \\psi_{BNB} & 1 - \\phi_B\\\\\n\\phi_{NB} \\psi_{NBB} & \\phi_{NB} (1-\\psi_{NBB}) & 1 - \\phi_{NB}\\\\\n0 & 0 & 1\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t-1}=B \\\\ z_{t-1}=NB \\\\ z_{t-1}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\phi_B\\) breeder survival, \\(\\phi_{NB}\\) non-breeders. \\(\\psi_{BNB}\\) probability individual breeding year non-breeder next year. \\(\\psi_{NBB}\\) probability non-breeder individual breeder next year. transition parameters matrix similar one used multistate models.Observation matrix\\[\n\\begin{matrix}\n& \\\\\n\\mathbf{\\Omega} =\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 & y_t=3\\\\ \\hdashline\n1 - p_B & p_B \\beta_B & 0 & p_B (1-\\beta_B) \\\\\n1-p_{NB} & 0 & p_{NB} \\beta_{NB} & p_{NB} (1-\\beta_{NB})\\\\\n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=B \\\\ z_{t}=NB \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]\\(\\beta_B\\) probability assign individual state B state B. \\(\\beta_{NB}\\) probability assign individual state NB state NB. \\(p_B\\) detection probability breeders, \\(p_{NB}\\) non-breeders.main difference multistate multievent models , observation parameters. introduce two new parameters. \\(\\delta_B\\): prob. correctly assign indiv. state B state B, \\(\\delta_{NB}\\): prob. correctly assign indiv. state NB state NB. put everything matrix, usual. observation matrix. rows states, breeding, non-breeding dead. columns, occasion, observation, detected ascertained B,\ndetected ascertained NB, detected state unknown, detected. example, prob detected assigned state B, given ’re state B product detection prob B delta prob correctly assigning B individual state B.animals captured, \\(p_B = p_{NB} = 1\\) first encounter:\\[\n\\begin{matrix}\n& \\\\\n    \\left ( \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right .\n\\end{matrix}\n\\hspace{-1.2em}\n\\begin{matrix}\n    y_t=0 & y_t=1 & y_t=2 & y_t=3\\\\ \\hdashline\n0 & \\beta_B & 0 & (1-\\beta_B)\\\\\n0 & 0 & \\beta_{NB} & (1-\\beta_{NB})\\\\\n1 & 0 & 0 & 0\n\\end{matrix}\n\\hspace{-0.2em}\n\\begin{matrix}\n& \\\\\n\\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12\\end{matrix} } \\right )\n    \\begin{matrix}\n    z_{t}=B \\\\ z_{t}=NB \\\\ z_{t}=D\n    \\end{matrix}\n\\end{matrix}\n\\]Note: Breeding assessment unaffected. first encounter, happens step 1 encounter degenerate individuals captured. Just set p’s 1 encounter matrix. breeding assessment matrix remains unchanged.model \\((\\phi_B, \\phi_{NB}, \\psi_{BNB}, \\psi_{NBB}, p_B, p_{NB}, \\beta_B, \\beta_{NB}, \\pi)\\)","code":"multievent <- nimbleCode({\n  # -------------------------------------------------\n  # Parameters:\n  # phiB: survival probability state B\n  # phiNB: survival probability state NB\n  # psiBNB: transition probability from B to NB\n  # psiNBB: transition probability from NB to B\n  # pB: recapture probability B\n  # pNB: recapture probability NB\n  # piB prob. of being in initial state breeder\n  # betaNB prob to ascertain the breeding status of an individual encountered as non-breeder\n  # betaB prob to ascertain the breeding status of an individual encountered as breeder\n  # -------------------------------------------------\n  # States (z):\n  # 1 alive B\n  # 2 alive NB\n  # 3 dead\n  # Observations (y):\n  # 1 = non-detected\n  # 2 = seen and ascertained as breeder\n  # 3 = seen and ascertained as non-breeder\n  # 4 = not ascertained\n  # -------------------------------------------------\n...multievent <- nimbleCode({\n...\n  # Priors\n  phiB ~ dunif(0, 1)\n  phiNB ~ dunif(0, 1)\n  psiBNB ~ dunif(0, 1)\n  psiNBB ~ dunif(0, 1)\n  pB ~ dunif(0, 1)\n  pNB ~ dunif(0, 1)\n  piB ~ dunif(0, 1)\n  betaNB ~ dunif(0, 1)\n  betaB ~ dunif(0, 1)\n...multievent <- nimbleCode({\n...\n  # vector of initial stats probs\n  delta[1] <- piB # prob. of being in initial state B\n  delta[2] <- 1 - piB # prob. of being in initial state NB\n  delta[3] <- 0 # prob. of being in initial state dead\n...multievent <- nimbleCode({\n...\n  # probabilities of state z(t+1) given z(t)\n  gamma[1,1] <- phiB * (1 - psiBNB)\n  gamma[1,2] <- phiB * psiBNB\n  gamma[1,3] <- 1 - phiB\n  gamma[2,1] <- phiNB * psiNBB\n  gamma[2,2] <- phiNB * (1 - psiNBB)\n  gamma[2,3] <- 1 - phiNB\n  gamma[3,1] <- 0\n  gamma[3,2] <- 0\n  gamma[3,3] <- 1\n...multievent <- nimbleCode({\n...\n  # probabilities of y(t) given z(t)\n  omega[1,1] <- 1 - pB             # Pr(alive B t -> non-detected t)\n  omega[1,2] <- pB * betaB         # Pr(alive B t -> detected B t)\n  omega[1,3] <- 0                  # Pr(alive B t -> detected NB t)\n  omega[1,4] <- pB * (1 - betaB)   # Pr(alive B t -> detected U t)\n  omega[2,1] <- 1 - pNB            # Pr(alive NB t -> non-detected t)\n  omega[2,2] <- 0                  # Pr(alive NB t -> detected B t)\n  omega[2,3] <- pNB * betaNB       # Pr(alive NB t -> detected NB t)\n  omega[2,4] <- pNB * (1 - betaNB) # Pr(alive NB t -> detected U t)\n  omega[3,1] <- 1                  # Pr(dead t -> non-detected t)\n  omega[3,2] <- 0                  # Pr(dead t -> detected N t)\n  omega[3,3] <- 0                  # Pr(dead t -> detected NB t)\n  omega[3,4] <- 0                  # Pr(dead t -> detected U t)\n...multievent <- nimbleCode({\n...\n  # probabilities of y(first) given z(first)\n  omega.init[1,1] <- 0          # Pr(alive B t = 1 -> non-detected t = 1)\n  omega.init[1,2] <- betaB      # Pr(alive B t = 1 -> detected B t = 1)\n  omega.init[1,3] <- 0          # Pr(alive B t = 1 -> detected NB t = 1)\n  omega.init[1,4] <- 1 - betaB  # Pr(alive B t = 1 -> detected U t = 1)\n  omega.init[2,1] <- 0          # Pr(alive NB t = 1 -> non-detected t = 1)\n  omega.init[2,2] <- 0          # Pr(alive NB t = 1 -> detected B t = 1)\n  omega.init[2,3] <- betaNB     # Pr(alive NB t = 1 -> detected NB t = 1)\n  omega.init[2,4] <- 1 - betaNB # Pr(alive NB t = 1 -> detected U t = 1)\n  omega.init[3,1] <- 1          # Pr(dead t = 1 -> non-detected t = 1)\n  omega.init[3,2] <- 0          # Pr(dead t = 1 -> detected N t = 1)\n  omega.init[3,3] <- 0          # Pr(dead t = 1 -> detected NB t = 1)\n  omega.init[3,4] <- 0          # Pr(dead t = 1 -> detected U t = 1)\n...\nmultievent <- nimbleCode({\n...\n  # likelihood\n  for (i in 1:N){\n    # latent state at first capture\n    z[i,first[i]] ~ dcat(delta[1:3])\n    y[i,first[i]] ~ dcat(omega.init[z[i,first[i]],1:4])\n    for (t in (first[i]+1):K){\n      # z(t) given z(t-1)\n      z[i,t] ~ dcat(gamma[z[i,t-1],1:3])\n      # y(t) given z(t)\n      y[i,t] ~ dcat(omega[z[i,t],1:4])\n    }\n  }\n})"},{"path":"dispersal.html","id":"results","chapter":"5 Movements between sites, and states","heading":"5.9.3 Results","text":"Breeders difficult assigned correct state. Non-breeders relatively well classified non-breeders. cost breeding, neither survival, future reproduction.","code":"##        mean   sd 2.5%  50% 97.5% Rhat n.eff\n## betaB  0.19 0.01 0.16 0.19  0.21 1.01   332\n## betaNB 0.76 0.05 0.66 0.76  0.86 1.01    65\n## pB     0.56 0.03 0.51 0.56  0.62 1.06   229\n## pNB    0.60 0.04 0.53 0.60  0.67 1.03   142\n## phiB   0.81 0.02 0.78 0.81  0.85 1.01   312\n## phiNB  0.84 0.02 0.80 0.84  0.87 1.00   354\n## piB    0.71 0.03 0.66 0.71  0.76 1.02   115\n## psiBNB 0.23 0.02 0.18 0.22  0.27 1.00   214\n## psiNBB 0.25 0.04 0.17 0.25  0.34 1.00    95"},{"path":"dispersal.html","id":"summary-4","chapter":"5 Movements between sites, and states","heading":"5.10 Summary","text":"Blabla.Blabla.Blabla.Blabla.","code":""},{"path":"dispersal.html","id":"suggested-reading-4","chapter":"5 Movements between sites, and states","heading":"5.11 Suggested reading","text":"Lebreton, J.-D., J. D. Nichols, R. J. Barker, R. Pradel J. . Spendelow (2009). Modeling Individual Animal Histories Multistate Capture–Recapture Models. Advances Ecological Research, 41:87-173.Lebreton, J.-D., J. D. Nichols, R. J. Barker, R. Pradel J. . Spendelow (2009). Modeling Individual Animal Histories Multistate Capture–Recapture Models. Advances Ecological Research, 41:87-173.Seminal paper Pradel (2005) Multievent: Extension Multistate Capture–Recapture Models Uncertain States. Biometrics, 61: 442-447.Seminal paper Pradel (2005) Multievent: Extension Multistate Capture–Recapture Models Uncertain States. Biometrics, 61: 442-447.Dupuis (1995) similar idea Arnason-Schwarz model: Dupuis, J. (1995) Bayesian estimation movement survival probabilities capture-recapture data. Biometrika. Vol. 82, pp 761-772.Dupuis (1995) similar idea Arnason-Schwarz model: Dupuis, J. (1995) Bayesian estimation movement survival probabilities capture-recapture data. Biometrika. Vol. 82, pp 761-772.See also review Gimenez et al. (2012) Estimating demographic parameters using hidden process dynamic models. Theoretical Population Biology 82: 307-316.See also review Gimenez et al. (2012) Estimating demographic parameters using hidden process dynamic models. Theoretical Population Biology 82: 307-316.","code":""},{"path":"introduction-7.html","id":"introduction-7","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"introduction-8.html","id":"introduction-8","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"take-home-messages.html","id":"take-home-messages","chapter":"Take-home messages","heading":"Take-home messages","text":"–>\n –>–>–>–>","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]

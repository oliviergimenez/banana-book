<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="1.2 Bayes’ theorem | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models" />
<meta property="og:type" content="book" />

<meta property="og:description" content="This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R." />
<meta name="github-repo" content="oliviergimenez/banana-book" />

<meta name="author" content="Olivier Gimenez" />

<meta name="date" content="2022-12-23" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="This is a textbook on the analysis of capture-recapture data with hidden Markov models (HMM) implemented in the Bayesian framework with R.">

<title>1.2 Bayes’ theorem | Bayesian Analysis of Capture-Recapture Data with Hidden Markov Models</title>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#welcome" id="toc-welcome">Welcome</a>
<ul>
<li><a href="license.html#license" id="toc-license">License</a></li>
</ul></li>
<li class="has-sub"><a href="preface.html#preface" id="toc-preface">Preface</a>
<ul>
<li><a href="why-this-book.html#why-this-book" id="toc-why-this-book">Why this book?</a></li>
<li><a href="who-should-read-this-book.html#who-should-read-this-book" id="toc-who-should-read-this-book">Who should read this book?</a></li>
<li><a href="what-will-you-learn.html#what-will-you-learn" id="toc-what-will-you-learn">What will you learn?</a></li>
<li><a href="what-wont-you-learn.html#what-wont-you-learn" id="toc-what-wont-you-learn">What won’t you learn?</a></li>
<li><a href="prerequisites.html#prerequisites" id="toc-prerequisites">Prerequisites</a></li>
<li><a href="acknowledgements.html#acknowledgements" id="toc-acknowledgements">Acknowledgements</a></li>
<li><a href="how-this-book-was-written.html#how-this-book-was-written" id="toc-how-this-book-was-written">How this book was written</a></li>
</ul></li>
<li><a href="about-the-author.html#about-the-author" id="toc-about-the-author">About the author</a></li>
<li class="part"><span><b>I I. Fundations</b></span></li>
<li><a href="introduction.html#introduction" id="toc-introduction">Introduction</a></li>
<li class="has-sub"><a href="1-crashcourse.html#crashcourse" id="toc-crashcourse"><span class="toc-section-number">1</span> Bayesian statistics &amp; MCMC</a>
<ul>
<li><a href="1.1-introduction-1.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">1.1</span> Introduction</a></li>
<li><a href="1.2-bayes-theorem.html#bayes-theorem" id="toc-bayes-theorem"><span class="toc-section-number">1.2</span> Bayes’ theorem</a></li>
<li><a href="1.3-what-is-the-bayesian-approach.html#what-is-the-bayesian-approach" id="toc-what-is-the-bayesian-approach"><span class="toc-section-number">1.3</span> What is the Bayesian approach?</a></li>
<li><a href="1.4-numerical-approx.html#numerical-approx" id="toc-numerical-approx"><span class="toc-section-number">1.4</span> Approximating posteriors via numerical integration</a></li>
<li class="has-sub"><a href="1.5-markov-chain-monte-carlo-mcmc.html#markov-chain-monte-carlo-mcmc" id="toc-markov-chain-monte-carlo-mcmc"><span class="toc-section-number">1.5</span> Markov chain Monte Carlo (MCMC)</a>
<ul>
<li><a href="1.5-markov-chain-monte-carlo-mcmc.html#monte-carlo-integration" id="toc-monte-carlo-integration"><span class="toc-section-number">1.5.1</span> Monte Carlo integration</a></li>
<li><a href="1.5-markov-chain-monte-carlo-mcmc.html#markovmodelmcmc" id="toc-markovmodelmcmc"><span class="toc-section-number">1.5.2</span> Markov chains</a></li>
<li><a href="1.5-markov-chain-monte-carlo-mcmc.html#metropolis-algorithm" id="toc-metropolis-algorithm"><span class="toc-section-number">1.5.3</span> Metropolis algorithm</a></li>
</ul></li>
<li class="has-sub"><a href="1.6-convergence-diag.html#convergence-diag" id="toc-convergence-diag"><span class="toc-section-number">1.6</span> Assessing convergence</a>
<ul>
<li><a href="1.6-convergence-diag.html#burn-in" id="toc-burn-in"><span class="toc-section-number">1.6.1</span> Burn-in</a></li>
<li><a href="1.6-convergence-diag.html#chain-length" id="toc-chain-length"><span class="toc-section-number">1.6.2</span> Chain length</a></li>
<li><a href="1.6-convergence-diag.html#what-if-you-have-issues-of-convergence" id="toc-what-if-you-have-issues-of-convergence"><span class="toc-section-number">1.6.3</span> What if you have issues of convergence?</a></li>
</ul></li>
<li><a href="1.7-summary.html#summary" id="toc-summary"><span class="toc-section-number">1.7</span> Summary</a></li>
<li><a href="1.8-suggested-reading.html#suggested-reading" id="toc-suggested-reading"><span class="toc-section-number">1.8</span> Suggested reading</a></li>
</ul></li>
<li><a href="faq.html#faq" id="toc-faq">FAQ</a></li>
<li><a href="references.html#references" id="toc-references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="bayes-theorem" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Bayes’ theorem</h2>
<p>Let’s not wait any longer and jump into it. Bayesian statistics relies on the Bayes’ theorem (or law, or rule, whatever you prefer) named after Reverend Thomas Bayes (Figure <a href="1.2-bayes-theorem.html#fig:revbayes">1.1</a>). This theorem was published in 1763 two years after Bayes’ death thanks to his friend’s efforts Richard Price, and was independently discovered by Pierre-Simon Laplace <span class="citation">(<a href="#ref-mcgrayne2011" role="doc-biblioref">McGrayne 2011</a>)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:revbayes"></span>
<img src="images/amazing-thomas-bayes-illustration.jpg" alt="Cartoon of Thomas Bayes with Bayes' theorem in background. Source: [James Kulich](https://www.elmhurst.edu/blog/thomas-bayes/)" width="100%" />
<p class="caption">
Figure 1.1: Cartoon of Thomas Bayes with Bayes’ theorem in background. Source: <a href="https://www.elmhurst.edu/blog/thomas-bayes/">James Kulich</a>
</p>
</div>
<p>As we will see in a minute, Bayes’ theorem is all about conditional probabilities, which are somehow tricky to understand. Conditional probability of outcome or event A given event B, which we denote <span class="math inline">\(\Pr(A \mid B)\)</span>, is the probability that A occurs, revised by considering the additional information that event B has occurred.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> The order in which A and B appear is important, make sure you do not confuse <span class="math inline">\(\Pr(A \mid B)\)</span> and <span class="math inline">\(\Pr(B \mid A)\)</span>.</p>
<p>Bayes’ theorem (Figure <a href="1.2-bayes-theorem.html#fig:bayestheorem">1.2</a>) gives you <span class="math inline">\(\Pr(A \mid B)\)</span> using marginal probabilities <span class="math inline">\(\Pr(A)\)</span> and <span class="math inline">\(\Pr(B)\)</span> and <span class="math inline">\(\Pr(B \mid A)\)</span>:
<span class="math display">\[\Pr(A \mid B) = \displaystyle{\frac{ \Pr(B \mid A) \; \Pr(A)}{\Pr(B)}}.\]</span>
Originally, Bayes’ theorem was seen as a way to infer an unkown cause A of a particular effect B, knowing the probability of effect B given cause A. Think for example of a situation where a medical diagnosis is needed, with A an unkown disease and B symptoms, the doctor knows P(symptoms|disease) and wants to derive P(disease|symptoms). This way of reversing <span class="math inline">\(\Pr(B \mid A)\)</span> into <span class="math inline">\(\Pr(A \mid B)\)</span> explains why Bayesian thinking used to be referred to as ‘inverse probability’.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bayestheorem"></span>
<img src="images/bayes_neon.jpeg" alt="Bayes' theorem spelt out in blue neon. Source: [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)"  />
<p class="caption">
Figure 1.2: Bayes’ theorem spelt out in blue neon. Source: <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Wikipedia</a>
</p>
</div>
<p>I don’t know about you, but I need to think twice for not messing the letters around. I find it easier to remember Bayes’ theorem written like this<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>:</p>
<span class="math display">\[ \Pr(\text{hypothesis} \mid \text{data}) = \frac{ \Pr(\text{data} \mid \text{hypothesis}) \; \Pr(\text{hypothesis})}{\Pr(\text{data})} \]</span>

<div class="rmdnote">
The <em>hypothesis</em> is a working assumption about which you want to learn using <em>data</em>. In capture–recapture analyses, the hypothesis might be a parameter like detection probability, or regression parameters in a relationship between survival probability and a covariate. Bayes’ theorem tells us how to obtain the probability of a hypothesis given the data we have.
</div>
<p>This is great because think about it, this is exactly what the scientific method is! We’d like to know how plausible some hypothesis is based on some data we collected, and possibly compare several hypotheses among them. In that respect, the Bayesian reasoning matches the scientific reasoning, which probably explains why the Bayesian framework is so natural for doing and understanding statistics.</p>
<p>You might ask then, why is Bayesian statistics not the default in statistics? Clearly, because of futile wars between male statisticians (including Ronald Fisher, Jerzy Neyman and Egon Sharpe Pearson among others), little progress was made for over two centuries. Also, until recently, there were practical problems to implement Bayes’ theorem. Recent advances in computational power coupled with the development of new algorithms have led to a great increase in the application of Bayesian methods within the last three decades.</p>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-mcgrayne2011" class="csl-entry">
McGrayne, Sharon Bertsch. 2011. <em>The <span>Theory</span> <span>That</span> <span>Would</span> <span>Not</span> <span>Die</span>: <span>How</span> <span>Bayes</span>’ <span>Rule</span> <span>Cracked</span> the <span>Enigma</span> <span>Code</span>, <span>Hunted</span> <span>Down</span> <span>Russian</span> <span>Submarines</span>, and <span>Emerged</span> <span>Triumphant</span> from <span>Two</span> <span>Centuries</span> of <span>Controversy</span></em>. Yale University Press.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>For example, a friend of yours rolls a fair dice and asks you the probability that the outcome was a six (event A). Your answer is 1/6 because each side of the dice is equally likely to come up. Now imagine that you’re told the number rolled was even (event B) before you answer your friend’s question. Because there are only three even numbers, one of which is six, you may revise your answer for the probability that a six was rolled from 1/6 to <span class="math inline">\(\Pr(A \mid B) = 1/3\)</span>.<a href="1.2-bayes-theorem.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>When teaching Bayes’ theorem, I am very much inspired by Tristan Mahr’s slides from his introduction to Bayesian regression <a href="https://www.tjmahr.com/bayes-intro-lecture-slides-2017/" class="uri">https://www.tjmahr.com/bayes-intro-lecture-slides-2017/</a><a href="1.2-bayes-theorem.html#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="1.1-introduction-1.html"><button class="btn btn-default">Previous</button></a>
<a href="1.3-what-is-the-bayesian-approach.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
